{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glove_spearman.txt', 'glove_apsynp.txt', 'word2vec_kendall.txt', 'word2vec_apsyn.txt', 'word2vec_pearson.txt', 'word2vec_apsynp.txt', 'glove_avg_cosine.txt', 'word2vec_avg_cosine.txt', 'word2vec_spearman.txt', 'glove_kendall.txt', 'glove_pearson.txt', 'glove_apsyn.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "fileList = os.listdir(path)\n",
    "try:\n",
    "    fileList.remove(\"ensemble.ipynb\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    fileList.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "print(fileList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.8132708141201568', '2.\\tWhen these lines of evidence are taken together it is concluded that with medium confidence or about as likely as not that the observed oxygen decreases can be attributed in part to human influences.\\t0.8075151946132734', '3.\\tHence, with only a couple of exceptions (e.g., Hansen et al., 2012), studies have focussed on how risks have changed or how different factors have contributed to an observed event, rather than claiming that the absolute probability of occurrence of that event would have been extremely low in the absence of human influence on climate.\\t0.804574717496861', '4.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t0.8019871331903687', '5.\\tBased on this evidence, including the new 21st century observations that were not yet available to AR4, we conclude that, on the basis of constraints provided by recent observed climate change, TCR is likely to lie in the range 1°C to 2.5°C and extremely unlikely to be greater than 3°C.\\t0.7979150879454215', '6.\\tStatistical tests can be used to check that observed residual temperature fluctuations (the lengths and clustering of the pins in panel (c)) are consistent with internal variability expected from coupled models, but ultimately these tests must complement physical arguments that the combination of responses to anthropogenic and natural forcing is the only available consistent explanation of recent observed temperature change.\\t0.7971626351403904', '7.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.7965684063156256', '8.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.7926772519694664', '9.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.7916199068878542', '10.\\tEstimates of the Equilibrium Climate Sensitivity (ECS) based on multiple and partly independent lines of evidence from observed climate change indicate that there is high confidence that ECS is extremely unlikely to be less than 1°C and medium confidence that the ECS is likely to be between 1.5°C and 4.5°C and very unlikely greater than 6°C.\\t0.7901012233469261']\n",
      "['1.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t187.970719045156', '2.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t187.95869587417428', '3.\\tA further consistency check often used in optimal fingerprinting is whether the estimated magnitude of the externally driven responses are consistent between model and observations (scaling factors consistent with unity in Box 10.1): if they are not, attribution is still possible provided the discrepancy is explicable in terms of known uncertainties in the magnitude of either forcing or response.\\t187.955900431878', '4.\\tAlthough it has been suggested (Gregory, 2010) that the cooling trend from successive volcanic events is an artefact because models were not spun up with volcanic forcing, this discrepancy is not expected to be as significant in the upper ocean as in the deeper layers where longer term adjustments take place (Gregory et al., 2012 ).\\t187.94951137070768', '5.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t187.9489758796877', '6.\\tAttribution studies therefore support the conclusion that ‘it is extremely likely that human activities have caused more than half of the observed increase in global mean surface temperatures from 1951 to 2010.’\\t187.94507797924115', '7.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t187.9439203226676', '8.\\tIf a scaling factor is significantly larger than zero (at some significance level), then the response to that forcing, as simulated by that model and given that estimate of internal variability and other potentially confounding responses, is detectable in these observations, whereas if the scaling factor is consistent with unity, then that model-simulated response is consistent with observed changes.\\t187.94016346535085', '9.\\tNote that the estimate will reflect any forcings with a time or time–space pattern resembling aerosol forcing that is not explicitly included in the overall estimate (see discussion in Olson et al., 2012), for example, BC on snow; and should hence be interpreted as an estimate of aerosol plus neglected forcings.\\t187.93980578114503', '10.\\tHence, with only a couple of exceptions (e.g., Hansen et al., 2012), studies have focussed on how risks have changed or how different factors have contributed to an observed event, rather than claiming that the absolute probability of occurrence of that event would have been extremely low in the absence of human influence on climate.\\t187.93889052142157']\n",
      "['1.\\tAt present, therefore, the evidence does not support the claim that we are observing weather events that would, individually, have been extremely unlikely in the absence of human-induced climate change, although observed trends in the concurrence of large numbers of events (see Section 10.6.1) may be more easily attributable to external factors.\\t0.6504347826086957', '2.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.6480713489409142', '3.\\tAnalyses that allow for the possibility that models might be consistently over- or underestimating the magnitude of the response to climate forcings are assessed in Section 10.3.1.1.3, the conclusions from which are not affected by evidence that model spread in GMST in CMIP3, is smaller than implied by the uncertainty in RF (Schwartz et al., 2007).\\t0.6452619843924192', '4.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.6311705685618729', '5.\\tBased on this evidence, including the new 21st century observations that were not yet available to AR4, we conclude that, on the basis of constraints provided by recent observed climate change, TCR is likely to lie in the range 1°C to 2.5°C and extremely unlikely to be greater than 3°C.\\t0.6295206243032331', '6.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.6278706800445931', '7.\\tThe fact that the AMO index is estimated from detrended historical temperature observations further increases the risk that its variance may be overestimated, because regressors and regressands are not independent.\\t0.6270680044593088', '8.\\tIf observed changes are consistent with simulations that include human influence, and inconsistent with those that do not, this would be sufficient for attribution providing there were no other confounding influences and it is assumed that models are simulating the responses to all external forcings correctly.\\t0.6249275362318841', '9.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.62479375696767', '10.\\tSensitivity of results to the pattern of forcing or response can be assessed by comparing results across multiple models or by representing pattern uncertainty explicitly (Huntingford et al., 2006), but errors that are common to all models (through limited vertical resolution, for example) will not be addressed in this way and are accounted for in this assessment by downgrading overall assessed likelihoods to be generally more conservative than the quantitative likelihoods provided by individual studies.\\t0.6230546265328875']\n",
      "['1.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t5.516838478029708', '2.\\tAs is emphasized in Section 10.2.1 and Box 10.1, attribution is not a purely statistical assessment: physical judgment is required to assess whether the combination of responses considered allows for all major potential confounding factors and whether any remaining discrepancies are consistent with a physically based understanding of the responses to external forcing and internal climate variability.\\t5.498775870908026', '3.\\tHowever, this is the case only if all relevant forcings and their uncertainties are considered, reducing the risk of misattribution due to spurious correlations between external forcings, and if the data are homogeneous and statistical tests properly applied (e.g., Legras et al., 2010).\\t5.476864923523054', '4.\\tSchwartz (2007) tried to relate the ECS to the strength of natural variability using the fluctuation dissipation theorem but studies suggest that the observations are too short to support a well constrained and reliable estimate and would yield an underestimate of sensitivity (Kirk-Davidoff, 2009); and that assuming single time scales is too simplistic for the climate system (Knutti and Hegerl, 2008) .\\t5.464888834496148', '5.\\tA further consistency check often used in optimal fingerprinting is whether the estimated magnitude of the externally driven responses are consistent between model and observations (scaling factors consistent with unity in Box 10.1): if they are not, attribution is still possible provided the discrepancy is explicable in terms of known uncertainties in the magnitude of either forcing or response.\\t5.434636901624566', '6.\\tIf there is a consistent causal relationship between two or more possibly non-stationary time series, then it should be possible to find a linear combination such that the residual is stationary (contains no stochastic trend) over time (Kaufmann and Stern, 2002; Kaufmann et al., 2006; Mills, 2009).\\t5.413029916165827', '7.\\tWe conclude with high confidence in the observational and modelling evidence that the decrease in NH snow extent since the 1970s is likely to be caused by all external forcings and has an anthropogenic contribution (see Table 10.1).\\t5.4090161352410036', '8.\\tIt is very likely that there is a substantial contribution from anthropogenic forcings to the global mean sea level rise since the 1970s.\\t5.400393545843114', '9.\\tThere remains some uncertainty about how much decadal variability of GMST that is attributed to AMO in some studies is actually related to forcing, notably from aerosols.\\t5.395755652141068', '10.\\tIt is very unlikely that NH temperature variations from 1400 to 1850 can be explained by internal variability alone.\\t5.376560136875785']\n",
      "['1.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.8481621342091491', '2.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.8463401913509434', '3.\\tAnalyses that allow for the possibility that models might be consistently over- or underestimating the magnitude of the response to climate forcings are assessed in Section 10.3.1.1.3, the conclusions from which are not affected by evidence that model spread in GMST in CMIP3, is smaller than implied by the uncertainty in RF (Schwartz et al., 2007).\\t0.843732594243024', '4.\\tThe fact that the AMO index is estimated from detrended historical temperature observations further increases the risk that its variance may be overestimated, because regressors and regressands are not independent.\\t0.8434764497394772', '5.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.8377796620874857', '6.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.8361119568281838', '7.\\tAt present, therefore, the evidence does not support the claim that we are observing weather events that would, individually, have been extremely unlikely in the absence of human-induced climate change, although observed trends in the concurrence of large numbers of events (see Section 10.6.1) may be more easily attributable to external factors.\\t0.8355219044344658', '8.\\tIf a scaling factor is significantly larger than zero (at some significance level), then the response to that forcing, as simulated by that model and given that estimate of internal variability and other potentially confounding responses, is detectable in these observations, whereas if the scaling factor is consistent with unity, then that model-simulated response is consistent with observed changes.\\t0.835399741258852', '9.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t0.8319522745734393', '10.\\tIn proposing that ‘the process of attribution requires the detection of a change in the observed variable or closely associated variables’ (Hegerl et al., 2010), the new guidance recognized that it may be possible, in some instances, to attribute a change in a particular variable to some external factor before that change could actually be detected in the variable itself, provided there is a strong body of knowledge that links a change in that variable to some other variable in which a change can be detected and attributed.\\t0.8286920797245231']\n",
      "['1.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t187.95136450290852', '2.\\tAnalyses that allow for the possibility that models might be consistently over- or underestimating the magnitude of the response to climate forcings are assessed in Section 10.3.1.1.3, the conclusions from which are not affected by evidence that model spread in GMST in CMIP3, is smaller than implied by the uncertainty in RF (Schwartz et al., 2007).\\t187.9491506538922', '3.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t187.937658412917', '4.\\tIf a scaling factor is significantly larger than zero (at some significance level), then the response to that forcing, as simulated by that model and given that estimate of internal variability and other potentially confounding responses, is detectable in these observations, whereas if the scaling factor is consistent with unity, then that model-simulated response is consistent with observed changes.\\t187.93522561230392', '5.\\tThe fact that the AMO index is estimated from detrended historical temperature observations further increases the risk that its variance may be overestimated, because regressors and regressands are not independent.\\t187.93204003334816', '6.\\tA further consistency check often used in optimal fingerprinting is whether the estimated magnitude of the externally driven responses are consistent between model and observations (scaling factors consistent with unity in Box 10.1): if they are not, attribution is still possible provided the discrepancy is explicable in terms of known uncertainties in the magnitude of either forcing or response.\\t187.93191114316878', '7.\\tIf observed changes are consistent with simulations that include human influence, and inconsistent with those that do not, this would be sufficient for attribution providing there were no other confounding influences and it is assumed that models are simulating the responses to all external forcings correctly.\\t187.93004244789796', '8.\\tStatistical tests can be used to check that observed residual temperature fluctuations (the lengths and clustering of the pins in panel (c)) are consistent with internal variability expected from coupled models, but ultimately these tests must complement physical arguments that the combination of responses to anthropogenic and natural forcing is the only available consistent explanation of recent observed temperature change.\\t187.9289381545104', '9.\\tSchwartz (2007) tried to relate the ECS to the strength of natural variability using the fluctuation dissipation theorem but studies suggest that the observations are too short to support a well constrained and reliable estimate and would yield an underestimate of sensitivity (Kirk-Davidoff, 2009); and that assuming single time scales is too simplistic for the climate system (Knutti and Hegerl, 2008) .\\t187.92486768933637', '10.\\tThe regional variability on decadal and longer time scales can be quite large (and is not well quantified in currently available observations) compared to secular changes in the winds that influence sea level.\\t187.92437480033163']\n",
      "['1.\\tHence, with only a couple of exceptions (e.g., Hansen et al., 2012), studies have focussed on how risks have changed or how different factors have contributed to an observed event, rather than claiming that the absolute probability of occurrence of that event would have been extremely low in the absence of human influence on climate.\\t0.9550504311805386', '2.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t0.9545621394037268', '3.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.9543307873265716', '4.\\tAlthough it has been suggested (Gregory, 2010) that the cooling trend from successive volcanic events is an artefact because models were not spun up with volcanic forcing, this discrepancy is not expected to be as significant in the upper ocean as in the deeper layers where longer term adjustments take place (Gregory et al., 2012 ).\\t0.9540416168544249', '5.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.9530265696445711', '6.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.9530193098515714', '7.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.9527642933786649', '8.\\tWhen these lines of evidence are taken together it is concluded that with medium confidence or about as likely as not that the observed oxygen decreases can be attributed in part to human influences.\\t0.9526118168871909', '9.\\tAttribution studies therefore support the conclusion that ‘it is extremely likely that human activities have caused more than half of the observed increase in global mean surface temperatures from 1951 to 2010.’\\t0.949838167592287', '10.\\tBased on this evidence, including the new 21st century observations that were not yet available to AR4, we conclude that, on the basis of constraints provided by recent observed climate change, TCR is likely to lie in the range 1°C to 2.5°C and extremely unlikely to be greater than 3°C.\\t0.9490983400362735']\n",
      "['1.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.8480878861073444', '2.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.8463555199003805', '3.\\tThe fact that the AMO index is estimated from detrended historical temperature observations further increases the risk that its variance may be overestimated, because regressors and regressands are not independent.\\t0.8435400835813601', '4.\\tAnalyses that allow for the possibility that models might be consistently over- or underestimating the magnitude of the response to climate forcings are assessed in Section 10.3.1.1.3, the conclusions from which are not affected by evidence that model spread in GMST in CMIP3, is smaller than implied by the uncertainty in RF (Schwartz et al., 2007).\\t0.8429140326116379', '5.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.8371025170223142', '6.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.8362743050026605', '7.\\tIf a scaling factor is significantly larger than zero (at some significance level), then the response to that forcing, as simulated by that model and given that estimate of internal variability and other potentially confounding responses, is detectable in these observations, whereas if the scaling factor is consistent with unity, then that model-simulated response is consistent with observed changes.\\t0.8355692759691777', '8.\\tAt present, therefore, the evidence does not support the claim that we are observing weather events that would, individually, have been extremely unlikely in the absence of human-induced climate change, although observed trends in the concurrence of large numbers of events (see Section 10.6.1) may be more easily attributable to external factors.\\t0.8351062513009625', '9.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t0.8320524918183736', '10.\\tIn proposing that ‘the process of attribution requires the detection of a change in the observed variable or closely associated variables’ (Hegerl et al., 2010), the new guidance recognized that it may be possible, in some instances, to attribute a change in a particular variable to some external factor before that change could actually be detected in the variable itself, provided there is a strong body of knowledge that links a change in that variable to some other variable in which a change can be detected and attributed.\\t0.8288163479748883']\n",
      "['1.\\tAt present, therefore, the evidence does not support the claim that we are observing weather events that would, individually, have been extremely unlikely in the absence of human-induced climate change, although observed trends in the concurrence of large numbers of events (see Section 10.6.1) may be more easily attributable to external factors.\\t0.8413555706174513', '2.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.8375848620540229', '3.\\tAnalyses that allow for the possibility that models might be consistently over- or underestimating the magnitude of the response to climate forcings are assessed in Section 10.3.1.1.3, the conclusions from which are not affected by evidence that model spread in GMST in CMIP3, is smaller than implied by the uncertainty in RF (Schwartz et al., 2007).\\t0.8349648329425882', '4.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.8212544583828708', '5.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.821058011755686', '6.\\tBased on this evidence, including the new 21st century observations that were not yet available to AR4, we conclude that, on the basis of constraints provided by recent observed climate change, TCR is likely to lie in the range 1°C to 2.5°C and extremely unlikely to be greater than 3°C.\\t0.8208566761852908', '7.\\tIf observed changes are consistent with simulations that include human influence, and inconsistent with those that do not, this would be sufficient for attribution providing there were no other confounding influences and it is assumed that models are simulating the responses to all external forcings correctly.\\t0.8182753141701574', '8.\\tIn proposing that ‘the process of attribution requires the detection of a change in the observed variable or closely associated variables’ (Hegerl et al., 2010), the new guidance recognized that it may be possible, in some instances, to attribute a change in a particular variable to some external factor before that change could actually be detected in the variable itself, provided there is a strong body of knowledge that links a change in that variable to some other variable in which a change can be detected and attributed.\\t0.8178299758886209', '9.\\tSensitivity of results to the pattern of forcing or response can be assessed by comparing results across multiple models or by representing pattern uncertainty explicitly (Huntingford et al., 2006), but errors that are common to all models (through limited vertical resolution, for example) will not be addressed in this way and are accounted for in this assessment by downgrading overall assessed likelihoods to be generally more conservative than the quantitative likelihoods provided by individual studies.\\t0.8155215057945089', '10.\\tHence, with only a couple of exceptions (e.g., Hansen et al., 2012), studies have focussed on how risks have changed or how different factors have contributed to an observed event, rather than claiming that the absolute probability of occurrence of that event would have been extremely low in the absence of human influence on climate.\\t0.8148961655129501']\n",
      "['1.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.6241248606465998', '2.\\tHence, with only a couple of exceptions (e.g., Hansen et al., 2012), studies have focussed on how risks have changed or how different factors have contributed to an observed event, rather than claiming that the absolute probability of occurrence of that event would have been extremely low in the absence of human influence on climate.\\t0.6157413600891861', '3.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t0.6118171683389075', '4.\\tWhen these lines of evidence are taken together it is concluded that with medium confidence or about as likely as not that the observed oxygen decreases can be attributed in part to human influences.\\t0.6092753623188406', '5.\\tBased on this evidence, including the new 21st century observations that were not yet available to AR4, we conclude that, on the basis of constraints provided by recent observed climate change, TCR is likely to lie in the range 1°C to 2.5°C and extremely unlikely to be greater than 3°C.\\t0.6086956521739131', '6.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.6059754738015607', '7.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.6052173913043479', '8.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.6052173913043479', '9.\\tStatistical tests can be used to check that observed residual temperature fluctuations (the lengths and clustering of the pins in panel (c)) are consistent with internal variability expected from coupled models, but ultimately these tests must complement physical arguments that the combination of responses to anthropogenic and natural forcing is the only available consistent explanation of recent observed temperature change.\\t0.604726867335563', '10.\\tA further consistency check often used in optimal fingerprinting is whether the estimated magnitude of the externally driven responses are consistent between model and observations (scaling factors consistent with unity in Box 10.1): if they are not, attribution is still possible provided the discrepancy is explicable in terms of known uncertainties in the magnitude of either forcing or response.\\t0.6024972129319955']\n",
      "['1.\\tHence, with only a couple of exceptions (e.g., Hansen et al., 2012), studies have focussed on how risks have changed or how different factors have contributed to an observed event, rather than claiming that the absolute probability of occurrence of that event would have been extremely low in the absence of human influence on climate.\\t0.9551859091007204', '2.\\tAttribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).\\t0.954640753585629', '3.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t0.9545685148738898', '4.\\tAlthough it has been suggested (Gregory, 2010) that the cooling trend from successive volcanic events is an artefact because models were not spun up with volcanic forcing, this discrepancy is not expected to be as significant in the upper ocean as in the deeper layers where longer term adjustments take place (Gregory et al., 2012 ).\\t0.9540866421172308', '5.\\tIt should, however, be borne in mind that this means that positive attribution results will tend to be biased towards well-observed, well-modelled variables and regions, which should be taken into account in the compilation of global impact assessments (Allen, 2011; Trenberth, 2011a).\\t0.9539024264068942', '6.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t0.9532947679111119', '7.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t0.9530742771611651', '8.\\tWhen these lines of evidence are taken together it is concluded that with medium confidence or about as likely as not that the observed oxygen decreases can be attributed in part to human influences.\\t0.9528026570068393', '9.\\tAttribution studies therefore support the conclusion that ‘it is extremely likely that human activities have caused more than half of the observed increase in global mean surface temperatures from 1951 to 2010.’\\t0.9499492354860897', '10.\\tBased on this evidence, including the new 21st century observations that were not yet available to AR4, we conclude that, on the basis of constraints provided by recent observed climate change, TCR is likely to lie in the range 1°C to 2.5°C and extremely unlikely to be greater than 3°C.\\t0.9489931470662981']\n",
      "['1.\\tAttribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.\\t5.880890309755937', '2.\\tThere is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.\\t5.8328839607170115', '3.\\tNote that the estimate will reflect any forcings with a time or time–space pattern resembling aerosol forcing that is not explicitly included in the overall estimate (see discussion in Olson et al., 2012), for example, BC on snow; and should hence be interpreted as an estimate of aerosol plus neglected forcings.\\t5.7656950274542265', '4.\\tAttribution studies therefore support the conclusion that ‘it is extremely likely that human activities have caused more than half of the observed increase in global mean surface temperatures from 1951 to 2010.’\\t5.759395041848913', '5.\\tAlthough it has been suggested (Gregory, 2010) that the cooling trend from successive volcanic events is an artefact because models were not spun up with volcanic forcing, this discrepancy is not expected to be as significant in the upper ocean as in the deeper layers where longer term adjustments take place (Gregory et al., 2012 ).\\t5.75469606084223', '6.\\tA further consistency check often used in optimal fingerprinting is whether the estimated magnitude of the externally driven responses are consistent between model and observations (scaling factors consistent with unity in Box 10.1): if they are not, attribution is still possible provided the discrepancy is explicable in terms of known uncertainties in the magnitude of either forcing or response.\\t5.740260676127641', '7.\\tIf a scaling factor is significantly larger than zero (at some significance level), then the response to that forcing, as simulated by that model and given that estimate of internal variability and other potentially confounding responses, is detectable in these observations, whereas if the scaling factor is consistent with unity, then that model-simulated response is consistent with observed changes.\\t5.717691695435214', '8.\\tIt is very likely that there is a substantial contribution from anthropogenic forcings to the global mean sea level rise since the 1970s.\\t5.709815068932423', '9.\\tThe final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.\\t5.696919014636995', '10.\\tOptimization of S/N ratio is not, however, essential for many attribution results (see, e.g., Box 10.1) and uncertainty analysis in conventional optimal fingerprinting does not require the covariance matrix to be inverted, so although regularization may help in some cases, it is not essential.\\t5.69368116206939']\n"
     ]
    }
   ],
   "source": [
    "set_list = []\n",
    "for txt in fileList:\n",
    "    s = set()\n",
    "    with open(txt, encoding=\"utf-8\") as f:\n",
    "        conclusions = f.read().split('\\n')[:-1]\n",
    "    print(conclusions[:10])\n",
    "    for conclusion in conclusions[:300]:\n",
    "        s.add(conclusion.split('\\t')[1])\n",
    "#     print(len(s))\n",
    "    set_list.append(s)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "202\n",
      "119\n",
      "118\n",
      "115\n",
      "108\n",
      "108\n",
      "107\n",
      "107\n",
      "107\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(set_list)):\n",
    "    set_list[0].intersection_update(set_list[i])\n",
    "    print(len(set_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Models may be very simple, just a set of statistical assumptions, or very complex, complete global climate models: it is not necessary, or possible, for them to be correct in all respects, but they must provide a physically consistent representation of processes and scales relevant to the attribution problem in question.', 'indicate that the observed changes are simulated with anthropogenic forcings, but not with natural forcings (even though there are some differences in the details of the forcings).', 'Attribution studies must compromise between estimating responses to different forcings separately, which allows for the possibility of different errors affecting different responses (errors in aerosol forcing that do not affect the response to GHGs, for example), and estimating responses to combined forcings, which typically gives smaller uncertainties because it avoids the issue of ‘degeneracy’: if two responses have very similar shapes in space and time, then it may be impossible to estimate the magnitude of both from a single set of observations because amplification of one may be almost exactly compensated for by amplification or diminution of the other (Allen et al., 2006).', 'Estimates of the Equilibrium Climate Sensitivity (ECS) based on multiple and partly independent lines of evidence from observed climate change indicate that there is high confidence that ECS is extremely unlikely to be less than 1°C and medium confidence that the ECS is likely to be between 1.5°C and 4.5°C and very unlikely greater than 6°C.', 'A further consistency check often used in optimal fingerprinting is whether the estimated magnitude of the externally driven responses are consistent between model and observations (scaling factors consistent with unity in Box 10.1): if they are not, attribution is still possible provided the discrepancy is explicable in terms of known uncertainties in the magnitude of either forcing or response.', 'Attribution results are typically expressed in terms of conventional ‘frequentist’ confidence intervals or results of hypothesis tests: when it is reported that the response to anthropogenic GHG increase is very likely greater than half the total observed warming, it means that the null hypothesis that the GHG-induced warming is less than half the total can be rejected with the data available at the 10% significance level.', 'It provides the central, although not the only (see Section 1.2.3) line of evidence that has supported statements such as ‘the balance of evidence suggests a discernible human influence on global climate’ or ‘most of the observed increase in global average temperatures since the mid-20th century is very likely due to the observed increase in anthropogenic greenhouse gas concentrations.’', 'The AR4 had reported that climate models that included anthropogenic and natural forcings simulated the observed thermal expansion since 1961 reasonably well, and that it is very unlikely that the warming during the past half century is due only to known natural causes (Hegerl et al., 2007b).', 'Although it has been suggested (Gregory, 2010) that the cooling trend from successive volcanic events is an artefact because models were not spun up with volcanic forcing, this discrepancy is not expected to be as significant in the upper ocean as in the deeper layers where longer term adjustments take place (Gregory et al., 2012 ).', 'Studies do not require scaling factors to be consistent with unity for attribution, but any discrepancy from unity should be understandable in terms of known uncertainties in forcing or response: a scaling factor of 10, for example, might suggest the presence of a confounding factor, calling into question any attribution claim.', 'We conclude with high confidence in the observational and modelling evidence that the decrease in NH snow extent since the 1970s is likely to be caused by all external forcings and has an anthropogenic contribution (see Table 10.1).', 'We therefore conclude that despite the uncertainties introduced by limited observational coverage, high internal variability, modelling uncertainties (Crook et al., 2011) and poorly understood local forcings, such as the effect of BC on snow, there is sufficiently strong evidence to conclude that it is likely that there has been an anthropogenic contribution to the very substantial warming in Arctic land surface temperatures over the past 50 years.', 'It is extremely likely that human activities caused more than half of the observed increase in GMST from 1951 to 2010.', 'Schwartz (2007) tried to relate the ECS to the strength of natural variability using the fluctuation dissipation theorem but studies suggest that the observations are too short to support a well constrained and reliable estimate and would yield an underestimate of sensitivity (Kirk-Davidoff, 2009); and that assuming single time scales is too simplistic for the climate system (Knutti and Hegerl, 2008) .', 'If observed changes are consistent with simulations that include human influence, and inconsistent with those that do not, this would be sufficient for attribution providing there were no other confounding influences and it is assumed that models are simulating the responses to all external forcings correctly.', 'To determine the principal causes of observed changes, we must first ascertain whether an observed change in climate is different from other fluctuations that occur without any forcing at all.', 'This appears to be consistent with the expected response to anthropogenic forcing as a result of an enhanced moisture content in the atmosphere but a direct cause-and-effect relationship between changes in external forcing and extreme precipitation had not been established at the time of the AR4.', 'For example, it is impossible in principle to detect a trend in the frequency of 1-in-100-year events in a 100-year record, yet if the probability of occurrence of these events is physically related to large-scale temperature changes, and we detect and attribute a large-scale warming, then the new guidance allows attribution of a change in probability of occurrence before such a change can be detected in observations of these events alone.', 'Although estimates of multi-decadal internal variability of GMST need to be obtained indirectly from the observational record because the observed record contains the effects of external forcings (meaning the combination of natural and anthropogenic forcings), the standard deviation of internal variability would have to be underestimated in climate models by a factor of at least three to account for the observed warming in the absence of anthropogenic influence.', 'It is very likely that these salinity changes have a discernable contribution from anthropogenic forcing since the 1960s.', 'Note that the estimate will reflect any forcings with a time or time–space pattern resembling aerosol forcing that is not explicitly included in the overall estimate (see discussion in Olson et al., 2012), for example, BC on snow; and should hence be interpreted as an estimate of aerosol plus neglected forcings.', 'It also requires an assessment that there are no confounding factors that could have caused a large part of the ‘attributed’ change.', 'A combination of evidence leads to this conclusion though by how much remains uncertain and may vary with time scale (Section 7.6.5).', 'At present, therefore, the evidence does not support the claim that we are observing weather events that would, individually, have been extremely unlikely in the absence of human-induced climate change, although observed trends in the concurrence of large numbers of events (see Section 10.6.1) may be more easily attributable to external factors.', 'When these lines of evidence are taken together it is concluded that with medium confidence or about as likely as not that the observed oxygen decreases can be attributed in part to human influences.', 'In conclusion, estimates of the Equilibrium Climate Sensitivity (ECS) based on multiple and partly independent lines of evidence from observed climate change, including estimates using longer records of surface temperature change and new palaeoclimatic evidence, indicate that there is high confidence that ECS is extremely unlikely less than 1°C and medium confidence that the ECS is likely between 1.5°C and 4.5°C and very unlikely greater than 6°C.', 'As Section 10.5.2 concludes, it is likely that the observed substantial mass loss of glaciers is due to human influence and that it is likely that anthropogenic forcing and internal variability are both contributors to recent observed changes on the Greenland ice sheet.', 'The final statistical step in an attribution study is to check that the residual variability, after the responses to external drivers have been estimated and removed, is consistent with the expected properties of internal climate variability, to ensure that the variability used for uncertainty analysis is realistic, and that there is no evidence that a potentially confounding factor has been omitted.', 'They report no appreciable differences between the fingerprints or detection results derived from the best or worst performing models, and so conclude that attribution of water vapour changes to anthropogenic forcing is not sensitive to the choice of models used for the assessment.', 'Attribution studies therefore support the conclusion that ‘it is extremely likely that human activities have caused more than half of the observed increase in global mean surface temperatures from 1951 to 2010.’', 'We conclude that it is likely that human influence has substantially increased the probability of occurrence of heat waves in some locations.', 'For individual events with return times greater than the time scale over which the signal of human influence is emerging (30 to 50 years, meaning P0 and P1 less than 2 to 3% in any given year), it is impossible to observe a change in occurrence frequency directly because of the shortness of the observed record, so attribution is necessarily a multi-step procedure.', 'Statistical tests can be used to check that observed residual temperature fluctuations (the lengths and clustering of the pins in panel (c)) are consistent with internal variability expected from coupled models, but ultimately these tests must complement physical arguments that the combination of responses to anthropogenic and natural forcing is the only available consistent explanation of recent observed temperature change.', 'Analyses that allow for the possibility that models might be consistently over- or underestimating the magnitude of the response to climate forcings are assessed in Section 10.3.1.1.3, the conclusions from which are not affected by evidence that model spread in GMST in CMIP3, is smaller than implied by the uncertainty in RF (Schwartz et al., 2007).', 'There is agreement among studies that the contribution of the AMO to global warming since 1951 is very small (considerably less than 0.1°C; see also Figure 10.6) and given that observed warming since 1951 is very large compared to climate model estimates of internal variability (Section 10.3.1.1.2), which are assessed to be adequate at global scale (Section 9.5.3.1), we conclude that it is virtually certain that internal variability alone cannot account for the observed global warming since 1951.', 'In general, a component of an observed change is attributed to a specific causal factor if the observations can be shown to be consistent with results from a process-based model that includes the causal factor in question, and inconsistent with an alternate, otherwise identical, model that excludes this factor.', 'The fact that the AMO index is estimated from detrended historical temperature observations further increases the risk that its variance may be overestimated, because regressors and regressands are not independent.', 'As discussed in the AR4, the probabilistic estimates available in the literature for climate system parameters, such as ECS and TCR have all been based, implicitly or explicitly, on adopting a Bayesian approach and therefore, even if it is not explicitly stated, involve using some kind of prior information.', 'Formally, risk is a function of both hazard and vulnerability (IPCC, 2012), although most studies attempting to quantify risk in the context of extreme weather do not explicitly use this definition, which is discussed further in Chapter 19 of WGII, but use the term as a shorthand for the probability of the occurrence of an event of a given magnitude.', '(2013) compare observed trends in GMST with a combination of simulated internal variability and the response to natural forcings and find that the observed trend would still be detected for trends over this period even if the magnitude of the simulated natural variability (i.e., the standard deviation of trends) were tripled.'}\n"
     ]
    }
   ],
   "source": [
    "print(set_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
