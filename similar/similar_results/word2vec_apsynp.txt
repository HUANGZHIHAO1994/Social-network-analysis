1.	Company disclosures greatly aid in the process of financial decision-making; therefore, they are consulted by financial investors and automated traders before exercising ownership in stocks. While humans are usually able to correctly interpret the content, the same is rarely true of computerized decision support systems, which struggle with the complexity and ambiguity of natural language. A possible remedy is represented by deep learning, which overcomes several shortcomings of traditional methods of text mining. For instance, recurrent neural networks, such as long short-term memories, employ hierarchical structures, together with a large number of hidden layers, to automatically extract features from ordered sequences of words and capture highly non-linear relationships such as context-dependent meanings. However, deep learning has only recently started to receive traction, possibly because its performance is largely untested. Hence, this paper studies the use of deep neural networks for financial decision support. We additionally experiment with transfer learning, in which we pre-train the network on a different corpus with a length of 139.1 million words. Our results reveal a higher directional accuracy as compared to traditional machine learning when predicting stock price movements in response to financial disclosures. Our work thereby helps to highlight the business value of deep learning and provides recommendations to practitioners and executives. (C) 2017 Elsevier B.V. All rights reserved.	188.1167927575745
2.	Just like its remarkable achievements in many computer vision tasks, the convolutional neural networks (CNN) provide an end-to-end solution in handwritten Chinese character recognition (HCCR) with great success. However, the process of learning discriminative features for image recognition is difficult in cases where little data is available. In this paper, we propose a matching network which builds a connection between template characters and handwritten characters inspired by the human learning process of writing Chinese characters. The matching network replaces the parameters in the softmax regression layer with the features extracted from the template character images. After the training process has been finished, the powerful discriminative features help us to generalize the predictive power not just to new data, but to entire new Chinese characters that never appear in the training set before. Experiments performed on the ICDAR-2013 offline HCCR datasets have shown that the proposed method achieves a comparable performance to current CNN-based classifiers. Besides, the matching network has a very promising generalization ability to new Chinese characters that never appear in the existing training set. (C) 2020 Elsevier Ltd. All rights reserved.	188.04162166605124
3.	Distributed deep learning systems (DDLS) train deep neural network models by utilizing the distributed resources of a cluster. Developers of DDLS are required to make many decisions to process their particular workloads in their chosen environment efficiently. The advent of GPU-based deep learning, the ever-increasing size of datasets, and deep neural network models, in combination with the bandwidth constraints that exist in cluster environments require developers of DDLS to be innovative in order to train high-quality models quickly. Comparing DDLS side-by-side is difficult due to their extensive feature lists and architectural deviations. We aim to shine some light on the fundamental principles that are at work when training deep neural networks in a cluster of independent machines by analyzing the general properties associated with training deep learning models and how such workloads can be distributed in a cluster to achieve collaborative model training. Thereby we provide an overview of the different techniques that are used by contemporary DDLS and discuss their influence and implications on the training process. To conceptualize and compare DDLS, we group different techniques into categories, thus establishing a taxonomy of distributed deep learning systems.	188.03805152943764
4.	Predicting the final closing price of a stock is a challenging task and even modest improvements in predictive outcome can be very profitable. Many computer-aided techniques based on either machine learning or statistical models have been adopted to estimate price changes in the stock market. One of the major challenges with traditional machine learning models is the feature extraction process. Indeed, extracting relevant features from data and identifying hidden nonlinear relationships without relying on econometric assumptions and human expertise is extremely complex and makes deep learning particularly attractive. In this paper, we propose a deep neural network-based approach to predict if the stock price will increase by 25% for the following year, same quarter or not. We also compare our deep learning method against 'shallow' approaches, random forest and gradient boosted machines. To test the proposed methods, KIS-VALUE database consisting of the Korea Composite Stock Price Index (KOSPI) of companies for the period 2007 to 2015 was considered. All the methods yielded satisfactory performance, namely, deep neural network achieved an AUC of 0.806. 'Shallow' approaches, random forest and gradient boosted machines have been used for comparisons.	188.03338334392498
5.	Recent developments in applying deep learning techniques to train end-to-end communication systems have shown great promise in improving the overall performance of the system. However, most of the current methods for applying deep learning to train physical-layer characteristics assume the availability of the explicit channel model. Training a neural network requires the availability of the functional form all the layers in the network to calculate gradients for optimization. The unavailability of gradients in a physical channel forced previous works to adopt simulation-based strategies to train the network and then fine tune only the receiver part with the actual channel. In this letter, we present a practical method to train an end-to-end communication system without relying on explicit channel models. By utilizing stochastic perturbation techniques, we show that the proposed method can train a deep learning-based communication system in real channel without any assumption on channel models.	188.02996132672507
6.	Deep convolutional networks (CNNs) reign undisputed as the new de-facto method for computer vision tasks owning to their success in visual recognition task on still images. However, their adaptations to crowd counting have not clearly established their superiority over shallow models. Existing CNNs turn out to be self-limiting in challenging scenarios such as camera illumination changing, partial occlusions, diverse crowd distributions, and perspective distortions for crowd counting because of their shallow structure. In this paper, we introduce a dynamic augmentation technique to train a much deeper CNN for crowd counting. In order to decrease overfitting caused by limited number of training samples, multitask learning is further employed to learn generalizable representations across similar domains. We also propose to aggregate multiscale convolutional features extracted from the entire image into a compact single vector representation amenable to efficient and accurate counting by way of "Vector of Locally Aggregated Descriptors" (VLAD). The "deeply supervised" strategy is employed to provide additional supervision signal for bottom layers for further performance improvement. Experimental results on three benchmark crowd datasets show that our method achieves better performance than the existing methods. Our implementation will be released at https://github.com/shizenglin/Multitask-Multiscale-Deep-NetVLAD.	188.0288168458523
7.	Dynamic gesture recognition, which plays an essential role in human-computer interaction, has been widely investigated but not yet fully addressed. The challenge mainly lies in three folders: 1) to model both of the spatial appearance and the temporal evolution simultaneously; 2) to address the interference from the varied and complex background; 3) the requirement of real-time processing. In this paper, we address the above challenges by proposing a novel deep deformable 3D convolutional neural network for end-to-end learning, which not only gains impressive accuracy in challenging datasets but also can meet the requirement of the real-time processing. We propose three types of very deep 3D CNNs for gesture recognition, which can directly model the spatiotemporal information with their inherent hierarchical structure. To eliminate the background interference, a light-weight spatiotemporal deformable convolutional module is specially designed to augment the spatiotemporal sampling locations of the 3D convolution by learning additional offsets according to the preceding feature map. It can not only diversify the shape of the convolution kernel to better fit the appearance of the hands and arms, but also help the models pay more attention to the discriminative frames in the video sequence. The proposed method is evaluated on three challenging datasets, EgoGesture, Jester and Chalearn-IsoGD, and achieves the state-of-the-art performance on all of them. Our model ranked first on Jester's official leader-board until the submission time. The code and the trained models are released for better communication and future works(1). (C) 2020 Elsevier Ltd. All rights reserved.	188.02778280267052
8.	Neural networks (NN) are considered as black boxes due to the lack of explainability and transparency of their decisions. This significantly hampers their deployment in environments where explainability is essential along with the accuracy of the system. Recently, significant efforts have been made for the interpretability of these deep networks with the aim to open up the black box. However, most of these approaches are specifically developed for visual modalities. In addition, the interpretations provided by these systems require expert knowledge and understanding for intelligibility. This indicates a vital gap between the explainability provided by the systems and the novice user. To bridge this gap, we present a novel framework i.e. Time-Series eXplanation (TSXplain) system which produces a natural language based explanation of the decision taken by a NN. It uses the extracted statistical features to describe the decision of a NN, merging the deep learning world with that of statistics. The two-level explanation provides ample description of the decision made by the network to aid an expert as well as a novice user alike. Our survey and reliability assessment test confirm that the generated explanations are meaningful and correct. We believe that generating natural language based descriptions of the network's decisions is a big step towards opening up the black box.	188.02728243262194
9.	Convolutional neural networks, as a type of deep learning approach, have revolutionized the field of computer vision and pattern recognition through state of the art performance in a large number of classification tasks. Machine learning has been recently incorporated into intelligent systems related to agricultural and food production to decrease manual processing when dealing with large number of operations. Feedforward artificial neural networks such as convolutional neural networks can be used in agriculture for the segmentation and classification of images containing objects of interests such as fruits, or leaves. It is however unknown what is the best architecture to use, if it is necessary to propose new architectures, and what is the impact of the input feature space on the classification performance. In this paper, we propose to detect two types of grapes (Albarino white grapes and Barbera red grapes) in images. We investigate 1) the impact of the input feature space: color images, grayscale images, and color histograms using convolutional neural networks; 2) the impact of the parameters such as the size of the blocks, and the impact of data augmentation; 3) the performance of 11 pre-trained deep learning architectures, i.e. using a transfer learning approach for the classification. The results support the conclusion that images of grapes can be efficiently segmented using different feature spaces where color images provide the best performance. With convolutional neural networks using transfer learning, the best performance is achieved with Resnet networks reaching an accuracy of 99% for both red and white grapes. Finally, data augmentation, image normalization, and the input feature space have a key impact on the overall performance. (C) 2020 Elsevier Ltd. All rights reserved.	188.02695472138151
10.	Gradient descent optimization of learning has become a paradigm for training deep convolutional neural networks (DCNN). However, utilizing other learning strategies in the training process of the DCNN has rarely been explored by the deep learning (DL) community. This serves as the motivation to introduce a non-iterative learning strategy to retrain neurons at the top dense or fully connected (FC) layers of DCNN, resulting in, higher performance. The proposed method exploits the Moore-Penrose Inverse to pull back the current residual error to each FC layer, generating well-generalized features. Further, the weights of each FC layers are recomputed according to the Moore-Penrose Inverse. We evaluate the proposed approach on six most widely accepted object recognition benchmark datasets: Scene-15, CIFAR-10, CIFAR-100, SUN-397, Places365, and ImageNet. The experimental results show that the proposed method obtains improvements over 30 state-of-the-art methods. Interestingly, it also indicates that any DCNN with the proposed method can provide better performance than the same network with its original Backpropagation (BP)-based training.	188.025898393393
11.	In recent years, neural networks have enjoyed a renaissance as function approximators in reinforcement learning. Two decades after Tesauro's TD-Gammon achieved near top-level human performance in backgammon, the deep reinforcement learning algorithm DQN achieved human-level performance in many Atari 2600 games. The purpose of this study is twofold. First, we propose two activation functions for neural network function approximation in reinforcement learning: the sigmoid-weighted linear unit (SiLU) and its derivative function (dSiLU). The activation of the SiLU is computed by the sigmoid function multiplied by its input. Second, we suggest that the more traditional approach of using on-policy learning with eligibility traces, instead of experience replay, and softmax action selection can be competitive with DQN, without the need for a separate target network. We validate our proposed approach by, first, achieving new state-of-the-art results in both stochastic SZ-Tetris and Tetris with a small 10 x 10 board, using TD(lambda) learning and shallow dSiLU network agents, and, then, by outperforming DQN in the Atari 2600 domain by using a deep Sarsa(lambda) agent with SiLU and dSiLU hidden units. (C) 2017 The Author(s). Published by Elsevier Ltd.	188.02477542927522
12.	Motivated by augmented and virtual reality applications such as telepresence, there has been a recent focus in real-time performance capture of humans under motion. However, given the real-time constraint, these systems often suffer from artifacts in geometry and texture such as holes and noise in the final rendering, poor lighting, and low-resolution textures. We take the novel approach to augment such real-time performance capture systems with a deep architecture that takes a rendering from an arbitrary viewpoint, and jointly performs completion, super resolution, and denoising of the imagery in real-time. We call this approach neural (re-)rendering, and our live system "LookinGood". Our deep architecture is trained to produce high resolution and high quality images from a coarse rendering in real-time. First, we propose a self-supervised training method that does not require manual ground-truth annotation. We contribute a specialized reconstruction error that uses semantic information to focus on relevant parts of the subject, e.g. the face. We also introduce a salient reweighing scheme of the loss function that is able to discard outliers. We specifically design the system for virtual and augmented reality headsets where the consistency between the left and right eye plays a crucial role in the final user experience. Finally, we generate temporally stable results by explicitly minimizing the difference between two consecutive frames. We tested the proposed system in two different scenarios: one involving a single RGB-D sensor, and upper body reconstruction of an actor, the second consisting of full body 3600 capture. Through extensive experimentation, we demonstrate how our system generalizes across unseen sequences and subjects. The supplementary video is available at http://youtu.be/Md3tdAKoLGU.	188.0244650140784
13.	Compute is a term coined from the etymology of French and Latin wordscomputerandcomputarerespectively, so is computing. This field of computing has grown enormously over the years. From the simple, traditional Turing machine invented in 1936 by Alan Turing to the current neural network (NN) computing. NNs, a field of artificial intelligence (AI) was exhilarated from the structure and inner workings of the brain. Just as the brain is, that is, an interconnection of neurons, so is the NN which is an interconnection of basic structures known as the perceptron. They do not differ much in structure. Their only difference is that one is artificial while the other is entirely biological. The hierarchical intricacies of the NN can be represented in three layers: the perceptron, artificial NN (ANN), and deep NN (DNN). With the influx of mental and behavioral disorders, basic surveillance, and the urgency to improve the mental health of people, studying the behavioral dynamics of people is requisite. CCTV and street cameras can only do so much, thus the need to employ the field of NN which makes use of supervised learning in training the models to perfect and automate surveillance. The results of this retrospective research indicate that the use of the NN model surpasses those of traditional methods in terms of efficiency and reliability.	188.0234571745042
14.	Vision-based person re-identification aims to match a persons identity across multiple images, which is a fundamental task in multimedia content analysis and retrieval. Deep neural networks have recently manifested great potential in this task. However, a major bottleneck of existing supervised deep networks is their reliance on a large amount of annotated training data. Manual labeling for person identities in large-scale surveillance camera systems is quite challenging and incurs significant costs. Some recent studies adopt generative model outputs as training data augmentation. To more effectively use these synthetic data for an improved feature learning and re-identification performance, this paper proposes a novel feature affinity-based pseudo labeling method with two possible label encodings. To the best of our knowledge, this is the first study that employs pseudo-labeling by measuring the affinity of unlabeled samples with the underlying clusters of labeled data samples using the intermediate feature representations from deep networks. We propose training the network with the joint supervision of cross-entropy loss together with a center regularization term, which not only ensures discriminative feature representation learning but also simultaneously predicts pseudo-labels for unlabeled data. We show that both label encodings can be learned in a unified manner and help improve the overall performance. Our extensive experiments on three person re-identification datasets: Market-1501, DukeMTMC-reID, and CUHK03, demonstrate significant performance boost over the state-of-the-art person re-identification approaches.	188.02236090973182
15.	This paper considers the scenario that multiple data owners wish to apply a machine learning method over the combined dataset of all owners to obtain the best possible learning output but do not want to share the local datasets owing to privacy concerns. We design systems for the scenario that the stochastic gradient descent (SGD) algorithm is used as the machine learning method, because SGD (or its variants) is at the heart of recent deep learning techniques over neural networks. Our systems differ from the existing systems in the following features: 1) any activation function can be used, meaning that no privacy-preserving-friendly approximation is required; 2) gradients computed by SGD are not shared but the weight parameters are shared instead; and 3) robustness against colluding parties even in the extreme case that only one honest party exists. One of our systems requires a shared symmetric key among the data owners (trainers) to ensure the secrecy of the weight parameters against a central server. We prove that our systems, while privacy preserving, achieve the same learning accuracy as SGD and, hence, retain the merit of deep learning with respect to accuracy. Finally, we conduct several experiments using benchmark datasets and show that our systems outperform the previous system in terms of learning accuracies.	188.0222738812969
16.	In recent years, we have witnessed the great success of deep learning on various problems both in low and high-level computer visions. The low-level vision problems, including inpainting, deblurring, denoising, super-resolution, and so on, are highly anticipated to occur in machine vision and image processing. Many deep learning based methods have been proposed to solve low-level vision problems. Most researches treat these problems independently; however, most of the time they appear concurrently. Motivated by the success of generative model in the field of image generation, we develop a deep cascade of neural networks to solve the inpainting, deblurring, denoising problems at the same time. Our model contains two networks: inpainting GAN and deblurring-denoising network. Inpainting GAN generates the coarse patches to fill the lost part in damaged image, and the deblurring-denoising network, stacked by a convolutional auto-encoder, will further refine them. Unlike other methods that handle each problem separately, our method jointly optimizes the two sub-networks. Because GAN training is not only unstable but also difficult, we adopt the Wasserstein distance as the loss function of the inpainting GAN and propose a gradual training strategy. Learning from the idea of residual learning, we utilize skip connections to pass image details from input to reconstruction layer. Experimental results have demonstrated that the proposed model can achieve state-of-the-art performance. Through the experiments, we also demonstrated the effectiveness of the cascade architecture.	188.02217340753015
17.	Neural networks have become very popular in recent years, because of the astonishing success of deep learning in various domains such as image and speech recognition. In many of these domains, specific architectures of neural networks, such as convolutional networks, seem to fit the particular structure of the problem domain very well and can therefore perform in an astonishingly effective way. However, the success of neural networks is not universal across all domains. Indeed, for learning problems without any special structure, or in cases where the data are somewhat limited, neural networks are known not to perform well with respect to traditional machine-learning methods such as random forests. In this article, we show that a carefully designed neural network with random forest structure can have better generalization ability. In fact, this architecture is more powerful than random forests, because the back-propagation algorithm reduces to a more powerful and generalized way of constructing a decision tree. Furthermore, the approach is efficient to train and requires a small constant factor of the number of training examples. This efficiency allows the training of multiple neural networks to improve the generalization accuracy. Experimental results on real-world benchmark datasets demonstrate the effectiveness of the proposed enhancements for classification and regression.	188.02183432715734
18.	X-ray imaging is a wide-spread real-time imaging technique. Magnetic Resonance Imaging (MRI) offers a multitude of contrasts that offer improved guidance to interventionalists. As such simultaneous real-time acquisition and overlay would be highly favorable for image-guided interventions, e.g., in stroke therapy. One major obstacle in this setting is the fundamentally different acquisition geometry. MRI k -space sampling is associated with parallel projection geometry, while the X-ray acquisition results in perspective distorted projections. The classical rebinning methods to overcome this limitation inherently suffers from a loss of resolution. To counter this problem, we present a novel rebinning algorithm for parallel to cone-beam conversion. We derive a rebinning formula that is then used to find an appropriate deep neural network architecture. Following the known operator learning paradigm, the novel algorithm is mapped to a neural network with differentiable projection operators enabling data-driven learning of the remaining unknown operators. The evaluation aims in two directions: First, we give a profound analysis of the different hypotheses to the unknown operator and investigate the influence of numerical training data. Second, we evaluate the performance of the proposed method against the classical rebinning approach. We demonstrate that the derived network achieves better results than the baseline method and that such operators can be trained with simulated data without losing their generality making them applicable to real data without the need for retraining or transfer learning.	188.02177745154464
19.	While the deep convolutional neural networks (DCNNs) have shown excellent performance in various applications, such as image classification, training a DCNN model from scratch is computationally expensive and time consuming. In recent years, a lot of studies have been done to accelerate the training of DCNNs, but most of them were performed in a one-time manner. Considering the learning patterns of the human beings, people typically feel more comfortable to learn things in an incremental way and may be overwhelmed when absorbing a large amount of new information at once. Therefore, we demonstrate a new training schema that splits the whole training process into several sub-training steps. In this study, we propose an efficient DCNN training framework where we learn the new classes of concepts incrementally. The experiments are conducted on CIFAR-100 with VGG-19 as the backbone network. Our proposed framework demonstrates a comparable accuracy compared with the model trained from scratch and has shown 1.42x faster training speed.	188.02154409135125
20.	Deep learning techniques are commonly used to process large amounts of data, and good results are obtained in many applications. Those methods, however, can lead to long training times. An alternative to simultaneously tune all parameters of a large network is to stack smaller modules, improving the model efficiency. However, methods such as Deep Stacked Network (DSN) have some problems that increase its training time and memory usage. To deal with these problems, Fast DSN (FDSN) was proposed, where the modules are trained using an Extreme Learning Machine (ELM) variant. Nonetheless, to speed-up the FDSN training, the ELM random feature mapping is shared among the modules, which can impact the network performance if the weights are not properly chosen. In this paper, we focus on the weight initialization of FDSN in order to improve its performance. We also propose FKDSN, a kernel-based variant of FDSN, besides discussing the theoretical complexity of the methods. We evaluate three different initialization approaches on ELM-trained neural networks over 50 public real-world regression datasets. Our experiments show that FDSN when combined with a more complex initialization method achieves similar results to ELM algorithms applied to large SLFNs, besides having a shorter training time and memory usage, implying that it can be suitable to be used on systems with restrict resources, such as Internet of Things devices. FKDSN also obtained similar results and training time to the large SLFNs, requiring less memory.	188.02139575640976
21.	As a typical cyber-physical system, 3D printing has developed very fast in recent years. There is a strong demand for mass customization, such as printing dental crowns. However, the accuracy of the 3D printed objects is low compared with traditional methods. The main reason is that the model to be printed is arbitrary and usually the quantity is small. The deformation is affected by the shape of the object and there is a lack of a universal method for the error compensation. It is neither easy nor economical to perform the compensation manually. In this paper, we present a framework for the automatic error compensation. We obtain the shape by technologies such as 3D scanning. And we use the "3D deep learning" method to train a deep neural network. For a specific task, such as dental crown printing, the network can learn the function of deformation when a large amount of data is used for training. To the best of our knowledge, this is the first application of the deep neural network to the error compensation in 3D printing. And we propose the "inverse function network" to compensate for the error. We use four types of deformations of the dental crowns to verify the performance of the neural network: 1) translation; 2) scaling up; 3) scaling down; and 4) rotation. The convolutional AutoEncoder structure is employed for the end-to-end learning. The experiments show that the network can predict and compensate for the error well. By introducing the new method, we can improve the accuracy with little need for increasing the hardware cost.	188.02117282369227
22.	Data for face analysis often exhibit highly-skewed class distribution, i.e., most data belong to a few majority classes, while the minority classes only contain a scarce amount of instances. To mitigate this issue, contemporary deep learning methods typically follow classic strategies such as class re-sampling or cost-sensitive training. In this paper, we conduct extensive and systematic experiments to validate the effectiveness of these classic schemes for representation learning on class-imbalanced data. We further demonstrate that more discriminative deep representation can be learned by enforcing a deep network to maintain inter-cluster margins both within and between classes. This tight constraint effectively reduces the class imbalance inherent in the local data neighborhood, thus carving much more balanced class boundaries locally. We show that it is easy to deploy angular margins between the cluster distributions on a hypersphere manifold. Such learned Cluster-based Large Margin Local Embedding (CLMLE), when combined with a simple k-nearest cluster algorithm, shows significant improvements in accuracy over existing methods on both face recognition and face attribute prediction tasks that exhibit imbalanced class distribution.	188.02105914214087
23.	Introduction: Increase in computing power and the deeper usage of the robust computing systems in the financial system is propelling the business growth, improving the operational efficiency of the financial institutions, and increasing the effectiveness of the transaction processing solutions used by the organizations. Problem: Despite that the financial institutions are relying on the credit scoring patterns for analyzing the credit worthiness of the clients, still there are many factors that are imminent for improvement in the credit score evaluation patterns. There is need for improving the pattern to enhance the quality of analysis. Objective: Machine learning is offering immense potential in Fintech space and determining a personal credit score. Organizations by applying deep learning and machine learning techniques can tap individuals who are not being serviced by traditional financial institutions. Methodology: One of the major insights into the system is that the traditional models of banking intelligence solutions are predominantly the programmed models that can align with the information and banking systems that are used by the banks. But in the case of the machine-learning models that rely on algorithmic systems require more integral computation which is intrinsic. Hence, it can be advocated that the models usually need to have some decision lines wherein the dynamic calibration model must be streamlined. Such structure demands the dynamic calibration to have a decision tree system to empower with more integrated model changes. Results: The test analysis of the proposed machine learning model indicates effective and enhanced analysis process compared to the non-machine learning solutions. The model in terms of using various classifiers indicate potential ways in which the solution can be significant. Conclusion: If the systems can be developed to align with more pragmatic terms for analysis, it can help in improving the process conditions of customer profile analysis, wherein the process models have to be developed for comprehensive analysis and the ones that can make a sustainable solution for the credit system management. Originality: The proposed solution is effective and the one conceptualized to improve the credit scoring system patterns. If the model can be improved with more effective parameters and learning metrics, it can be sustainable outcome. Limitations: The model is tested in isolation and not in comparison to any of the existing credit scoring patterns. Only the inputs in terms of shortcomings from the existing models are taken in to account and accordingly the proposed solution is developed.	188.02073436782686
24.	Deep learning techniques have been successfully used in learning a common representation for multi view data, wherein different modalities are projected onto a common subspace. In a broader perspective, the techniques used to investigate common representation learning falls under the categories of 'canonical correlation-based' approaches and 'autoencoder-based' approaches. In this paper, we investigate the performance of deep autoencoder-based methods on multi-view data. We propose a novel step-based correlation multi-modal deep convolution neural network (CorrMCNN) which reconstructs one view of the data given the other while increasing the interaction between the representations at each hidden layer or every intermediate step. The idea of step reconstruction reduces the constraint of reconstruction of original data, instead, the objective function is optimized for reconstruction of representative features. This helps the proposed model to generalize for representation and transfer learning tasks efficiently for high dimensional data. Finally, we evaluate the performance of the proposed model on three multi-view and cross-modal problems viz., audio articulation, cross-modal image retrieval and multilingual (cross-language) document classification. Through extensive experiments, we find that the proposed model performs much better than the current state-of-the-art deep learning techniques on all three multi-view and cross-modal tasks. (C) 2019 Elsevier Ltd. All rights reserved.	188.02055030859037
25.	Cooperative wind farm control is a complex problem due to wake effect, and it is hard to find the proper model. Reinforcement learning can find the optimal policy in a dynamic environment using "trial and error," but may damage the machine and cause high cost during the learning process. In order to address this challenge, this article proposes the knowledge-assisted reinforcement learning framework by combining the low-fidelity analytical model with a reinforcement learning framework. Moreover, the knowledge-assisted deep deterministic policy gradient (KA-DDPG) algorithm and three kinds of knowledge-assisted learning methods are proposed based on the framework. The proposed methods are tested in nine different scenarios of WFSim. The simulation results show that the KA-DDPG algorithm can reach the maximum power output and ensure safety during learning. In addition, the learning cost is reduced by accelerating the learning process.	188.01968752146473
26.	Deep learning has the ability to mine complex relationships in fault diagnosis. Deep convolutional neural network (DCNN) with deep structures, instead of shallow ones, can be applied to mining useful information from the original vibration data. However, when the number of the training samples is small, the diagnosis accuracy will be affected. As an improvement of the DCNN, deep convolutional neural network based on the Fisher-criterion (FDCNN) can be used for the fault diagnosis of small samples. But the model parameters in the method are based on human labor or prior knowledge, which is bound to bring negative influence on the diagnosis accuracy. Therefore, a novel adaptive Fisher-based deep convolutional neural network (AFDCNN) method, which can optimize the model parameters adaptively, is proposed as an improvement of the FDCNN. Comparative verification test results show that AFDCNN has more outstanding performance.	188.0192457091061
27.	Although Reinforcement learning has already been considered one of the most important and well-known techniques of machine learning, its applicability remains limited in the real-world problems due to its long initial learning time and unstable learning. Especially, the problem of an overwhelming number of the branching factors under real-time constraint still stays unconquered, demanding a new method for the next generation of reinforcement learning. In this paper, we propose Genetic State-Grouping Algorithm based on deep reinforcement learning. The core idea is to divide the entire set of states into a few state groups. Each group consists of states that are mutually similar, thus representing their common features. The state groups are then processed with the Genetic Optimizer, which finds outstanding actions. These steps help the Deep Q Network avoid excessive exploration, thereby contributing to the significant reduction of initial learning time. The experiment on the real-time fighting video game (FightingICE) shows the effectiveness of our proposed approach. (c) 2020 Elsevier Ltd. All rights reserved.	188.01884998622106
28.	The integration of two or more intelligent systems, such as deep neural networks and fuzzy techniques, results in so-called hybrid intelligent systems. These have recently attracted considerable attention owing to their broad success in several complex real-world applications. An interesting example is the development of adaptive computer-based learning environments, in which learner responses to certain questions are considered so that the next level of the learning process may be determined. However, these methods fail to capture the behavior and emotional expressions of the learner during the learning process. Capturing these could make the learning flow more adaptive, and could allow the learning environment to redirect learners to different learning paths based on their capabilities and interaction levels. In this regard, the contribution of the present study is threefold. First, it proposes an approach for modeling an intelligent adaptive e-learning environment by considering the integration of the learner responses to questions and their emotional states. In the proposed approach, a loosely coupled integration between a convolutional neural network (CNN) and a fuzzy system is adopted. The CNN is used to detect a learner's facial expressions, and outperforms other CNN models on the same training benchmark. The fuzzy system is used to determine the next learning level based on the extracted facial expression states from the CNN and several response factors by the learner. Second, the study introduces methods whereby a group of facial expressions is aggregated into a single representative. Third, it introduces corpora for evaluating the performance of the proposed approach. The corpora of 12 learners contain 72 learning activities and 1735 data points of distinct emotional states. The experimental results using these corpora demonstrate that the proposed approach provides adaptive learning flows that match the learning capabilities of all learners in a group. Moreover, the approach allows decision makers to monitor the learning performance for each learner. (C) 2020 Elsevier Ltd. All rights reserved.	188.0185846103288
29.	Convolutional neural networks, or CNNs, raised the bar for most computer vision problems and have an increasing impact in remote sensing. However, since they usually contain multiple pooling layers, detection of exact borders of small objects at their original resolution remains yet a challenging topic. Additionally, efforts are being made to reduce the amount of training data. In this paper, we investigate the potential of fully convolutional neural networks (FCNs) for individual vehicle detection in combined elevation and optical data using relatively few training samples. By the proposed multibranch CNN, we combine object recognition within a deep learning framework with the object segmentation at a high resolution, for which two CNN branches are employed. Data fusion is accomplished with a pseudo-Siamese approach. The pixelwise classification likelihood, also referred to as heatmap, is harmoniously post processed by a vectorization module, which is based on the minimum bounding rectangle (MBR) extraction and allows for delineation of groups of vehicles. Two methods were developed in which MBRs are supported either by pairs of parallel lines or by region growing. Our approach allows efficient training with few training samples, while delivering high-quality detection results and good computational performance. In our detailed evaluation, we investigate the benefits of data fusion and compare our approach to other state-of-the-art networks. Different datasets were used, containing optical images and elevation data, derived either from airborne laser scanning or from photogrammetric reconstruction. The obtained results are very promising with F-1 scores up to 97%.	188.01821267161532
30.	Action recognition is of great importance in understanding human motion from video. It is an important topic in computer vision due to its many applications such as video surveillance, human-machine interaction and video retrieval. One key problem is to automatically recognize low-level actions and high-level activities of interest. This paper proposes a way to cope with low-level actions by combining information of human body joints to aid action recognition. This is achieved by using high-level features computed by a convolutional neural network which was pre-trained on Imagenet, with articulated body joints as low-level features. These features are then used to feed a Long Short-Term Memory network to learn the temporal dependencies of an action. For pose prediction, we focus on articulated relations between body joints. We employ a series of residual auto-encoders to produce multiple predictions which are then combined to provide a likelihood map of body joints. In the network topology, features are processed across all scales which capture the various spatial relationships associated with the body. Repeated bottom-up and top-down processing with intermediate supervision of each auto-encoder network is applied. We demonstrate state-of-the-art results on the popular FLIC, LSP and UCF Sports datasets.	188.01813306967853
31.	Control of underactuated dynamical systems has been studied for decades in robotics, and is now emerging in other fields such as neuroscience. Most of the advances have been in model based control theory, which has limitations when the system under study is very complex and it is not possible to construct a model. This calls for data driven control methods like machine learning, which has spread to many fields in the recent years including control theory. However, the success of such algorithms has been dependent on availability of large datasets. Moreover, due to their black box nature, it is challenging to analyze how such algorithms work, which may be crucial in applications where failure is very costly. In this paper, we develop two related novel supervised learning algorithms. The algorithms are powerful enough to control a wide variety of complex underactuated dynamical systems, and yet have a simple and intelligent structure that allows them to work with a sparse data set even in the presence of noise. Our algorithms output a bang-bang (binary) control input by taking in feedback of the state of the dynamical system. The algorithms learn this control input by maximizing a reward function in both short and long time horizons. We demonstrate the versatility of our algorithms by applying them to a diverse range of applications including: switching between bistable states, changing the phase of an oscillator, desynchronizing a population of synchronized coupled oscillators, and stabilizing an unstable fixed point. For most of these applications we are able to reason why our algorithms work by using traditional dynamical systems and control theory. We also compare our learning algorithms with some traditional control algorithms, and reason why our algorithms work better. (C) 2020 Elsevier B.V. All rights reserved.	188.01805746196442
32.	Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learfied end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2 846 human whole-body motions and 6 187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions. (C) 2018 Elsevier B.V. All rights reserved.	188.01788549503692
33.	Point cloud filtering is a fundamental problem in geometry modeling and processing. Despite of advancement in recent years, the existing methods still suffer from two issues: 1) they are either designed without preserving sharp features or or less robust in features preservation; and 2) they usually have many parameters and require tedious parameter tuning. In this paper, we propose a novel deep learning approach that automatically and robustly filters point clouds by removing noise and preserving their sharp features. Our point-wise learning architecture consists of an encoder and a decoder. The encoder directly takes points (a point and its neighbors) as input, and learns a latent representation vector which is going through the decoder to relate the ground-truth position with a displacement vector. The trained neural network can automatically generate a set of clean points from a noisy input. Extensive experiments show that our approach outperforms the state-of-the-art deep learning techniques in terms of both visual quality and quantitative error metrics. We will make our code and dataset publicly available.	188.01745290703832
34.	The Convolutional Neural Networks (CNNs) based multi-focus image fusion methods have recently attracted enormous attention. They greatly enhanced the constructed decision map compared with the previous state of the art methods that have been done in the spatial and transform domains. Nevertheless, these methods have not reached to the satisfactory initial decision map, and they need to undergo vast post-processing algorithms to achieve a satisfactory decision map. In this paper, a novel CNNs based method with the help of the ensemble learning is proposed. It is very reasonable to use various models and datasets rather than just one. The ensemble learning based methods intend to pursue increasing diversity among the models and datasets in order to decrease the problem of the overfitting on the training dataset. It is obvious that the results of an ensemble of CNNs are better than just one single CNNs. Also, the proposed method introduces a new simple type of multi-focus images dataset. It simply changes the arranging of the patches of the multi-focus datasets, which is very useful for obtaining the better accuracy. With this new type arrangement of datasets, the three different datasets including the original and the Gradient in directions of vertical and horizontal patches are generated from the COCO dataset. Therefore, the proposed method introduces a new network that three CNNs models which have been trained on three different created datasets to construct the initial segmented decision map. These ideas greatly improve the initial segmented decision map of the proposed method which is similar, or even better than, the other final decision map of CNNs based methods obtained after applying many post-processing algorithms. Many real multi-focus test images are used in our experiments, and the results are compared with quantitative and qualitative criteria. The obtained experimental results indicate that the proposed CNNs based network is more accurate and have the better decision map without post-processing algorithms than the other existing state of the art multi-focus fusion methods which used many post-processing algorithms.	188.01726751188596
35.	The success of neural networks is typically attributed to their ability to closely mimic relationships between features and labels observed in the training dataset. This, however, is only part of the answer: in addition to being fit to data, neural networks have been shown to be useful priors on the conditional distribution of labels given features and can be used as such even in the absence of trustworthy training labels. This feature of neural networks can be harnessed to train high quality models on low quality training data in tasks for which large high-quality ground truth datasets don't exist. One of these problems is assertion classification in biomedical texts: discriminating between positive, negative and speculative statements about certain pathologies a patient may have. We present an assertion classification methodology based on recurrent neural networks, attention mechanism and two flavours of transfer learning (language modelling and heuristic annotation) that achieves state of the art results on MIMIC-CXR radiology reports.	188.01693065533937
36.	Psychological stress affects physiological parameters of a person. Prolonged exposure to stress can have detrimental effects which might require expensive treatments. Acute levels of stress in people who are already diagnosed with borderline personality disorder or schizophrenia, can cost them their lives. To self-manage this important health problem in the framework of smart healthcare, a deep learning based novel system (Stress-Lysis) is proposed in this article. The learning system is trained such that it monitors stress levels in a person through human body temperature, rate of motion and sweat during physical activity. The proposed Stress-Lysis has been trained with a total of 26,000 samples per dataset and demonstrates accuracy as high as 99.7 & x0025;. The collected data are transmitted and stored in the cloud which can help in real time monitoring of a person's stress levels, thereby reducing the risk of death and expensive treatments. The proposed system has the ability to produce results with an overall accuracy of 98.3 & x0025; to 99.7 & x0025;, is simple to implement and its cost is moderate. Stress-Lysis can not only help in keeping an individual self-aware by providing immediate feedback to change the lifestyle of the person in order to lead a healthier life but also plays a significant role in the state-of-the-art by allowing computing on the edge devices.	188.01687232211302
37.	Text classification is of importance in natural language processing, as the massive text information containing huge amounts of value needs to be classified into different categories for further use. In order to better classify text, our paper tries to build a deep learning model which achieves better classification results in Chinese text than those of other researchers' models. After comparing different methods, long short-term memory (LSTM) and convolutional neural network (CNN) methods were selected as deep learning methods to classify Chinese text. LSTM is a special kind of recurrent neural network (RNN), which is capable of processing serialized information through its recurrent structure. By contrast, CNN has shown its ability to extract features from visual imagery. Therefore, two layers of LSTM and one layer of CNN were integrated to our new model: the BLSTM-C model (BLSTM stands for bi-directional long short-term memory while C stands for CNN.) LSTM was responsible for obtaining a sequence output based on past and future contexts, which was then input to the convolutional layer for extracting features. In our experiments, the proposed BLSTM-C model was evaluated in several ways. In the results, the model exhibited remarkable performance in text classification, especially in Chinese texts.	188.01654625733408
38.	Opinion review is of great importance for both customers and organizations. Indeed, it helps customers in buying decisions and represents a valuable feedback for the companies, allowing them to improve their productions. However, numerous greedy companies resort to fake reviews in order to influence the customer and brighten the brand image, or to defame the one of their competitors. Various models are proposed in order to detect deceptive opinion reviews. Most of these models adopt traditional methods focusing on feature extraction and traditional classifiers. Unfortunately, these models do not capture the semantic aspect while ignoring the opinion's context. In order to tackle this issue, we propose a new approach based on Paragraph Vector Distributed Bag of Words (PV-DBOW) and the Denoising Autoencoder (DAE). The proposed customized model provides a strong representation which is based on a global representation of the opinions while preserving their semantics. Indeed, the embedding vectors capture the semantic meaning of all words in the context of each opinion. The generated review representations are fed into a fully connected neural network in order to detect deceptive opinion spam. The obtained results concerning the deception dataset show that our model is effective and outperforms the existing state-of-the-art methodologies. (C) 2020 Elsevier Ltd. All rights reserved.	188.01624070473247
39.	At present, Discriminative Correlation Filter(DCF) based trackers and Deep Learning based trackers are the main methods to achieve visual tracking. Although they have achieved promising performance in many cases, there are still some inherent flaws that they can't overcome. Neither of the two main tracking algorithms can achieve satisfactory tracking performance, and considering that they can complement each other to some extent. In this paper, we focus on combining them together for a better tracking. To this end, we select several Correlation Filter and Deep Learning based tracking methods, then modify them appropriately and take different combinations to get a comprehensive result. To meet the real-time requirements, in the DCF branch, we mainly use hand-crafted features rather than deep features. Finally, we propose a new adaptive fusion approach to improve the tracking robustness and accuracy. Comprehensive experiments are performed on several benchmark datasets, using the evaluation criteria which have been proposed by the corresponding benchmarks. In order to fully understand the role of each branch and the effect of fusion strategy, our approach is compared with corresponding individual branches meanwhile the combination of our branches is compared with different fusion strategies. Finally, our approach is compared with state-of-the-art trackers, and the results show that our method has good accuracy and robustness when compared with other methods.	188.0155427399626
40.	Using a large-scale Deep Learning approach applied to a high-frequency database containing billions of market quotes and transactions for US equities, we uncover nonparametric evidence for the existence of a universal and stationary relation between order flow history and the direction of price moves. The universal price formation model exhibits a remarkably stable out-of-sample accuracy across a wide range of stocks and time periods. Interestingly, these results also hold for stocks which are not part of the training sample, showing that the relations captured by the model are universal and not asset-specific. The universal model-trained on data from all stocks-outperforms asset-specific models trained on time series of any given stock. This weighs in favor of pooling together financial data from various stocks, rather than designing asset- or sector-specific models, as is currently commonly done. Standard data normalizations based on volatility, price level or average spread, or partitioning the training data into sectors or categories such as large/small tick stocks, do not improve training results. On the other hand, inclusion of price and order flow history over many past observations improves forecast accuracy, indicating that there is path-dependence in price dynamics.	188.01535520102567
41.	In addition to materials, labor, equipment, and method, construction cost depends on many other factors such as the project locality, type, construction duration, scheduling, and the extent of use of recycled materials. Further, the fluctuation of economic variables and indexes (EV&Is), such as liquidity, wholesale price index, and building services index, causes variation in costs. These changes may increase or reduce the construction cost, are hard to predict, and are normally ignored in the traditional cost estimation computation. This paper presents an innovative construction cost estimation model using advanced machine-learning concepts and taking into account the EV&Is. A data structure is proposed that incorporates a set of physical and financial (P&F) variables of the real estate units as well as a set of EV&Is variables affecting the construction costs. The model includes an unsupervised deep Boltzmann machine (DBM) learning approach along with a softmax layer (DBM-SoftMax), and a three-layer back-propagation neural network (BPNN) or another regression model, support vector machine (SVM). The role of DBM-SoftMax is to extract relevant features from the input data. The role of the BPNN or SVM is to turn the trained unsupervised DBM into a supervised regression network. This combination improves the effectiveness and accuracy of both conventional BPNN and SVM. A sensitivity analysis was performed within the algorithm in order to achieve the best results taking into account the impact of the EV&I factors in different times (time lags). The model was verified using the construction cost data for 372 low- and midrise buildings in the range of three to nine stories. Cost estimation errors of the proposed model were much less than those of both the BPNN-only and SVM-only models, thus demonstrating the effectiveness of the strategies employed in this research and the superiority of the proposed model. (C) 2018 American Society of Civil Engineers.	188.0152744050069
42.	Heterogeneous face recognition (HFR) is a challenging problem in face recognition and subject to large textural and spatial structure differences of face images. Different from conventional face recognition in homogeneous environments, there exist many face images taken from different sources (including different sensors or different mechanisms) in reality. In addition, limited training samples of cross-modality pairs make HFR more challenging due to the complex generation procedure of these images. Despite the great progress that has been achieved in recent years, existing works mainly focus on HFR from only cross-modality image matching. However, it is more practical to obtain both facial images and semantic descriptions about facial attributes in real-world situations, in which the semantic description clues are nearly always obtained during the process of image generation. Motivated by human cognitive mechanisms, we naturally utilize the explicit invariant semantic description, i.e., face attributes, to help address the gap among face images of different modalities. Existing facial attributes-related face recognition methods primarily regard attributes as the high-level features used to enhance recognition performance, ignoring the inherent relationship between face attributes and identities. In this article, we propose novel coupled attribute learning for the HFR (CAL-HFR) method without labeling the attributes manually. Deep convolutional networks are employed to directly map face images in heterogeneous scenarios to a compact common space where distances are taken as dissimilarities of pairs. Coupled attribute guided triplet loss (CAGTL) is designed to train an end-to-end HFR network that can effectively eliminate defects of incorrectly estimated attributes. Extensive experiments on multiple heterogeneous scenarios demonstrate that the proposed method achieves superior performance compared with that of state-of-the-art methods. Furthermore, we make publicly available our generated pairwise annotated heterogeneous facial attribute database for evaluation and promoting related research.	188.0149951113817
43.	Broad learning system (BLS) has been proposed as an alternative method of deep learning. The architecture of BLS is that the input is randomly mapped into series of feature spaces which form the feature nodes, and the output of the feature nodes are expanded broadly to form the enhancement nodes, and then the output weights of the network can be determined analytically. The most advantage of BLS is that it can be learned incrementally without a retraining process when there comes new input data or neural nodes. It has been proven that BLS can overcome the inadequacies caused by training a large number of parameters in gradient-based deep learning algorithms. In this paper, a novel variant graph regularized broad learning system (GBLS) is proposed. Taking account of the locally invariant property of data, which means the similar images may share similar properties, the manifold learning is incorporated into the objective function of the standard BLS. In GBLS, the output weights are constrained to learn more discriminative information, and the classification ability can be further enhanced. Several experiments are carried out to verify that our proposed GBLS model can outperform the standard BLS. What is more, the GBLS also performs better compared with other state-of-the-art image recognition methods in several image databases.	188.0148422108781
44.	Since the development of food diaries could enable people to develop healthy eating habits, food image recognition is in high demand to reduce the effort in food recording. Previous studies have worked on this challenging domain with datasets having fixed numbers of samples and classes. However, in the real-world setting, it is impossible to include all of the foods in the database because the number of classes of foods is large and increases continually. In addition to that, inter-class similarity and intraclass diversity also bring difficulties to the recognition. In this paper, we solve these problems by using deep convolutional neural network features to build a personalized classifier which incrementally learns the user's data and adapts to the user's eating habit. As a result, we achieved the state-of-the-art accuracy of food image recognition by the personalization of 300 food records per user.	188.01458964453724
45.	Compression artifacts reduction (CAR) is a challenging problem in the field of remote sensing. Most recent deep learning based methods have demonstrated superior performance over the previous hand-crafted methods. In this paper, we propose an end-to-end one-two-one (OTO) network, to combine different deep models, i.e., summation and difference models, to solve the CAR problem. Particularly, the difference model motivated by the Laplacian pyramid is designed to obtain the high frequency information, while the summation model aggregates the low frequency information. We provide an in-depth investigation into our OTO architecture based on the Taylor expansion, which shows that these two kinds of information can be fused in a nonlinear scheme to gain more capacity of handling complicated image compression artifacts, especially the blocking effect in compression. Extensive experiments are conducted to demonstrate the superior performance of the OTO networks, as compared to the state-of-the-arts on remote sensing datasets and other benchmark datasets. The source code will be available here: https://github.com/bczhangbczhang/. (C) 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	188.0144157412269
46.	Image segmentation is the most fundamental part of computer vision, which is the foundation of all other methods of image processing. The quality of image segmentation technology will affect the subsequent processing considerably. Comparing with traditional image segmentation algorithms, image segmentation algorithm based on deep learning is constantly proposed, with high performance and efficiency. But there is also a lot of room for improvement. For example, key parts such as fastening bolt are usually small in size, polluted and covered, and do not have enough characteristic information, so it is difficult to obtain satisfactory results. These factors affect the accuracy of the test, which is easy to cause serious accidents. As traditional methods sometimes cannot meet the requirement of high-accuracy result, deep learning play a particularly important role in facing those problems. To solve the problem that traditional object recognition methods are not robust enough to extract image features, parts recognition accuracy is low, and segmentation is not possible, we have made some modifications based on Mask R-CNN. In this method, convolutional neural network is used to extract features from part images. Then we use some annotated images from dataset to fine-tuned Mask R-CNN network to guarantee the accuracy. At the same time, data enhancement and k-folding cross-validation are carried out to improve the robustness of the model. Finally, the result of part recognition and segmentation by building the experimental platform proves the significance of the method.	188.01425523902975
47.	Due to the extensive practical value of time series prediction, many excellent algorithms have been proposed. Most of these methods are developed assuming that massive labeled training data are available. However, this assumption might be invalid in some actual situations. To address this limitation, a transfer learning framework with deep architectures is proposed. Since convolutional neural network (CNN) owns favorable feature extraction capability and can implement parallelization more easily, we propose a deep transfer learning method resorting to the architecture of CNN, termed as DTr-CNN for short. It can effectively alleviate the available labeled data absence and leverage useful knowledge to the current prediction. Notably, in our method, transfer learning process is implemented across different datasets. For a given target domain, in real-world scenarios, relativity of truly available potential source datasets may not be obvious, which is challenging and rarely referred to in most existing time series prediction methods. Aiming at this problem, the incorporation of Dynamic Time Warping (DTW) and Jensen-Shannon (JS) divergence is adopted for the selection of the appropriate source domain. Effectiveness of the proposed method is empirically underpinned by the experiments conducted on one group of synthetic and two groups of practical datasets. Besides, an additional experiment on NN5 dataset is conducted. (C) 2020 Elsevier Ltd. All rights reserved.	188.01379888290353
48.	Loss functions play a key role in training superior deep neural networks. In convolutional neural networks (CNNs), the popular cross entropy loss together with softmax does not explicitly guarantee minimization of intra-class variance or maximization of inter-class variance. In the early studies, there is no theoretical analysis and experiments explicitly indicating how to choose the number of units in fully connected layer. To help CNNs learn features more fast and discriminative, there are two contributions in this paper. First, we determine the minimum number of units in FC layer by rigorous theoretical analysis and extensive experiment, which reduces CNNs' parameter memory and training time. Second, we propose a negative-focused weights-biased softmax (W-Softmax) loss to help CNNs learn more discriminative features. The proposed W-Softmax loss not only theoretically formulates the intra-class compactness and inter-class separability, but also can avoid overfitting by enlarging decision margins. Moreover, the size of decision margins can be flexibly controlled by adjusting a hyperparameter alpha. Extensive experimental results on several benchmark datasets show the superiority of W-Softmax in image classification tasks. (C) 2020 Elsevier Ltd. All rights reserved.	188.01317466121202
49.	But he's a human being, and a terrible thing is happening to him. So attention must be paid. He's not to be allowed to fall into his grave like an old dog. Attention, attention must be finally paid to such a person. Arthur Miller Work in the fields of bioethics and public health ethics over several decades has been theoretically diverse, but particular styles of theorizing, let alone individual theories, do have distinctive philosophical assumptions and discursive characteristics. For example, in the domain of clinical bioethics a strong emphasis has been given to respect for autonomous will-formation by individuals in medical decisions and behavioral choices directly affecting them. In the domain of public health ethics and policy bioethics, where debates over issues such as health access and financing and over mandatory vaccination policies are ongoing, there is a clash between an individualistic understanding of rights, liberty, and privacy, on the one hand, and a communitarian understanding of the common good and the health and well-being of society as a whole, on the other. Cutting across this spectrum of individualism and holism, there is another discernable array of approaches to theorizing and concept formation in bioethics. Two in particular are pertinent to this article. One may be called an 'applied' mode of bioethics, which is focused on applying moral principles and rules to specific situations of action and choice. A contrasting 'relational' mode of bioethics seeks to present normative interpretations of historically embedded patterns of agency, interdependency, and institutional structures of power. To be sure, many specific works of bioethics utilize both an applied and a relational approach, but I believe that this distinction is heuristically useful. It can alert us to the fact that seemingly univocal concepts, such as autonomy, justice, equality, dignity, and personhood, carry a different meaning when they are theorized as principles to be applied from when they are theorized as practices to be interpreted. In this article my aim is to advance the discussion of relational approaches within bioethics by an interpretive analysis of the concept of solidarity and the concept of care when seen as modes of moral and political practice. I single out solidarity for this discussion because the range of moral questions traditionally associated with the concept are normatively integral to many key issues with which health policy and public health must deal-such as just access to healthcare, civic and financial support for social insurance and social welfare policies, and the intergenerational justice issues that bedevil the transition to an aging society and the mitigation of global climate change. In bioethics and public health ethics today, solidarity should be taken seriously and not dismissed as an obsolete idea from a bygone political era, and a recent surge of interest in the concept attests to this. On the other hand, care is an extremely influential normative concept in bioethics and has been for several decades. But the praxis and institutional support for care, no less than those of solidarity, are vulnerable in the current ideological climate and need to be supported discursively and politically. The practices of care are also essential to the core problems with which health policy and public health must grapple. I believe that solidarity and care offer instructive constitutive contexts within which the moral identity of persons is grounded and articulated in recognition, affirming the moral standing of those oppressed as equal members of a moral community, and in attention, attesting to the moral presence and considerability of those vulnerable and in need. Solidarity constitutes just affirmation of the other as subject, not merely object; care constitutes just attention to the other in a cognate way as subject, not object. This recognition of, and attention paid to, persons as moral subjects, in turn, can politically motivate a society in three respects. The recognition of solidarity and the attention of care can prompt progressive change toward a democratic willingness: (a) to provide for equal respect for rights and dignity; (b) to provide the social resources and services needed for just health and well-being; and (c) to focus its creativity and wealth on the actualization of potential flourishing of each and all. As Carol Gould observes concerning solidarity on this score: 'the proliferation of solidarity relations that establish commonalities across differences, along with the linkages that develop among individuals and groups within solidarity movements, help to construct more universalistic conceptions of our obligations to each other.' Though much has been written on the protean concepts of solidarity and care, much still remains to be seen and said, for their ethical meaning and political significance change as they develop and manifest themselves in action over time. My discussion explores how persons and groups are recognized within the practices of solidarity and care; what stance or posture persons and groups take toward one another; and how their standing as free and equal members of a moral community is constituted and sustained by these practices. The guiding thread is right recognition of the full ethical standing of other human beings as subjects rather than as objects. Just recognition of moral standing and moral attention in solidarity and care is my explicit focus, finding the moral imagination and political will to sustain them, my background theme. Relational bioethics is a conceptually dynamic and rather eclectic field today, frequently drawing on paradigm-shifting work in moral and political philosophy and on conceptual innovations ongoing in the humanities and the social sciences, including feminist theories, critical theories of various kinds, and orientations informed by philosophical pragmatism and hermeneutics, among others. Inspired by several cognate modes of critical discourse, relational theorizing has turned away from both methodological and ethical individualism. Often, it is more concerned with diachronic (streaming over time) social practices than with synchronic (snapshot in time) individual acts. It favors what Margaret Urban Walker has called the 'expressive-collaborative' model of morality over the 'theoretical-juridical' model. It strives to place the agency of individuals within a constitutive context of meaning and interdependence. This context includes both dyadic and small group transactions among persons in direct contact and social, structural interdependencies growing out of institutionalized forms of power. Relational theorizing is a space of historical and cultural embeddedness and embodied living in the natural, material world. Moreover, due to this contextual perspective, relational theorizing and its discourse are reflexive in questioning their own philosophical grounding and epistemic legitimacy, and they are willing to move away from once solid convictions concerning objectivity, impartiality, and rational authority. All theory and praxis, on this view-including bioethics-inevitably reflects some positional perspective, especially when it most strenuously claims not to, and the best that can be done is to sustain a continuing engagement with different values and viewpoints over time. Closure of conflicting interpretations in the public space of question and answer is apt to be provisional and contingent. While chastening, this need not be an epistemological loss. Within such a critical reflexivity, possibilities open up for new ways of thinking about the basic object of study of ethics and for an emphasis on substantive aspects of ethical agency and value that have been relatively neglected heretofore. The object of study in bioethics (or in ethics generally) or in social science is not intuitively given or logically or methodologically determined. Settling on what should be taken as the unit of ethics analysis is the result of an on-going, contested process of interpretation, partly derived from available theoretical concepts, partly from the exercise of experience-based practical judgment. As social theorist Craig Calhoun argues, concerning this contest, we should 'see the process as basic and never ending, and [subject] it to our continuing attention, rather than [imagine] that it is settled once and for all'. When bioethics focuses on relational practices, its designated object of study becomes those patterns and structures of interrelated activity, choice, and the exercise of power in time. These patterns are understood dynamically, as well as diachronically, with emergent properties and functions taking shape contingently rather than deterministically. Dynamic patterns in social life and human action may at times be spontaneous or random. However, when these patterns endure they comprise 'practices', which may be defined as rule-based, value-laden forms of agency and activity in which diverse human capabilities or potentialities are actualized in the social and material worlds. Let us consider the elements of this definition more fully. First, social practices are structured sociologically by roles and relationships involving authority, power, distribution, and exchange. Governments, corporations, and hospitals are examples of institutionalized structures where social practices of various kinds take place. Social practices are also structured normatively by various conceptions of rightness, goodness, and value. Finally, social practices are experienced within lifeworlds of social-cultural meanings, where action-guiding reasons and motivations are formed, culturally mediated self- and group-identities are shaped, and ongoing reinterpretation of roles and relationships takes place. How are social practices so conceived possible and sustainable? Here the theoretical mediation between individualistic and communitarian orientations takes place. Diachronic social practices are made possible by moral agents who possess the ability to interpretively apprehend what other human beings are thinking in and through their agency, and to read the meaning such expressive agency conveys among agents as they interact together. A moral philosophy that took human beings to be radically solipsistic and opaque to one another would be unable to account for, let alone justify, its own discourse. A theory of practices presupposes the possibility of social communication and cultural hermeneutics. A practice is a form of activity that is valued in a society and governed by ethical norms. By engaging in these orderly, yet living, flexible activities, individuals pursue the attainment of excellence and seek to actualize potential capabilities. In this way, cultures and societies provide pathways for the development of flourishing lives well lived. It is through practices that virtues of character are developed, rights are respected and duties fulfilled, and beneficial collective consequences are pursued and obtained. To be sure, practices are conceptually constructed or 'theorized', as are notions like autonomous reason, but they are grounded in ongoing cultural traditions and experimental or innovative new modes of social cooperation. Practices are both embodied and enacted. In the embodiment of practices, they are informed by tacit knowing or habitus-Pierre Bourdieu stresses their phenomenological and pre-reflective aspects. In the enactment of practices, evaluative deliberations take place and reflective judgments are arrived at that shape future activity and the structure of subsequent lives-Alasdair MacIntyre stresses their aspects that mirror Aristotle's notion of phronesis or practical judgment. Drawing explicitly on the work of Simone Weil and implicitly on Emmanuel Levinas, David Wiggins suggestively and rather effusively locates solidarity at 'the root of the ethical'. His essay can be read as a strong reinterpretation of the object of ethical analysis or the moral point of view. He is not interested in offering a stipulative definition of solidarity or a classification of its various types. Solidarity names a fundamental awareness, arbitrary and uncalculating, and an ability to respond to a call to ethical action in the presence of another in peril-another who is a moral subject, a being with a visage, a gaze, an ontological claim to stake, a political inheritance to claim, a place of membership rightfully to occupy. In tune with considerations of this sort, I posit right recognition and attention at the center of my analysis of solidarity and care as moral practices. My approach is a modification of what has been called 'interpretive phenomenology' and has been well developed in the literature of nursing and nursing ethics. While it is clearly well designed for the study of care, I believe it can also throw important light on solidarity. Like philosophical phenomenology more broadly, interpretive phenomenology seeks to offer a deeper understanding of intentional activity and its aim than agents themselves may explicitly possess; an understanding that may be more perspicacious than their own sense of what they are doing or bringing about. The following characterization of the general approach by Patricia Benner informs my discussion of solidarity and care: The understanding sought in interpretive phenomenology considers historical change, transformations, gains, losses, temporality, and context horizontal ellipsis The ethos embedded in [interpretive] phenomenology is respect for the social and cultural nature of being human. Human practices, skills, habits, meanings, and, in particular, recognition practices allow for the other to be encountered and made visible. When unarticulated, taken-for-granted practices and meanings fade from our social ecology and the social fabric of our lives, and we lose what they enable us to see, create, and represent. As I seek to develop it, this interpretive approach involves seeing human beings and doings in and through relationships of recognition, mutuality, respect and concern, need and vulnerability. In this relational dynamic, the watchword is the variety, not uniformity, of transactional agency and interdependent positions and projects. The context for the importance of right recognition and attention in solidarity and care is pluralism, reflexive perspectivalism, and a restructuring of economic and social institutions that would open society to new forms of inclusive, discursive engagement. Solidarity promotes these conditions and values as a future demand and promise; care honors them as a precondition for the possibility of the healing and meaning it facilitates. Perhaps I can clear the way for my account of solidarity offered below by briefly mentioning some contrasting and complementary approaches. In recent studies of solidarity, two overlapping concerns have been salient. One is to counter interpretations of solidarity that make it unduly insular and defined by exclusive, closed bonds of shared experience or loyalty. The other is to counter interpretations of solidarity that render it unduly political in the sense of being instrumental and strategic rather than viewing it as a form of life that can give expression to a normative moral or political ideal. The first problem of overly thick solidarity in which certain beliefs and values are so deeply shared that they are beyond debate, is addressed by Jodi Dean. She presents a critique of what she calls 'conventional solidarity', and defines a counter-notion of 'reflective solidarity'-a space of mutuality in which in which genuine difference, discursive conflict, and pluralism would be at home and neither uncritical consensus nor the predominance of only one group of voices would prevail. Focusing on the second problem, Carol Gould and Craig Calhoun both seek ways of introjecting a cosmopolitan orientation into the practice of solidarity. Gould does so by aligning it with justice and human rights in the formation of global networks of political activity. And Calhoun, whose emphasis is more on discursive agency, does so by exploring how a more universal kind of solidarity can emerge from the ongoing discourse within the public sphere. In contrast to these concerns that the bonds of solidarity will be overly tight and narrowly nationalistic, ethnic or localized, Avery Kolers is concerned that bonds of solidarity will not be thick enough to override the primacy of individual judgment and conscience. Then the practice of solidarity will be too weak and will ultimately break down into something irresolute and individualistically self-serving, whether in the authentic form of Quaker witness inspired by inner light or the inauthentic moral narcissism of radical chic. 'Conscience just isn't enough to enable us to comprehend the nature of grave evils or our role in them,' he writes. 'Ultimately we must overcome conscience in favor of solidarity horizontal ellipsis Conscience is directed at ensuring one's own moral integrity rather than at fostering the political movement that could secure moral results that challenge one's standing. ' Solidarity on Kolers's view is about taking sides and deferring to the views of others concerning why and how their rights and interests should prevail. It is a political practice that attempts to achieve moral outcomes, rather than one that is constitutive of moral norms. It gives voice primarily to those for whom solidarity is enacted, rather than containing within its own practice the standard of parity of voice and agency toward which it aims as an achieved political condition for all. Thus Kolers defines solidarity as 'reason-driven political action on other's terms'. This appeal to deference sets him apart from the more dialogic and egalitarian interaction envisioned by Dean, Gould, and Calhoun in their various ways. He is taken by the danger that both reflective or dialogic communication and the self-correcting function of networks of solidarity will subtly reinforce forms of domination and power instead of overcoming them. By integrating the notion of right recognition of the moral standing of others, I am trying to understand thick relationships of community and more abstract and principled commitments to justice and respect for persons as orientations that can mutually inform and refine one another. My strategy is to conceptualize the practice of solidarity in developmental and transformational ways so that the practice of solidarity contains within itself a shaping of moral psychology and moral learning, from relatively thin commitments at first, to increasingly strong commitments over time, as a deeper understanding of the other fuels a kind of political and ethical maturity in oneself. Important groundwork for the perspective on solidarity that I offer here has been laid by Barbara Prainsack and Alena Buyx, whose work provides an institutional and structural analysis of solidarity, distinguishing among various levels of social organization within which it can be practiced. I agree that in understanding solidarity as a practice one cannot ignore the interaction between agency and the institutional structures within which agency takes place. Nor should one take solidarity as an abstract regulative idea rather than a concept whose philosophical and motivational force develops in and through active social practices. Nonetheless, my own approach tends to be more moral psychological, stressing the cognitive and motivational bases for a growth of understanding and cooperation among self and other in the practice of solidarity. Among those actively working on the concept, my thinking about solidarity is perhaps closest to that of Andrew Mason, who is primarily interested in the concept and practices of community, but who crucially brings community and solidarity into close theoretical proximity. He offers a study of what might be called 'comparative relationalities', and I am attempting to follow along these lines here with a comparative discussion of solidarity and care. For his part, Mason deploys solidarity and community together not so much by characterizing solidarity as more intense and intimate than it is often taken to be, nor by making community less so, but by circumventing a dichotomous view (the legacy, one might say, of Aristotle and Kant alike) altogether. He builds solidarity into a normative conception of community, and his formulation is worth considering at length: A community is not just a group of people who share a range of values and a way of life, identify with the group and its practices, and recognize each other as fellow members. In order for a group to constitute a community in the moralized sense, two further conditions need to be met. First, there must be solidarity between its members. 'Solidarity' is a multiply ambiguous notion, but in the sense I intend it consists in mutual concern: minimally this means that members must give each other's interests some non-instrumental weight in their practical reasoning. horizontal ellipsis Second, there must be no systematic exploitation or (on some versions) no systematic injustice. My own specific concern is to accentuate the normative aspects of this type of interpretation of the practices of solidarity and care: how persons and groups are recognized within these practices; what stance or posture persons and groups take toward one another; and how their standing as free and equal members of a moral community is constituted and sustained by these practices. The practice of solidarity begins with the latent possibilities of a given place at a given time. It builds on senses of historical memory and tradition, and it feeds on the gratitude felt when one remembers the service and contributions that others have made to one's way of life in the past, or when one has the moral imagination to foresee the contributions that newcomers can make in the future. Solidarity begins with the recognition of reciprocal and symbiotic interdependence among members of a moral community and then intervenes in-interrupts-an ongoing community when it is unjustly exclusionary and refuses to recognize the moral standing of some within it. Solidarity inherently leads us to view our own lives and agency as bound together with the rights, well-being, health, and dignity of others here and now. I take the fundamental gesture and stance of solidarity to be standing up beside another, thereby signaling publicly one's recognition of that person's (or group's) moral standing. In addition, there are three distinct postures agents assume toward others whose moral standing is in need of defense. These may be called standing up for, standing up with, and standing up as.Standing up for. This mode of solidarity assumes the stance of advocacy. It involves assisting, defending, and pleading the cause of the other. It stands up against exclusion and oppression. In general discussions of solidarity, the other is often taken to be a stranger, but that is not necessary; it makes perfect sense to talk about being in solidarity with friends and acquaintances. Moreover, the other need not be a human individual: one can stand up for other species, an ecosystem, or a cultural way of life. What is crucial is that there is some kind of power or knowledge differential between self and other in a relationship of solidarity and some kind of injustice or danger impinging upon the life of the other. This kind of solidarity can advocate for improved treatment or benefits for an oppressed or vulnerable group, but does not necessarily challenge the underlying basis for their subordinate social status. Yet, if it does not undermine structural inequalities, standing up for solidarity can perpetuate subordination rather than achieve equality.Standing up with. Solidarity as standing up with takes another step in the recognition of moral standing. Moving from the standpoint for to the standpoint with requires deeper engagement with the experience and lifeworld of the other. The difference created by the specificity of lifeworlds nonetheless resides within an overarching interpretive commonality, namely, the ability to understand lifeworlds other than one's own. Without such understanding, others cannot truly be treated with respect, they can only be tolerated, benignly neglected, not interfered with. This closer understanding can tend to humanize and personalize the relationship further, and the potential benefit becomes more reciprocal. Those who stand with others may find their own initial prejudgments concerning others transformed by the encounter. Those who practice solidarity must open themselves to the opportunity-and risk-it poses. Relating to other people or groups in the specificity of their values and vocabularies of self-interpretation can simultaneously develop respect for the specific standpoints of others. It can also enable a greater capacity for intercultural and transpersonal interpretive understanding broadly within a democratic political culture and way of life.Standing up as. The third standpoint is solidarity as standing up as. Obviously this suggests a yet stronger degree of identification between the providers of solidaristic support and the recipients of such support. The solidarity of standing up as involves finding a kind of covering connection that does not negate diversity among individuals at all, but rather establishes the grounds of its respect, protection, and perpetuation. To move through the trajectory of solidarity is to move in the direction of greater imaginative creativity and range in the moral life. Standing up for depends upon a kind of abstract moral commitment to support the application of general norms to the life situation of the other as a being with a certain inherent moral status. It thereby embraces shared moral norms (equal protection of the law, universal human rights), but without necessarily embracing the lived reality and distinct perspectives of the other. Standing up with involves adopting a perspective that is more internal to the lifeworld and the contextually meaningful agency of the other. Standing up as returns to generality, in the sense of a recognition of common humanity, a global or planetary membership, but also moves one imaginatively more deeply into a comprehension of difference and the distinctive individuality of the other. As the moral recognition of the other is altered by this interpretive journey, so is the moral imagination of the self. Arguably a growth in one's capacity to project oneself imaginatively into the perspective and viewpoint of the other person, and a growth in moral awareness or the ability to see connections previously unseen are plausible outcomes of the interpretive transformation effected by the trajectory of solidarity. The practices of solidarity mainly arise in the face of morally aberrant and unjust situations that are stifling human potential and where those being oppressed or suppressed need mobilized support and recognition. What the recipients of solidarity need, and the agents of solidarity provide, is affirmation and tangible support. In contrast, what the recipients of care need, and the agents of care provide, is attention. Though closely related and mutually reinforcing in many ways, solidarity and care are not the same, as affirmation and attention are different stances with different moral significance and developmental potentials. The practices of care are premised on situations that are neither aberrant nor unjust per se but are an inherent part of human species-being. Like solidarity, care also deepens the moral imagination of both those who care for others and those who are cared for by others. If focusing on solidarity shifts away from individualism and independence toward mutuality and interdependence, focusing on care shifts away from the individualism of self-reliance to an individuality validated by reliance on others. The practices of care are called forth where a common background condition of potential fragility, vulnerability, insufficiency, and mortality take center stage in the lives of persons in need or trouble and in the lives of those around them. Care offers a universalism that is concrete and thick. It is quite possible to imagine (and to find close empirical approximations of) societies where solidarity is absent. Not so with care. Even the subjugated and impoverished society of the Ik so strikingly (and controversially) described by Colin Turnbull, retained ways of caring for their very young, if not for their very old. They almost, but not quite, lost their cultural concept of care. Care theorists, such as Eva Feder Kittay, point out that universalism is biologically grounded on the necessity of maternal care. Every living human being has in common the fact that once they were cared for by someone (female or male) who took on a mothering role and relationship with them. This commonality extends backward in time. All persons who cared as a mother for a child were able to do so only because mothering had been extended to them by a previous generation. Human society fundamentally depends on the production and reproduction of this structure of care-giving roles and relationships. Equality, Kittay argues, is not based on properties that an individual possesses by virtue of who that individual is, but instead on properties that one possesses by virtue of properties that another person has or once had. In keeping with this, care theorist Joan Tronto also views care as a concrete universal, or a 'species activity' and has proposed that caring: includes everything that we do to maintain, continue, and repair our 'world' so that we can live in it as well as possible. That world includes our bodies, our selves, and our environment, all of which we seek to interweave in a complex, life-sustaining web. This provides yet another reason to distinguish between solidarity and care. Solidarity is based on who the other is as an individual human being and on 'properties' they possess, if by properties we mean something like their moral standing and considerability, their entitlement to dignity and to respect for their human rights. When it comes to care, however, we are dealing not so much with recognition due to persons as with the ongoing, intergenerational, evolutionary web of living that all practices of care at any given moment are a part of. Solidarity is a response that unjustly denied recognition and moral standing calls for. Caring is a response that need calls forth, drawing on cognitive commitments and emotional capabilities that previous practices of caring have made possible. Care, like all the practices that relational bioethics examines and evaluates, should not be defined as good or just in all circumstances and in all its forms. The important work of ethical specification and judgment is skipped over when we equate care with virtues such as agape (selfless love of the other) and caritas (charity), or with social emotions such as other-regarding altruism or sympathy. Thus it is important to ask what substantive values should inform caring as a moral practice and its effects. How best to describe the stance and intentionality of caring, its transformative moral psychological effects on agents of care and recipients, and its role in governing structural and institutional power so as to mitigate the tension between social order and social diversity? With these questions in mind, I turn again to construct a developmental moral phenomenology of the practice of care. Before presenting my own account, I should note that Tronto has already offered something akin to what I have in mind. She distinguishes among caring about, taking care of, care giving, and care receiving. Caring about denotes the initial recognition of another's need for care. Taking care of involves assuming responsibility for the determined need of the other and undertaking steps to meet that need. Care giving involves assuming a more direct, physical, and intimate role in the practices of care. Need can be recognized and attended to in many distanced and indirect ways, but giving care is hands-on, physical work. It signifies a new level of commitment and engagement than the other forms the activity of care can take. Finally, care receiving as a distinct component of the practice of care recognizes that the recipient will often be a responsive agent in the care relationship. These distinctions are helpful, particularly in the context of Tronto's concern with the ethically and democratically appropriate institutionalization of the practices of care in a society as a whole. I seek, on the other hand, to explore a structured growth of moral awareness that may be illuminating to ascribe to the praxis of care, as I have tried to do with solidarity. The fundamental stance of the practice of care is to pay attention to. Just as right recognition of personhood and moral standing is fundamental to the solidaristic posture of standing up beside, so too the directed gaze of attention is fundamental to the posture of care. When someone, a student or a distracted friend during a conversation, is called upon to pay attention, their focus shifts and even their bodily orientation may change: they open their eyes, they listen actively, they lean in. Right recognition here comes from becoming visible to another as a sign of acknowledgment and respect. In some cultures and settings, paying attention to someone takes the form of making eye contact as a sign of such respect; in others, deliberately not making eye contact has the same significance. Both are gestures and postures of care. In this sense, the propensity to attend, to care, is not primarily biological or reflexive; it is a mode of culturally meaningful agency, it is a wink rather than a blink. Standing up beside the oppressed-and up against the oppressor-is a gesture that extracts 'payment' in the form of public witness, which can incur negative sanctions or give one an aura of virtue by association. Paying attention to is also not cost-free in terms of its effects on plans in one's life or on other persons, whom the practice of care displaces from one's attention. Solidarity sets priorities, care balances and reshuffles them. Finally, on this account of the moral phenomenology of care, the presence of physical or psychological limitation or impairment is not primarily what calls forth the duty to care, although it is often the trigger for an intensified focus of attention and the commencement of new caring relationships and services. The moral raison d'etre of paying attention to is the evil of invisibility, disregard, and abandonment. Willie Loman's wife, Linda, understood this in Death of a Salesman, when she called upon her son to care for his father. 'Attention must be paid.' She was not asking him to help Willie with his medications. The need for care is indeed universal, both biologically and culturally, because it responds to vulnerability, suffering, and mortality. However, being erased and deserted, reduced to bare self-reliance, having to fend for oneself alone-these conditions are neither universal nor inevitable. They are potentials in the human condition that the practice of care was morally and culturally invented to prevent, just as the practice of solidarity was invented to prevent the evil of misprision. And failure to prevent these evils not only diminishes the humanity of those who did not receive attention and recognition, but also diminishes those who failed to give them. There are three distinct postures that agents of care assume toward others in need. No doubt there are many more, but I want to single these out here. I shall call them attentive rehabilitation, attentive companionship, and attentive commitment. These moments in the practices of care are relational interactions between individuals or groups, with each side having voice (to the extent possible) and engaging in a give and take of initiative and response. However, as with my analysis of solidarity, this is presented primarily from the perspective of the agent of care rather than the other receiving care.Attentive rehabilitation of the other. To care is to take steps to rehabilitate or return the other in need to a situation of enhanced living or, as Tronto aptly puts it, repairing the other's world. If return to the status quo ante is impossible, rehabilitative attention becomes a project of helping to construct a new mode of life that will be meaningful and sustainable for the other, who will then go on to live with-and in spite of-social or physical limitations. This is the aspect of care that is perhaps closest to care giving and care provision in a professional sense. It is certainly based on respectful recognition of the moral standing of the patient, but its main hallmark is efficacy in the restoration of function. It is also the aspect of care that is closest in intention to solidarity, for the attention paid here is largely affirming, and the line I have tried to draw between affirmation and attention is blurred. But to probe more deeply into the dimensions of care that have to do with suffering and loss of self and meaning, we need to move beyond restoration and repair.Attentive companionship with and for the other. Companionship is an aspect of care that includes, but is not limited to, physically spending time together and direct communication, as humanly important as they are. Companionship, in the sense I am trying to get at, lays the groundwork for a developing sense of promise, presence, and assurance in the minds and hearts of both the agent of care and the other. Companionship recognizes the evil of abandonment and is one of the most powerful answering responses to this evil on behalf of the human good. It is difficult to say what concept best conveys the aspect of care that can provide this reassurance and abiding sense of connection between and among individuals and groups. Promise connotes perhaps too formal and legalistic a sense. Loyalty connotes something perhaps overly psychological. Friendship is tempting but again may suggest an affection or emotional bond that is stronger than I want to convey for this aspect of care.In any case, the reassurance of a promise of non-abandonment is what is built into this mode of attentiveness. Note that this reassurance applies, albeit differently, to both the agent and the recipient of care. My notion is that the suffering experienced by those with unmet needs for care takes place against an ever-present prospect of being left alone. Those young and well often ask to be left alone, not realizing truly what they are inviting, when what they actually want is more privacy and a less intrusive care presence. Caring as attentive companionship makes the grim prospect of abandonment recede in the other's imagination and hence palliates the suffering-often in the form of dread, anxiety, and loss of self-confidence and self-esteem-they experience.To move into a mode of attentive companionship in the care process is clearly a step beyond rehabilitation. What prompts such a step, or better, what is germinated by it? My answer is a new sense of gratitude in the moral imagination of the agent of care. It may be the gratitude felt for the newly arrived life of an infant, and the realization of how vital the assurance of non-abandonment will be to the developmental flourishing of the child. It may be intergenerational gratitude that is reciprocal, as when adult children alter their own lives and priorities to assure companionship to an ailing or lonely parent. It may be a sense of obligation or debt based on remembering the constructive activities of the other, which indirectly has been of significant social and individual benefit to the attentive companion. This is the case, for example, in care-providing institutions that serve military veterans, and this moral sensibility could indeed be extended to all, military and non-military alike, who have sacrificed for the sake of public service. Or it may be itself a form of solidarity at the heart of the practice of care, because it is based on recognition of the human value of rescuing a person from fear and despair to give them a better chance of flourishing in the future.Attentive commitment to the other. This represents a stronger and deeper sense of caring connection, in which the caring agent has internalized a stronger sense of duty and embraced a longer-term, and maybe more arduous, promise to the care recipient. However, the notion of care as attentive commitment to, precisely because it takes in a longer time horizon, can bring out the structural and public policy dimensions of the practice of care, as well. The fact is that individuals and private groups (like families) cannot actually sustain this modality of care without significant social, economic, and institutional support. Part of their commitment would be to work toward building systems of public provision for care services in their role as democratic citizens. Indeed, the politics of social insurance and long-term care policy in the United States would be altered if millions of unpaid family care givers could find the information, time, and energy to mobilize in favor of new financing and service delivery systems. To the extent that we want to develop an ecology of care-the creation of a cultural ethos and an institutional framework that promotes and supports practices of care not only in the household and family but also in the public sphere and the civil society-then we must link practices of care to forms of democratic political reform to make society more just, equitable, and conducive to health and well-being. Within the broader political economy and social welfare policy of a nation, paying attention in private life and in public policy-civic care-can reinforce one another. The practice of care can sometimes be imperious and domineering. And all too often caring becomes merely custodial. Yet, when it realizes its full moral promise, care offers nurture, protection, provision, and support for the other. It does not so much domineer as give the person receiving it a new insight about his or her own life. Since the need for care often follows injury, illness, and loss of various kinds, care offers hope through a new way of seeing the positive possibilities present in a given situation. It sustains purpose in the face of diminution. Care among humans is a transaction among individuals who are the authors of their own acts and lives, despite their need, impairment, or limitations. But they are symbiotic, not solipsistic, authors. Like solidarity, care is grounded in the gratitude felt when one recognizes the service and contributions that others have made to one's way of life. And like the practice of solidarity, the practice of care interrupts an ongoing form of life in order to be present with another in the face of their need, vulnerability, and suffering, finally winning through to a life well lived. Solidarity and care can arise developmentally out of an engagement with the vocation of repairing a needful, vulnerable, responsive world. The author declares no conflict of interest. Miller, A. (1967). Death of a salesman. New York, NY: Viking Press, Act 1, 56. For example see reflections on the field by Callahan, D. (2012). In search of the good: A life in bioethics. Cambridge, MA: MIT Press; Fox, R. C., & Swazey, J. (2008). Bioethics observed. New York, NY: Oxford University Press; Brody, H. (2009). The future of bioethics. New York, NY: Oxford University Press. For related perspectives see, Lindemann, H., Verkerk, M., & Walker, M. U. (Eds.). (2009). Naturalized bioethics: Toward responsible knowing and practice. New York, NY: Cambridge University Press. I present an argument along these lines in Jennings, B. (2016). Reconceptualizing autonomy: A relational turn in bioethics. Hastings Center Report, 46, 11-16. I use the term 'considerability' in reference to Goodpaster, K. (1978). On being morally considerable. The Journal of Philosophy, 75, 308-325. Gould, C. G. (2007). Transnational solidarities. Journal of Social Philosophy, 38, 148-164, p. 162. Transformative work in this area includes Code, L. (2006). Ecological thinking: The politics of epistemic location. New York, NY: Oxford University Press; Gergen, K. J. (2009). Relational being: Beyond self and community. New York, NY: Oxford University Press; Nedelsky, J. (2011). Law's relations: A relational theory of self, autonomy, and law. New York, NY: Oxford University Press. For a classic discussion see Lukes, S. (1985). Individualism. New York, NY: Blackwell Publishing. See Walker, M. U. (1998). Moral understandings. New York, NY: Routledge, pp. 7-14 and passim. See also Rorty, A. O. (1988). Mind in action (pp. 271-298). Boston, MA: Beacon Press. Ackerly, B. A. (2000). Political theory and feminist social criticism. Cambridge, UK: Cambridge University Press. Noe, A. (2012). Varieties of presence. Cambridge, MA: Harvard University Press; Pitts-Taylor, V. (2013). I feel your pain: Embodied knowledges and situated neurons. Hypatia, 28, 852-869. Calhoun, C. (1995). Critical social theory (p. 65). Oxford, UK: Blackwell. See Taylor, C. (1995). Philosophical arguments (pp. 165-180). Cambridge, MA: Harvard University Press. Habermas, J. (1987). The theory of communicative action (2 vols., pp. 113-197). Boston, MA: Beacon Press. For a discussion of this theory see Finlayson, J. G. (2005). Habermas: A very short introduction. New York, NY: Oxford University Press. Hutto, D. D. (2008). Folk psychological narratives: The sociocultural basis of understanding reasons. Cambridge, MA: MIT Press. See Prainsack, B., & Buyx, A. (2017). Solidarity in biomedicine and beyond (pp. 43-52). Cambridge, UK: Cambridge University Press. Bourdieu, P. (1990). The logic of practice. Stanford, CA: Stanford University Press. MacIntyre, A. (2007). After virtue (3rd ed., pp. 187-203). Notre Dame, IN: University of Notre Dame Press. Wiggins, D. (2008). Solidarity and the root of the ethical. The Lindley Lecture. Lawrence: University of Kansas. Retrieved from http://hdl.handle.net/1808/12420 This argument and the following discussion of the dynamics of solidarity draw upon Jennings, B., & Dawson, A. (2015). Solidarity in the moral imagination of bioethics. Hastings Center Report, 45, 31-38. Benner, P. (Ed.). (1994). Interpretive phenomenology: Embodiment, caring, and ethics in health and illness. Thousand Oaks, CA: Sage Publications. Ibid., p. xv (emphasis added). Dean, J. (1996). Solidarity of strangers. Berkeley: University of California Press. Gould, op. cit. note 5. Calhoun, C. (2002). Imagining solidarity: Cosmopolitanism, constitutional patriotism, and the public sphere. Public Culture, 14, 147-171. Kolers, A. (2016). A moral theory of solidarity (pp. 13, 24). New York, NY: Oxford University Press (emphasis in the original). Ibid., p. 50. See Prainsack & Buyx, op. cit. note 16; Prainsack, B., & Buyx, A. (2012). Solidarity in contemporary bioethics-Towards a new approach. Bioethics, 26, 343-350; Prainsack, B., & Buyx, A. (2011). Solidarity: Reflections on an emerging concept in bioethics. London, UK: The Nuffield Council. Mason, A. (2000). Community, solidarity, and belonging: Levels of community and their normative significance (p. 27). Cambridge, UK: Cambridge University Press. The terminology related to care is more complex and varied, in English, than that related to solidarity. I have chosen to use the term 'care' rather than resort to terms such as caring, care giving, care providing, and the like. When conjoined with the concept of a practice, care should be understood always to connote a dynamic pattern of agency, intention, and action over time. For my purposes in this article, this pattern and its consequences are more important than specific acts performed within practices of care, such as direct physical assistance with activities of everyday living, psychological assistance, ensuring comfort and safety, and the like. Care is touching, but as John Dewey pointed out, it is also minding. See Boydston, J. A. (Ed.). (2008). Art as experience. In The Later Works of John Dewey, 1925-1953 (Vol. 10, p. 68). Carbondale: Southern Illinois University Press. See Held, V. (2006). The ethics of care: Personal, political and global. New York, NY: Oxford University Press. Turnbull, C. M. (1972). The mountain people. New York, NY: Simon and Schuster. Diamond, C. (1988). Losing your concepts. Ethics, 98, 255-277. Kittay, E. F. (1999). Love's labor: Essays on women, equality and dependency. New York, NY: Routledge. Tronto, J. (1994). Moral boundaries: A political argument for an ethic of care (p. 103). New York, NY: Routledge (emphasis in the original). For an insightful discussion of this definition see Puig de la Bellacasa, M. (2017). Matters of care: Speculative ethics in more than human worlds (pp. 4-13). Minneapolis: University of Minnesota Press. Tronto, J. (2013). Caring democracy: Markets, equity, and justice (pp. 105-108). New York, NY: New York University Press. INTRODUCTION THINKING AND ACTING THROUGH PRACTICES SOLIDARITY AND CARE SOLIDARITY THE MORAL TRAJECTORY OF SOLIDARITY CARE THE MORAL TRAJECTORY OF CARE CONCLUSION CONFLICT OF INTEREST Footnotes Many working in bioethics today are engaging in forms of normative interpretation concerning the meaningful contexts of relational agency and institutional structures of power. Using the framework of relational bioethics, this article focuses on two significant social practices that are significant for health policy and public health: the practices of solidarity and the practices of care. The main argument is that the affirming recognition of, and caring attention paid to, persons as moral subjects can politically motivate a society in three respects. The recognition of solidarity and the attention of care can prompt progressive change toward a democratic willingness: (a) to provide for equal respect for rights and dignity; (b) to provide the social resources and services needed for just health and well-being; and (c) to focus its creativity and wealth on the actualization of potential flourishing of each and all. Solidarity is discussed as a morally developmental stance that moves from standing up for another, standing up with another, and standing up as another. Care is discussed as a morally developmental stance that moves from the attentive rehabilitation of another, attentive companionship with and for another, and attentive commitment to another.	188.01299738281998
50.	Deep Learning (DL) networks are recent revolutionary developments in artificial intelligence research. Typical networks are stacked by groups of layers that are further composed of many convolutional kernels or neurons. In network design, many hyper-parameters need to be defined heuristically before training in order to achieve high cross-validation accuracies. However, accuracy evaluation from the output layer alone is not sufficient to specify the roles of the hidden units in associated networks. This results in a significant knowledge gap between DL's wider applications and its limited theoretical understanding. To narrow the knowledge gap, our study explores visualization techniques to illustrate the mutual information (MI) in DL networks. The MI is a theoretical measurement, reflecting the relationship between two sets of random variables even if their relationship is highly non-linear and hidden in high-dimensional data. Our study aims to understand the roles of DL units in classification performance of the networks. Via a series of experiments using several popular DL networks, it shows that the visualization of MI and its change patterns between the input/output with the hidden layers and basic units can facilitate a better understanding of these DL units' roles. Our investigation on network convergence suggests a more objective manner to potentially evaluate DL networks. Furthermore, the visualization provides a useful tool to gain insights into the network performance, and thus to potentially facilitate the design of better network architectures by identifying redundancy and less-effective network units.	188.01275020165636
51.	Future Internet is expected to meet explosive traffic growth and extremely complex architecture, which tend to make the traditional NTC strategies inefficient and even ineffective. Inspired by the latest breakthroughs of AI and its power to address large-scale and complex difficulties, the network community has begun to consider shifting the NTC paradigm from legacy rule-based to novel AI-based. As an applied inter-discipline, design and implementation are important. Although there have been some preliminary explorations along this frontier, they are either limited by only envisioning the prospects, or too scattered to provide high-level insight into a general methodology. To this end, we start with the domain knowledge relationships of AI and NTC, summarizing a baseline workflow toward deep reinforcement learning, which will be the dominant method for the AI-NTC paradigm. On top of that, we argue that AI-NTC training and running must be carried out in online environments in closed-loop fashion for the purpose of putting ti into practice. A series of challenges and opportunities are discussed from a realistic viewpoint, and a set of new architecture and mechanism to enable the online and closed-loop AI-NTC paradigm are proposed. Hopefully, this work can help the AI community to better understand NTC and the NTC community to better live with AI.	188.0123364900258
52.	A reflex is a simple closed-loop control approach that tries to minimize an error but fails to do so because it will always react too late. An adaptive algorithm can use this error to learn a forward model with the help of predictive cues. For example, a driver learns to improve steering by looking ahead to avoid steering in the last minute. In order to process complex cues such as the road ahead, deep learning is a natural choice. However, this is usually achieved only indirectly by employing deep reinforcement learning having a discrete state space. Here, we show how this can be directly achieved by embedding deep learning into a closed-loop system and preserving its continuous processing. We show in z-space specifically how error backpropagation can be achieved and in general how gradient-based approaches can be analyzed in such closed-loop scenarios. The performance of this learning paradigm is demonstrated using a line follower in simulation and on a real robot that shows very fast and continuous learning.	188.0122007447788
53.	Face recognition "in the wild" has been revolutionized by the deployment of deep learning-based approaches. In fact, it has been extensively demonstrated that deep convolutional neural networks (DCNNs) are powerful enough to overcome most of the limits that affected face recognition algorithms based on hand-crafted features. These include variations in illumination, pose, expression, and occlusion, to mention some. The DCNNs discriminative power comes from the fact that low- and high-level representations are learned directly from the raw image data. As a consequence, we expect the performance of a DCNN to be influenced by the characteristics of the image/video data that are fed to the network, and their preprocessing. In this paper, we present a thorough analysis of several aspects that impact on the use of DCNN for face recognition. The evaluation has been carried out from two main perspectives: the network architecture and the similarity measures used to compare deeply learned features; and the data (source and quality) and their pre-processing (bounding box and alignment). The results obtained on the IARPA Janus Benchmark-A, MegaFace, UMDFaces, and YouTube Faces data sets indicate viable hints for designing, training, and testing DCNNs. Considering the outcomes of the experimental evaluation, we show how competitive performance with respect to the state of the art can be reached even with standard DCNN architectures and pipeline.	188.01201302969875
54.	Image-to-image translation has drawn great attention during the past few years. It aims to translate an image in one domain to a target image in another domain. However, three big challenges remain in image-to-image translation: (1) the lack of large amounts of aligned training pairs for various tasks; (2) the ambiguity of multiple possible outputs from a single input image; and (3) the lack of simultaneous training for multi-domain translation with a single network. Therefore in this paper, we propose a unified framework for learning to generate diverse outputs using unpaired training data and allow for simultaneous multi-domain translation via a single model. Moreover, we also observed from experiments that the implicit disentanglement of content and style could lead to undesirable results. Thus we investigate how to extract domain-level signal as explicit supervision so as to achieve better image-to-image translation. Extensive experiments show that the proposed method outperforms or is comparable with the state-of-the-art methods for various applications.	188.01183684175456
55.	The decision-making ability of deep reinforcement learning has been proved successfully in a variety of fields. Here, we use this method for precise character detection by making tight bounding boxes around the Chinese characters in historical documents. An agent is trained to learn the control policy of fine-tuning a bounding box step-by-step through a Markov Decision Process. We introduce a novel fully convolutional network with position-sensitive Region-of-Interest (RoI) pooling (FCPN). The network receives character patches as input without fixed size, and it can fuse position information into the features of actions. Besides, we propose a dense reward function (DRF) that provides excellent rewards according to different actions and environment states, improving the decision-making ability of the agent. Our approach is designed as a universal method that can be applied to the output of all character-level or word-level text detectors to obtain more precise detection results. Application to the Tripitaka Koreana in Han (TKH) and Multiple Tripitaka in Han (MTH) datasets confirm the very promising performance of this method. In particular, our approach yields a significant improvement under a large Intersection over Union (IoU) of 0.8. The robustness and generality are also proved by experiments on the scene text datasets ICDAR2013 and ICDAR2015. (C) 2020 Elsevier Ltd. All rights reserved.	188.0116571711096
56.	Cardiac electrophysiology (EP) models achieved good progress in simulating cardiac electrical activity. However numerical issues and computational times hamper clinical applicability of such models. Moreover, personalisation can still be challenging and model errors can be difficult to overcome. On the other hand, deep learning methods achieved impressive results but suffer from robustness issues in healthcare due to their lack of physiological knowledge. We propose a novel approach which is based on deep learning in order to replace numerical integration of partial differential equations. This has the advantage to directly learn spatio-temporal correlations, which increases stability. Moreover, once trained, solutions are very fast to compute. We present first results in state estimation based on few measurements and evaluate the forecasting power of the trained network. The proposed method performed very well on this preliminary evaluation. It opens up possibilities towards data-driven personalisation, to overcome model error by learning from the data.	188.01157078105697
57.	Emotions widely affect human decision-making. This fact is taken into account by affective computing with the goal of tailoring decision support to the emotional states of individuals. However, the accurate recognition of emotions within narrative documents presents a challenging undertaking due to the complexity and ambiguity of language. Performance improvements can be achieved through deep learning; yet, as demonstrated in this paper, the specific nature of this task requires the customization of recurrent neural networks with regard to bidirectional processing, dropout layers as a means of regularization, and weighted loss functions. In addition, we propose sent2affect, a tailored form of transfer learning for affective computing: here the network is pre-trained for a different task (i.e. sentiment analysis), while the output layer is subsequently tuned to the task of emotion recognition. The resulting performance is evaluated in a holistic setting across 6 benchmark datasets, where we find that both recurrent neural networks and transfer learning consistently outperform traditional machine learning. Altogether, the findings have considerable implications for the use of affective computing.	188.01145441040038
58.	In recent years many methods have been proposed for eye detection. In some cases however, such as driver drowsiness detection, lighting conditions are so challenging that only the thermal imaging is a robust alternative to the visible light sensors. However, thermal images suffer from poor contrast and high noise, which arise due to the physical properties of the long waves processing. In this paper we propose an efficient method for eyes detection based on thermal image processing which can be successfully used in challenging environments. Image pre-processing with novel virtual high dynamic range procedure is proposed, which greatly enhances thermal image contrast and allows for more reliable computation of sparse image descriptors. The bag-of-visual-words approach with clustering was selected for final detections. We compare our method with the YOLOv3 deep learning model. Our method attains high accuracy and fast response in real conditions without computational complexity and requirement of a big dataset associated with the deep neural networks. For quantitative analysis a series of thermal video sequences were recorded in which eye locations were manually annotated. Created dataset was made publicly available on our website.	188.01122400446712
59.	Infodemiology is the process of mining unstructured and textual data so as to provide public health officials and policymakers with valuable information regarding public health. The appearance of this new data source, which was previously unimaginable, has opened up a new way in which to improve public health systems, resulting in better communication policies and better detection systems. However, the unstructured nature of the Internet, along with the complexity of the infectious disease domain, prevents the information extracted from being easily understood. Moreover, when dealing with languages other than English, for which some of the most common Natural Language Processing resources are not available, the correct exploitation of this data becomes even more difficult. We intend to fill these gaps proposing an ontology-driven aspect-based sentiment analysis with which to measure the general public's opinions as regards infectious diseases when expressed in Spanish by employing a case study of tweets concerning the Zika, Dengue and Chikungunya viruses in Latin America. Our proposal is based on two technologies. We first use ontologies in order to model the infectious disease domain with concepts such as risks, symptoms, transmission methods or drugs, among other concepts. We then measure the relationship between these concepts in order to determine the degree to which one concept influences other concepts. This new information is subsequently applied in order to build an aspect-based sentiment analysis model based on statistical and linguistic features. This is done by applying deep-learning models. Our proposal is available on a web platform, where users can see the sentiment for each concept at a glance and analyse how each concept influences the sentiment of the others. (c) 2020 Elsevier B.V. All rights reserved.	188.01091241104177
60.	At present, in the field of fault diagnosis, deep learning has shown state-of-the-art performance in processing mechanical big data. This paper studies the deep neural networks(DNN) model based on auto-encoder, which has high performance in bearing fault diagnosis. However, the traditional structure of stacked auto-encoders has the problem of internal covariant transfer, that inhibits the training efficiency and generalization ability of the network. To overcome the aforementioned deficiency and further explore the performance of DNN, a batch normalization layer is employed in the fully connected layer of the DNN during training, so the network can obtain the stable distribution of activation values. Therefore, this paper proposes a new intelligent diagnosis method named batch normalization deep neural networks(BN-DNN). Finally, the experimental results show that: (1) The performance of BN-DNN is better than DNN. (2) BN-DNN can directly process the raw vibration signals, and the diagnostic accuracy can be maintained above 99% under different working conditions.	188.01062802578627
61.	Recently, modern smartphones equipped with a variety of embedded-sensors, such as accelerometers and gyroscopes, have been used as an alternative platform for human activity recognition (HAR), since they are cost-effective, unobtrusive and they facilitate real-time applications. However, the majority of the related works have proposed a position-dependent HAR, i.e., the target subject has to fix the smartphone in a pre-defined position. Few studies have tackled the problem of position-independent HAR. They have tackled the problem either using handcrafted features that are less influenced by the position of the smartphone or by building a position-aware HAR. The performance of these studies still needs more improvement to produce a reliable smartphone-based HAR. Thus, in this paper, we propose a deep convolution neural network model that provides a robust position-independent HAR system. We build and evaluate the performance of the proposed model using the RealWorld HAR public dataset. We find that our deep learning proposed model increases the overall performance compared to the state-of-the-art traditional machine learning method from 84% to 88% for position-independent HAR. In addition, the position detection performance of our model improves superiorly from 89% to 98%. Finally, the recognition time of the proposed model is evaluated in order to validate the applicability of the model for real-time applications.	188.0100404980497
62.	Batch process quality prediction is an important application in manufacturing and chemical industries. The complexity of batch processes is characterized by multiphase, nonlinearity, dynamics, and uneven durations so that modeling of these batch processes is rather difficult. Moreover, there are other challenges in the face of quality prediction. Specifically, the process trajectories over the whole running duration potentially make specific contributions to the final targets so that the prediction issue embraces tremendously high-dimensional inputs but very low-dimensional outputs. This means that the prediction suffers from a severe dimensional imbalance between inputs and outputs. Motivated by these difficulties, this paper proposes a new deep learning-based framework for complex feature representative and quality prediction. Long short-term memory (LSTM) is used to extract comprehensive quality-relevant hidden features from a long-time sequence in each phase, significantly reducing the predictor dimensions. And these features from different phases are further integrated and compressed by a stacked auto-encoder (SAE). A practical industrial example testifies to the efficacy of the proposed framework.	188.00970680999737
63.	Recent developments in deep-reinforcement learning have yielded promising results in artificial games and test domains. To explore opportunities and evaluate the performance of these machine learning techniques, various benchmark suites are available, such as the Arcade Learning Environment, rllab, OpenAI Gym, and the StarCraft II Learning Environment. This set of benchmark suites is extended with the open business simulation model described here, which helps to promote the use of machine learning techniques as value-adding tools in the context of strategic decision making and economic model calibration and harmonization. The benchmark suite extends the current state-of-the-art problems for deep-reinforcement learning by offering an infinite state and action space for multiple players in a non-zero-sum game environment of imperfect information. It provides a model that can be characterized as both a credit assignment problem and an optimization problem. Experiments with this suite's deep-reinforcement learning algorithms, which yield remarkable results for various artificial games, highlight that stylized market behavior can be replicated, but the infinite action space, simultaneous decision making, and imperfect information pose a computational challenge. With the directions provided, the benchmark suite can be used to explore new solutions in machine learning for strategic decision making and model calibration.	188.00933723676093
64.	BACKGROUND: The processing of brain signals for Motor imagery (MI) classification to have better accuracy is a key issue in the Brain-Computer Interface (BCI). While conventional methods like Artificial neural network (ANN), Linear discernment analysis (LDA), K-Nearest Neighbor (KNN), Support vector machine (SVM), etc. have made significant progress in terms of classification accuracy, deep transfer learning-based systems have shown the potential to outperform them. BCI can play a vital role in enabling communication with the external world for persons with motor disabilities. NEW METHODS: Deep learning has been a success in many fields. However, for Electroencephalogram (EEG) signals, relatively minimal work has been carried out using deep learning. This paper proposes a combination of Continuous Wavelet Transform (CWT) along with deep learning-based transfer learning to solve the problem. CWT transforms one dimensional EEG signals into two-dimensional time-frequency-amplitude representation enabling us to exploit available deep networks through transfer learning. RESULTS: The effectiveness of the proposed approach is evaluated in this study using an openly available BCI competition data-set. The results of the approach have been compared to earlier works on the same dataset, and a promising validation accuracy of 95.71% is achieved in our investigation. COMPARISON WITH EXISTING METHODS AND CONCLUSION: Our approach has shown significant improvement over other studies, which is 5.71% improvement over earlier reported algorithm (Tabar and Halici, 2017) using the same dataset. Results show the validity of the proposed Deep Transfer-Learning based technique as a state of the art technique for MI classification in BCI.	188.00904188620774
65.	In this paper, we propose a deep learning based approach for facial action unit (AU) detection by enhancing and cropping regions of interest of face images. The approach is implemented by adding two novel nets (a.k.a. layers): the enhancing layers and the cropping layers, to a pretrained convolutional neural network (CNN) model. For the enhancing layers (noted as E-Net), we have designed an attention map based on facial landmark features and apply it to a pretrained neural network to conduct enhanced learning. For the cropping layers (noted as C-Net), we crop facial regions around the detected landmarks and design individual convolutional layers to learn deeper features for each facial region. We then combine the E-Net and the C-Net to construct a so-called Enhancing and Cropping Net (EAC-Net), which can learn both features enhancing and region cropping functions effectively. The EAC-Net integrates three important elements, i.e., learning transfer, attention coding, and regions of interest processing, making our AU detection approach more efficient and more robust to facial position and orientation changes. Our approach shows a significant performance improvement over the state-of-the-art methods when tested on the BP4D and DISFA AU datasets. The EAC-Net with a slight modification also shows its potentials in estimating accurate AU intensities. We have also studied the performance of the proposed EAC-Net under two very challenging conditions: (1) faces with partial occlusion and (2) faces with large head pose variations. Experimental results show that (1) the EAC-Net learns facial AUs correlation effectively and predicts AUs reliably even with only half of a face being visible, especially for the lower half; (2) Our EAC-Net model also works well under very large head poses, which outperforms significantly a compared baseline approach. It further shows that the EAC-Net works much better without a face frontalization than with face frontalization through image warping as pre-processing, in terms of computational efficiency and AU detection accuracy.	188.00899673412593
66.	Several industries in many different domains are looking at deep learning as a way to take advantage of the insights in their data, to improve their competitiveness, to open up novel business possibilities, or to resolve the problem that thought to be impossible to tackle. The large scale of the systems where deep learning is applied and the need of preserving the privacy of the used data have imposed a shift from the traditional centralized deployment to a more collaborative one. However, this has opened up several vulnerabilities caused by compromised nodes and inputs, with traditional crypto primitives and access control models exploited to offer protection means. Providing security can be costly in terms of higher energy consumption, calling for a wise use of these protection means. This paper exploits game theory to model interactions among collaborative deep learning nodes and to decide when using actions to support security enhancements.	188.00894243347545
67.	In visual recognition, the key to the performance improvement of ResNet is the success in establishing the stack of deep sequential convolutional layers using identical mapping by a shortcut connection. It results in multiple paths of data flow under a network and the paths are merged with the equal weights. However, it is questionable whether it is correct to use the fixed and predefined weights at the mapping units of all paths. In this paper, we introduce the active weighted mapping method which infers proper weight values based on the characteristic of input data on the fly. The weight values of each mapping unit are not fixed but changed as the input image is changed, and the most proper weight values for each mapping unit are derived according to the input image. For this purpose, channel-wise information is embedded from both the shortcut connection and convolutional block, and then the fully connected layers are used to estimate the weight values for the mapping units. We train the backbone network and the proposed module alternately for a more stable learning of the proposed method. Results of the extensive experiments show that the proposed method works successfully on the various backbone architectures from ResNet to DenseNet. We also verify the superiority and generality of the proposed method on various datasets in comparison with the baseline.	188.00887921589833
68.	Fundamentally, Structural Health Monitoring (SHM) of mechanical systems is essential to avoid their catastrophic failure. The first key contribution of this paper is presenting a new method for damage detection of mechanical systems in presence of the uncertainties such as modeling errors, measurement errors, varying loading conditions and environmental noises based on Finite Element (FE) model and real healthy state. On the other hand, deep learning has been widely used in image and signal analyses with great success. According to this enhancement, the second key contribution of this paper is designing a developed Deep Convolutional Neural Network (DCNN) with training interference and customized architecture to learn the features. In industrial environments, most structures are exposed to varying environmental conditions and it is difficult to collect data containing real damages, and generally, only the data of a real healthy system is available; therefore, it is necessary to have an effective method for damage detection of real systems based on the artificial damages and real healthy data. From this standpoint, the third key contribution of this paper is training process of the proposed DCNN using raw frequency data of the FE model and real healthy state, which is then tested using the raw frequency data of the real system. The proposed DCNN can directly learn the features from raw frequency data of the FE model and real healthy state and discover the damage-sensitive features in order to damage detection of a real system. In this method, only dynamic responses of real healthy system are used to updating the FE model and minimizing the errors. The efficacy of the proposed method is validated using the experimental beam structure. Time data and several manual features from time and frequency data as well as two intelligent methods are used as comparisons. The results show that the proposed method can learn the features from raw frequency data and achieve higher accuracy than other comparative methods. (C) 2020 Elsevier Ltd. All rights reserved.	188.00885777750872
69.	Interorganizational scholars have long thought about how firms learn through buyer relationships. However, it is not clear whether dyadic learning gains are susceptible to imitation or are only inherited and whether these gains decay over time or are of an enduring nature. In this paper, I import ideas from the organizational imprinting literature into the interorganizational literature and apply the knowledge-based and learning views of the firm to examine how suppliers with differing initial endowments learn to work together with a buyer. The findings from an inductive multiple case study of spinoff and nonspinoff suppliers of an automotive manufacturer parent in Turkey reveal the following three learning mechanisms: informal relationships and social capital, transfer of routines, and shared identity. Although nonspinoff suppliers also exhibit evidence of several learning processes to a certain extent, spinoff suppliers' deeper relationship, in particular their shared identity, with their parent based on their direct parental heritage tends to be more difficult for them to copy. No matter how hard nonspinoff suppliers try, they have "one hand tied behind their back," they remain stepchildren, and they never truly become a biological child. By providing a novel setting and a rich set of qualitative data on the learning behaviors of these two types of suppliers, this study teases apart the knowledge and resources that can be "learned from external sources" versus those that can "only be inherited."	188.00871907613953
70.	In today's financial markets, where most trades are performed in their entirety by electronic means and the largest fraction of them is completely automated, an opportunity has risen from analyzing this vast amount of transactions. Since all the transactions are recorded in great detail, investors can analyze all the generated data and detect repeated patterns of the price movements. Being able to detect them in advance, allows them to take profitable positions or avoid anomalous events in the financial markets. In this work we proposed a deep learning methodology, based on Convolutional Neural Networks (CNNs), that predicts the price movements of stocks, using as input large-scale, high-frequency time-series derived from the order book of financial exchanges. The dataset that we use contains more than 4 million limit order events and our comparison with other methods, like Multilayer Neural Networks and Support Vector Machines, shows that CNNs are better suited for this kind of task.	188.00863905862667
71.	For performing multi-class classification, deep neural networks almost always employ a One-vs-All (OvA) classification scheme with as many output units as there are classes in a dataset. The problem of this approach is that each output unit requires a complex decision boundary to separate examples from one class from all other examples. In this paper, we propose a novel One-vs-One (OvO) classification scheme for deep neural networks that trains each output unit to distinguish between a specific pair of classes. This method increases the number of output units compared to the One-vs-All classification scheme but makes learning correct decision boundaries much easier. In addition to changing the neural network architecture, we changed the loss function, created a code matrix to transform the one-hot encoding to a new label encoding, and changed the method for classifying examples. To analyze the advantages of the proposed method, we compared the One-vs-One and One-vs-All classification methods on three plant recognition datasets (including a novel dataset that we created) and a dataset with images of different monkey species using two deep architectures. The two deep convolutional neural network (CNN) architectures, Inception-V3 and ResNet-50, are trained from scratch or pre-trained weights. The results show that the One-vs-One classification method outperforms the One-vs-All method on all four datasets when training the CNNs from scratch. However, when using the two classification schemes for fine-tuning pre-trained CNNs, the One-vs-All method leads to the best performances, which is presumably because the CNNs had been pre-trained using the One-vs-All scheme. (C) 2020 The Authors. Published by Elsevier Ltd.	188.00849429609218
72.	Convolutional neural networks (CNNs) represent deep learning architectures that are currently used in a wide range of applications, including computer vision, speech recognition, time series analysis in fi-nance, and many others. At the same time, CNNs are very demanding in terms of the hardware and time cost of a computing system, which considerably restricts their practical use, e.g., in embedded systems, real-time systems, and mobile volatile devices. The goal of this paper is to reduce the resources required to build and operate CNNs. To achieve this goal, a CNN architecture based on Residue Number System (RNS) and the new Chinese Remainder Theorem with fractions is proposed. The new architecture gives an efficient solution to the main problem of RNSs associated with restoring the number from its residues, which determines the main contribution to the CNN structure. In accordance with the results of hardware simulation on Kintex7 xc7k70tfbg484-2 FPGA, the use of RNS in the convolutional layer of a neural net-work reduces hardware cost by 32.6% compared to the traditional approach based on the binary number system. In addition, the use of the proposed hardware-software architecture reduces the average image recognition time by 37.06% compared to the software implementation. (C) 2020 Elsevier B.V. All rights reserved.	188.0077865670573
73.	Prediction of volatility for different types of financial assets is one of the tasks of greater mathematical complexity in time series prediction, mainly due to its noisy, non-stationary and heteroscedastic structure. On the other hand, gold is an asset of particular importance for hedging and diversification of investment portfolios, and therefore it is important to predict future volatility of this asset. This paper seeks to significantly improve the forecast of gold volatility by combining two deep learning methodologies: short-term memory networks (LSTM) added to convolutional neural networks (specifically a pre-trained VGG16 network). It is important to mention that these types of hybrid architectures have not been used in time series prediction, so it is a completely new approach to solving these types of problems. The CNN-LSTM hybrid model is capable of including images as input which provides a wide variety of information associated with both static and dynamic characteristics of the series. In parallel, different lags of profitability of the series are entered as input, which allows it to learn from the temporal structure. The results show a substantial improvement when this hybrid model is compared to the GARCH and LSTM models. A 37% reduction in MSE is observed compared to the classic GARCH model, and 18% compared to the LSTM model. Finally, the Model Confidence Model (MCS) determines a significant improvement in the prediction of the hybrid model. The fundamental importance of this research lies in the application of a new type of architecture capable of processing various sources of information for any time series prediction task. (C) 2020 Elsevier Ltd. All rights reserved.	188.00772811135568
74.	Deep learning (DL) is affecting each and every sphere of public and private lives and becoming a tool for daily use. The power of DL lies in the fact that it tries to imitate the activities of neurons in the neocortex of human brain where the thought process takes place. Therefore, like the brain, it tries to learn and recognize patterns in the form of digital images. This power is built on the depth of many layers of computing neurons backed by high power processors and graphics processing units (GPUs) easily available today. In the current scenario, we have provided detailed survey of various types of DL systems available today, and specifically, we have concentrated our efforts on current applications of DL in medical imaging. We have also focused our efforts on explaining the readers the rapid transition of technology from machine learning to DL and have tried our best in reasoning this paradigm shift. Further, a detailed analysis of complexities involved in this shift and possible benefits accrued by the users and developers.	188.0073759217585
75.	Functional Near-Infrared Spectroscopy (fNIRS) has shown promise for being potentially more suitable (than e.g. EEG) for brain-based Human Computer Interaction (HCI). While some machine learning approaches have been used in prior HCI work, this paper explores different approaches and configurations for classifying Mental Workload (MWL) from a continuous HCI task, to identify and understand potential limitations and data processing decisions. In particular, we investigate three overall approaches: a logistic regression method, a supervised shallow method (SVM), and a supervised deep learning method (CNN). We examine personalised and generalised models, as well as consider different features and ways of labelling the data. Our initial explorations show that generalised models can perform as well as personalised ones and that deep learning can be a suitable approach for medium size datasets. To provide additional practical advice for future brain-computer interaction systems, we conclude by discussing the limitations and data-preparation needs of different machine learning approaches. We also make recommendations for avenues of future work that are most promising for the machine learning of fNIRS data.	188.00723050105853
76.	Features learned by deep Convolutional Neural Networks (CNNs) have been recognized to be more robust and expressive than hand-crafted ones. They have been successfully used in different computer vision tasks such as object detection, pattern recognition and image understanding. Given a CNN architecture and a training procedure, the efficacy of the learned features depends on the domain-representativeness of the training examples. In this paper we investigate the use of CNN-based features for the purpose of food recognition and retrieval. To this end, we first introduce the Food-475 database, that is the largest publicly available food database with 475 food classes and 247,636 images obtained by merging four publicly available food databases. We then define the food-domain representativeness of different food databases in terms of the total number of images, number of classes of the domain and number of examples for class. Different features are then extracted from a CNN based on the Residual Network with 50 layers architecture and trained on food databases with diverse food-domain representativeness. We evaluate these features for the tasks of food classification and retrieval. Results demonstrate that the features extracted from the Food-475 database outperform the other ones showing that we need larger food databases in order to tackle the challenges in food recognition, and that the created database is a step forward toward this end.	188.00695551622096
77.	Intelligent fault detection and diagnosis, as an important approach, play a crucial role in ensuring the stable, reliable and safe operation of rolling bearings, which is one of the most main components in the rotating machinery. However, the data distribution shift is inevitable in the practical scene due to changes in internal and external environments, it is still challenging to establish an effective fault di-agnosis model that can eliminate the same distribution assumption. In light of the above demands, a novel transfer learning framework based on deep multi-scale convolutional neural network (MSCNN) is presented in this paper. First, a novel multi-scale module is ingenious established based on dilated convolution, which is used as the key part to obtain differential features through different perceptual fields. Then, in order to further reduce the complexity of the proposed model, a global average pooling technol-ogy is adopted to replace the traditional fully-connected layer. Finally, the architecture and weights of the MSCNN pre-trained on source domain are transferred to the other different but similar tasks with proper fine-tuning instead of training a network from scratch. The proposed MSCNN is evaluated by different transfer scenarios constructed on two famous rolling bearing test-bed. Three case studies show that the proposed framework not only has excellent performance on the source domain, but also has superior transferability on variable working conditions and domains. (C) 2020 Published by Elsevier B.V.	188.006925787346
78.	The problem of common sense remains a major obstacle to progress in artificial intelligence. Here, we argue that common sense in humans is founded on a set of basic capacities that are possessed by many other animals, capacities pertaining to the understanding of objects, space, and causality. The field of animal cognition has developed numerous experimental protocols for studying these capacities and, thanks to progress in deep reinforcement learning (RL), it is now possible to apply these methods directly to evaluate RL agents in 3D environments. Besides evaluation, the animal cognition literature offers a rich source of behavioural data, which can serve as inspiration for RL tasks and curricula.	188.0068694112041
79.	As the human-robot interaction is catching eye day by day with the increase in need of automation in every field, personal robots are increasing in every area which may be coping needs of elderly people, treating autistic patients or child therapy, even in the area of babysitting the child. As robots are helping human being in all such cases, robots need to understand human emotion in order to treat human in a more customized manner. Predicting human emotion has been a difficult problem which is being solved over a decade's time. In this paper, we have built a model which can predict human emotion from an image in real time. The network build is based on convolutional neural network which has reduced parameters by 90x from that of Vanilla CNN and also 50x from the latest state-of-the-art research carried out to the best of our knowledge. The network build is tested robustly on 8 different datasets, namely Fer2013, CK and CK+, Chicago Face Database, JAFFE Dataset, FEI face dataset, IMFDB, TFEID and custom dataset build in our laboratory having different angles, faces, backgrounds and age groups. The network achieves 74% accuracy which is an improved accuracy from the state-of-the-art accuracy with reduced computation complexity.	188.0067569130805
80.	Benchmark datasets are critical for developing, evaluating, and comparing remote sensing image retrieval (RSIR) approaches. However, current benchmark datasets are deficient in that (1) they were originally collected for land use/land cover classification instead of RSIR; (2) they are relatively small in terms of the number of classes as well as the number of images per class which makes them unsuitable for developing deep learning based approaches; and (3) they are not appropriate for RSIR due to the large amount of background present in the images. These limitations restrict the development of novel approaches for RSIR, particularly those based on deep learning which require large amounts of training data. We therefore present a new large-scale remote sensing dataset termed "PatternNet" that was collected specifically for RSIR. PatternNet was collected from high-resolution imagery and contains 38 classes with 800 images per class. Significantly, PatternNet's large scale makes it suitable for developing novel, deep learning based approaches for RSIR. We use PatternNet to evaluate the performance of over 35 RSIR methods ranging from traditional handcrafted feature based methods to recent, deep learning based ones. These results serve as a baseline for future research on RSIR. (C) 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	188.00659903455644
81.	Machine learning has shown enormous potential for computer-aided drug discovery. Here we show how modern convolutional neural networks (CNNs) can be applied to structure-based virtual screening. We have coupled our densely connected CNN (DenseNet) with a transfer learning approach which we use to produce an ensemble of protein family-specific models. We conduct an in-depth empirical study and provide the first guidelines on the minimum requirements for adopting a protein family specific model. Our method also highlights the need for additional data, even in data-rich protein families. Our approach outperforms recent benchmarks on the DUD-E data set and an independent test set constructed from the ChEMBL database. Using a clustered cross-validation on DUD-E, we achieve an average AUC ROC of 0.92 and a 0.5% ROC enrichment factor of 79. This represents an improvement in early enrichment of over 75% compared to a recent machine learning benchmark. Our results demonstrate that the continued improvements in machine learning architecture for computer vision apply to structure-based virtual screening.	188.00592135316316
82.	In many optimal design searches, the function to optimize is a simulator that is computationally expensive. While current High Performance Computing (HPC) methods are not able to solve such problems efficiently, parallelism can be coupled with approximate models (surrogates or meta-models) that imitate the simulator in timely fashion to achieve better results. This combined approach reduces the number of simulations thanks to surrogate use whereas the remaining evaluations are handled by supercomputers. While the surrogates' ability to limit computational times is very attractive, integrating them into the overarching optimization process can be challenging. Indeed, it is critical to address the major trade-off between the quality (precision) and the efficiency (execution time) of the resolution. In this article, we investigate Evolution Controls (ECs) which are strategies that define the alternation between the simulator and the surrogate within the optimization process. We propose a new EC based on the prediction uncertainty obtained from Monte Carlo Dropout (MCDropout), a technique originally dedicated to quantifying uncertainty in deep learning. Investigations of such uncertainty-aware ECs remain uncommon in surrogate-assisted evolutionary optimization. In addition, we use parallel computing in a complementary way to address the high computational burden. Our new strategy is implemented in the context of a pioneering application to Tuberculosis Transmission Control. The reported results show that the MCDropout-based EC coupled with massively parallel computing outperforms strategies previously proposed in the field of surrogate-assisted optimization. (c) 2020 Elsevier B.V. All rights reserved.	188.00585059231122
83.	The identification of a person's gender plays an important role in various visual surveillance and monitoring applications which are growing more ubiquitously. This paper proposes a method for gender classification of pedestrians based on whole body images which, unlike facial-based methods, allows for observation from different viewpoints. We use a parts-based model that combines global and local information to make inference. Convolutional neural network (CNN) is leveraged for its superior feature learning and classification capability. Our method requires that only the gender label is available for the training images, without the need for any other expensive annotation such as the anatomical parts, key points or other attributes. We trained a CNN on the bounding box containing the whole body (global CNN) or a defined portion of the body (local CNN). Experimental results show that the upper half region of the body is the most discriminative for gender, in comparison with the middle or lower half. The best model is a jointly trained combination of a global CNN and a local upper body CNN, which achieves higher accuracy than previous works on publicly available datasets.	188.00574024712031
84.	Deep learning in recent years has entered the chemistry and materials research arsenal with many successful accomplishments in tasks considered to be intractable using traditional means. However, the widespread application of this data-driven technology is still challenged by the requirement of large training data, poor model interpretability, and hard-to-detect errors that undermine the soundness of conclusion. Here, we performed a systematic study for the modeling of the formation energies of inorganic compounds using deep learning. Our results proved the advantage of deep learning methods over several non-deep learning methods in this specific task and demonstrated the abstraction of knowledge using deep learning, which was a unique ability compared to non-deep learning methods. Several aspects that critically affected the conclusion were also highlighted, including the importance to rigorously compare model performance with the same dataset, the design of input representation, and the careful selection of model architecture. Findings from the current study demonstrate the capabilities of deep learning solving complicated problems in materials research and serve as new guidelines for future practicing of deep learning in this field. Published under license by AIP Publishing.	188.00563725237333
85.	Financial markets forecasting represents a challenging task for a series of reasons, such as the irregularity, high fluctuation, noise of the involved data, and the peculiar high unpredictability of the financial domain. Moreover, literature does not offer a proper methodology to systematically identify intrinsic and hyper-parameters, input features, and base algorithms of a forecasting strategy in order to automatically adapt itself to the chosen market. To tackle these issues, this paper introduces a fully automated optimized ensemble approach, where an optimized feature selection process has been combined with an automatic ensemble machine learning strategy, created by a set of classifiers with intrinsic and hyper-parameters learned in each marked under consideration. A series of experiments performed on different real-world futures markets demonstrate the effectiveness of such an approach with regard to both to the Buy and Hold baseline strategy and to several canonical state-of-the-art solutions.	188.00563528052572
86.	Visible light communication is a popular research area where proposed communication methods must satisfy the lighting related requirements as well. Suggested VLC modules should not only improve communication quality such as decreasing error rates but also comply with other lighting related constraints such as sustaining certain level of illumination. This increases the complexity of the optimization problem. Moreover, most of the time the suggested modules focus on a specific block of communication system which downgrades the system-wide performance on coming together. To solve this complex problem and jointly optimize the whole system, we suggest a deep learning based method, VLCnet. Despite the increasing number of neural network based channel decoders in the literature, few of them are addressing real-life application constraints. VLCnet is an error rate decreasing solution which takes into account, reducing flicker and sustaining certain illumination level. Moreover, our channel impulse response (CIR) is taken from reference CIRs for VLC and our study considers the input-dependent noise originated by the shot noise for the sake of generality. Flicker reducing activation units (FRAU) are the key part of VLCnet and the main novelty of this publication. FRAU is an example of a competitive layer and ensures run length limitation for flicker reduction. Both with input-independent and dependent noise, simulation results show performance superiority of the proposed VLCnet method. Although they have different setups, all results demonstrate the benefit of training with certain amount of noise. From the practicality perspective, proposed system is easy to be deployed since inference operation does not have iterations unlike most of the conventional detectors.	188.005620273931
87.	With the rapid development of mobile Internet, the Internet of Things and other new technologies, mobile devices are generating massive amounts of spatio-temporal trajectory data. This paper aims to propose a method that can automatically classify transportation mode and speed, help people understand the mobility of moving objects, thus making people's life more convenient and traffic management easier. Although there have been some studies on trajectory classification, yet they either require manual feature selection or fail to fully consider the impact of time and space on classification results. None of them can extract features automatically and comprehensively. Hence, we propose Deep Multi-Scale Learning Model and design a deep neural network to learn features under multi-scale time and space granularities automatically. The obtained features are fused to output final classification results. Our method is based on the latest image classification network structure DenseNet, and incorporates attention mechanism and residual learning. This model is able to fully capture spatial features so as to enhance feature propagation and capture long-term dependence. Moreover, the number of network structure parameters is also reduced. We have evaluated our Deep Multi-Scale Learning Model on two real datasets. The results show that our model is superior to the current state-of-the-art models in top-1 accuracy, recall and f1-score. Furthermore, the classification results from our model can help to understand mobility accurately. (C) 2019 Elsevier B.V. All rights reserved.	188.00551586949354
88.	Judgments are taken in a structured way; both human and business management decisions involve a hierarchical process that requires a level of compromise between risk, cost, reward, experience and knowledge. This article proposes a management decision structure that emulates the human brain approach based on genetic and deep learning cluster algorithms and the random neural network. Reinforcement learning takes quick and specific local decisions, deep learning clusters enables identity and memory, and deep learning management clusters make final strategic decisions. The presented genetic algorithm transmits the learned information to future generations in the network weights rather than the neurons. Because the subject's information, a combination of memory, identity and decision data, is never lost but transmitted, the genetic algorithm provides immortality. The management decision structure has been applied and validated in a smart investment Fintech application: an intelligent banker that makes buy and sell asset decisions with an associated market and risk that entirely transmits itself to a future generation. Results are rewarding; the management decision structure with genetics and machine learning based on the random neural network algorithm that emulates the human brain and biology transmits information to future generations and learns autonomously, gradually and continuously while adapting to the environment.	188.00546053046955
89.	Recently, the image super-resolution (SR) methods based on residual learning have obtained remarkable quality performance. However, the current residual-learning methods have low computational performance and slow convergence rate. In this paper, we propose a high-efficiency two-level residual network to make the network learn more useful high-frequency information. Only 5 convolution layers in the LR space are used in our residual network, and no parameters are introduced in the other layers. Compared with the long training time up to several hours or days of previous deep residual networks, our simplified network can make the training time reduce to half an hour. Besides, our simplified network achieves satisfactory quality performance. The evaluation on the public datasets shows that our method can process SR of ultra-high definition (UHD) videos in real-time (more than 24 frames per second) on a generic graphical processing unit (GPU).	188.00540360189746
90.	Image restoration is an important technique to deal with the degradation of the image. This paper presents an efficient and trusty denoising scheme, which combines the convolutional neural network (CNN) technique with the traditional variational model, to offer interpretable and high quality reconstructions. In this scheme, CNN, which has proven effectiveness in feature extraction tasks, is adopted to obtain the designed edge features from the noisy images, to be the prior of the reconstruction through an edge regularization. In the proposed denoising model, the total variation (TV) regularization is also adopted for its superior performance in allowing the sharp edges. The solution of the proposed model is obtained by using the Bregman splitting method, with the existence and the uniqueness of the solution also analyzed in this paper. Extensive experiments show that the two regularizations combined in the proposed model are able to fix the staircasing defects effectively and retrieve the fine textures in the recovered images as well, which outperforms the state-of-the-art interpretable denoising methods. Moreover, the proposed edge regularization can be easily extended into other kinds of noise or other restoration tasks, which implies the strong adaptivity of the proposed scheme.	188.00510047361277
91.	In this paper, we propose a novel approach for efficient training of deep neural networks in a bottom-up fashion using a layered structure. Our algorithm, which we refer to as deep cascade learning, is motivated by the cascade correlation approach of Fahlman and Lebiere, who introduced it in the context of perceptrons. We demonstrate our algorithm on networks of convolutional layers, though its applicability is more general. Such training of deep networks in a cascade directly circumvents the well-known vanishing gradient problem by ensuring that the output is always adjacent to the layer being trained. We present empirical evaluations comparing our deep cascade training with standard end-end training using back propagation of two convolutional neural network architectures on benchmark image classification tasks (CIFAR-10 and CIFAR-100). We then investigate the features learned by the approach and find that better, domain-specific, representations are learned in early layers when compared to what is learned in end-end training. This is partially attributable to the vanishing gradient problem that inhibits early layer filters to change significantly from their initial settings. While both networks perform similarly overall, recognition accuracy increases progressively with each added layer, with discriminative features learned in every stage of the network, whereas in end-end training, no such systematic feature representation was observed. We also show that such cascade training has significant computational and memory advantages over end-end training, and can be used as a pretraining algorithm to obtain a better performance.	188.00504254605687
92.	In order to conduct an in-depth study on financial transactions of block chain, the classical back propagation (BP) neural network based on the artificial neural network (ANN) model is selected, and its propagation mode, weight change, and learning process are analyzed. For the problem of slow convergence speed and local minimum value of BP neural network, based on the idea of deep learning, the initial value and training step are changed by auto-encoder and restricted Boltzmann machine, and the theory is analyzed. Taking the stock index futures trading in the block chain financial trading as an example, the stock price trading of stock index futures is studied using the two deep learning neural network models to predict the price changes. The results show that the auto-encoder, as an unsupervised learning system, performs better than the restricted Boltzmann machine in setting the initial weights and thresholds, with fewer iterations, faster convergence rate, and smaller convergence error. The results obtained by the auto-encoder can be used as initialization settings and data analysis. The prediction accuracy of the whole model is around 59%. When the transaction cost is not considered, the transaction can be conducted based on the prediction signal of the deep learning model. Therefore, deep learning neural network model can be applied to block chain financial transactions as a reference for financial transactions, which has a good practical significance for the development of this field. (C) 2020 Elsevier B.V. All rights reserved.	188.00491640250243
93.	In this paper, we propose a novel deep learning-based framework for facial landmark detection. This framework takes as input face image returned by a face detector (Faster R-CNN) and generates as output a set of landmarks positions. Prior CNN-based methods often select randomly small local patches to predict an initial guess of landmarks locations. One issue with these local patches is that the adjacent landmarks might share the same regions due to the overlapping, thus, they might not convey precise information of each individual landmark. By contrast, our approach formulates this problem as a divide-conquer search for facial patches using CNN architecture in a hierarchy, where the input face image is re-cursively split into two cohesive non-overlapped subparts until each one contains only the region around the expected landmark. To attain better division of face topology, the search is carried out in a structured coarse-to-fine manner, where a learned hierarchical model of the face defining the granularity of each division level is introduced. We also propose a cascaded regressor to detect and refine the position of the individual landmark in each predicted non-overlapped patch. We adopt a carefully designed shallow CNN architecture so that to improve real-time performance. In addition, unlike previous cascaded methods, our regressor does not require auxiliary input such as initial landmarks locations. Extensive experiments on several challenging datasets (including MTFL, AFW, AFLW, COFW, 300W, and 300VW) show that our approach is particularly impressive in the unconstrained scenarios where it outperforms prior arts in both accuracy and efficiency. (C) 2020 Elsevier Ltd. All rights reserved.	188.004547736552
94.	Decades of psychological research have been aimed at modeling how people learn features and categories. The empirical validation of these theories is often based on artificial stimuli with simple representations. Recently, deep neural networks have reached or surpassed human accuracy on tasks such as identifying objects in natural images. These networks learn representations of real-world stimuli that can potentially be leveraged to capture psychological representations. We find that state-of-the-art object classification networks provide surprisingly accurate predictions of human similarity judgments for natural images, but they fail to capture some of the structure represented by people. We show that a simple transformation that corrects these discrepancies can be obtained through convex optimization. We use the resulting representations to predict the difficulty of learning novel categories of natural images. Our results extend the scope of psychological experiments and computational modeling by enabling tractable use of large natural stimulus sets.	188.0045357456698
95.	We present a convolutional neural network (CNN) equipped with a novel and efficient adaptive dual attention module (ADAM) for automated skin lesion segmentation from dermoscopic images, which is an essential yet challenging step for the development of a computer-assisted skin disease diagnosis system. The proposed ADAM has three compelling characteristics. First, we integrate two global context modeling mechanisms into the ADAM, one aiming at capturing the boundary continuity of skin lesion by global average pooling while the other dealing with the shape irregularity by pixel-wise correlation. In this regard, our network, thanks to the proposed ADAM, is capable of extracting more comprehensive and discriminative features for recognizing the boundary of skin lesions. Second, the proposed ADAM supports multi-scale resolution fusion, and hence can capture multi-scale features to further improve the segmentation accuracy. Third, as we harness a spatial information weighting method in the proposed network, our method can reduce a lot of redundancies compared with traditional CNNs. The proposed network is implemented based on a dual encoder architecture, which is able to enlarge the receptive field without greatly increasing the network parameters. In addition, we assign different dilation rates to different ADAMs so that it can adaptively capture distinguishing features according to the size of a lesion. We extensively evaluate the proposed method on both ISBI2017 and ISIC2018 datasets and the experimental results demonstrate that, without using network ensemble schemes, our method is capable of achieving better segmentation performance than state-of-the-art deep learning models, particularly those equipped with attention mechanisms.	188.00427492316848
96.	It is crucial for robots to autonomously steer in complex environments safely without colliding with any obstacles. Compared to conventional methods, deep reinforcement learning-based methods are able to learn from past experiences automatically and enhance the generalization capability to cope with unseen circumstances. Therefore, we propose an end-to-end deep reinforcement learning algorithm in this paper to improve the performance of autonomous steering in complex environments. By embedding a branching noisy dueling architecture, the proposed model is capable of deriving steering commands directly from raw depth images with high efficiency. Specifically, our learning-based approach extracts the feature representation from depth inputs through convolutional neural networks and maps it to both linear and angular velocity commands simultaneously through different streams of the network. Moreover, the training framework is also meticulously designed to improve the learning efficiency and effectiveness. It is worth noting that the developed system is readily transferable from virtual training scenarios to real-world deployment without any fine-tuning by utilizing depth images. The proposed method is evaluated and compared with a series of baseline methods in various virtual environments. Experimental results demonstrate the superiority of the proposed model in terms of average reward, learning efficiency, success rate as well as computational time. Moreover, a variety of real-world experiments are also conducted which reveal the high adaptability of our model to both static and dynamic obstacle-cluttered environments.	188.00410779587554
97.	In this paper, we present a deep neural network (DNN) training approach called the "DeepMimic" training method. Enormous amounts of data are available nowadays for training usage. Yet, only a tiny portion of these data is manually labeled, whereas almost all of the data are unlabeled. The training approach presented utilizes, in a most simplified manner, the unlabeled data to the fullest, in order to achieve remarkable (classification) results. Our DeepMimic method uses a small portion of labeled data and a large amount of unlabeled data for the training process, as expected in a real-world scenario. It consists of a mentor model and a student model. Employing a mentor model trained on a small portion of the labeled data and then feeding it only with unlabeled data, we show how to obtain a (simplified) student model that reaches the same accuracy and loss as the mentor model, on the same test set, without using any of the original data labels in the training of the student model. Our experiments demonstrate that even on challenging classification tasks the student network architecture can be simplified significantly with a minor influence on the performance, i.e., we need not even know the original network architecture of the mentor. In addition, the time required for training the student model to reach the mentor's performance level is shorter, as a result of a simplified architecture and more available data. The proposed method highlights the disadvantages of regular supervised training and demonstrates the benefits of a less traditional training approach.	188.00403572263036
98.	Land cover classification is a significant task in remote sensing that aims at land cover monitoring and adjustment. Instance segmentation in deep learning has been widely used in land cover classification. However, this method requires high quality, labor-intensive pixel-level annotations. A bisupervised pipeline is proposed especially for datasets with ambiguous samples, which reduces the requirement of labeling accuracy. In order to supervise learning with ambiguous annotation samples, the pipeline has two losses to feedback, namely main loss and auxiliary loss. The main loss is still responsible for the expected output. According to the difference degree between ambiguous samples, categories are constructed artificially. The auxiliary loss generates feedback through categories, sharing decoder layers of main output during the training process. In the prediction process, auxiliary loss is used to update the main loss results. The neural network adopts the structure of U-Net with the pyramid pooling module, in which the multiscale feature is used in the feature extraction process. We also compare five different backbones and choose Inception-V3 as the backbone to improve the feature extraction capabilities of network encoders. The use of transposed convolution instead of traditional upsampling in decoders can improve the segmentation details. Our bisupervise network obtains Jaccard index of 83.936% and F1 -score of 91.17% on Gaofen-2 imagery dataset. The results demonstrate that the proposed method can achieve better classification performance in datasets with ambiguous annotations. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)	188.00403465434727
99.	Deep convolutional neural networks (CNNs) have in recent years achieved record-breaking performance on many image classification tasks and are therefore well-suited for computer aided detection (CAD). The need for uncertainty quantification for CAD motivates the need for a probabilistic framework for deep learning. The most well-known probabilistic neural network model is the Bayesian neural network (BNN), but BNNs are notoriously difficult to sample for large complex network architectures, and as such their use is restricted to small problems. It is known that the limit of BNNs as their widths increase toward infinity is a Gaussian process (GP), and there has been considerable research interest in these infinitely wide BNNs. Recently, this classic result has been extended to deep architectures in what is termed the neural network Gaussian process (NNGP) model. In this work, we implement an NNGP model and apply it to the ChestXRay14 dataset at the full resolution of 1024x1024 pixels. Even without any convolutional aspects to the network architecture and without any data augmentation, our five layer deep NNGP model outperforms other non-convolutional models and therefore helps to narrow the performance gap between non-convolutional and convolutional models. Our NNGP model is fully Bayesian and therefore offers uncertainty information through its predictive variance that can be used to formulate a predictive confidence measure. We show that the performance of the NNGP model is significantly boosted after low-confidence predictions are rejected, suggesting that convolution is most beneficial only for these low-confidence examples. Finally, our results indicate that an extremely large fully-connected neural network with appropriate regularization could perform as well as the NNGP if not for the computational bottleneck resulting from the large number of model parameters.	188.00370638946941
100.	In this paper, a new approach to scene parsing is proposed which integrates part-whole hierarchies relationship in the last feature map to assign a semantic class label to each pixel. Recently, deep learning based approaches have had a great impact on scene parsing. However, these methods could not preserve the spatial information about the high-level (or mid-level) features. Hence, Hinton, one of the fathers of deep learning, introduced the capsule concept to encode pose information such as orientation. All of the capsules which have a similar pose matrix value are grouped to form a parent capsule. However, their work has two challenges: 1) the extensive time required to perform dynamic routing agreement to obtain the routing coefficient and 2) the variation of the appearance and the spatial hierarchies between part capsules and their corresponding parent are not encoded. In this study, to consider these challenges, the general Hough transform (GHT) and tensor normal distribution are utilized to propose a novel capsule concept. In this case, each capsule has k offset vectors for each semantic class. The offset vectors are oriented from the capsule to the k other capsules which have an effective role in assigning that capsule to a specific semantic class. The problem formulation is proposed such that evaluating the approach on large datasets is feasable. Also, a new score function is designed to accumulate the vote's strengths for capsule class estimation. To do so, we use tensor normal distribution in which the covariance matrix is defined as the Kronecker product of the capsule feature covariance and the between-capsule covariance. The proposed approach, for the first time, encodes the relations between part capsules to vote to a whole capsule through the between-capsule covariance matrix. To evaluate our proposed approach, it is applied to SiftFlow, NYUD-v2 and PASCAL VOC 2012 datasets. The results show that our approach achieves superior performance. (c) 2020 Elsevier Ltd. All rights reserved.	188.0034001890123
101.	To benefit the skin care, this paper aims to design an automatic and effective visual analysis framework, with the expectation of recognizing the skin disease from a given image conveying the disease affected surface. This task is nontrivial, since it is hard to collect sufficient well-labeled samples. To address such problem, we present a novel transfer learning model, which is able to incorporate external knowledge obtained from the rich and relevant Web images contributed by grassroots. In particular, we first construct a target domain by crawling a small set of images from vertical and professional dermatological websites. We then construct a source domain by collecting a large set of skin disease related images from commercial search engines. To reinforce the learning performance in the target domain, we initially build a learning model in the target domain, and then seamlessly leverage the training samples in the source domain to enhance this learning model. The distribution gap between these two domains are bridged by a linear combination of Gaussian kernels. Instead of training models with low-level features, we resort to deep models to learn the succinct, invariant, and high-level image representations. Different from previous efforts that focus on a few types of skin diseases with a small and confidential set of images generated from hospitals, this paper targets at thousands of commonly seen skin diseases with publicly accessible Web images. Hence the proposed model is easily repeatable by other researchers and extendable to other disease types. Extensive experiments on a real-world dataset have demonstrated the superiority of our proposed method over the state-of-the-art competitors.	188.00323201357298
102.	Recurrent Neural Network (RNN) based Deep Knowledge Tracing (DKT) can extract a complex representation of student knowledge just using the historical time series of correct-incorrect responses given as input and can predict the student's performance on the next problem. funtoot is a personalized and adaptive learning system used by students to practice problems in school and at home. Our analysis of students' interaction with funtoot showed a time-gap as high as 1 h, 1 day and also 1 week between two problems attempted by a student in a task. In this work, along with the time series of previous correct-incorrect responses, we also encode the time-gap as a feature to investigate its effect on predictions. We call this variant of DKT as DKT-t. We test these models on our dataset and two major publicly available datasets from - Assistments and Carnegie Learning's Cognitive Tutor and analyze the predicted student knowledge by both the models and report our findings. We also show that DKT-t can help us trace the forgetting curve given various response sequences and their knowledge states.	188.00320771551634
103.	Unsupervised learning methods are effective and suitable tools for damage detection. The main reason for the popularity of these methods in structural health monitoring originates from the fact that the process of learning can be implemented by information of the only normal condition called training data. In contrast, supervised learning methods require information of both normal and current conditions for the process of interest. Because civil engineering structures are expensive and complex, it is not reasonable and economical to impose intentional damage on providing training data. Hence, it is not simple to directly exploit supervised learning techniques in structural health monitoring. To deal with this limitation, this article proposes a novel two-level strategy including three algorithms for using the concepts of both unsupervised learning and supervised learning. The major contribution of this strategy is to consider supervised learning as a validation tool for damage detection. First, the results of damage detection are obtained from two unsupervised learning methods developed by Mahalanobis squared distance and a deep autoencoder neural network in the first two algorithms of the proposed strategy. The main objective is to separate accurate and confusing results of damage detection based on Type I and Type II errors. Second, the confusing results are fed into the third algorithm to train a classifier and compute their classification margins for making the final decision and validating damage detection. The effectiveness and applicability of the proposed strategy are assessed by a numerical concrete beam and an experimental laboratory frame. Results show that this strategy with the aid of the Naive Bayes classifier enables the unsupervised learning methods to make accurate decisions.	188.0030812372455
104.	The majority of older people wish to live independently at home as long as possible despite having a range of age-related conditions including cognitive impairment. To facilitate this, there has been an extensive focus on exploring the capability of new technologies with limited success. This paper investigates whether MS Kinect (a motion-based sensing 3-D scanner device) within the MiiHome (My Intelligent Home) project in conjunction with other sensory data, machine learning and big data techniques can assist in the diagnosis and prognosis of cognitive impairment and hence prolong independent living. A pool of Kinect devices and various sensors powered by minicomputers providing internet connectivity are being installed in up to 200 homes. This enables continuous remote monitoring of elderly residents living alone. Passive and off-the-shelf sensor technologies were chosen to implement data acquisition specifically from sources that are part of the fabric of the homes, so that no extra effort is required from the participants. Various constraints including environmental, geometrical and big data were identified and appropriately dealt with. A visualization tool (MAGID) was developed for validation and verification of numerous behavioural activities. Then, a subset of data, from twelve pensioners aged over 65 with age-related cognitive decline and frailty, were collected over a period of 6 months. These data were subjected to several machine learning algorithms (multilayer perceptron neural network, neuro-fuzzy and deep learning) for classification and to extract routine behavioural patterns. These patterns were then analysed further to ascertain any health-related information and their attributes. For the first time, important routine behaviour related to Activities of Daily Living (ADL) of elderly people with cognitive and physical decline has been learnt by machine learning techniques from selected sample data obtained by MS Kinect. Medically important behaviour, e.g. eating, walking, sitting, was best learnt by deep learning with accuracy of 99.30% during training stage and average error rate of 1.83% with maximum of 12.98% during the implementation phase. Observations obtained from the application of the above learnt behaviours are presented as trends over a period of time. These trends, supplemented by other sensory signals, have provided a clearer picture of physical (in)activities (including falls) of the pensioners. The calculated behavioural attributes related to key indicators of health events can be used to model the trajectory of health status related to cognitive decline in a home setting. These results, based on a small number of elderly residents over a short period of time, imply that within the results obtained from the MiiHome project, it is possible to find indicators of cognitive decline. However, further studies are needed for full clinical validation of these indications in conjunction with assessment of cognitive decline of the participants.	188.00292502178098
105.	Handwritten text recognition is one of the most valuable recognition systems because of the unique characteristics of each person's handwriting. Thus, recognition systems need to be more adaptable to recognize same or different characters with different characteristics. On the other hand, one of the most challenging tasks in handwritten text recognition problems is recognizing ancient documents which include several noise within them. While digitizing these documents, these noise appear in different types which effects any recognition system. So, digitizing ancient documents, applying proper pre-processing techniques and performing effective classifier are the main steps of efficient recognition system. In this paper, a complete Ethiopian ancient Geez character recognition system using deep convolutional neural network is proposed in order to recognize twenty-six base characters of this alphabet. The proposed system obtained an accuracy of 99.39% with a model loss of 0.044 which demonstrates its efficiency.	188.0028094101514
106.	The wide spread of fake news has caused huge losses to both governments and the public. Many existing works on fake news detection utilized spreading information like propagators profiles and the propagation structure. However, such methods face the difficulty of data collection and cannot detect fake news at the early stage. An alternative approach is to detect fake news solely based on its content. Early content-based methods rely on manually designed linguistic features. Such shallow features are domain-dependent, and cannot easily be generalized to cross-domain data. Recently, many natural language processing tasks resort to deep learning methods to learn word, sentence, and document representations. In this paper, we propose a novel graph-based neural network model named SemSeq4FD for early fake news detection based on enhanced text representations. In SemSeq4FD, we model the global pair-wise semantic relations between sentences as a complete graph, and learn the global sentence representations via a graph convolutional network with self-attention mechanism. Considering the importance of local context in conveying the sentence meaning, we employ a 1D convolutional network to learn the local sentence representations. The two representations are combined to form the enhanced sentence representations. Then a LSTM-based network is used to model the sequence of enhanced sentence representations, yielding the final document representation for fake news detection. Experiments conducted on four real-world datasets in English and Chinese, including cross-source and cross-domain datasets, demonstrate that our model can outperform the state-of-the-art methods.	188.00273886979878
107.	We propose an effective deep neural network aiming at remote sensing image registration problem. Unlike conventional methods doing feature extraction and feature matching separately, we pair patches from sensed and reference images, and then learn the mapping directly between these patch-pairs and their matching labels for later registration. This end-to-end architecture allows us to optimize the whole processing (learning mapping function) through information feedback when training the network, which is lacking in conventional methods. In addition, to alleviate the small data issue of remote sensing images for training, our proposal introduces a self-learning by learning the mapping function using images and their transformed copies. Moreover, we apply a transfer learning to reduce the huge computation cost in the training stage. It does not only speed up our framework, but also get extra performance gains. The comprehensive experiments conducted on seven sets of remote sensing images, acquired by Radarsat, SPOT and Landsat, show that our proposal improves the registration accuracy up to 2.4-53.7%. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	188.00263576267585
108.	Online social networks allow powerless people to gain enormous amounts of control over particular people's lives and profit from the anonymity or social distance that the Internet provides in order to harass other people. One of the most frequently targeted groups comprise women, as misogyny is, unfortunately, a reality in our society. However, although great efforts have recently been made to identify misogyny, it is still difficult to distinguish as it can sometimes be very subtle and deep, signifying that the use of statistical approaches is not sufficient. Moreover, as Spanish is spoken worldwide, context and cultural differences can complicate this identification. Our contribution to the detection of misogyny in Spanish is two-fold. On the one hand, we apply Sentiment Analysis and Social Computing technologies for detecting misogynous messages in Twitter. On the other, we have compiled the Spanish MisoCorpus-2020, a balanced corpus regarding misogyny in Spanish, and classified it into three subsets concerning (1) violence towards relevant women, (2) messages harassing women in Spanish from Spain and Spanish from Latin America, and (3) general traits related to misogyny. Our proposal combines a classification based on average word embeddings and linguistic features in order to understand which linguistic phenomena principally contribute to the identification of misogyny. We have evaluated our proposal with three machine-learning classifiers, achieving the best accuracy of 85.175%. Finally the proposed approach is also validated with existing corpora for misogyny and aggressiveness detection such as AMI and HatEval obtaining good results (C) 2020 Elsevier B.V. All rights reserved.	188.00256990250395
109.	Deep learning based action recognition methods require large amount of labelled training data. However, labelling large-scale video data is time consuming and tedious. In this paper, we consider a more challenging few-shot action recognition problem where the training samples are few and rare. To solve this problem, memory network has been designed to use an external memory to remember the experience learned in training and then apply it to few-shot prediction during testing. However, existing memory-based methods just update the visual information with fixed label embeddings in the memory, which cannot adapt well to novel activities during testing. To alleviate the issue, we propose a novel end-to-end cross-modal memory network for few-shot activity recognition. Specifically, the proposed memory architecture stores the dynamic visual and textual semantics for some high-level attributes related to human activities. And the learned memory can provide effective multi-modal information for new activity recognition in the testing stage. Extensive experimental results on two video datasets, including HMDB51 and UCF101, indicate that our method could achieve significant improvements over other previous methods. (C) 2020 Elsevier Ltd. All rights reserved.	188.00256825100382
110.	Activity recognition and transportation mode detection are the key research areas for context-aware systems. In smart environments such as cities, buildings, transportation systems etc., ambient intelligence applications watch on human activities in order to increase the quality of transportation, health, traffic and human-oriented services. Literature review shows that existing studies typically deal with recognition of motorized and non-motorized daily activities under the name of human activity recognition and transport mode detection. Only few studies worked on these problems with rich datasets in terms of the number of classes. To the best of our knowledge, for the first time, a study examines nearly the whole motorized/non-motorized transportation modes of people including still, walk, run, climbing upstairs, climbing downstairs, bicycle, motorbike, car, metro, train, high speed rail (HSR), tram and metrobus, excluding ferry and airplane. To outperform existing solutions on such a large dataset, an extended version of the well-known HTC dataset, especially consisting of similar classes, such as train, metro, tram and high speed rail, we propose a combined solution of an Long Short-Term Memory network and Healing algorithm. In our experiments, we first reveal the limits of traditional machine learning algorithms on such number of classes. In addition to that, apart from other studies exploiting deep learning approach, we then examine the potential input types for LSTM network, including raw sensor data, knowledge-based features and features obtained via Auto Encoder. Experimental results show that our proposed idea, feeding knowledge-based features into frames of LSTM network make a remarkable difference and bring out a robust, orientation-independent and generic solution for these well-known problems including activity recognition and transport mode detection. Besides, we examined the hyper-parameters of our deep learning approach and specified the effective parameter set including window size, number of frames, unit size, dropout rate and batch size. Our test results reveal that we could achieve a success rate of 95.5% and outperform the state-of-the art solutions for 12 different transportation modes with the help of our former algorithm, namely Healing, on a totally journey-independent dataset where instances for train, validation and test datasets are selected from different journeys.	188.0025626950415
111.	How to design deep neural networks (DNNs) for the representation and analysis of high dimensional but small sample size data is still a big challenge. One solution is to construct a sparse network. At present, there exist many approaches to achieve sparsity for DNNs by regularization, but most of them are carried out only in the pre-training process due to the difficulty in the derivation of explicit formulae in the fine-tuning process. In this paper, a log-sum function is used as the regularization terms for both the responses of hidden neurons and the network connections in the loss function of the fine-tuning process. It provides a better approximation to the L-0-norm than several often used norms. Based on the gradient formula of the loss function, the fine-tuning process can be executed more efficiently. Specifically, the commonly used gradient calculation in many deep learning research platforms, such as PyTorch or TensorFlow, can be accelerated. Given the analytic formula for calculating gradients used in any layer of DNN, the error accumulated from successive numerical approximations in the differentiation process can be avoided. With the proposed log-sum enhanced sparse deep neural network (LSES-DNN), the spar-sity of the responses and the connections can be well controlled to improve the adaptivity of DNNs. The proposed model is applied to MRI data for both the diagnosis of schizophrenia and the study of brain developments. Numerical experiments demonstrate its superior performance among several classical classifiers tested. (C) 2020 Elsevier B.V. All rights reserved.	188.00209994246308
112.	Particulate matter with a mass concentration of particles with a diameter less than 2.5mum (PM2.5) is a key air quality parameter. A real-time knowledge of PM2.5 is highly valuable for lowering the risk of detrimental impacts on human health. To achieve this goal, we developed a new deep learning model-EntityDenseNet to retrieve ground-level PM2.5 concentrations from Himawari-8, a geostationary satellite providing high temporal resolution data. In contrast to the traditional machine learning model, the new model has the capability to automatically extract PM2.5 spatio-temporal characteristics. Validation across mainland China demonstrates that hourly, daily and monthly PM2.5 retrievals contain the root-mean-square errors of 26.85, 25.3, and 15.34mug/m3, respectively. In addition to a higher accuracy achievement when compared with various machine learning inversion methods (backpropagation neural network, extreme gradient boosting, light gradient boosting machine, and random forest), EntityDenseNet can "peek inside the black box" to extract the spatio-temporal features of PM2.5. This model can show, for example, that PM2.5 levels in the coastal city of Tianjin were more influenced by air from Hebei than Beijing. Further, EntityDenseNet can still extract the seasonal characteristics that demonstrate that PM2.5 is more closely related within three month groups over mainland China: (1) December, January and February, (2) March, April and May, (3) July, August and September, even without meteorological information. EntityDenseNet has the ability to obtain high temporal resolution satellite-based PM2.5 data over China in real-time. This could act as an important tool to improve our understanding of PM2.5 spatio-temporal features.	188.0020911186475
113.	This paper concerns the deployment problem of wireless sensor networks (WSNs) with mobile robotic sensor nodes for spatiotemporal monitoring. The proposed approach, deep reinforced learning tree (DRLT), utilizes deep reinforcement learning (DRL) to improve the efficiency of searching the most informative sampling locations. The parameterized sampling locations in an infinite horizon space are modeled according to their spatiotemporal correlations and subject to various constraints, including field estimation error and information gain. And the model-based information gain can be calculated efficiently over an infinite horizon. In this manner, the effectiveness of the sampling locations is learned through DRLT during the exploration by the robotic sensors. Then DRLT can instruct the robotic sensors to avoid unnecessary sampling locations in future iterations. Also, it is proved in this paper that the proposed algorithm is capable of searching for the near-optimal sampling locations effectively and guaranteeing a minimum field estimation error. Simulation based on national oceanic and atmospheric administration (NOAA) datasets is presented, which demonstrates the significant enhancements made by the proposed algorithm. Compared with the traditional approaches, such as the information theory-based greedy approach or random sampling, the proposed method shows a superior performance with regard to both estimation error and planning efficiency.	188.00191022881702
114.	As Machine Learning applications increase the demand for optimised implementations in both embedded and high-end processing platforms, the industry and research community have been responding with different approaches to implement these solutions. This work presents approximations to arithmetic operations and mathematical functions that, associated with a customised adaptive artificial neural networks training method, based on RMSProp, provide reliable and efficient implementations of classifiers. The proposed solution does not rely on mixed operations with higher precision or complex rounding methods that are commonly applied. The intention of this work is not to find the optimal simplifications for specific deep learning problems but to present an optimised framework that can be used as reliably as one implemented with precise operations, standard training algorithms and the same network structures and hyper-parameters. By simplifying the 'half-precision' floating point format and approximating exponentiation and square root operations, the authors' work drastically reduces the field programmable gate array implementation complexity (e.g. -43 and -57% in two of the component resources). The reciprocal square root approximation is so simple it could be implemented only with combination logic. In a full software implementation for a mixed-precision platform, only two of the approximations compensate the processing overhead of precision conversions.	188.00181421492323
115.	Facial recognition is a tractable problem today because of the prevalence of Deep Learning implementations. Approaches for creating structured datasets from unstructured web data are more easily accessible as are GPUs that deep learning frameworks can use to learn from this data. In DARPA's MEMEX effort, which sought to create better search capabilities for law enforcement to scan the deep and dark web, we are interested in leveraging the Tensorflow framework to reproduce a seminal Deep Learning facial recognition model called VGG-Face. On MEMEX we desired to build the VGG-Face model and to train feature extraction for use in prioritization of leads for possible law enforcement follow-up. We describe our efforts to recreate the VGG-Face dataset, along with our efforts to create the Deep Learning network implementation for it using Tensorflow. Though other implementations of VGG-Face on Tensorflow exist, none of them fully reproduce as much of the dataset as we do today (similar to 48% of the data still exists), nor have detailed documentation and steps for reproducing each step in the workflow. We contribute those instructions and leverage Texas Advanced Computing Center's Maverick2 supercomputer to perform the work. We report experimental results on building the dataset, and training the network to achieve a 77.99% validation accuracy on the 2,622 celebrity use case from VGG-Face. This paper can be a useful recipe in building new Tensorflow facial recognition.	188.00172043573386
116.	For many real-world applications, predicting a price range is more practical and desirable than predicting a concrete value. In this case, price prediction can be regarded as a classification problem. Although deep forest is recognized as the best solution to many classification problems, a crucial issue limits its direct application to price prediction, i.e., it treated all the misclassifications equally no matter how far away they are from the real classes, since their impacts on the accuracy are the same. This is unreasonable to price prediction as the misclassification should be as close to the real price range as possible even if they have to be wrongly classified. To address this issue, we propose a cost-sensitive deep forest for price prediction, which maintains the high accuracy of deep forest, and propels the misclassifications to be closer to the real price range to reduce the cost of misclassifications. To make the classification more meaningful, we develop a discretization method to pre-define the classes of price, by modifying the conventional K-means method. The experimental results based on multiple real-world datasets (i.e., car sharing, house renting and real estate selling) show that, the cost-sensitive deep forest can significantly reduce the cost in comparison with the conventional deep forest and other baselines, while keeping satisfactory accuracy. (C) 2020 Elsevier Ltd. All rights reserved.	188.00162478618057
117.	Remote sensing scene classification is gaining much more interest in the recent few years for many strategic fields such as security, land cover and land use monitoring. Several methods have been proposed in the literature and they can be divided into three main classes based on the features used: handcrafted features, features obtained by unsupervised learning and those obtained from deep learning. Handcrafted features are generally time consuming and suboptimal. Unsupervised learning based features which have been proposed later gave better results but their performances are still limited because they mainly rely on shallow networks and are not able to extract powerful features. Deep learning based features are recently investigated and gave interesting results. But, they cannot be usually used because of the scarcity of labelled remote sensing images and are also computationally expensive. Most importantly, whatever kind of feature is used, the neighbourhood information of them is ignored. In this paper, we propose a novel remote sensing scene representation and classification approach called Bag of Visual SubGraphs (BoVSG). First, each image is segmented into superpixels in order to summarize the image content while retaining relevant information. Then, the superpixels from all images are clustered according to their colour and texture features and a random label is assigned to each cluster that probably corresponds to some material or land cover type. Thus superpixels belonging to the same cluster have the same label. Afterwards, each image is modelled with a graph where nodes correspond to labelled superpixels and edges model spatial neighbourhoods. Finally, each image is represented by a histogram of the most frequent subgraphs corresponding to land cover adjacency patterns. This way, local spatial relations between the nodes are also taken into account. Resultant feature vectors are classified using standard classification algorithms. The proposed approach is tested on three popular datasets and its performance outperforms state-of-the-art methods, including deep learning methods. Besides its accuracy, the proposed approach is computationally much less expensive than deep learning methods.	188.0015780009399
118.	In this paper, a model-free deep reinforcement learning (DRL) strategy is presented with an artificial neural network (ANN) as reaction simulation environment, to obtain a fed-batch control strategy for an experimental bioreactor. The proposed method is a fundamental attempt to control reactions by employing state-of-the-art machine learning tools without the aid of well-established mechanistic understanding of the reaction system. This application utilizes the Asynchronous Advantage Actor-Critic (A3C) algorithm, a member of the DRL family, that takes advantage of actor-critic algorithm and asynchronous learning by parallel learning agents to achieve stability and efficiency of the learning process. The resulting controller demonstrates robust performance in the fed-batch bioreactor since it can be adjusted to meet varying constraining factors including nutrient limitations and culture lengths. Results are presented for a bioreactor that produces cyanobacterial-phycocyanin (C-PC) in Plectonema sp. UTEX 1541. Experimental validations show a 52.1% increase in the product yield, and a 20.1% increase in C-PC concentration compared to a control group with the same total nutrient input replenished in a non-optimized manner. (C) 2020 Elsevier Ltd. All rights reserved.	188.001521588432
119.	Purpose: A deeper understanding was sought of what peer-based social support means to young people with juvenile arthritis within the UK and ways in which it could be best provided. Design and Methods: A secondary analysis of underused, descriptively rich data relating to peer-based support contributed by young people with juvenile arthritis, their parents/carers and healthcare professionals from a qualitative study (seeking their views on a potential self-management mobile-app) was carried out using methods suggested by Interpretive Phenomenological Analysis. Results: Peer-based support can provide a newkind of ` normality' for young peoplewith juvenile arthritis, including greater understanding, relief, reassurance, shared learning and increased self-efficacy. However, the risk of stigma through this shared identity suggests a need to offer various forms of access including using new electronic media. Conclusion and Implications: The evidence suggests that although desired, the potential social cost of identifying with peers livingwith juvenile arthritis is influenced by theway such support is provided, which in turn impacts on howreadily itwill be accessed. This suggests the need to provide various means of accessing peer-based contact, including electronic media, to ensure that young peoplewith juvenile arthritis benefit. Therefore, when promoting and supporting peer-based social support, as far as possible, professionals need to individualise ways in which such support can be accessed because there is no 'one size fits all' approach. (C) 2018 Elsevier Inc. All rights reserved.	188.00150060857428
120.	Establishing up-to-date large scale building maps is essential to understand the urban dynamics, such asestimating population, urban planning, and many other applications. Although many computer vision tasks have been successfully carried out with deep convolutional neural networks, there is a growing need to understand their large scale impact on building mapping with remote sensing imagery. Taking advantage of the scalability of convolutional neural networks (CNNs) and using only few areas with the abundance of building footprints, for the first time we conduct a comparative analysis of four state-of-the-art CNNs for extracting building footprints across the entire continental United States. The four CNN architectures namely: Branch-out CNN, fully convolutional network (FCN), conditional random field as recurrent neural network (CRFasRNN), and SegNet, support semantic pixelwise labeling and focus on capturing textural information at multiscale. We use 1-meter resolution aerial images from National Agriculture Imagery Program as the test-bed, and compare the extraction results across the four methods. In addition, we propose to combine signed-distance labels with SegNet, the preferred CNN architecture identified by our extensive evaluations, to advance building extraction results to instance level. We further demonstrate the usefulness of fusing additional near IR information into the building extraction framework. Large scale experimental evaluations are conducted and reported using metrics that include: Precision, recall rate, intersection over union, and the number of buildings extracted. With the improved CNN model and no requirement of further postprocessing, we have generated building maps for the United States with an average processing time less than oneminute for an area of size similar to 56 km(2). The quality of extracted buildings and processing time demonstrated that the proposed CNN based framework fits the need of building extraction at scale.	188.0014574773075
121.	We present the largest database for visual kinship recognition, Families In the Wild (FIW), with over 13,000 family photos of 1,000 family trees with 4-to-38 members. It took only a small team to build FIW with efficient labeling tools and work-flow. To extend FIW, we further improved upon this process with a novel semi-automatic labeling scheme that used annotated faces and unlabeled text metadata to discover labels, which were then used, along with existing FIW data, for the proposed clustering algorithm that generated label proposals for all newly added data-both processes are shared and compared in depth, showing great savings in time and human input required. Essentially, the clustering algorithm proposed is semi-supervised and uses labeled data to produce more accurate clusters. We statistically compare FIW to related datasets, which unarguably shows enormous gains in overall size and amount of information encapsulated in the labels. We benchmark two tasks, kinship verification and family classification, at scales incomparably larger than ever before. Pre-trained CNN models fine-tuned on FIW outscores other conventional methods and achieved state-of-the art on the renowned KinWild datasets. We also measure human performance on kinship recognition and compare to a fine-tuned CNN.	188.00141370449063
122.	Inspired by the philosophy employed by human beings to determine whether a presented face example is genuine or not, i.e., to glance at the example globally first and then carefully observe the local regions to gain more discriminative information, for the face anti-spoofing problem, we propose a novel framework based on the Convolutional Neural Network (CNN) and the Recurrent Neural Network (RNN). In particular, we model the behavior of exploring face-spoofing-related information from image sub-patches by leveraging deep reinforcement learning. We further introduce a recurrent mechanism to learn representations of local information sequentially from the explored sub-patches with an RNN. Finally, for the classification purpose, we fuse the local information with the global one, which can be learned from the original input image through a CNN. Moreover, we conduct extensive experiments, including ablation study and visualization analysis, to evaluate our proposed framework on various public databases. The experiment results show that our method can generally achieve state-of-the-art performance among all scenarios, demonstrating its effectiveness.	188.00137538430982
123.	Graph-based embedding aims to reduce the dimension of high dimensional data and to extract relevant features for learning tasks. In this letter, we propose an Elastic graph-based embedding with deep architecture which deeply explores the structural information of the data. We introduce a flexible deep learning that can overcome the limitations and weaknesses of single-layer learning models. The proposed deep architecture incorporates the geometrical manifold structure of the data. The resulting framework can be used for semi-supervised and supervised settings. Besides, the resulting optimization problems can be solved efficiently. We apply the algorithm on five public image datasets including scene, face and object datasets. These experiments demonstrate the effectiveness of the proposed embedding method, and also show that the proposed method compares favorably with many competing state-of-the-art graph-based methods. (C) 2020 Elsevier Ltd. All rights reserved.	188.00123207595394
124.	Early fall detection is a crucial research challenge since the time delay from fall to first aid is a key factor that determines the consequences of a fall. Wearable sensors allow a reliable way for daily-life activities tracking, able to detect immediately a high-risk fall via a machine learning framework. Towards this direction, accelerometer devices are used widely for the assessment of fall risk. Although there is a plethora of studies under this perspective with promising results, several challenges still remain such as the extremely demanding data and power management as well as the discovery of false positive falls. In this work we propose a complete methodology based on the combination of the computationally demanding convolutional neural networks along with a lightweight change detection method. Our basic assumption is that it is possible to control computational resources for the operation of a classifier, suffice to be activated when a strong change in user's movements is identified. The proposed methodology was applied to real experimental data providing reliable results that justify the original hypothesis.	188.00120213056047
125.	Several studies have researched the antecedents influencing the perceived trust of guests towards hosts on Airbnb typically relying on survey data. However, the contribution of these antecedents to trust building in a practical context remains unclear. To fill this gap, we focused on the antecedents within the manageable information about hosts and proposed a computational framework for understanding the antecedents influencing perceived trust. Specifically, perceived trust was proxied by the growth rate of bookings and the validity of the proxy method was proved through comparing with human labeled data. From the snapshot information about hosts, the antecedents were quantified through text mining and face recognition methods. The least square regression was applied to analyze and compare the influence of these antecedents. We found that the contribution of reputation is not less than the summation of all the other antecedents. Additionally, in terms of self descriptions, it is worthwhile to pay more attention to interactions and services. Expressing positive sentiment in either self-descriptions or profile photo is also helpful. The response behavior pattern and the number of verifications also matter. At last, several effective trust prediction models were built by using deep neural network and the ensemble method. The findings shed light on the working of the antecedents in trust formation and can provide instructions for the transaction partners, designers and managers of online services in the sharing economy.	188.00116390660037
126.	This paper presents a scalable object detection workflow for detecting objects, such as settlements, from remotely sensed (RS) imagery. We have successfully deployed this workflow on Titan supercomputer and utilized it for the task of mapping human settlement at a country scale. The performance of various stages in the workflow was analyzed before making it operational. The workflow implemented various strategies to address issues such as suboptimal resource utilization and long-tail effects due to unbalanced image workload, data loss due to runtime failures, and maximum wall-time constraints imposed by Titan's job scheduling policy. A mean shift clustering-based static load balancing strategy was implemented, which partitions the image load such that each partition contained similar-sized images. Furthermore, a checkpoint-restart strategy was added in the workflow as a fault-tolerance mechanism to prevent the data losses due to unforeseen runtime failures. The performance of the above-mentioned strategies was observed in various scenarios, such as node failure, exceeding wall time, and successful completion. Using this workflow, we have processed an RS data set that has a spatial resolution of 0.31 m and is comprised of 685 675 km(2) of area of the Republic of Zambia in under six hours using 5426 nodes of the Titan supercomputer.	188.00115648427806
127.	In the past few years, with the rapid development of CPU-GPU heterogeneous computing, the issue of task scheduling in the heterogeneous cluster has attracted a great deal of attention. This problem becomes more challenging with the need for efficient co-execution of tasks on the GPUs. However, the uncertainty of heterogeneous cluster and the interference caused by resource contention among co-executing tasks can lead to the unbalanced use of computing resource and further cause the degradation in performance of computing platform. In this article, we propose a two-stage task scheduling approach for streaming applications based on deep reinforcement learning and neural collaborative filtering, which considers fine-grained task division and task interference on the GPU. Specifically, the Learning-Driven Workload Parallelization (LDWP) method selects an appropriate execution node for the mutually independent tasks. By using the deep Q-network, the cluster-level scheduling model is online learned to perform the current optimal scheduling actions according to the runtime status of cluster environments and characteristics of tasks. The Interference-Aware Workload Parallelization (IAWP) method assigns subtasks with dependencies to the appropriate computing units, taking into account the interference of subtasks on the GPU by using neural collaborative filtering. For making the learning of neural network more efficient, we use pre-training in the two-stage scheduler. Besides, we use transfer learning technology to efficiently rebuild task scheduling model referring to the existing model. We evaluate our learning-driven and interference-aware task scheduling approach on a prototype platform with other widely used methods. The experimental results show that the proposed strategy can averagely improve the throughout for distributed computing system by 26.9 percent and improve the GPU resource utilization by around 14.7 percent.	188.0009010540735
128.	Deep learning is a subset of machine learning where algorithms are created and function similar to those in machine learning, but there are numerous layers of these algorithms each providing a different interpretation to the data it feeds on. Mobile Ad-Hoc Network (MANET) is picking up huge popularity due to their potential of providing low-cost solutions to real-world communication problems. MANETs are more susceptible to the security attacks because of the properties such as node mobility, lack of centralized management and limited bandwidth. To tackle these security issues, traditional cryptography schemes can-not completely safeguard MANETs in terms of novel threats and vulnerabilities, thus by applying deep learning methods in IDS are capable of adapting the dynamic environments of MANETs and enables the system to make decisions on intrusion while continuing to learn about their mobile environment. IDS represent the second line of defense against malevolent behavior to MANETs since they monitor network activities in order to detect any malicious attempt performed by Intruders. Recently, more and more researchers applied deep neural networks (DNNs) to solve intrusion detection problems. Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN), the two main types of DNN architectures, are widely explored to enhance the performance of intrusion detection system. In this paper, we present the most well-known deep learning models CNN, Inception-CNN, Bi-LSTM and GRU and we made a systematic comparison of CNN and RNN on the deep learning-based intrusion detection systems, aiming to give basic guidance for DNN selection in MANET	188.00075938771974
129.	We present a simulation-based study using deep convolutional neural networks (DCNNs) to identify neutrino interaction vertices in the MINERvA passive targets region, and illustrate the application of domain adversarial neural networks (DANNs) in this context. DANNs are designed to be trained in one domain (simulated data) but tested in a second domain (physics data) and utilize unlabeled data from the second domain so that during training only features which are unable to discriminate between the domains are promoted. MINERvA is a neutrino-nucleus scattering experiment using the NuMI beamline at Fermilab. A-dependent cross sections are an important part of the physics program, and these measurements require vertex finding in complicated events. To illustrate the impact of the DANN we used a modified set of simulation in place of physics data during the training of the DANN and then used the label of the modified simulation during the evaluation of the DANN. We find that deep learning based methods offer significant advantages over our prior track-based reconstruction for the task of vertex finding, and that DANNs are able to improve the performance of deep networks by leveraging available unlabeled data and by mitigating network performance degradation rooted in biases in the physics models used for training.	188.000736341648
130.	While the term artificial intelligence and the concept of deep learning are not new, recent advances in high-performance computing, the availability of large annotated data sets required for training, and novel frameworks for implementing deep neural networks have led to an unprecedented acceleration of the field of molecular (network) biology and pharmacogenomics. The need to align biological data to innovative machine learning has stimulated developments in both data integration (fusion) and knowledge representation, in the form of heterogeneous, multiplex, and biological networks or graphs. In this chapter we briefly introduce several popular neural network architectures used in deep learning, namely, the fully connected deep neural network, recurrent neural network, convolutional neural network, and the autoencoder. Deep learning predictors, classifiers, and generators utilized in modern feature extraction may well assist interpretability and thus imbue AI tools with increased explication, potentially adding insights and advancements in novel chemistry and biology discovery.The capability of learning representations from structures directly without using any predefined structure descriptor is an important feature distinguishing deep learning from other machine learning methods and makes the traditional feature selection and reduction procedures unnecessary. In this chapter we briefly show how these technologies are applied for data integration (fusion) and analysis in drug discovery research covering these areas: (1) application of convolutional neural networks to predict ligand-protein interactions; (2) application of deep learning in compound property and activity prediction; (3) de novo design through deep learning. We also: (1) discuss some aspects of future development of deep learning in drug discovery/chemistry; (2) provide references to published information; (3) provide recently advocated recommendations on using artificial intelligence and deep learning in -omics research and drug discovery.	188.00071349572687
131.	The U.S. power grid is transforming to become "smarter," cleaner, and more efficient. This is leading to the addition of significant distributed variable renewable generation. Due to the variable nature of renewable generation, the short- and long-term supply-demand imbalances are less predictable, and conventional approaches to mitigating the imbalance will not be efficient or cost-effective. To address this challenge, transactive control technologies have been proposed. The transactive control approach requires individual end-use loads to express flexibility as a function of price. To model flexibility while maintaining robustness to any non-linear behavior exhibited by end-use loads, machine learning approaches for load forecasting are being explored. However, certain aspects, such as how much training data is required and how deep models for load forecasting should be structured and trained are not well understood. This work explores how to apply sequence-to-sequence recurrent neural networks to short-term electrical load forecasting with a case study of four commercial office buildings. We find that it is best to start the training in the middle of a heating or cooling season with at least six months of data. We further show that models perform best when predictions are conditioned on three to 12 h of prior data, with a decrease in performance for shorter contexts. We identify recommended ranges for common hyperparameters that could be used by practitioners applying similar models to their own tasks. Finally, we find that transferability of models across buildings is highly dependent on the building pairs, but in the best case, models are highly transferable. (C) 2020 Published by Elsevier B.V.	188.00064157826336
132.	Cloud manufacturing is a new manufacturing model that aims to provide on-demand manufacturing services to consumers over the Internet. Service composition is an essential issue as well as an important technique in cloud manufacturing (CMfg) that supports construction of larger-granularity, value-added services by combining a number of smaller-granularity services to satisfy consumers' complex requirements. Meta-heuristics algorithms such as genetic algorithm, particle swarm optimization, and ant colony algorithm are frequently employed for addressing service composition issues in cloud manufacturing. These algorithms, however, require complex design flows and painstaking parameter tuning, and lack adaptability to dynamic environment. Deep re-inforcement learning (DRL) provides an alternative approach for solving cloud manufacturing service compo-sition (CMfg-SC) issues. DRL as model-free artificial intelligent methods enables a system to learn optimal service composition solutions through training, which can therefore circumvent the aforementioned problems with meta-heuristics algorithms. This paper is dedicated to exploring possible applications of DRL in CMfg-SC. A logistics-involved QoS-aware DRL-based CMfg-SC is proposed. A dueling Deep Q-Network (DQN) with prior-itized replay named PD-DQN is designed as the DRL algorithm. Effectiveness, robustness, adaptability, and scalability of PD-DQN are investigated, and compared with that of the basic DQN and Q-learning. Experimental results indicate that PD-DQN is able to effectively address the CMfg-SC problem.	188.0005913640004
133.	The rapid growth in autonomous industrial environments has increased the need for intelligent video surveillance. As a predominant element of video surveillance, recognition of complex human movements is important in a wide range of surveillance applications. However, the current state-of-the-art video surveillance techniques use supervised deep learning pipelines for human activity recognition (HAR). A key shortcoming of such techniques is the inability to learn from unlabeled video streams. To operate effectively in natural environments, video surveillance techniques have to be able to handle huge volumes of unlabeled video data, monitor and generate alerts and insights derived from multiple characteristics such as spatial structure, motion flow, color distribution, etc. Furthermore, most conventional learning systems lack memory persistence capability which can reduce the influence of outdated information in memory-guided decision-making resulting in limiting plasticity and overfitting based on specific past events. In this article, we propose a new adaptation of the Growing Self-Organizing Map (GSOM) to address these shortcomings by 1) adopting two proven concepts of traditional deep learning, hierarchical, and multistream learning, applied into GSOM self-structuring architecture to accommodate learning from unlabeled video data and their diverse characteristics, 2) address overfitting and the influence of outdated information on neural architecture by implementing a transience property in the algorithm. We demonstrate the proposed model using three benchmark video datasets and the results confirm its validity and usability for HAR.	188.00040464438894
134.	Mobile sensing has allowed the emergence of a variety of solutions related to the monitoring and recognition of human activities (HAR). Such solutions have been implemented in smartphones for the purpose of better understanding human behavior. However, such solutions still suffer from the limitations of the computing resources found on smartphones. In this sense, the HAR area has focused on the development of solutions of low computational cost. In general, the strategies used in the solutions are based on shallow and deep learning algorithms. The problem is that not all of these strategies are feasible for implementation in smartphones due to the high computational cost required, mainly, by the steps of data preparation and the training of classification models. In this context, this article evaluates a new set of alternative strategies based on Symbolic Aggregate Approximation (SAX) and Symbolic Fourier Approximation (SFA) algorithms with the purpose of developing solutions with low computational cost in terms of memory and processing. In addition, this article also evaluates some classification algorithms adapted to manipulate symbolic data, such as SAX-VSM, BOSS, BOSS-VS and WEASEL. Experiments were performed on the UCI-HAR, SHOAIB and WISDM databases commonly used in the literature to validate HAR solutions based on smartphones. The results show that the symbolic representation algorithms are faster in the feature extraction phase, on average, by 84.81%, and reduce the consumption of memory space, on average, by 94.48%, and they have accuracy rates equivalent to conventional algorithms.	188.0003212273033
135.	ALEKS, which stands for "Assessment and LEarning in Knowledge Spaces", is a web-based, artificially intelligent, adaptive learning and assessment system. Previous work has shown that student knowledge retention within the ALEKS system exhibits the characteristics of the classic Ebbinghaus forgetting curve. In this study, we analyze in detail the factors affecting the retention and forgetting of knowledge within ALEKS. From a dataset composed of over 3 3 million ALEKS assessment questions, we first identify several informative variables for predicting the knowledge retention of ALEKS problem types (where each problem type covers a discrete unit of an academic course). Based on these variables, we use an artificial neural network to build a comprehensive model of the retention of knowledge within ALEKS. In order to interpret the results of this neural network model, we apply a technique called permutation feature importance to measure the relative importance of each feature to the model. We find that while the details of a student's learning activity are as important as the time that has passed from the initial learning event, the most important information for our model resides in the specific problem type under consideration.	188.00028377184168
136.	Accurate species identification is the basis for all aspects of taxonomic research and is an essential component of workflows in biological research. Biologists are asking for more efficient methods to meet the identification demand. Smart mobile devices, digital cameras as well as the mass digitisation of natural history collections led to an explosion of openly available image data depicting living organisms. This rapid increase in biological image data in combination with modern machine learning methods, such as deep learning, offers tremendous opportunities for automated species identification. In this paper, we focus on deep learning neural networks as a technology that enabled breakthroughs in automated species identification in the last 2 years. In order to stimulate more work in this direction, we provide a brief overview of machine learning frameworks applicable to the species identification problem. We review selected deep learning approaches for image based species identification and introduce publicly available applications. Eventually, this article aims to provide insights into the current state-of-the-art in automated identification and to serve as a starting point for researchers willing to apply novel machine learning techniques in their biological studies. While modern machine learning approaches only slowly pave their way into the field of species identification, we argue that we are going to see a proliferation of these techniques being applied to the problem in the future. Artificial intelligence systems will provide alternative tools for taxonomic identification in the near future.	188.0002217823469
137.	In recent years, weeds have been responsible for most agricultural yield losses. To deal with this threat, farmers resort to spraying the fields uniformly with herbicides. This method not only requires huge quantities of herbicides but impacts the environment and human health. One way to reduce the cost and environmental impact is to allocate the right doses of herbicide to the right place and at the right time (precision agriculture). Nowadays, unmanned aerial vehicles (UAVs) are becoming an interesting acquisition system for weed localization and management due to their ability to obtain images of the entire agricultural field with a very high spatial resolution and at a low cost. However, despite significant advances in UAV acquisition systems, the automatic detection of weeds remains a challenging problem because of their strong similarity to the crops. Recently, a deep learning approach has shown impressive results in different complex classification problems. However, this approach needs a certain amount of training data, and creating large agricultural datasets with pixel-level annotations by an expert is an extremely time-consuming task. In this paper, we propose a novel fully automatic learning method using convolutional neuronal networks (CNNs) with an unsupervised training dataset collection for weed detection from UAV images. The proposed method comprises three main phases. First, we automatically detect the crop rows and use them to identify the inter-row weeds. In the second phase, inter-row weeds are used to constitute the training dataset. Finally, we perform CNNs on this dataset to build a model able to detect the crop and the weeds in the images. The results obtained are comparable to those of traditional supervised training data labeling, with differences in accuracy of 1.5% in the spinach field and 6% in the bean field.	188.00014098093376
138.	Image segmentation is the method of partitioning an image into a group of pixels that are homogenous in some manner. The homogeneity dependents on some attributes like intensity, color etc. Segmentation being a pre-processing step in image processing have been used in the number of applications like identification of objects to medical images, satellite images and much more. The taxonomy of an image segmentation methods collectively can be divided among two categories Traditional methods and Soft Computing (SC) methods. Unlike Traditional methods, SC methods have the ability to simulate human thinking and are flexible to work with their ownership function, have been predominantly applied to the task of image segmentation. SC techniques are tolerant of partial truth, imprecision, uncertainty, and approximations. Soft Computing approaches also having advantages of providing cost-effective, high performance and steadfast solutions. In this survey paper, our emphasis is on core SC approaches like Fuzzy logic, Artificial Neural Network, and Genetic Algorithm used for image segmentation. The contribution lies in the fact to present this paper to the researchers that explore state-of-the-art elaboration of almost all dimensions associated with the image segmentation. The idea is to encapsulate various aspects like emerging topics, methods, evaluation parameters, the problem associated with different type of images, databases, segmentation applications, and other resources so that, it could be advantageous for researchers to make effort in developing new methods for segmentation. The paper accomplishes with findings and concluding remarks.	188.00003923677252
139.	Deep learning technology has been widely developed in all walks of life, especially in the medical research field. Recently, the deep neural network model has become a deeper and better direction, and followed by the problem of computing resources. The feasibility of a large neural network model can be evaluated by its suitability to sophisticated medical devices. With this basis, we propose an adaptive model optimization framework (AMOF). Compared to reported model compression techniques, we focus on the correlation between channels. AMOF cannot only output an accurate compression ratio, but also search for the optimal pruning channel. Specifically, evolutionary algorithms were introduced on the basis of reinforcement learning. Due to the complexity of a neural network, we propose a co-evolutionary algorithm, so as to guarantee the simultaneous evolution of multiple populations and finally output the optimal cutting channel. Notably, AMOF, combining reinforcement learning and evolutionary algorithm, can ensure the accuracy of this model applied under the full compression condition. The effectiveness of AMOF was proved by a large number of experimental tests. For example, on the CIFAR-10, the ResNet56 channel after our frame trimming was reduced by 30%; and the accuracy remained at 89.27%. Compared to the reinforcement learning compression method alone, AMOF can increase by 3.5 percentage points in the ResNet20 model.	187.99978907462668
140.	Biomechanical analyses provide an extensive source of data that are deeply explored by physicians, engineers and trainers from the mechanical and physiological point of view. This data includes kinetic and kinematic parameters that are quite useful to study human locomotion. However, most of these analyses stay on a very superficial level. Recently data and computational science expanded their coverage to new areas and new analysis tools are available. These analyses include the use of machine learning tools for data mining processes. All of these new tools open a total new level of data analysis, thus newer and deeper questions are proposed in order to provide more accurate prediction results with strict decision support. On the other hand, Squat is an exercise widely used for physical conditioning since it puts into operation various muscles at the same time of the lower and upper train. However bad squatting could drive to injuries at the back and knee level. These injuries are especially common in patients without physical conditioning. In this study, squat data is analyzed using Self-Organizing Maps (SOM) to identify possible relevant parameters from the subjects that could affect the movement performance especially at the knee joint.	187.99974982395443
141.	Keypoint detection is one of the most important pre-processing steps in tasks such as face modeling, recognition and verification. In this paper, we present an iterative method for Keypoint Estimation and Pose prediction of unconstrained faces by Learning Efficient H-CNN Regressors (KEPLER) for addressing the unconstrained face alignment problem. Recent state-of-the-art methods have shown improvements in facial keypoint detection by employing Convolution Neural Networks (CNNs). Although a simple feed forward neural network can learn the mapping between input and output spaces, it does not learn the inherent structural dependencies that well. We present a novel architecture called H-CNN (Heatmap-CNN) acting on an N-dimensional input image which captures informative structured global and local features and thus favors accurate keypoint detecion in in-the wild face images. H-CNN is jointly trained on the visibility, fiducials and 3D-pose of the face. As the iterations proceed, the error decreases making the gradients small and thus requiring efficient training of deep networks to mitigate this. KEPLER performs global corrections in pose and fiducials for the first four iterations followed by local corrections at a later stage. As a byproduct, KEPLER also provides robust estimate of 3D pose (pitch, yaw and roll) of the face. We also show that without using any 3D information, KEPLER outperforms recent state-of-the-art methods for alignment on challenging datasets such as AFW [1] and AFLW [12]. (C) 2018 Elsevier B.V. All rights reserved.	187.99961618340797
142.	Artificial intelligence-based machinery fault diagnosis techniques have been increasingly considered in many industrial fields. The convolutional neural network (CNN) is able to learn features from raw signals because of its filter structure. Thus, several studies have applied CNN-based methods for machinery fault recognition and classification. However, most of these studies are based on a balanced data set, while ignoring that normal data and fault data tend to be highly imbalanced in real-world applications. Conventional CNNs do not work well for highly imbalanced fault diagnostics tasks and often lead to the degradation of performance. Therefore, in this article, a learning framework called deep focus parallel convolutional neural network (DFPCN) is proposed to overcome the weakness. It has powerful feature learning capabilities due to its parallel convolutional architecture. A new loss function named adaptive cross entropy loss (ACE loss) is designed for the DFPCN to focus training on minority health condition samples which are hard to classify. The effectiveness and superiority of the proposed DFPCN are validated by a highly imbalanced data set constructed from bearing vibration signals. The diagnostics results demonstrate that DFPCN outperforms the state-of-the-art CNN-based methods in terms of accuracy and stability, and avoids adding computational burden with the redundant samples when compared with oversampling methods.	187.99939108310394
143.	Natural Language Generation (NLG) plays a critical role in Spoken Dialogue Systems (SDSs), aims at converting a meaning representation into natural language utterances. Recent deep learning-based generators have shown improving results irrespective of providing sufficient annotated data. Nevertheless, how to build a generator that can effectively utilize as much of knowledge from a low-resource setting data is a crucial issue for NLG in SDSs. This paper presents a variational-based NLG framework to tackle the NLG problem of having limited annotated data in two scenarios, domain adaptation and low-resource in-domain training data. Based on this framework, we propose a novel adversarial domain adaptation NLG taclking the former issue, while the latter issue is also handled by a second proposed dual variational model. We extensively conducted the experiments on four different domains in a variety of training scenarios, in which the experimental results show that the proposed methods not only outperform previous methods when having sufficient training dataset but also show its ability to work acceptably well when there is a small amount of in-domain data or adapt quickly to a new domain with only a low-resource target domain data. (C) 2020 Published by Elsevier Ltd.	187.9991294747508
144.	Environmental exploration is one of the common tasks in the robotic domain which is also known as foraging. In comparison with the typical foraging tasks, our work focuses on the Multi-Robot Task Allocation (MRTA) problem in the exploration and destruction domain, where a team of robots is required to cooperatively search for targets hidden in the environment and attempt to destroy them. As usual, robots have the prior knowledge about the suspicious locations they need to explore but they don't know the distribution of interested targets. So the destruction task is dynamically generated along with the execution of exploration task. Each robot has different strike ability and each target has uncertain anti-strike ability, which means either the robot or target is likely to be damaged in the destruction task according to that whose ability is higher. The above setting significantly increases the complexity of exploration and destruction problem. The auction-based approach, vacancy chain approach and a deep Q-learning approach based on strategy-level selection are employed in this paper to deal with this problem. A new simulation system based on Robot Operating System and Gazebo is specially built for this MRTA problem. Subsequently, extensive simulation results are provided to show that all proposed approaches are able to solve the MRTA problem in exploration and destruction domain. In addition, experimental results are further analyzed to show that each method has its own advantages and disadvantages.	187.9986282407972
145.	Current system thermal-hydraulic codes have limited credibility in simulating real plant conditions, especially when the geometry and boundary conditions are extrapolated beyond the range of test facilities. Because mesh size is one of the model parameters for these coarse-mesh codes with simplified boundary-layer treatments, the mesh-induced error and model error are tightly connected, which makes it difficult to evaluate mesh effect or model scalability independently, as in classical scaling analysis. This paper proposes a data-driven approach, Feature-Similarity Measurement (FSM), to establish a technical basis to overcome these difficulties by exploring local patterns using machine learning. The underlying local patterns in multiscale data are represented by a set of physical features that embody the information from a physical system of interest, empirical correlations, and the effect of mesh size. After performing a limited number of high-fidelity numerical simulations and a sufficient amount of fast-running coarse-mesh simulations, an error database is built, and deep learning is applied to construct and explore the relationship between the local physical features and simulation errors. As a result, a data-driven model can be developed to provide an accurate estimate on the simulation error even when global-scale gaps exist. Case studies based on mixed convection have been designed for demonstrating the capability of data-driven models in bridging global-scale gaps. (C) 2020 Elsevier Ltd. All rights reserved.	187.99859805423776
146.	To defend against an increasing number of sophisticated malware attacks, deep-learning based Malware Detection Systems (MDSs) have become a vital component of our economic and national security. Traditionally, researchers build the single deep learning model using the entire dataset. However, the single deep learning model may not handle the increasingly complex malware data distributions effectively since different sample subspaces representing a group of similar malware may have unique data distribution. In order to further improve the performance of deep learning based MDSs, we propose a Multi-Level Deep Learning System (MLDLS) that organizes multiple deep learning models using the tree structure. Each model in the tree structure of MLDLS was not built on the whole dataset. Instead, each deep learning model focuses on learning a specific data distribution for a particular group of malware and all deep learning models in the tree work together to make a final decision. Consequently, the learning effectiveness of each deep learning model built for one cluster can be improved. Experimental results show that our proposed system performs better than the traditional approach. (C) 2019 Elsevier Ltd. All rights reserved.	187.99854491022376
147.	Background: Deep learning systems have improved performance of devices through more accurate object detection in a significant number of areas, for medical aid in general, and also for navigational aids for the visually impaired. Systems addressing different needs are available, and many manage effectively the detection of static obstacles.Purpose: This research provides a review of deep learning systems used with navigational tools for the visually Impaired and a framework for guidance for future research.Methods: We compare current deep learning systems used with navigational tools for the visually impaired and compile a taxonomy of indispensable features for systems.Results: Challenges to detection. Our taxonomy of improved navigational systems shows that it is sufficiently robust to be generally applied.Conclusion: This critical analysis is, to the best of our knowledge, the first of its kind and will provide a much-needed overview of the field. Implication for Rehabilitation Deep learning systems can provide lost cost solutions for the visually impaired. Of these, convolutional neural networks (CNN) and fully convolutional neural networks (FCN) show great promise in terms of the development of multifunctional technology for the visually impaired (i.e., being less specific task oriented). CNN have also potential for overcoming challenges caused by moving and occluded objects. This work has also highlighted a need for greater emphasis on feedback to the visually impaired which for many technologies is limited.	187.99812472284597
148.	Similarity has always been a key aspect in computer science and statistics. Any time two element vectors are compared, many different similarity approaches can be used, depending on the final goal of the comparison (Euclidean distance, Pearson correlation coefficient, Spearman's rank correlation coefficient, and others). But if the comparison has to be applied to more complex data samples, with features having different dimensionality and types which might need compression before processing, these measures would be unsuitable. In these cases, a siamese neural network may be the best choice: it consists of two identical artificial neural networks each capable of learning the hidden representation of an input vector. The two neural networks are both feedforward perceptrons, and employ error back-propagation during training; they work parallelly in tandem and compare their outputs at the end, usually through a cosine distance. The output generated by a siamese neural network execution can be considered the semantic similarity between the projected representation of the two input vectors. In this overview we first describe the siamese neural network architecture, and then we outline its main applications in a number of computational fields since its appearance in 1994. Additionally, we list the programming languages, software packages, tutorials, and guides that can be practically used by readers to implement this powerful machine learning model.	187.99792880190216
149.	Automatic dynamic sign language recognition is even more challenging than gesture recognition due to the fact that the vocabularies are large and signs are context dependent. Previous works in this direction tend to build classifiers based on complex hand-crafted features computed from the raw inputs. As a type of deep learning model, convolutional neural networks (CNNs) have significantly advanced the accuracy of human gesture classification. However, such methods are currently used to treat video frames as 2D images and recognize gestures at the individual frame level. In this paper, we present a data driven system in which 3D-CNNs are applied to extract spatial and temporal features from video streams, and the motion information is captured by noting the variation in depth between each pair of consecutive frames. To further boost the performance, multi-modal of video streams, including infrared, contour and skeleton are used as input for the architecture and the prediction results estimated from the different sub-networks were fused together. In order to validate our method, we introduce a new challenging multi-modal dynamic sign language dataset captured with Kinect sensors. We evaluate the proposed approach on the collected dataset and achieve superior performance. Moreover, our method achieves a mean Jaccard Index score of 0.836 on the ChaLearn Looking at People Gesture datasets.	187.99786613403523
150.	Artificial intelligence education (AIEd) is defined in the field of education as the utilization of artificial intelligence. There are currently many AIEd-driven applications in schools and universities. This paper applies an artificial intelligence module combined with the knowledge recommendation to the system and develops an online English teaching system in comparison with the common teaching auxiliary system. The method of English teaching is useful in investigating the potential internal connections between evaluation outcomes and various factors. This article develops deep learning-assisted online intelligent English teaching system that utilizes to create a modern tool platform to help students improve their English language teaching efficiency in line with their mastery of knowledge and personality. The decision tree algorithm and neural networks have been used and to generate an English teaching assessment implementation model based on decision tree technologies. It provides valuable data from extensive information, summarizes rules and data, and helps teachers to improve their education and the English scores of students. This system reflects the thinking of the artificial intelligence expert system. Test application demonstrates that the system can help students improve their learning efficiency and will make learning content more relevant. Besides, the system provides an example model with similar methods and has a referential definition.	187.997572878252
151.	While deep learning is undoubtedly the predominant learning technique across speech processing, it is still not widely used in health-based applications. The corpora available for health-style recognition problems are often small, both concerning the total amount of data available and the number of individuals present. The Bipolar Disorder corpus, used in the 2018 Audio/Visual Emotion Challenge, contains only 218 audio samples from 46 individuals. Herein, we present a multi-instance learning framework aimed at constructing more reliable deep learning-based models in such conditions. First, we segment the speech files into multiple chunks. However, the problem is that each of the individual chunks is weakly labelled, as they are annotated with the label of the corresponding speech file, but may not be indicative of that label. We then train the deep learning-based (ensemble) multi-instance learning model, aiming at solving such a weakly labelled problem. The presented results demonstrate that this approach can improve the accuracy of feedforward, recurrent, and convolutional neural nets on the 3-class mania classification tasks undertaken on the Bipolar Disorder corpus.	187.99747651751153
152.	The viewpoint variability across a network of non-overlapping cameras is a challenging problem affecting person re-identification performance. In this paper, we investigate how to mitigate the cross-view ambiguity by learning highly discriminative deep features under the supervision of a novel loss function. The proposed objective is made up of two terms, the steering meta center term and the enhancing centers dispersion term, that steer the training process to mining effective intra-class and inter-class relationships in the feature domain of the identities. The effect of our loss supervision is to generate a more expanded feature space of compact classes where the overall level of the inter-identities' interference is reduced. Compared with the existing metric learning techniques, this approach has the advantage of achieving a better optimization because it jointly learns the embedding and the metric contextually. Our technique, by dismissing side-sources of performance gain, proves to enhance the CNN invariance to viewpoint without incurring increased training complexity (like in Siamese or triplet networks) and outperforms many related state-of-the-art techniques on Market-1501 and CUHK03.	187.99741970125558
153.	Social networking sites have a wealth of user-generated unstructured text for fine-grained sentiment analysis regarding the changing dynamics in the marketplace. In aspect-level sentiment analysis, aspect term extraction (ATE) task identifies the targets of user opinions in the sentence. In the last few years, deep learning approaches significantly improved the performance of aspect extraction. However, the performance of recent models relies on the accuracy of dependency parser and part-of-speech (POS) tagger, which degrades the performance of the system if the sentence doesn't follow the language constraints and the text contains a variety of multi-word aspect-terms. Furthermore, lack of domain and contextual information is again an issue to extract domain-specific, most relevant aspect terms. The existing approaches are not capable of capturing long term dependencies for noun phrases, which in turn fails to extract some valid aspect terms. Therefore, this paper proposes a two-step mixed unsupervised model by combining linguistic patterns with deep learning techniques to improve the ATE task. The first step uses rules-based methods to extract the single word and multi-word aspects, which further prune domain-specific relevant aspects using fine-tuned word embedding. In the second step, the extracted aspects in the first step are used as label data to train the attention-based deep learning model for aspect-term extraction. The experimental evaluation on the SemEval-16 dataset validates our approach as compared to the most recent and baseline techniques. (c) 2020 Elsevier Ltd. All rights reserved.	187.9973931431495
154.	A hyperspectral image (HSI) includes a vast quantity of samples, a large number of bands, and randomly occurring redundancy. Classifying such complex data is challenging, and its classification performance can be affected significantly by the amount of labeled training samples, as well as the quality, position, and others factors of these samples. Collecting such labeled training samples is labor and time consuming, motivating the idea of taking advantage of labeled samples from other pre-existing related images. Therefore, transfer learning, which can mitigate the semantic gap between existing and new HSIs, has drawn increasing research attention. However, existing transfer learning methods for HSIs (which mainly concentrate on how to overcome the divergence among images) may fail to carefully consider the contents to be transferred and thus limit their performances. In this paper, we present two novel ideas: 1) we, for the first time, introduce an active learning process to initialize the salient samples on the HSI data, which would be transferred later; and 2) we propose constructing and connecting higher level features for the source and target HSI data to further overcome the cross-domain disparity. Different from existing methods, the proposed framework requires no a priori knowledge on the target domain, and it works for both homogeneous and heterogeneous HSI data. Experimental results on three real-world HSIs support the effectiveness of the proposed method for HSI classification.	187.99726835561754
155.	Large-scale data with human annotations is of crucial importance for training deep convolutional neural network (DCNN) to ensure stable and reliable performance. However, accurate annotations, such as bounding box and pixel-level annotations, demand expensive labeling effort s, which has prevented wide application of DCNN in industries. Focusing on the problem of surface defect detection, this paper proposes a weakly supervised learning method named Category-Aware object Detection network (CADN) to tackle the dilemma. CADN is trained with image tag annotations only and performs image classification and defect localization simultaneously. The weakly supervised learning is achieved by extracting category aware spatial information in a classification pipeline. CADN could be equipped with either a lighter or a larger backbone network as the feature extractor resulting in better real-time performance or higher accuracy. To address the two conflicting objectives simultaneously, both of which are significant concerns in industrial applications, knowledge distillation strategy is adopted to force the learned features of a lighter CADN to mimic that of a larger CADN. Accordingly, the accuracy of the lighter CADN is improved while high real-time performance is maintained. The proposed approach is verified on our own defect dataset as well as on an open-source defect dataset. As demonstrated, satisfied performance is achieved by the proposed method, which could meet industrial requirements completely. Meanwhile, the method minimizes human effort s involved in image labelling, thus promoting the applications of DCNN in industries. (C) 2020 Elsevier Ltd. All rights reserved.	187.99718931251
156.	This paper studies the joint communication, caching and computing design problem for achieving the operational excellence and the cost efficiency of the vehicular networks. Moreover, the resource allocation policy is designed by considering the vehicle's mobility and the hard service deadline constraint. These critical challenges have often been either neglected or addressed inadequately in the existing work on the vehicular networks because of their high complexity. We develop a deep reinforcement learning with the multi-timescale framework to tackle these grand challenges in this paper. Furthermore, we propose the mobility-aware reward estimation for the large timescale model to mitigate the complexity due to the large action space. Numerical results are presented to illustrate the theoretical findings developed in the paper and to quantify the performance gains attained.	187.99710185010912
157.	We propose an end-to-end learning framework for segmenting generic objects in both images and videos. Given a novel image or video, our approach produces a pixel-level mask for all "object-like" regions-even for object categories never seen during training. We formulate the task as a structured prediction problem of assigning an object/background label to each pixel, implemented using a deep fully convolutional network. When applied to a video, our model further incorporates a motion stream, and the network learns to combine both appearance and motion and attempts to extract all prominent objects whether they are moving or not. Beyond the core model, a second contribution of our approach is how it leverages varying strengths of training annotations. Pixel-level annotations are quite difficult to obtain, yet crucial for training a deep network approach for segmentation. Thus we propose ways to exploit weakly labeled data for learning dense foreground segmentation. For images, we show the value in mixing object category examples with image-level labels together with relatively few images with boundary-level annotations. For video, we show how to bootstrap weakly annotated videos together with the network trained for image segmentation. Through experiments on multiple challenging image and video segmentation benchmarks, our method offers consistently strong results and improves the state-of-the-art for fully automatic segmentation of generic (unseen) objects. In addition, we demonstrate how our approach benefits image retrieval and image retargeting, both of which flourish when given our high-quality foreground maps. Code, models, and videos are at: http://vision.cs.utexas.edu/projects/pixelobjectness/	187.99707388363862
158.	Box level annotation of a large number of logo images for training purpose of typical deep learning architecture is highly challenging. Thus, a method that can detect the logo with the help of training to remove box-level annotations can be helpful. In this paper, we present a method of logo detection that utilizes weakly supervised learning of Convolutional Neural Network (CNN) to generate a deep saliency map. The saliency map is generated from the back-propagated response of the CNN trained with the classification task. The saliency map produces responses for the regions of logos. GrabCut segmentation method has been applied then to obtain the bounding box corresponding to the logo class predicted by the CNN for a given image. AlexNet, CaffeNet, and VGGNet deep architectures has been fine-tuned for the classification purpose. The framework is further utilized for detection through a back-propagated saliency map. The performance of the proposed methodology has been validated on the FlickrLogos-32 logo benchmark dataset. The proposed method outperforms the state-of-the-art baseline fully supervised methods with mean average precision (mAP) of 75.83%.	187.99705974869283
159.	As the central area of human activities, built-up area has been one of the most important objects that are recognized from a remote sensing image. Built-up area in different regions has characteristics as follows: the structure and texture of the built-up area are complex and diverse; the buildings have multitudinous materials; the vegetation distribution and background around the built-up area are changeable. The existing built-up area detection methods still face the challenge to achieve favorable precision and generalization ability. In this paper, a double-stream convolutional neural network (DSCNN) model is proposed to extract the built-up area automatically, which can combine the complementary cues of high-resolution panchromatic and multispectral image. Some post-processing steps are adopted to make the results more reasonable. We manually annotated a large-scale dataset for training and testing DSCNN. Experiments demonstrate that the proposed method has a higher overall accuracy as well as better generalization ability compared to the state-of-the-art techniques.	187.99700530243825
160.	Deep auto-encoders (DAEs) have achieved great success in learning data representations via the powerful representability of neural networks. But most DAEs only focus on the most dominant structures which are able to reconstruct the data from a latent space and neglect rich latent structural information. In this work, we propose a new representation learning method that explicitly models and leverages sample relations, which in turn is used as supervision to guide the representation learning. Different from previous work, our framework well preserves the relations between samples. Since the prediction of pairwise relations themselves is a fundamental problem, our model adaptively learns them from data. This provides much flexibility to encode real data manifold. The important role of relation and representation learning is evaluated on the clustering task. Extensive experiments on benchmark data sets demonstrate the superiority of our approach. By seeking to embed samples into subspace, we further show that our method can address the large-scale and out-of-sample problem. Our source code is publicly available at: https://github.com/nbShawnLu/RGRL.	187.99697272226427
161.	With the popularization of the intelligent manufacturing, much attention has been paid in such intelligent computing methods as deep learning ones for machinery fault diagnosis. Thanks to the development of deep learning models, the interference of the human experience can be greatly reduced, and the fault diagnosis accuracy can also be increased under certain conditions. To improve the generalization ability of the intelligent fault diagnostics, the deep transfer learning consisting of both transfer learning and deep learning components was accordingly developed. This paper reviews the research progress of the deep transfer learning for the machinery fault diagnosis in recently years. It is summarizing, classifying and explaining many publications on this topic with discussing various deep transfer architectures and related theories. On this basis, this review expounds main achievements, challenges and future research of the deep transfer learning. This provides clear directions for the selection, design or implementation of the deep transfer learning architecture in the field of the machinery fault diagnostics. (C) 2020 Elsevier B.V. All rights reserved.	187.99696453298588
162.	Modern agriculture is facing unique challenges in building a sustainable future for food production, in which the reliable detection of plantation threats is of critical importance. The breadth of existing information sources, and their equivalent sensors, can provide a wealth of data which, to be useful, must be transformed into actionable knowledge. Approaches based on Information Communication Technologies (ICT) have been shown to be able to help farmers and related stakeholders make decisions on problems by examining large volumes of data while assessing multiple criteria. In this paper, we address the automated identification (and count the instances) of the major threat of olive trees and their fruit, the Bactrocera Oleae (a.k.a. Dacus) based on images of the commonly used McPhail trap's contents. Accordingly, we introduce the "Dacus Image Recognition Toolkit" (DIRT), a collection of publicly available data, programming code samples and web-services focused at supporting research aiming at the management the Dacus as well as extensive experimentation on the capability of the proposed dataset in identifying Dacuses using Deep Learning methods. Experimental results indicated performance accuracy (mAP) of 91.52% in identifying Dacuses in trap images featuring various pests. Moreover, the results also indicated a trade-off between image attributes affecting detail, file size and complexity of approaches and mAP performance that can be selectively used to better tackle the needs of each usage scenario.	187.99691270581002
163.	This study builds a fully deconvolutional neural network (FDNN) and addresses the problem of single image super-resolution (SISR) by using the FDNN. Although SISR using deep neural networks has been a major research focus, the problem of reconstructing a high resolution (HR) image with an FDNN has received little attention. A few recent approaches toward SISR are to embed deconvolution operations into multilayer feedforward neural networks. This paper constructs a deep FDNN for SISR that possesses two remarkable advantages compared to existing SISR approaches. The first improves the network performance without increasing the depth of the network or embedding complex structures. The second replaces all convolution operations with deconvolution operations to implement an effective reconstruction. That is, the proposed FDNN only contains deconvolution layers and learns an end-to-end mapping from low resolution (LR) to HR images. Furthermore, to avoid the oversmoothness of the mean squared error loss, the trained image is treated as a probability distribution, and the Kullback-Leibler divergence is introduced into the final loss function to achieve enhanced recovery. Although the proposed FDNN only has 10 layers, it is successfully evaluated through extensive experiments. Compared with other state-of-the-art methods and deep convolution neural networks with 20 or 30 layers, the proposed FDNN achieves better performance for SISR.	187.99690642987144
164.	Currently, with the rapid development of deep learning, many breakthroughs have been made in the field of facial expression recognition (FER). However, according to our prior knowledge, facial images contain not only expression-related features but also some identity-related features, and the identity-related features vary from person to person which often have a negative influence on the FER process. It is one of the most important challenges in the field of FER. In this paper, a novel feature separation model exchange-GAN is proposed for the FER task, which can realize the separation of expression-related features and expression-independent features with high purity. And the FER method based on the exchange-GAN can overcome the interference of identity-related features to a large extent. First, the feature separation is achieved by the exchange-GAN through partial feature exchange and various constraints. Then we ignore the expression-independent features, and conduct FER only according to the expression-related features to alleviate the adverse effect of identity-related features. Finally, some experiments are conducted on three famous databases with the FER methods proposed in this paper. The experimental results show that the proposed FER method can alleviate the interference of identity-related information through feature separation by the exchange-GAN and achieve excellent performance for the objects that have not appeared in the training set. What's more, our method can obtain very competitive FER accuracy on the three experimental databases. (C) 2020 Elsevier B.V. All rights reserved.	187.99677376149447
165.	This paper researches on the problem of object recognition using RGB-D data. Although deep convolutional neural networks have so far made progress in this area, they are still suffering a lot from lack of large-scale manually labeled RGB-D data. Labeling large-scale RGB-D dataset is a time-consuming and boring task. More importantly, such large-scale datasets often exist a long tail, and those hard positive examples of the tail can hardly be recognized. To solve these problems, we propose a multimodal self-augmentation and adversarial network (MSANet) for RGB-D object recognition, which can augment the data effectively at two levels while keeping the annotations. Toward the first level, series of transformations are leveraged to generate class-agnostic examples for each instance, which supports the training of our MSANet. Toward the second level, an adversarial network is proposed to generate class-specific hard positive examples while learning to classify them correctly to further improve the performance of our MSANet. Via the above schemes, the proposed approach wins the best results on several available RGB-D object recognition datasets, e.g., our experimental results indicate a 1.5% accuracy boost on benchmark Washington RGB-D object dataset compared with the current state of the art.	187.99667002192444
166.	Deep learning is one of the fastest growing technologies in computer science with a plethora of applications. But this unprecedented growth has so far been limited to the consumption of deep learning experts. The primary challenge being a steep learning curve for learning the programming libraries and the lack of intuitive systems enabling non-experts to consume deep learning. Towards this goal, we study the effectiveness of a "no-code" paradigm for designing deep learning models. Particularly, a visual drag-and-drop interface is found more efficient when compared with the traditional programming and alternative visual programming paradigms. We conduct user studies of different expertise levels to measure the entry level barrier and the developer load across different programming paradigms. We obtain a System Usability Scale (SUS) of 90 and a NASA Task Load index (TLX) score of 21 for the proposed visual programming compared to 68 and 52, respectively, for the traditional programming methods.	187.9966657490205
167.	The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection. In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field.	187.9965268985893
168.	Current drug development is still costly and slow given tremendous technological advancements in drug discovery and medicinal chemistry. Using machine learning (ML) to virtually screen compound libraries promises to fix this for generating drug leads more efficiently and accurately. Herein, we explain the broad basics and integration of both virtual screening (VS) and ML. We then discuss artificial neural networks (ANNs) and their usage for VS. The ANN is emerging as the dominant classifier for ML in general, and has proven its utility for both structure-based and ligand-based VS. Techniques such as dropout, multitask learning and convolution improve the performance of ANNs and enable them to take on chemical meaning when learning about the drug-target-binding activity of compounds.	187.99646222718746
169.	Human activity recognition can benefit various applications including healthcare services and context awareness. Since human actions will influence WiFi signals, which can be captured by the channel state information (CSI) of WiFi, WiFi CSI based human activity recognition has gained more and more attention. Due to the complex relationship between human activities and WiFi CSI measurements, the accuracies of current recognition systems are far from satisfactory. In this paper, we propose a new deep learning based approach, i.e., attention based bi-directional long short-term memory (ABLSTM), for passive human activity recognition using WiFi CSI signals. The BLSTM is employed to learn representative features in two directions from raw sequential CSI measurements. Since the learned features may have different contributions for final activity recognition, we leverage on an attention mechanism to assign different weights for all the learned features. Real experiments have been carried out to evaluate the performance of the proposed ABLSTM for human activity recognition. The experimental results show that our proposed ABLSTM is able to achieve the best recognition performance for all activities when compared with some benchmark approaches.	187.9964500134136
170.	Disaster-scene images documenting the magnitude and effects of natural disasters nowadays can be easily collected through crowd-sourcing aided by mobile technologies (e.g., smartphones or drones). One challenging issue that confronts the first-responders who desire the use of such data is the non-structured nature of these crowdsourced images. Among other techniques, one natural way is to structuralize disaster-scene images through captioning. Through captioning, their imagery contents are augmented by descriptive captions that further enable more effective search and query (S&Q). This work presents a preliminary test by exploiting an end-to-end deep learning framework with a linked CNN-LSTM architecture. Demonstration of the results and quantitative evaluation are presented that showcase the validity of the proposed concept.	187.99640735569452
171.	This paper proposes a learning-based approach to optimize the multiple traveling salesman problem (MTSP), which is one classic representative of cooperative combinatorial optimization problems. The MTSP is interesting to study, because the problem arises from numerous practical applications and efficient approaches to optimize the MTSP can potentially be adapted for other cooperative optimization problems. However, the MTSP is rarely researched in the deep learning domain because of certain difficulties, including the huge search space, the lack of training data that is labeled with optimal solutions and the lack of architectures that extract interactive behaviors among agents. This paper constructs an architecture consisting of a shared graph neural network and distributed policy networks to learn a common policy representation to produce near-optimal solutions for the MTSP. We use a reinforcement learning approach to train the model, overcoming the requirement data labeled with ground truth. We use a two-stage approach, where reinforcement learning is used to learn an allocation of agents to vertices, and a regular optimization method is used to solve the single-agent traveling salesman problems associated with each agent. We introduce a S-samples batch training method to reduce the variance of the gradient, improving the performance significantly. Experiments demonstrate our approach successfully learns a strong policy representation that outperforms integer linear programming and heuristic algorithms, especially on large scale problems. (C) 2020 Elsevier B.V. All rights reserved.	187.99637264824403
172.	In this paper, we present Speech Enhancement through Wave-U-Net (SEWUNet), an end-to-end approach to reduce noise from speech signals. This background context is detrimental to several downstream systems, including automatic speech recognition (ASR) and word spotting, which in turn can negatively impact end-user applications. We show that our proposal does improve signal-to-noise ratio (SNR) and word error rate (WER) compared with existing mechanisms in the literature. In the experiments, network input is a 16 kHz sample rate audio waveform corrupted by an additive noise. Our method is based on the Wave-U-Net architecture with some adaptations to our problem. Four simple enhancements are proposed and tested with ablation studies to prove their validity. In particular, we highlight the weight initialization through an autoencoder before training for the main denoising task, which leads to a more efficient use of training time and a higher performance. Through quantitative metrics, we show that our method is prefered over the classical Wiener filtering and shows a better performance than other state-of-the-art proposals. (C) 2020 Elsevier Ltd. All rights reserved.	187.9963146135959
173.	The application of deep learning to symbolic domains remains an active research endeavour. Graph neural networks (GNN), consisting of trained neural modules which can be arranged in different topologies at run time, are sound alternatives to tackle relational problems which lend themselves to graph representations. In this paper, we show that GNNs are capable of multitask learning, which can be naturally enforced by training the model to refine a single set of multi-dimensional embeddings is an element of R-d and decode them into multiple outputs by connecting MLPs at the end of the pipeline. We demonstrate the multi-task learning capability of the model in the relevant relational problem of estimating network centrality measures, focusing primarily on producing rankings based on these measures, i.e. is vertex v(1) more central than vertex v(2) given centrality c?. We then show that a GNN can be trained to develop a lingua franca of vertex embeddings from which all relevant information about any of the trained centrality measures can be decoded. The proposed model achieves 89% accuracy on a test dataset of random instances with up to 128 vertices and is shown to generalise to larger problem sizes. The model is also shown to obtain reasonable accuracy on a dataset of real world instances with up to 4k vertices, vastly surpassing the sizes of the largest instances with which the model was trained (n = 128). Finally, we believe that our contributions attest to the potential of GNNs in symbolic domains in general and in relational learning in particular.	187.9963003438315
174.	Named entity recognition (NER) is the core part of information extraction that facilitates the automatic detection and classification of entities in natural language text into predefined categories, such as the names of persons, organizations, locations, and so on. The output of the NER task is crucial for many applications, including relation extraction, textual entailment, machine translation, information retrieval, etc. Literature shows that machine learning and deep learning approaches are the most widely used techniques for NER. However, for entity extraction, the abovementioned approaches demand the availability of a domain-specific annotated data set. Our goal is to develop a hybrid NER system composed of rule-based deep learning as well as clustering-based approaches, which facilitates the extraction of generic entities (such as person, location, and organization) out of natural language texts of domains that lack generic named entities labeled domain data sets. The proposed approach takes the advantages of both deep learning and clustering approaches but separately, in combination with a knowledge-based approach by using a postprocessing module. We evaluated the proposed methodology on court cases (judgments) as a use case since it contains generic named entities of different forms that are poorly or not present in open-source NER data sets. We also evaluated our hybrid models on two benchmark data sets, namely, Computational Natural Language Learning (CoNLL) 2003 and Open Knowledge Extraction (OKE) 2016. The experimental results obtained from benchmark data sets show that our hybrid models achieved substantially better performance in terms of the F-score in comparison to other competitive systems.	187.9961994415667
175.	Tool wear is a crucial factor influencing the quality of workpieces in the machining industry. The efficient and accurate prediction of tool wear can enable the tool to be changed in a timely manner to avoid unnecessary costs. Various parameters, such as cutting force, vibration, and acoustic emission (AE), impact tool wear. Signals are collected by different sensors and then constitute the raw data. There are two main types of methods used to make predictions, namely model-based and data-driven methods. Data-driven methods are typically preferred when a mathematical model is not available. In such a situation, artificial intelligent methods, such as support vector regression (SVR) and artificial neural networks (ANNs), are applied. Recently, deep learning algorithms have been widely used because of their accuracy, computing speed, and excellent performance in solving nonlinear problems. In this study, a deep learning network called deep belief network (DBN) is applied to predict the flank wear of a cutting tool. To confirm the superiority of the DBN in predicting tool wear, the performance of the DBN is compared with the performances obtained using ANNs and SVR in terms of the mean-squared error (MSE) and the coefficient of determination (R-2), considering data from more than 900 experiments.	187.99619848384097
176.	Histopathological images contain rich phenotypic information that can be used to monitor underlying mechanisms contributing to disease progression and patient survival outcomes. Recently, deep learning has become the mainstream methodological choice for analyzing and interpreting histology images. In this paper, we present a comprehensive review of state-of-the-art deep learning approaches that have been used in the context of histopathological image analysis. From the survey of over 130 papers, we review the field's progress based on the methodological aspect of different machine learning strategies such as supervised, weakly supervised, unsupervised, transfer learning and various other sub-variants of these methods. We also provide an overview of deep learning based survival models that are applicable for disease-specific prognosis tasks. Finally, we summarize several existing open datasets and highlight critical challenges and limitations with current deep learning approaches, along with possible avenues for future research.	187.99588254552577
177.	The article analyzes olonkho as fundamental source of wisdom and the teachings of the ancestors about the sensible life and humanism. In olonkho, we can see portrayals of high moral standards of sensible life, and traditional values, which were skillfully depicted using expressive means and stylistic devices of the Yakut language. Traditional values reflect the imaginative world view, a unique Yakut model of the world and life, which is specifically represented by an entire system of spiritual concepts of a philosophical understanding of the world creation and human life. Many scholars highlight the important role that Platon A. Sleptsov - Oyunsky played in maintaining and popularizing olonkho. In the troublesome years of new political and government relations being established, owing to his efforts and outstanding organizational skills, he collected a valuable scope of olonkho stories from the first-hand source - the olonkho storytellers. Being a repository of philosophical and religious worldviews as well as of pedagogical and educational principles, today, these creative writings are in the center of researchers' attention. The study of pedagogics and the methods of studying olonkho in schools began in the 1970s. Presently, the search for educators and methodologists in Yakutia is based on the studies of the leading Russian researchers - N.A. Rubakin, M.M. Bakhtin, N.S. Berdyaev, D.S. Likhachov, B.S. Gershunsky, G.D. Gachev, T.D. Polozova, etc. All these scholars regard the perception of language arts as a personal and deep mental process. The following three concept sphere blocks were singled out: 1- I am a small part of the Universe, 2 - I am a child of nature, 3 - I am an Aiyy person and the creator of life. In this system, the spiritual concept sphere can lead the people step-by-step to learning about the vitally important values and to a deep understanding of their personal "I" and their inner spiritual world. We have proved the didactic necessity to educate students about olonkho in accordance with this concept system.	187.99574939268774
178.	Both normal ageing and neurodegenerative diseases cause morphological changes to the brain. Age-related brain changes are subtle, nonlinear, and spatially and temporally heterogenous, both within a subject and across a population. Machine learning models are particularly suited to capture these patterns and can produce a model that is sensitive to changes of interest, despite the large variety in healthy brain appearance. In this paper, the power of convolutional neural networks (CNNs) and the rich UK Biobank dataset, the largest database currently available, are harnessed to address the problem of predicting brain age. We developed a 3D CNN architecture to predict chronological age, using a training dataset of 12,802 T1-weighted MRI images and a further 6,885 images for testing. The proposed method shows competitive performance on age prediction, but, most importantly, the CNN prediction errors DeltaBrainAge=AgePredicted-AgeTrue correlated significantly with many clinical measurements from the UK Biobank in the female and male groups. In addition, having used images from only one imaging modality in this experiment, we examined the relationship between DeltaBrainAge and the image-derived phenotypes (IDPs) from all other imaging modalities in the UK Biobank, showing correlations consistent with known patterns of ageing. Furthermore, we show that the use of nonlinearly registered images to train CNNs can lead to the network being driven by artefacts of the registration process and missing subtle indicators of ageing, limiting the clinical relevance. Due to the longitudinal aspect of the UK Biobank study, in the future it will be possible to explore whether the DeltaBrainAge from models such as this network were predictive of any health outcomes.	187.995606075343
179.	Recent studies have reported that deep learning techniques could achieve high performance in medical image analysis such as computer-aided diagnosis (CADx). However, there is a limitation in interpreting the diagnostic decisions of deep learning due to the black-box nature. To increase confidence in the diagnostic decisions of deep learning, it is necessary to develop a deep neural network with the interpretable structure which could provide a reasonable explanation of diagnostic decisions. In this study, a novel deep neural network has been devised to provide visual evidence of the diagnostic decisions of CADx. The proposed deep network is designed to include a visual interpreter which could provide important areas as the visual evidence of the diagnostic decision in the deep neural network. Based on the observation that the radiologists usually make a diagnostic decision based on the lesion characteristics (the margin and the shape of masses), the visual interpreter provides visual evidence related with the margin and the shape, respectively. To verify the effectiveness of the proposed method, experiments were conducted on mammogram datasets. Experimental results show that the proposed method could provide more important areas as the visual evidence compared with the conventional visualization method. These results imply that the proposed visual interpretation method could be a promising approach to overcome the current limitation of the deep learning for CADx.	187.99556343198213
180.	Energy management in buildings using phase change materials (PCM) to improve thermal performance is challenging due to the nonlinear thermal capacity of the PCM. To address this problem, this paper adopts a model-free actor-critic on-policy reinforcement learning method based on deep deterministic policy gradient (DDPG). The proposed approach overcomes the major weakness of model-based approaches, such as approximate dynamic programming (ADP), which require an explicit thermal model of the building under control. This requirement makes a plug-and-play implementation of the energy management algorithm in an existing smart meter difficult due to the wide variety of building design and construction types. To overcome this difficulty, we use a DDPG algorithm that can learn policies in continuous action spaces without access to the full dynamics of the building. We demonstrate the competitive performance of DDPG by benchmarking it against an ADP-based approach with access to the full thermal dynamics of the building.	187.9955304267013
181.	Mass personalization-a megatrend in industrial manufacturing and production-requires fast adaptations of robotics and automation solutions to continually decreasing lot sizes. In this paper, the challenges of applying robot-based automation in a highly individualized production are highlighted. To face these challenges, a framework is proposed that combines latest machine learning (ML) techniques, like deep learning, with high-end physics simulation environments. ML is used for programming and parameterizing machines for a given production task with minimal human intervention. If the simulation environment realistically captures physical properties like forces or elasticity of the real world, it provides a high-quality data source for ML. In doing so, new tasks are mastered in simulation faster than in real-time, while at the same time existing tasks are executed. The functionality of the simulation-driven ML framework is demonstrated on an industrial use case.	187.99538899860252
182.	Mapping all the neurons in the brain requires automatic reconstruction of entire cells from volume electron microscopy data. The flood-filling network (FFN) architecture has demonstrated leading performance for segmenting structures from this data. However, the training of the network is computationally expensive. In order to reduce the training time, we implemented synchronous and data-parallel distributed training using the Horovod library, which is different from the asynchronous training scheme used in the published FFN code. We demonstrated that our distributed training scaled well up to 2048 Intel Knights Landing (KNL) nodes on the Theta supercomputer. Our trained models achieved similar level of inference performance, but took less training time compared to previous methods. Our study on the effects of different batch sizes on FFN training suggests ways to further improve training efficiency. Our findings on optimal learning rate and batch sizes agree with previous works.	187.9952944019743
183.	Previous research has demonstrated that providing learners with self-control over some aspect of practice enhances motor learning (for a review see Wulf, 2007). One explanation for the self-control effect is that learners engage in deeper information processing when they are allowed to make choices during practice. Recent research has supported this line of thinking by showing that the self-control effect was eliminated for learners who engaged in a cognitive load task during the interval following completion of discrete task trials (Carter & Ste-Marie, 2017). The current study tested the effects of imposing a cognitive load task during the completion of continuous task trials. Participants (N = 48) were divided into self-control (SC), self-control with load (SCL), and two corresponding yoked (YK, YKL) groups. Participants learned a continuous tracing task and then performed 24-hour retention and transfer tests. Retention and transfer test movement times were significantly faster for SC compared to YK participants within the No Load condition but did not differ between these participants within the Load condition. Errors were similar among all groups in retention and transfer. These results provide support for the importance of information processing in regards to the self-controlled learning benefit.	187.99522116223034
184.	The size of tomato fruits is closely related to the market segment and price. Manual sorting in tomato is very dependent on human interpretation and thus, very prone to error. The study presents thresholding, machine learning and deep learning techniques in classifying the tomato as small, medium and large based from a single tomato fruit image implemented using Open CV libraries and Python programming. Tomato images with different sizes are gathered where features like area, perimeter and enclosed circle radius are extracted. The experiment shows that using thresholding, a classification accuracy of 85.83%, 65.83% and 80% was achieved for area, perimeter and enclosed circle radius, respectively. For machine learning, the training accuracy rates were recorded as 94.00%-95.00% for SVM, 97.50-92.50% for KNN and 90.33-92.50% for ANN. Comparison of models revealed that SVM is the most model without over fitting. The deep learning approach, regardless of the algorithm, produced low performances with 82.31%-78.21%-55.97% trainingvalidation-testing accuracy for VGG16, 48.17%-41.44%-37.64% for InceptionV3 and 56.05%-44.96%-22.78% for ResNet50 models. Comparative analysis showed that machine learning technique bested the performance of the thresholding and deep learning techniques in classifying the tomato fruit size in terms of accuracy performance.	187.99518518089627
185.	Learning meaningful representations for different granularities of texts is a challenging and on-going area of research in natural language processing. Recently, neural sentence modeling that learns continuous valued vector representations for sentences in a low dimensional latent semantic space has gained increasing attention. In this work, we propose a novel method to learn meaning representation for variable-sized sentence based on recursive auto-encoders. The key difference between our model and others is that we embed the sentence meaning while jointly learning evolved word representation in unsupervised manner and without using any parse or dependency tree. Our deep compositional model is not only able to construct meaningful sentence representation but also to keep pace with the words meanings evolving. We evaluate our obtained embeddings on semantic similarity task. The experimental results show the effectiveness of our proposed model and demonstrate that it can achieve a competitive performance without any feature engineering.	187.9951312893677
186.	Despite that existing knowledge graphs embedding (KGE) based methods can achieve better recommendation performance compared with deep learning based ones, such improvement is limited due to lack of capturing the shared information between user-item interaction and item-item relation encoded in knowledge graph (KG) by fully leveraging the implicit and explicit relationship. To address this issue, in this paper, we propose a principled deep knowledge-enhanced network (DKEN) framework based on deep learning and KGE to model the semantics of entities and relations encoded in the KG. In particular, the DKEN utilizes deep neural networks (DNN) to learn higher-order feature interactions and ensembles KGE features with DNN features into an end-to-end learning process naturally to exploit implicit interaction and explicitt semantic features. Furthermore, a cross information sharing (CIS) layer is designed to facilitate information sharing between items and entities, and two aggregators are developed to improve the performance of the model. Extensive experiments on several public datasets, as well as online AB tests of an industrial recommendation scenario in the Ant Financial Service Group, demonstrate that DKEN achieves remarkably better performance than several state-of-the-art baselines. (c) 2020 Elsevier Inc. All rights reserved.	187.99510213738796
187.	The ability of a machine to understand the motion and behaviour of a particular actor is a very important task in machine vision. This problem has so many possible applications in domains such as motion retargeting, robot navigation, healthcare, psychology, augmented reality applications such as games etc. In this paper we demonstrate a human-robot interaction system based on a gestural query, where the computer response is a computer generated video of another human movement. This work differs from other recent video retargeting systems since it is not meant to modify the target video as such, but rather query a video database for the most responsive segment through gestural interpretation process. For this purpose we developed a generative video system capable of extracting the latent representation of free movements such as dance and expressive gesture, and querying and re-editing multiple found video segments in response to an input movement query. One of the main challenges in this approach is finding the "units" of continuous movement input so that both the style of the target video and the relevant aspect of the query video would be related in a meaningful way. In this paper we describe a gestural motif extraction system that combines deep feature learning with structural similarity analysis to allow such query based human-computer motion interaction.	187.9950733398141
188.	This research aims in detecting violent crowd flows in the context of Bangladesh. For this purpose, we have collected a dataset which includes both violent and non-violent crowd flows. Different deep learning algorithms and approaches have been applied on this dataset to detect scenarios which contain violence. Convolutional neural networks (CNN) and long short-term memory network (LSTM) based architectures have been experimented separately on this dataset and in combination as well. Moreover, a model that was already pretrained on violent movie scenes has been used to leverage transfer learning which outperformed all other experimented approaches with an accuracy of 95.67%. Surprisingly, the sequence model alone or in combination with CNN has not performed well on this particular dataset. The proposed model is lightweight hence it can be deployed easily in any security systems consisting of CCTV cameras or unmanned aerial vehicles (UAVs).	187.99496840013518
189.	Determining whether a fault occurs locally or globally is highly important for large-scale industrial processes involving multiple operating units. Moreover, the complex nonlinearity among process variables is a prominent feature of modern industries. This paper proposes a distributed-ensemble stacked autoencoder (DE-SAE) model based on deep learning technology for monitoring non-linear, large-scale, multi-unit processes. First, the deep features of the variables involved in each operating unit are extracted with the stacked autoencoder (SAE) to represent the essential structure of the unit. Two statistics are separately constructed using the deep features and the reconstruction error for detecting the faults in local units. Subsequently, the deep representations of the variables from each operating unit are modeled with the SAE to extract the global information for global monitoring. The proposed DE-SAE model uses deep learning techniques to solve the complex non-linear relationships in industrial processes, while considering their local and global information. Therefore, the method can explain the monitoring results better. Experimental results obtained from the numerical simulation and Tennessee-Eastman process confirm the feasibility and superiority of this method. (C) 2020 Elsevier Inc. All rights reserved.	187.9949073114671
190.	The virtualization concept and elasticity feature of cloud computing enable users to request resources on-demand and in the pay-as-you-go model. However, the high flexibility of the model makes the on-time resource scaling problem more complex. A variety of techniques such as threshold-based rules, time series analysis, or control theory are utilized to increase the efficiency of dynamic scaling of resources. However, the inherent dynamicity of cloud-hosted applications requires autonomic and adaptable systems that learn from the environment in real-time. Reinforcement Learning (RL) is a paradigm that requires some agents to monitor the surroundings and regularly perform an action based on the observed states. RL has a weakness to handle high dimensional state space problems. Deep-RL models are a recent breakthrough for modeling and learning in complex state space problems. In this article, we propose a Hybrid Anomaly-aware Deep Reinforcement Learning-based Resource Scaling (ADRL) for dynamic scaling of resources in the cloud. ADRL takes advantage of anomaly detection techniques to increase the stability of decision-makers by triggering actions in response to the identified anomalous states in the system. Two levels of global and local decision-makers are introduced to handle the required scaling actions. An extensive set of experiments for different types of anomaly problems shows that ADRL can significantly improve the quality of service with less number of actions and increased stability of the system.	187.99474936658436
191.	The COVID-19 pandemic is an emerging respiratory infectious disease, also known as coronavirus 2019. It appears in November 2019 in Hubei province (in China), and more specifically in the city of Wuhan, then spreads in the whole world. As the number of cases increases with unprecedented speed, many parts of the world are facing a shortage of resources and testing. Faced with this problem, physicians, scientists and engineers, including specialists in Artificial Intelligence (AI), have encouraged the development of a Deep Learning model to help healthcare professionals to detect COVID-19 from chest X-ray images and to determine the severity of the infection in a very short time, with low cost. In this paper, we propose CVDNet, a Deep Convolutional Neural Network (CNN) model to classify COVID-19 infection from normal and other pneumonia cases using chest X-ray images. The proposed architecture is based on the residual neural network and it is constructed by using two parallel levels with different kernel sizes to capture local and global features of the inputs. This model is trained on a dataset publically available containing a combination of 219 COVID-19, 1341 normal and 1345 viral pneumonia chest x-ray images. The experimental results reveal that our CVDNet. These results represent a promising classification performance on a small dataset which can be further achieve better results with more training data. Overall, our CVDNet model can be an interesting tool to help radiologists in the diagnosis and early detection of COVID-19 cases.	187.99472522444427
192.	Nonintrusive load monitoring (NILM) is a technique that infers appliance-level energy consumption patterns and operation state changes based on feeder power signals. With the availability of fine-grained electric load profiles, there has been increasing interest in using this approach for demand-side energy management in smart grids. NILM is a multilabel classification problem due to the simultaneous operation of multiple appliances. Recently, deep learning based techniques have been shown to be a promising approach to solving this problem, but annotating the huge volume of load profile data with multiple active appliances for learning is very challenging and impractical. In this article, a new semisupervised multilabel deep learning based framework is proposed to address this problem with the goal of mitigating the reliance on large labeled datasets. Specifically, a temporal convolutional neural network is used to automatically extract high-level load signatures for individual appliances. These signatures can be efficiently used to improve the feature representation capability of the framework. Case studies conducted on two open-access NILM datasets demonstrate the effectiveness and superiority of the proposed approach.	187.99465385222442
193.	We present a machine learning approach that integrates geometric deep learning and Sobolev training to generate a family of finite strain anisotropic hyperelastic models that predict the homogenized responses of polycrystals previously unseen during the training. While hand-crafted hyperelasticity models often incorporate homogenized measures of microstructural attributes, such as the porosity or the averaged orientation of constituents, these measures may not adequately represent the topological structures of the attributes. We fill this knowledge gap by introducing the concept of the weighted graph as a new high-dimensional descriptor that represents topological information, such as the connectivity of anisotropic grains in an assemble. By leveraging a graph convolutional deep neural network in a hybrid machine learning architecture previously used in Frankel et al. (2019), the artificial intelligence extracts low-dimensional features from the weighted graphs and subsequently learns the influence of these low-dimensional features on the resultant stored elastic energy functionals. To ensure smoothness and prevent unintentionally generating a non-convex stored energy functional, we adopt the Sobolev training method for neural networks such that a stress measure is obtained implicitly by taking directional derivatives of the trained energy functional. Results from numerical experiments suggest that Sobolev training is capable of generating a hyperelastic energy functional that predicts both the elastic energy and stress measures more accurately than the classical training that minimizes L-2 norms. Verification exercises against unseen benchmark FFT simulations and phase-field fracture simulations that employ the geometric learning generated elastic energy functional are conducted to demonstrate the quality of the predictions. (C) 2020 Elsevier B.V. All rights reserved.	187.9946248757032
194.	In recent years, Community Question Answering (CQA) has emerged as a popular platform for knowledge curation and archival. An interesting aspect of question answering is that it combines aspects from natural language processing, information retrieval, and machine learning. In this paper, we have explored how the depth of the neural network influences the accuracy of prediction of deleted questions in question-answering forums. We have used different shallow and deep models for prediction and analyzed the relationships between number of hidden layers, accuracy, and computational time. The results suggest that while deep networks perform better than shallow networks in modeling complex non-linear functions, increasing the depth may not always produce desired results. We observe that the performance of the deep neural network suffers significantly due to vanishing gradients when large number of hidden layers are present. Constantly increasing the depth of the model increases accuracy initially, after which the accuracy plateaus, and finally drops. Adding each layer is also expensive in terms of the time required to train the model. This research is situated in the domain of neural information retrieval and contributes towards building a theory on how deep neural networks can be efficiently and accurately used for predicting question deletion. We predict deleted questions with more than 90% accuracy using two to ten hidden layers, with less accurate results for shallower and deeper architectures.	187.9944884090982
195.	While mental health related issues usually began in childhood or adolescence, only a small portion of this population receives proper diagnosis and treatment. In part, this scenario is caused due the lack of specialized tools for mental disorders screening, mainly those which reduce cost and time needed. Recently, authors have been analyzing how machine learning could help to build new psychological assessment tools. However, only few researches proposed building specialized tools for groups composed mostly of children. This work aims to propose a model which combines clinical tests and deep learning for supporting child psychological screening. Results suggested that deep learning tools may fit the intended scenario, once the classification models tested performed well even with a small sample size.	187.994254340118
196.	Deep learning has received increasing attention in the last decade. Its amazing success, is partly attributed to the evolution of normalization and activation techniques. However, less works have devoted to explore both modules together. This work, therefore, aims at pushing for a deeper understanding on the effect of normalization and activation together analytically. We design a generic method which integrates both normalization and activation together as a whole, named as the Generic Shift-Normalization Activation Approach (GSNA), in reserving richer information propagation in neural networks. A rigorous mathematical analysis was performed to investigate the benefits of the designed method, such as its computation complexity, performance potential as well as optimization over trainable parameter initialization. Further, extensive experiments are conducted to demonstrate the superiority and generality of the designed method in many computer vision benchmarking tasks, such as CIFAR-10/100, SVHN, ImageNet32 x 32, etc. To explore its generality, we also conduct some experiments on natural language understanding tasks like text classification, natural language inference, and some variational generative task as well. More interestingly, GSNA can be naturally incorporated into the existing neural networks with arbitrary architectures, demonstrating its generic effectiveness in deep learning field. (C) 2020 Elsevier Ltd. All rights reserved.	187.99424063373033
197.	The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.	187.99421656494323
198.	Semantic image segmentation can be used in various driving applications, such as automatic braking, road sign alerts, park assists, and pedestrian warnings. More often, AI applications, such as autonomous modules are available in expensive vehicles. It would be appreciated if such facilities can be made available in the lower end of the price spectrum. Existing methodologies, come with a costly overhead with large number of parameters and need of costly hardware. Within this scope, the key contribution of this work is to promote the possibility of compact semantic image segmentation so that it can be extended to deploy AI based solutions to less expensive vehicles. While developing cheap and fast models one must also not compromise the factor of reliability and robustness. The proposed work is primarily based on our previous model named "SegFast", and is aimed to perform thorough analysis across a multitude of datasets. Beside "spark" modules and depth-wise separable transposed convolutions, kernel factorization is implemented to further reduce the number of parameters. The effect of MobileNet as an encoder to our model has also been analyzed. The proposed method shows a promising decrease in the number of parameters and significant gain in terms of runtime even on a single CPU environment. Despite all those speedups, the proposed approach performs at a similar level to many popular but heavier networks, such as SegNet, UNet, PSPNet, and FCN.	187.9941833475524
199.	Over the last three decades, rapid industrialization in China has generated an unprecedentedly high level of air pollution and associated health problems. Given that China accounts for one-fifth of the world population and suffers from severe air pollution, a comprehensive review of the indicators accounting for the health costs in relation to air pollution will benefit evidence-based and health-related environmental policy-making. This paper reviews the conventional static and the new dynamic approach adopted for air pollution-related health cost accounting in China and analyzes the difference between the two in estimating GDP loss. The advantages of adopting the dynamic approach for health cost accounting in China, with conditions guaranteeing its optimal performance are highlighted. Guidelines on how one can identify an appropriate approach for health cost accounting in China are put forward. Further, we outline and compare the globally-applicable and China-specific indicators adopted by different accounting methodologies, with their pros and cons being discussed. A comprehensive account of the available databases and methodologies for health cost accounting in China are outlined. Future directions to guide health cost accounting in China are provided. Our work provides valuable insights into future health cost accounting research in China. Our study has strengthen the view that the dynamic approach is comparatively more preferred than the static approach for health cost accounting in China, if more data is available to train the dynamic models and improve the robustness of the parameters employed. In addition, future dynamic model should address the socio-economic impacts, including benefits or losses of air pollution polices, to provide a more robust policy picture. Our work has laid the key principles and guidelines for selecting proper econometric approaches and parameters. We have also identified a proper estimation method for the Value of Life in China, and proposed the integration of engineering approaches, such as the use of deep learning and big data analysis for health cost accounting at the fine-grained level (city-district or sub-regional level). Our work has also identified the gap for more accurate health cost accounting at the fine-grained level in China, which will subsequently affect the quality of health-related air pollution policy decision-making at such levels, and the health-related quality of life of the citizens in China.	187.994152393893
200.	Intrinsic image decomposition is a highly ill-posed problem in computer vision referring to extract albedo and shading from an image. In this paper, we regard it as an image-to-image translation issue and propose a novel thought, which makes use of parallel convolutional neural networks (ParCNN) to learn albedo and shading with different spatial features and data distributions, respectively. At the same time, the energy is preserved as much as possible under the constraint of image reconstruction loss shared by the two networks. Moreover, we add the gradient prior based on the traditional image formation process into the loss function, which can lead to a performance improvement of our basic learning model by jointing advantages of the physically-based method and the data-driven method. We choose MPI Sintel dataset for model training and testing. Quantitative and qualitative evaluation results outperform the state-of-the-art methods.	187.99412636827356
201.	Identifying genetic variants associated with complex diseases is a central focus of genome-wide association studies. These studies extensively adopt univariate analysis by ignoring interaction effects. It is widely accepted that the etiology of most complex diseases depends on interactions between genetic variants and / or environmental factors. Several machine learning and data mining methods have been consistently successful in exposing these interaction effects. However, there has been no major breakthrough due to various biological complexities, and statistical computational challenges facing in the field of genetic epidemiology, despite of many efforts. Deep learning is emerging machine learning approach that promises to reveal the hidden patterns of big data for accurate predictions. In this study, a deep neural network is unified with a random forest by forming hybrid architecture, for achieving reliable detection of multi-locus interactions between single nucleotide polymorphisms. The proposed hybrid method is evaluated on various simulated scenarios in the absence of main effect for six epistasis models. The best model with optimal hyper-parameters (grid and random grid search) is chosen to enhance the power of the method by maximising the model's prediction accuracy. The performance metrics of each model is analysed for both training and validation. Further, the performance of the method in the presence of noise due to missing data, genotyping errors, genetic heterogeneity, and phenocopy, and their combined effects are evaluated. The power of the method in detecting two-locus interactions is compared with the previous methods in the presence and absence of noise. On an average, the power of the proposed method is much higher than the previous methods for all simulated scenarios. Finally, findings are confirmed on a chronical dialysis patient's data, obtained from the published study performed at the Kaohsiung Chang Gung Memorial Hospital. It is observed that the interaction between SNP 21 (2) and SNP 28 (2) in the mitochondrial D-loop has the highest risk for the disease manifestation.	187.9941119645634
202.	Nowadays, despite the popularity of deep convolutional neural networks (CNNs), the efficient training of network models remains challenging due to several problems. In this paper, we present a layer-wise learning based stochastic gradient descent method (LLb-SGD) for gradient-based optimization of objective functions in deep learning, which is simple and computationally efficient. By simulating the cross-media propagation mechanism of light in the natural environment, we set an adaptive learning rate for each layer of neural networks. In order to find the proper local optimum quickly, the dynamic learning sequence spanning different layers adaptively adjust the descending speed of objective function in multi-scale and multi-dimensional environment. To the best of our knowledge, this is the first attempt to introduce an adaptive layer-wise learning schedule with a certain degree of convergence guarantee. Due to its generality and robustness, the method is insensitive to hyper-parameters and therefore can be applied to various network architectures and datasets. Finally, we show promising results compared to other optimization methods on two image classification benchmarks using five standard networks.	187.9939951072814
203.	Nowadays, malware has become an epidemic problem. Among the attacks exploiting the computer resources of victims, one that has become usual is related to the massive amounts of computational resources needed for digital currency cryptomining. Cybercriminals steal computer resources from victims, associating these resources to the crypto-currency mining pools they benefit from. This research work focuses on offering a solution for detecting such abusive cryptomining activity, just by means of passive network monitoring. To this end, we identify a new set of highly relevant network flow features to be used jointly with a rich set of machine and deep-learning models for real-time cryptomining flow detection. We deployed a complex and realistic cryptomining scenario for training and testing machine and deep learning models, in which clients interact with real servers across the Internet and use encrypted connections. A complete set of experiments were carried out to demonstrate that, using a combination of these highly informative features with complex machine learning models, cryptomining attacks can be detected on the wire with telco-grade precision and accuracy, even if the traffic is encrypted.	187.99388252349996
204.	Sequential pattern mining (SPM) is one of the main application areas in the field of online business, e-commerce, bioinformatics, etc. The traditional approaches in SPM are unable to accurately mine the huge volume of data. Therefore, the proposed work employs a sequential mining model based on deep learning to minimize complexity in handling huge data. Application areas such as online retailing, finance, and e-commerce face a dynamic change in data, which results in non-stationary data. Therefore, our proposed work uses discrete wavelet analysis to convert non-stationary data into time series. In the proposed SPM, a reformed hybrid combination of convolutional neural network (CNN) with long short-term memory (LSTM) is designed to find out customer behavior and purchasing patterns in terms of time. CNN is used to find the concerned itemsets (frequent) at the end of the pattern and LSTM for finding the time interval among each pair of successive itemsets. The proposed work mines the sequential pattern from a progressive database that removes the obsolete data. Finally, the accuracy of the proposed work is compared with some traditional algorithms to demonstrate its robustness.	187.99380048535323
205.	This paper is concerned with paraphrase detection, i.e., identifying sentences that are semantically identical. The ability to detect similar sentences written in natural language is crucial for several applications, such as text mining, text summarization, plagiarism detection, authorship authentication and question answering. Recognizing this importance, we study in particular how to address the challenges with detecting paraphrases in user generated short texts, such as Twitter, which often contain language irregularity and noise, and do not necessarily contain as much semantic information as longer clean texts. We propose a novel deep neural network-based approach that relies on coarse-grained sentence modelling using a convolutional neural network (CNN) and a recurrent neural network (RNN) model, combined with a specific fine-grained word level similarity matching model. More specifically, we develop a new architecture, called DeepParaphrase, which enables to create an informative semantic representation of each sentence by (1) using CNN to extract the local region information in form of important n-grams from the sentence, and (2) applying RNN to capture the long-term dependency information. In addition, we perform a comparative study on state-of-the-art approaches within paraphrase detection. An important insight from this study is that existing paraphrase approaches perform well when applied on clean texts, but they do not necessarily deliver good performance against noisy texts, and vice versa. In contrast, our evaluation has shown that the proposed DeepParaphrase-based approach achieves good results in both types of texts, thus making it more robust and generic than the existing approaches.	187.9937350505436
206.	Foreground targets localization in video sequences receives much popularity in computer vision during the past few years, and its studies are highly related toward machine learning techniques. Driven by the recent popular deep learning techniques in machine learning, many contemporary localization studies are equipped with popular deep learning methods, and their performance has been benefited a lot by the prominent generalization capability of deep learning methods. In this study, inspired by deep metric learning, which is a new trend in deep learning, a novel single-target localization method is proposed. This new method is composed of two steps. First, an offline deep-ranked metric learning step is fulfilled and its gradient at the end-to-end learning procedure of the whole deep learning model is derived for realizing the conventional stochastic gradient algorithm. Also, an alternative proximal gradient algorithm is introduced to boost the efficiency as well. Second, an online models updating step is employed by the consecutive updating manner as well as the incremental updating manner, in order to make the offline learned outcome more adaptive during the progression of video sequences, in which challenging circumstances, such as sudden illumination changes, obstacles, shape transformation, complex background, etc., are likely to occur. This new single-target localization method has been compared with several shallow learning-based or deep learning-based localization methods in a large video database. Both qualitative and quantitative analysis have been comprehensively conducted to reveal the superiority of the new single-target localization method from the statistical point of view.	187.99368477540088
207.	We present a deep learning method to investigate the effect of flexoelectricity in nanostructures. For this purpose, deep neural network (DNN) algorithm is employed to map the relation between the inputs and the material response of interest. The DNN model is trained and tested making use of database that has been established by solving the governing equations of flexoelectricity using a NURBS-based IGA formulation at design points in the full probability space of the input parameters. Firstly, pure flexoelectric cantilever nanobeam is investigated under mechanical and electrical loading conditions. Then, structures of composite system constituted by two non-piezoelectric material phases are addressed in order to find the optimized topology with respect to the energy conversion factor. The results show promising capabilities of the proposed method, in terms of accuracy and computational efficiency. The deep learning method we used have produced superior optimal designs compared to the numerical methods. The findings of this study will be of profound interest to researcher involved further in the optimization and design of flexoelectric structures.	187.9935440508463
208.	Good authentication performance and liveness detection are two key requirements in many authentication systems. To avoid replay attacks, a novel visual speaker authentication scheme with random prompt texts is proposed. Compared with the fixed password scenario, visual speaker authentication with random prompt texts is much more challenging because it is impossible to ask the client to pronounce every possible prompt text to be used as training samples. In order to solve this problem, a new deep convolutional neural network is proposed in this paper and it has three functional parts, namely, the lip feature network, the identity network, and the content network. In the lip feature network, a series of 3D residual units have been adopted, which can depict the static and dynamic characteristics of the lip biometrics comprehensively. By considering the distinguishing features of the identity and content authentication tasks, the identity network and the content network are designed accordingly. An end-to-end, multi-task learning scheme is proposed which can optimize the weights of all the above three networks simultaneously. Experiments have been carried out to evaluate the performance of the proposed network under both the fixed-password and the random prompt texts scenario. From the experimental results, it is shown that the proposed approach can achieve superior performance in the fixed-password scenario compared with several state-of-the-art approaches. Furthermore, it also achieves satisfactory authentication results in the random prompt texts scenario and thus it provides a reliable solution for user authentication where liveness is guaranteed. (C) 2018 Elsevier Ltd. All rights reserved.	187.99354212889378
209.	Encoder-decoder models have been widely used in image captioning, and most of them are designed via single long short term memory (LSTM). The capacity of single-layer network, whose encoder and decoder are integrated together, is limited for such a complex task of image captioning. Moreover, how to effectively increase the "vertical depth" of encoder-decoder remains to be solved. To deal with these problems, a novel deep hierarchical encoder-decoder network is proposed for image captioning, where a deep hierarchical structure is explored to separate the functions of encoder and decoder. This model is capable of efficiently exerting the representation capacity of deep networks to fuse high level semantics of vision and language in generating captions. Specifically, visual representations in top levels of abstraction are simultaneously considered, and each of these levels is associated to one LSTM. The bottom-most LSTM is applied as the encoder of textual inputs. The application of the middle layer in encoder-decoder is to enhance the decoding ability of top-most LSTM. Furthermore, depending on the introduction of semantic enhancement module of image feature and distribution combine module of text feature, variants of architectures of our model are constructed to explore the impacts and mutual interactions among the visual representation, textual representations, and the output of the middle LSTM layer. Particularly, the framework is training under a reinforcement learning method to address the exposure bias problem between the training and the testing by the policy gradient optimization. Qualitative analyses indicate the process that our model "translates" image to sentence and further visualization presents the evolution of the hidden states from different hierarchical LSTMs over time. Extensive experiments demonstrate that our model outperforms current state-of-the-art models on three benchmark datasets: Flickr8K, Flickr30K, and MSCOCO. On both image captioning and retrieval tasks, our method achieves the best results. On MSCOCO captioning Leaderboard, our method also achieves superior performance.	187.9935343440564
210.	Recommendation system has been widely used in search, online advertising, e-Commerce, etc. Most products and services can be formulated as a personalized recommendation problem. Based on users' past behavior, the goal of personalized history-based recommendation is to dynamically predict the user's propensity (online purchase, click, etc.) distribution over time given a sequence of previous activities. In this paper, with an e-Commerce use case, we present a novel and general recommendation approach that uses a recurrent network to summarize the history of users' past purchases, with a continuous vectors representing items, and an attention-based recurrent mixture density network, which outputs each mixture component dynamically, to accurate model the predictive distribution of future purchase. We evaluate the proposed approach on two publicly available datasets, MovieLens-20M and RecSysl 5. Both experiments show that the proposed approach, which explicitly models the multi-modal nature of the predictive distribution, is able to greatly improve the performance over various baselines in terms of precision, recall and nDCG. The new modeling framework proposed can be easily adopted to many domain-specific problems, such as item recommendation in e-Commerce, ads targeting in online advertising, click-through-rate modeling, etc.	187.99353040324718
211.	The individual cell represents the fundamental unit of life. Its manner of functioning has been the focus of biomedical research for centuries. In recent years, advances in high throughput so-called single cell sequencing techniques have made it possible to study individual cells and their genetic profile. This enables revolutionary new insights into tissue composition, cell-cell interactions and dynamic processes in health and disease. The resulting profile data, e.g. from single cell transcriptomics, however, provide analysts with new challenges: data sets are typically very large, noisy and highly interconnected with other annotation data, making them unsuitable for established procedures. The setting calls for the application of novel algorithms originating from the field of artificial intelligence, which are adapted to deal with this type of challenge. Together, single cell sequencing and artificial intelligence can be considered powerful tools for biomedical research, enabling insights at the highest resolution. This article provides a short overview of the recent developments in both technologies and gives examples for their impact on medical applications. Subsequently, it is demonstrated how methods from artificial intelligence can be successfully applied for the analysis of single cell transcriptomics data. Since the successful application of such methods still requires a detailed understanding of their requirements, an even stronger interaction between specialists of both disciplines may become necessary in the future. We therefore conclude this article with a comment on the use of new platforms for collaboration and knowledge exchange.	187.99349691938102
212.	Computed tomography (CT) has been extensively used in nondestructive testing, medical diagnosis, etc. In the field of modern medicine, metal implants are widely used in people's daily life, and the serious artifacts in CT reconstruction images caused by metal implants cannot be ignored. Sinogram contains the most realistic projection information of patients. Processing in the sinogram domain directly can make the effective information maximum extent preserved. In this paper, we propose a novel method based on full convolutional network (FCN) for metal artifact reduction in the sinogram domain. The networks we introduced use the complete sinogram data to learn a mapping function to correct the metal-corrupted sinogram data. The network takes the metal-corrupted sinogram as the input and takes the artifact-free sinogram as the target. Compared with the existing deep learning based CT artifact reduction methods, our work just uses the sinogram information to correct the metal artifacts. The proposed network can process images of different sizes. Our initial results on a simulated dataset to demonstrate the potential effectiveness of this new approach to suppressing artifacts.	187.99343679214982
213.	Improving the food supply chain efficiency has been identified as an essential means to enhance food security, while reducing pressure on natural resources. Adequate food loss and waste (FLW) management has been proposed as an approach to meet these objectives. The main hypothesis of this study is to consider that the "strong fluctuations and short-term changes" on eating habits may have major consequences on potential FLW generation and management, as well as on GHG emissions, all taking into account the nutritional and the economic cost. Due to the exceptional lockdown measures imposed by the Spanish government, as a consequence of the emerging coronavirus disease, COVID-19, food production and consumption systems have undergone significant changes, which must be properly studied in order to propose strategies from the lessons learned. Taking Spain as a case study, the methodological approach included a deep analysis of the inputs and outputs of the Spanish food basket, the supply chain by means of a Material Flow Analysis, as well as an economic and comprehensive nutritional assessment, all under a life cycle thinking approach. The results reveal that during the first weeks of the COVID-19 lockdown, there was no significant adjustment in overall FLW generation, but a partial reallocation from extra-domestic consumption to households occurred (12% increase in household FLW). Moreover, the economic impact (+11%), GHG emissions (+10%), and the nutritional content (-8%) complete the multivariable impact profile that the COVID-19 outbreak had on FLW generation and management. Accordingly, this study once again highlights that measures aimed at reducing FLW, particularly in the household sector, are critical to make better use of food surpluses and FLW prevention and control, allowing us to confront future unforeseen scenarios. (C) 2020 Elsevier B.V. All rights reserved.	187.99337452549952
214.	In the last few years, deep learning in neural networks demonstrated impressive successes in the areas of computer vision, speech and image recognition, text generation, and many others. However, sensitive engineering areas such as nuclear engineering benefited less from these efficient techniques. In this work, deep learning expert systems are utilized to model and predict time series progression of a design-basis nuclear accident, featuring a loss of coolant accident. Two major findings are accomplished in this work. First, the ability to train expert systems with high accuracy, which could help nuclear power plant operators to figure out plant responses during the accident. Second, building fast, efficient, and accurate deep models to simulate nuclear phenomena, which could be valuable to nuclear computational science. In this work, large amount of time series data is obtained from simulation tools by simulating different conditions of the base-case/nominal accident scenario. Four critical outputs/responses are monitored during the accident (e.g. temperature, pressure, break flow rate, water level). Two approaches are adopted in this work. The first approach is to use feedforward deep neural networks (DNN) to fit all time steps and outputs in a single model. The second approach is to use long short-term memory (LSTM) to fit all time steps together for each reactor response separately. Both DNN and LSTM demonstrate very good performance in predicting the test and base-case scenarios, with accuracy as low as 92% and as high as 99%, where these test scenarios are unknown to the expert systems and are not included in the model training. In addition, both approaches demonstrate a significant reduction in computational costs, as the deep expert system is able to accurately predict the accident 100,000 times faster than the original simulation tool. Given sufficient data, the methodology adopted in this study demonstrates that DNN/LSTM expert systems can be used as a decision support system to model advanced time series phenomena within nuclear power plants with high accuracy and negligible computational costs. Published by Elsevier Ltd.	187.99326998534403
215.	One of the most important challenges for Autonomous Driving and Driving Assistance systems is the detection of the road to perform or monitor navigation. Many works can be found in the literature to perform road and lane detection, using both algorithmic processing and learning based techniques. However, no single solution is mentioned to be applicable in any circumstance of mixed scenarios of structured, unstructured, lane based, line based or curb based limits, and other sorts of boundaries. So, one way to embrace this challenge is to have multiple techniques, each specialized on a different approach, and combine them to obtain the best solution from individual contributions. That is the central concern of this paper. By improving a previously developed architecture to combine multiple data sources, a solution is proposed to merge the outputs of two Deep Learning based techniques for road detection. A new representation for the road is proposed along with a workflow of procedures for the combination of two simultaneous Deep Learning models, based on two adaptations of the ENet model. The results show that the overall solution copes with the alternate failures or under -performances of each model, producing a road detection result that is more reliable than the one given by each approach individually. (C) 2020 Elsevier B.V. All rights reserved.	187.9932244458016
216.	Since ancient times, the dream of realizing inclusive, fair and personalized learning has been chasing in the education filed all over the world. With the rapid development of information technologies, the traditional large-scale education system generated in the industrial revolution era cannot satisfy the increasing demand for personalized education services in the information era. Thus currently the reform and innovation of education is at a critical turning point. To specify, personalized learning is being focused on during the global education innovation and reform, and deep reform within the education field is being promoted by big data technology. Compared with other countries, during the current global education innovation and reform, China is facing more difficult challenges caused by a large number of active learners, complex learning environment, large-scale education resource supply, and a wide variety of learning service. Therefore the problem about how to provide large-scale, high-accuracy and personalized learning in China needs to be solved urgently, which is unique without precedents. The arising of information technologies, such as internet, cloud computing, big data, and artificial intelligent, has brought in not only diversified resources, scale data, and intelligent computing, but also the fusion between education and natural science. Consequently, the scientific paradigm of education has been changed from traditional experience-based research into data driven research. Such change, on the one hand, has offered a new approach to realize accurate and scientific education; on the other hand, has made an initial breakthrough in personalized learning. A historical opportunity to educate a learner according to his/her natural ability has finally arrived. To promote the data-driven application innovation as well as to achieve scale and personalized education, have both become an inexorable trend for the modern education. Due to the continuous influence of information technologies, the boundaries of learning time and space have both been broken completely. In addition, many great changes have taken place in learning environments, methods and contents, which obviously provide learners with more choices about what to learn and how to learn. In the future, the aim of personalized learning is to satisfy the personalized development demand for each learner, however it will definitely face serious challenges, e.g., how to understand learning subjects, how to construct learning environment, and how to implement teaching. In this paper, three basic scientific problems to be solved in personalized learning are discussed, which include (1) educational scenarios is calculable; (2) learning subjects is understandable; (3) learning services is customizable. Furthermore, in order to realize differentiated instruction, personalized learning, refined management, and intelligent services, breakthroughs in both theories and technologies needed are presented in this paper, including human-technology learning environment, learning data sensing and fusion, edge computing for education scenes, learning mechanism in digital environments, student modeling and analysis under data driven, group dynamics of the learner group, education resource supply, accurate education service, intelligent tutoring system. Education is a complex dynamic system, which needs both breakthrough research and systematic research. To effectively promote the research of personalized learning, actions needs to be taken, including for example implementing education research and experiment systematically, speeding up breakthroughs and talent training, solving scientific problems in the education field by means of multidisciplinary approach and wisdom as well as the multi-party cooperation mechanism named "politics-industry-academic-research-application". Based on a comprehensive analysis on countermeasures and research trends to personalized learning in western developed countries, in order to cope with challenges of personalized learning and help meet the goals of Education 2030 in China, the following four suggestions are proposed in this paper: (1) promoting the formation of educational science; (2) speeding up the construction of laws and regulations related to large-scale educational data; (3) exploring data-driven instructional evaluation mechanism and methods; and (4) increasing policy support in the research on teaching competency standards and teachers' promotion path in the new era.	187.9931993367224
217.	In order to understand the environmental trend of network finance and the impact of network finance on traditional ommercial banks, after analyzing the transaction risks of network finance, this study learns from the advanced models of credit risk measurement and early warning at home and abroad and the latest artificial intelligence technology, combining them with China's national conditions, so as to establish a credit risk measurement system suitable for commercial banks. In this study, the research is carried out from the perspectives of theory and practice, technology and business, and the credit risk warning system, measurement model and implementation tools are comprehensively sorted out, then the basic theories and core ideas are studied. In accordance with the concept of big data mining, this study proposes a financial crisis early warning model based on artificial intelligence system. Based on the empirical analysis of the main causes of the rapid decline in the asset quality of China's joint-stock commercial banks, and based on the characteristics of big data mining in the information explosion era, it is pointed out that the artificial intelligence is a powerful tool to improve the ability of credit risk measurement. It can be confirmed that the development of network finance has brought different impacts on the business, business model, and business philosophy of banks. (C) 2020 Elsevier B.V. All rights reserved.	187.9930718114228
218.	This paper describes how a concept-based approach to teaching was used to update how concurrent and distributed systems were taught at the University of Copenhagen. This approach focuses on discussion to drive student engagement whilst fostering a deeper understanding of the presented topics compared to more traditional displays of crude facts. The course is split into three sections: local concurrency, networked concurrency, and concurrency in hardware. This allows for an easier student journey through the course, as they are introduced to all core concepts in the first section, then have them reinforced in greater detail in the subsequent sections. Finally, the experience gained in updating this course is presented so others attempting to do similar may learn from it.	187.99306915276122
219.	We explore the use of deep learning hierarchical models for problems in financial prediction and classification. Financial prediction problems - such as those presented in designing and pricing securities, constructing portfolios, and risk management - often involve large data sets with complex data interactions that currently are difficult or impossible to specify in a full economic model. Applying deep learning methods to these problems can produce more useful results than standard methods in finance. In particular, deep learning can detect and exploit interactions in the data that are, at least currently, invisible to any existing financial economic theory. Copyright (c) 2016 John Wiley & Sons, Ltd.	187.9930311298382
220.	In this paper, we believe that the mixed selectivity of neuron in the top layer encodes distributed information produced from other neurons to offer a significant computational advantage over recognition accuracy. Thus, this paper proposes a hierarchical network framework that the learning behaviors of features combined from hundreds of midlayers. First, a subnetwork neuron, which itself could be constructed by other nodes, is functional as a subspace features extractor. The top layer of a hierarchical network needs subspace features produced by the subnetwork neurons to get rid of factors that are not relevant, but at the same time, to recast the subspace features into a mapping space so that the hierarchical network can be processed to generate more reliable cognition. Second, this paper shows that with noniterative learning strategy, the proposed method has a wider and shallower structure, providing a significant role in generalization performance improvements. Hence, compared with other state-of-the-art methods, multiple channel features with the proposed method could provide a comparable or even better performance, which dramatically boosts the learning speed. Our experimental results show that our platform can provide a much better generalization performance than 55 other state-of-the-art methods.	187.9929632594197
221.	For a natural social human-robot interaction, it is essential for a robot to learn the human-like social skills. However, learning such skills is notoriously hard due to the limited availability of direct instructions from people to teach a robot. In this paper, we propose an intrinsically motivated reinforcement learning framework in which an agent gets the intrinsic motivation-based rewards through the action-conditional predictive model. By using the proposed method, the robot learned the social skills from the human-robot interaction experiences gathered in the real uncontrolled environments. The results indicate that the robot not only acquired human-like social skills but also took more human-like decisions, on a test dataset, than a robot which received direct rewards for the task achievement. (C) 2018 Elsevier Ltd. All rights reserved.	187.9928811937017
222.	Deep-learning-based algorithms have shown great achievements in fault diagnosis of rotating machinery components in recent years. However, training deep networks is cumbersome and time-consuming. Furthermore, when working conditions change, their diagnostic performance degrades significantly. To address these problems, a novel deep kernel extreme learning machine (DK-ELM) is presented in this paper. First, we propose a discriminative manifold ELM auto-encoder (DM-ELM-AE), which exploits both the geometry of the training sample's marginal distribution and the label information. Then, multiple DM-ELM-AEs are stacked to form a deep feature extractor to extract discriminative and robust high-level features from vibration measurements automatically. Based on the extracted features, final fault pattern classification is carried out using a kernel ELM instead of a conventional ELM classifier. In this way, good diagnostic performance can be attained, regardless of working conditions. The experimental results show that the DK-ELM yields more promising results than other state-of-the-art algorithms in terms of diagnosis accuracy and adaptation ability to working conditions. It achieved 2% improvement in testing accuracy compared with the kernel ELM, and nearly 5% improvement compared with classical deep learning algorithms under different working conditions. In addition, it inherits the superb training efficiency from the ELM and is much easier to implement than deep learning algorithms.	187.9928519887219
223.	The process of continuously reallocating funds into financial assets, aiming to increase the expected return of investment and minimizing the risk, is known as portfolio management. In this paper, a portfolio management framework is developed based on a deep reinforcement learning framework called DeepBreath. The DeepBreath methodology combines a restricted stacked autoencoder and a convolutional neural network (CNN) into an integrated framework. The restricted stacked autoencoder is employed in order to conduct dimensionality reduction and features selection, thus ensuring that only the most informative abstract features are retained. The CNN is used to learn and enforce the investment policy which consists of reallocating the various assets in order to increase the expected return on investment. The framework consists of both offline and online learning strategies: the former is required to train the CNN while the latter handles concept drifts i.e. a change in the data distribution resulting from unforeseen circumstances. These are based on passive concept drift detection and online stochastic batching. Settlement risk may occur as a result of a delay in between the acquisition of an asset and its payment failing to deliver the terms of a contract. In order to tackle this challenging issue, a blockchain is employed. Finally, the performance of the DeepBreath framework is tested with four test sets over three distinct investment periods. The results show that the return of investment achieved by our approach outperforms current expert investment strategies while minimizing the market risk. Crown Copyright (C) 2020 Published by Elsevier Ltd.	187.99272487816177
224.	In this paper, we investigate the problem of Temporal Action Proposal (TAP) generation, which plays a fundamental role in large-scale untrimmed video analysis but remains largely unsolved. Most of the prior works proposed the temporal actions by predicting the temporal boundaries or actionness scores of video units. Nevertheless, context information among surrounding video units has not been adequately explored, which may result in severe loss of information. In this work, we propose a context-aware temporal action proposal network which makes full use of the contextual information in two aspects: 1) To generate initial proposals, we design a Bi-directional Parallel LSTMs to extract the visual features of a video unit by considering its contextual information. Therefore, the prediction of temporal boundaries and actionness scores will be more accurate because it knows what happened in the past and what will happen in the future; and 2) To refine the initial proposals, we design an action-attention based reranking network which considers both surrounding proposal and initial actionness scores to assign true action proposals with high confidence scores. Extensive experiments are conducted on two challenging datasets for both temporal action proposal generation and detection tasks, demonstrating the effectiveness of the proposed approach. In particular, on THUMOS'14 dataset, our method significantly surpasses state-of-the-art methods by 7.73% on AR@50. Our code is released at: https://github.com/Rheelt/TAPG. (C) 2020 Elsevier Ltd. All rights reserved.	187.99269169506954
225.	In this paper, we propose a method for the estimation of the interaction forces between the motorized system and object through the visual and electric information. In particular, we propose a new interaction force sensing method based on sequential images and the electrical current from the motor during the interaction between the system and environment to estimate the interaction force using deep learning. In the previous method, to measure the interaction force using only visual information, the prediction is inaccurate when the system interacts with an undeformable target, even though the aspect of the change appears small in the image. We use a neural network structure for estimating the interaction force from the time-series data of visual and electric information using deep learning, which combines the convolution neural network and long short-term memory models. From the evaluation to show the feasibility of the interaction force estimation, the proposed learning models successfully estimate the forces for four targets (rigid box, rigid box on sponge, sponge, and stapler), which are both deformable and undeformable objects. The proposed method demonstrates the best results in the interaction force estimation between the motorized system and object.	187.9926562501721
226.	Segmentation of neuroanatomy based on fully convolutional networks (FCNs) has been proven to be powerful in numerous medical applications with excellent performance. However, the lack of annotated data and the inconsistency between different datasets make it difficult in training a deep network model for brain segmentation. In this paper, we propose a 3D patch-wise based model to learn the brain segmentation, namely ScaDO net (Scaffold-Dense-Octave net). This scaffold-like net is designed by Scaffold blocks to perform the 3D patch-wise brain segmentation task. Even with more than one hundred convolution layers, the number of parameters and FLOPs (Float Point Operations) are strictly controlled by a set of well-defined hyperparameters. Furthermore, the octave convolution is incorporated into the ScaDO net to reduce the FLOPs and keep the number of parameters. To give reasonable suggestions in practical applications, we have conducted ablation studies about FLOPs-DICE trade-off, which showed that setting appropriate hyperparameters would achieve a high DICE value with relatively small FLOPs. Compared with the state-of-the-art methods, the experimental results on different heterogeneous brain datasets have demonstrated that the proposed ScaDO net can achieve an accurate brain segmentation, even for small and delicate subcortical structures. With over one hundred convolution layers, the proposed method has as shorter than 40s for per MRI volume.	187.99261696822805
227.	Addressing current global challenges such as biodiversity loss, global change, and increasing demands for ecosystem services requires improved ecological prediction. Recent increases in data availability, process understanding, and computing power are fostering quantitative approaches in ecology. However, flexible methodological frameworks are needed to utilize these developments towards improved ecological prediction. Deep learning is a rapidly evolving branch of machine learning, yet has received only little attention in ecology to date. It refers to the training of deep neural networks (DNNs), i.e. artificial neural networks consisting of many layers and a large number of neurons. We here provide a reproducible example (including code and data) of designing, training, and applying DNNs for ecological prediction. Using bark beetle outbreaks in conifer-dominated forests as an example, we show that DNNs are well able to predict both short-term infestation risk at the local scale and long-term outbreak dynamics at the landscape level. We furthermore highlight that DNNs have better overall performance than more conventional approaches to predicting bark beetle outbreak dynamics. We conclude that DNNs have high potential to form the backbone of a comprehensive disturbance forecasting system. More broadly, we argue for an increased utilization of the predictive power of DNNs for a wide range of ecological problems.	187.9925903205493
228.	The current standalone deep learning framework tends to result in overfitting and low utility. This problem can be addressed by either a centralized framework that deploys a central server to train a global model on the joint data from all parties, or a distributed framework that leverages a parameter server to aggregate local model updates. Server-based solutions are prone to the problem of a single-point-of-failure. In this respect, collaborative learning frameworks, such as federated learning (FL), are more robust. Existing federated learning frameworks overlook an important aspect of participation: fairness. All parties are given the same final model without regard to their contributions. To address these issues, we propose a decentralized Fair and Privacy-Preserving Deep Learning (FPPDL) framework to incorporate fairness into federated deep learning models. In particular, we design a local credibility mutual evaluation mechanism to guarantee fairness, and a three-layer onion-style encryption scheme to guarantee both accuracy and privacy. Different from existing FL paradigm, under FPPDL, each participant receives a different version of the FL model with performance commensurate with his contributions. Experiments on benchmark datasets demonstrate that FPPDL balances fairness, privacy and accuracy. It enables federated learning ecosystems to detect and isolate low-contribution parties, thereby promoting responsible participation.	187.99240457227518
229.	Insights into the incidence and survival of cancer, the influence of lifestyle and environmental factors and the interaction of treatment regimens with outcomes are hugely dependent on observational research, patient data derived from the healthcare system and from volunteers participating in cohort studies, often non-selective. Since 25th May 2018, the European General Data Protection Regulation (GDPR) applies to such data. The GDPR focusses on more individual control for data subjects of 'their' data. Yet, the GDPR was preceded by a long debate. The research community participated actively in that debate, and as a result, the GDPR has research exemptions as well. Some of those apply directly; other exemptions need to be implemented into national law. Those exemptions will be discussed together with a general outline of the GDPR. I propose a substantive definition of research-absent in the GDPR-which can warrant its special status in the GDPR. The debate is not over yet. Most legal texts exhibit ambiguity and are interpreted against a background of values. In this case, those could be subsumed under informational self-determination versus solidarity and the deeper meaning of autonomy. Values will also guide national implementation and their interpretation. The value of individual control or informational self-determination should be balanced by nuanced visions about our mutual dependency in healthcare, as an ever-learning system, especially in the European solidarity-based healthcare systems. Good research governance might be a way forward to escape the consent or anonymise dichotomy. (C) 2018 The Author. Published by Elsevier Ltd.	187.9923867196861
230.	Automatic text summarization (ATS) has recently achieved impressive performance thanks to recent advances in deep learning and the availability of large-scale corpora. However, there is still no guarantee that the generated summaries are grammatical, concise, and convey all salient information as the original documents have. To make the summarization results more faithful, this paper presents an unsupervised approach that combines rhetorical structure theory, deep neural model, and domain knowledge concern for ATS. This architecture mainly contains three components: domain knowledge base construction based on representation learning, the attentional encoder-decoder model for rhetorical parsing, and subroutine-based model for text summarization. Domain knowledge can be effectively used for unsupervised rhetorical parsing thus rhetorical structure trees for each document can be derived. In the unsupervised rhetorical parsing module, the idea of translation was adopted to alleviate the problem of data scarcity. The subroutine-based summarization model purely depends on the derived rhetorical structure trees and can generate content-balanced results. To evaluate the summary results without golden standard, we proposed an unsupervised evaluation metric, whose hyper-parameters were tuned by supervised learning. Experimental results show that, on a large-scale Chinese dataset, our proposed approach can obtain comparable performances compared with existing methods. (C) 2020 Elsevier Ltd. All rights reserved.	187.99229053912387
231.	In the healthcare sector, there is a strong demand for accurate objective pain assessment as a key for effective pain management. Real-time and accurate objective pain assessment help hospital staffs and caregivers decide the proper dosage of pain medication to be provided to a patient in a timely manner. The state-of-the-art automatic and objective pain assessment techniques in the literature can be classified into two main categories: physiological-based and behavioral-based. The firstclass monitors the changes in patients' physiological data such as Electrocardiography (ECG), Electromyography (EMG), Photoplethysmography (PPG) to identify autonomic nervous system reactions to pain, while the second class utilizes behavioral reactions to pain such as techniques using computer vision-based techniques by extracting features from patients' head poses and facial expressions. Recent pain monitoring systems have become multi-modal meaning that they deploy a combination of both approaches to improve pain monitoring accuracy. Although such complex models are highly accurate in pain monitoring, they are more computationally intensive imposing feasibility limitations to implement them on wearable devices in terms of energy efficiency (battery life) as well as computation latency. A smart and selfaware system capable of adaptively making a decision at run-time in response to the changes in pain level and context can minimize energy consumption by dynamically offloading tasks to the gateway devices at the edge layer. For this reason, in this paper, a self-aware system is proposed for the continuous assessment of pain intensity at the edge layer. Using the BioVid heat pain dataset, our approach demonstrates a promising reduction in terms of energy consumption with a negligible accuracy loss compared with its non-adaptive counterpart.	187.99226684471807
232.	Despite claims that finger-vein biometrics can detect aliveness, recent research has shown that current systems can be fooled by forged vein patterns printed on a distinctive paper, raising considerable security concerns regarding the identification authenticity of these systems. Additionally, finger-vein identification exhibits low accuracy rates in real-world applications due to the inferior image quality caused by varied finger thicknesses and vein pattern variations caused by finger axial rotation. To address these issues, we propose a lightweight convolutional neural network (CNN) called the Finger-Vein Recognition and AntiSpoofing Network (FVRAS-Net), which integrates the recognition task and the antispoofing task into a unified CNN model by utilizing a multitask learning (MTL) approach and achieves high security and strong real-time performance. Then, a multi-intensity illumination strategy is introduced into the embedded biometric system to automatically select the most informative image for finger-vein identification, which can effectively improve the recognition performance of the real system. Finally, a challenging finger-vein database with images depicting severe axial finger rotation is built for more rigorous validation of the proposed system, which enriches the database resources for the finger-vein recognition community. Experiments demonstrate that the proposed FVRAS-Net achieves excellent performance in both recognition and antispoofing tasks on public data sets, especially on challenging databases with images depicting axial rotation.	187.99226076487264
233.	In the field of Architecture, Engineering, Construction, and Facility Management (AEC/FM), job site surveying is critical for tasks such as construction progress monitoring and quality assurance and quality control. Moving obstacles often occlude the sight of view, and sometimes block the view of interest. However, images are often collected for documentation and analysis of the building under construction or operation. The occluding objects, such as the construction workers, compromise the collected image data. On the other hand, the capability of the Context Encoders model took the pioneering step providing the opportunity of image inpainting. This research applies Context Encoders to remove redundant objects in images and inpaints the background context. The original Context Encoders model, a deep learning model, requires a large training dataset for a decent image inpainting. In the model, the region in need of context inpainting is constrained to be a predefined area, fixed in size and position in the image. In this work, we adapted a deep learning architecture, U-Net, for a direct image -to-image translation for context inpainting, and thus relaxing the fixed size and position constraints in the original Context Encoders model. Simultaneously in a single framework, the proposed model not only erases redundant objects but also inpaints the missing content in the pixel scale, based on surrounding semantic clues. Employing the U-Net yields encouraging results for cases in operating buildings and those under construction.	187.99218506354367
234.	In this paper, we provide a comprehensive survey in human action recognition and prediction, which has always been a universal and critical area in computer vision. Human action recognition is the first step for a machine to understand and percept the nature, which is small part in machine perception. Human action prediction is the higher layer than human action recognition that is small part in machine cognition, which would give the machine the ability of imagination and reasoning. Here, we only discuss human action recognition from two methodologies that is based on presentations and deep learning, separately. Then, 4 public datasets of human action recognition are descripted closely. Some challenges in dataset are also proposed because of the significance to the development of computer vision. Meanwhile, we compare and summarize recent-published research achievements under deep learning. In the end, we conclude about mentioned methods and future challenges to work on for computer vision.	187.99214853835434
235.	Object proposal quality assessment without ground truth as reference is a challenging task. Some existing methods measure the quality with hand-crafted metrics for subjective metrics, such as objectness and foreground confidence. Recently, deep learning is adopted for direct assessment for quantifiable metric, such as Intersection over Union (IoU). However, we find that IoU, the commonly used quality metric, is far from fully describing the quality of an object proposal. Proposals with the same IoU score may carry totally different amount of discriminative attribute. We introduce a new metric named Discriminative Information Richness (DIR) to characterize the discriminative degree of the given object proposal. DIR is derived from the response intensity of the projected deep feature maps, whose high correlation response indicates the discriminative regions. Besides, we design a convolutional neural network named DrlNet to simultaneously predict IoU scores and perceive the richness of the identification information. DrlNet is defined as a multi-metric joint deep regression network for both spatial covering prediction and discriminative information richness perception. Compared with the solely IoU based models, DrlNet can provide more comprehensive quality assessment. We perform comprehensive experiments on both PASCAL VOC dataset and COCO dataset. The experimental results show that our DrlNet performs well on both proposal selection and object detection tasks. Particularly, experimental results on COCO dataset demonstrate the good generalization ability of the proposed model. (C) 2020 Elsevier Inc. All rights reserved.	187.99212250471902
236.	The reconstruction of shredded documents consists of coherently arranging fragments of paper (shreds) to recover the original document(s). A great challenge in computational reconstruction is to properly evaluate the compatibility between the shreds. While traditional pixel-based approaches are not robust to real shredding, more sophisticated solutions compromise significantly time performance. The solution presented in this work extends our previous deep learning method for single-page reconstruction to a more realistic/complex scenario: the reconstruction of several mixed shredded documents at once. In our approach, the compatibility evaluation is modeled as a two-class (valid or invalid) pattern recognition problem. The model is trained in a self-supervised manner on samples extracted from simulated-shredded documents, which obviates manual annotation. Experimental results on three datasets - including a new collection of 100 strip-shredded documents produced for this work - have shown that the proposed method outperforms the competing ones on complex scenarios, achieving accuracy superior to 90%. (C) 2020 Elsevier Ltd. All rights reserved.	187.99201495256082
237.	This paper presents a cost-sensitive active Question-Answering (QA) framework for learning a nine-layer And-Or graph (AOG) from web images. The AOG explicitly represents object categories, poses/viewpoints, parts, and detailed structures within the parts in a compositional hierarchy. The QA framework is designed to minimize an overall risk, which trades off the loss and query costs. The loss is defined for nodes in all layers of the AOG, including the generative loss (measuring the likelihood of the images) and the discriminative loss (measuring the fitness to human answers). The cost comprises both the human labor of answering questions and the computational cost of model learning. The cost-sensitive QA framework iteratively selects different storylines of questions to update different nodes in the AOG. Experiments showed that our method required much less human supervision (e.g. labeling parts on 3-10 training objects for each category) and achieved better performance than baseline methods.	187.99196635135735
238.	The main objective of educational institutions is to achieve the integral development of their students in their learning and knowledge construction process. One way to achieve these objectives is the accompaniment and continuous monitoring of students in this process, adapting the methods to their training needs. In online and mixed teaching modalities (eLearning methodology), this monitoring is carried out through the digital platforms in which it is carried out in the academic activity, such as the learning management system platforms. These virtual teaching and learning environments (EVA) allow access to learners' fingerprints, generating a large volume of data, that analysis allows a deep way of their behavior in those policies. This article collects the results of the exploration of student activity in the virtual campus (Blackboard Learn), which is in the first phase of Learning Analytics project carried out by the Nebrija University and discusses its implications for educational institutions. The data extracted correspond to the 2016-2017 course and have been analyzed around four blocks of information: user behavior, user activity, activity in the content areas and activity in the forums.	187.99176366603194
239.	Multi-access edge computing (MEC) aims to extend cloud service to the network edge to reduce network traffic and service latency. A fundamental problem in MEC is how to efficiently offload heterogeneous tasks of mobile applications from user equipment (UE) to MEC hosts. Recently, many deep reinforcement learning (DRL)-based methods have been proposed to learn offloading policies through interacting with the MEC environment that consists of UE, wireless channels, and MEC hosts. However, these methods have weak adaptability to new environments because they have low sample efficiency and need full retraining to learn updated policies for new environments. To overcome this weakness, we propose a task offloading method based on meta reinforcement learning, which can adapt fast to new environments with a small number of gradient updates and samples. We model mobile applications as Directed Acyclic Graphs (DAGs) and the offloading policy by a custom sequence-to-sequence (seq2seq) neural network. To efficiently train the seq2seq network, we propose a method that synergizes the first order approximation and clipped surrogate objective. The experimental results demonstrate that this new offloading method can reduce the latency by up to 25 percent compared to three baselines while being able to adapt fast to new environments.	187.99171503986378
240.	Drug-drug interactions (DDIs) are crucial for drug research and pharmacovigilance. These interactions may cause adverse drug effects that threaten public health and patient safety. Therefore, the DDIs extraction from biomedical literature has been widely studied and emphasized in modern biomedical research. The previous rules-based and machine learning approaches rely on tedious feature engineering, which is labourious, time-consuming and unsatisfactory. With the development of deep learning technologies, this problem is alleviated by learning feature representations automatically. Here, we review the recent deep learning methods that have been applied to the extraction of DDIs from biomedical literature. We describe each method briefly and compare its performance in the DDI corpus systematically. Next, we summarize the advantages and disadvantages of these deep learning models for this task. Furthermore, we discuss some challenges and future perspectives of DDI extraction via deep learning methods. This review aims to serve as a useful guide for interested researchers to further advance bioinformatics algorithms for DDIs extraction from the literature.	187.9916005118927
241.	In the field of multimodal communication, sign language is and continues to be, one of the most understudied areas. Thanks to the recent advances in the field of deep learning, there are far-reaching implications and applications that neural networks can have for sign language mastering. This paper describes a method for ASL alphabet recognition using Convolutional Neural Networks (CNN), which allows to monitor user's learning progress. American Sign Language (ASL) alphabet recognition by computer vision is a challenging task due to the complexity in ASL signs, high interclass similarities, large intraclass variations, and constant occlusions. We produced a robust model that classifies letters correctly in a majority of cases. The experimental results encouraged us to investigate the adoption of AI techniques to support learning of a sign language, as a natural language with its own syntax and lexicon. The challenge was to deliver a mobile sign language training solution that users may adopt during their everyday life. To satisfy the indispensable additional computational resources to the locally connected enduser devices, we propose the adoption of a Fog-Computing Architecture.	187.99152281020648
242.	To obtain comprehensive bearing vibration characteristic information and improved the accuracy of vibration state recognition, this paper proposed the pre-fully connected deep CNN (PFC-CNN) method and based on this, established the bearing vibration state recognition model. Firstly, the CNN's front fully connected structure was design and the front fully connected layer was used to reduce the complexity of the signal and extracted the global characteristics of the signal. On this basis, the fusion feature learning of global features and local features (which got by CNN's local perceptual field) was studied. Secondly, the back-propagation training of the whole network was studied, and the discrimination degree and recognition accuracy of the corresponding features of different state categories were finally improved. Results of experimental study showed that compared with other methods, the proposed method in this paper improved the identification accuracy which can reach 96.25%. (C) 2020 Elsevier Ltd. All rights reserved.	187.99139953545216
243.	The COrona VIrus Disease 19 (COVID-19) pandemic required the work of all global experts to tackle it. Despite the abundance of new studies, privacy laws prevent their dissemination for medical investigations: through clinical de-identification, the Protected Health Information (PHI) contained therein can be anonymized so that medical records can be shared and published. The automation of clinical de-identification through deep learning techniques has proven to be less effective for languages other than English due to the scarcity of data sets. Hence a new Italian de-identification data set has been created from the COVID-19 clinical records made available by the Italian Society of Radiology (SIRM). Therefore, two multi-lingual deep learning systems have been developed for this low-resource language scenario: the objective is to investigate their ability to transfer knowledge between different languages while maintaining the necessary features to correctly perform the Named Entity Recognition task for de-identification. The systems were trained using four different strategies, using both the English Informatics for Integrating Biology & the Bedside (i2b2) 2014 and the new Italian SIRM COVID-19 data sets, then evaluated on the latter. These approaches have demonstrated the effectiveness of cross-lingual transfer learning to de-identify medical records written in a low resource language such as Italian, using one with high resources such as English.	187.9913961649092
244.	With the exponential growth of data and the high demand for the analysis of large datasets, the MapReduce framework has been widely utilized to process data in a timely, cost-effective manner. It is well-known that the performance of MapReduce is limited by its default configuration parameters, and there are a few research studies that have focused on finding the optimal configurations to improve the performance of the MapReduce framework. Recently, machine learning based approaches have been receiving more attention to be utilized to auto configure the MapReduce parameters to account for the dynamic nature of the applications. In this article, we propose and develop a reinforcement learning (RL)-based scheme, named RL-MRCONF, to automatically configure the MapReduce parameters. Specifically, we explore and experiment with two variations of RL-MRCONF; one variation is based on the traditional RL algorithm and the second is based on the deep RL algorithm. Results obtained from simulations show that the RL-MRCONF has the ability to successfully and effectively auto-configure the MapReduce parameters dynamically according to changes in job types and computing resources. Moreover, simulation results show our proposed RL-MRCONF scheme outperforms the traditional RL-based implementation. Using datasets provided by MR-Perf, simulation results show that our proposed scheme provides around 50% performance improvement in terms of execution time when compared with MapReduce using default settings.	187.99135540390765
245.	Content-based image retrieval can quickly find images associated with query instance from large-scale medical image databases, which can provide effective aided diagnosis information for doctors, and is beneficial to improve the accuracy of diagnosis. Deep supervised hashing not only has the ability to extract rich features from deep neural networks but also can make full use of supervised information to improve retrieval accuracy. It is also more efficient and memory-saving due to reducing the dimension of the feature vectors by the hash mapping. Therefore, it has attracted much attention. In the paper, a novel end-to-end supervised deep hashing method is proposed, where feature extraction and binary code learning are carried out by joint optimization. The semantic similarity is maintained by label information and the neighborhood structures are preserved by graph regularization. Moreover, the discrete constrained objective function is optimized directly without relaxation. Experiments have been conducted on the pulmonary nodule image dataset and the results demonstrate the proposed method can yield better Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions retrieval performance by comparing with the state-of-the-art hashing methods.	187.99135453958078
246.	The generalization performance in deep learning is linked to the size and the variations of the samples available during training. This is apparent in the domain of computeraided gastrointestinal tract abnormality detection, where the lesions can vary a lot from each other and the number of available samples is limited, mainly due to personal data protection legislations. In this work we present a novel approach of tackling the problem of limited training data availability by making use of artificially generated images. More specifically we trained a Generative Adversarial Network (GAN) using Wireless Capsule Endoscopy (WCE) images to generate fake but realistic images from the small bowel. The generated images were then used to train a Convolutional Neural Network (CNN) to identify inflammatory conditions on real WCE images. To evaluate the performance of our approach, in our experiments we compare the generalization performance of the same CNN architecture trained separately with real and fake images, obtaining 90.9% and 79.1% Area Under Receiver Operating Characteristic (AUC), respectively. The results show that training using solely artificially generated data can be effective in cases where real training data are inaccessible.	187.991318657636
247.	Building highly nonlinear and nonparametric models is central to several state-of-the-art machine learning systems. Kernel methods form an important class of techniques that induce a reproducing kernel Hilbert space (RKHS) for inferring non-linear models through the construction of similarity functions from data. These methods are particularly preferred in cases where the training data sizes are limited and when prior knowledge of the data similarities is available. Despite their usefulness, they are limited by the computational complexity and their inability to support end-to-end learning with a task-specific objective. On the other hand, deep neural networks have become the de facto solution for end-to-end inference in several learning paradigms. In this paper, we explore the idea of using deep architectures to perform kernel machine optimization, for both computational efficiency and end-to-end inferencing. To this end, we develop the deep kernel machine optimization framework, that creates an ensemble of dense embeddings using Nystrom kernel approximations and utilizes deep learning to generate task-specific representations through the fusion of the embeddings. Intuitively, the filters of the network are trained to fuse information from an ensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel dropout regularization to enable improved training convergence. Finally, we extend this framework to the multiple kernel case, by coupling a global fusion layer with pretrained deep kernel machines for each of the constituent kernels. Using case studies with limited training data, and lack of explicit feature sources, we demonstrate the effectiveness of our framework over conventional model inferencing techniques.	187.99114325937904
248.	The improved knowledge of wave height and period conditions has considerably influenced on ocean navigation, marine fishery and engineering, especially in the polar regions. The methods of predicting ocean wave height which involve field measurements, numerical simulation, physical models and analytical solutions have been gradually developed with intelligent functions. Despite numerical wave models being dominant for recent decades, wave forecasting is still facing many challenges such as small region forecasting and large amounts of data needed. This paper presents a novel deep learning algorithm, namely Long Short Term Memory (LSTM), incorporating with Principal Component Analysis (PCA) to predict the wave height by using data from four wave buoys as deployed in the polar westerlies for two and half months. The PCA method is used to extract principal components from a set of input signals while LSTM is adopted to avoid long term independences during the forecasting. The novelty of this paper is to investigate an artificial intelligence (AI) based model in the field of time sequence forecasting in order to determine the performance of wave conditions by using AI technology. The result from this integrated method demonstrates that the LSTM model has the potential to better predict wave height in the polar condition based on time-space domain information. The PCA is proved essential for selection of input signals and for correlation analysis. For comparison, different data-driven models are applied and the results also show the purposed model achieves the highest scores in terms of R-squared value. Besides, the paper also discusses the challenges for long term and high-value prediction which needs to be optimized in the future work.	187.99105527620583
249.	Cybersecurity data remains a challenge for the machine learning community as the high volume of traffic makes it difficult to properly disambiguate anomalous from normal behaviour. That decision is the core of an intelligent Intrusion Detection System (IDS), a component responsible for raising alerts whenever a potential threat is detected. However, with high volume data in contemporary systems, these IDSs generate numerous alerts, too large for human operators to exhaustively investigate. Moreover, simply reporting a single possible threat is often not sufficient, since the security analyst has to investigate the alert without any further clues of the underlying cause. In order to combat these issues, we empirically compare popular deep neural learning architectures for the problem of intrusion detection in sequential data streams. Contrary to a majority of research studies, we do not take a classification-based approach that requires labeled examples of hostile attacks. Instead, we adopt an unsupervised anomaly detection approach that aims to model a benign sequential data distribution against which new test instances are compared to. We also examine one additional deep network in the form of an attention model capable of providing explanations in addition to its predictions; such information is of crucial importance to network operators since it provides additional guidance to resolve potential threats. For our experiments, we evaluate the models against a variety of data sets of different complexities, ranging from simple unidimensional (synthetic and Yahoo!) to more complex multi-source (CICIDS2017 and small real-world enterprise network) data streams. In order to facilitate end-user needs, we focus on ranking-based metrics for comparing different deep neural architectures. This evaluation is especially important for security analysts to prioritize their anomaly investigations. Overall, our experiments demonstrate that a variant of a recurrent neural network generally outperforms a popular non-sequential deep autoencoder commonly used for unsupervised anomaly detection. The attentional model did not provide sufficiently good performance and explanations that we discuss in our analysis. Nonetheless, given that the global financial outlays for cybersecurity are calculated in trillions of dollars, our evaluation and identification of the top-performing RNN architectures for anomaly detection in sequential data streams can lead to improved intelligent IDS design, while our contributions of attentional explanation will hopefully lay the foundations for future improvements to the explanatory capability of these intelligent learning-based IDSs. (C) 2020 Elsevier Ltd. All rights reserved.	187.99095166530924
250.	Deep learning model tends to promote models with deep structure. Despite its high accuracy, the model was not practical when high computing power was not available. Thus, deep model with not-so-deep structure or less number of model parameters is needed for low capacity computer. Logo and brand recognition task is an important and challenging problem in computer vision with wide potential applications. The inherent challenge to address this task is not only due to the presence of logo in various direction and clutters as well as imbalanced dataset but also because of high computing workload when deep learning models were adopted. This paper presents empirical results of logo recognition method using MiniVGGNet and MiniGoogleNet models combined with augmentation technique to increase variation and number of samples. The results show that the proposed model combined with augmentation technique increased accuracy of model accuracies and fasten training convergence of both models.	187.9909499074759
251.	Recently, deep learning-based intelligent fault diagnosis techniques have obtained good classification performance with amount of supervised training data. However, domain shift problem between the training and testing data usually occurs due to variation in operating conditions and interferences of environment noise. Transfer learning provides a promising tool for handling the cross-domain diagnosis problems by leveraging knowledge from the source domain to help learning in the target domain. Most existing studies attempt to learn both domain features in a common feature space to reduce the domain shift, which are not optimal on specific discriminative tasks and can be limited to small shifts. This article proposes a novel domain adversarial transfer network (DATN), exploiting task-specific feature learning networks and domain adversarial training techniques for handling large distribution discrepancy across domains. First, two asymmetric encoder networks integrating deep convolutional neural networks are designed for learning hierarchical representations from the source domain and target domain. Then, the network weights learned in source tasks are transferred to improve training on target tasks. Finally, domain adversarial training with inverted label loss is introduced to minimize the difference between source and target distributions. To validate the effectiveness and superiority of the proposed method in the presence of large domain shifts, two fault data sets from different test rigs are investigated, and different fault severities, compound faults, and data contaminated by noise are considered. The experimental results demonstrate that the proposed method achieves the average accuracy of 96.45% on the bearing data set and 98.92% on the gearbox data set, which outperforms other algorithms.	187.9909333566647
252.	Monitoring and diagnostics are vitally important in smart manufacturing systems since early detection can reduce downtime, protect environment, improve work efficiency, and save cost. The current work for monitoring and diagnostics mainly process the system condition data from multisensor by some mainstream machine learning and deep learning methods. However, these methods' performance is limited by the following weaknesses: (1) The multi-sensor information are not well used, and its feature fusion is not considerd. (2) Current advanced methods, such as convolution neural network (CNN), long short-term memory neural network (LSTM), are still facing some problems due to their inherent structures. CNN does not consider the sequential and temporal dependency; LSTM does not consider spatial correlation. Thus, a novel integrated model based on deep learning and multi-sensor feature fusion is proposed. The developed parallel convolutional neural network (PCNN) in the integrated model can achieve multisensory feature fusion to overcome the first weakness. The integrated CNN, deep residual networks (DRN), LSTM, can solve the second point. Specifically, the signals collected from multiple sensors are turned into multi-channel images, and the PCNN is designed to extract and fused the features of the converted images. Then, DRN and LSTM are developed to accept the extracted high-dimensional features by the designed CNN and generate the prediction results by fully connected neural networks. Two experiments, including cutting tool monitoring and bearing fault diagnosis, are conducted to validate the superiority and robustness of the proposed method. Compared with the state-of-the-art algorithms, the results show that the proposed model is more robust and accurate. (C) 2020 Elsevier Ltd. All rights reserved.	187.9908048952849
253.	Although computer-aided diagnosis (CAD) is widely used in mammography, conventional CAD programs that use prompts to indicate potential cancers on the mammograms have not led to an improvement in diagnostic accuracy. Because of the advances in machine learning, especially with use of deep (multilayered) convolutional neural networks, artificial intelligence has undergone a transformation that has improved the quality of the predictions of the models. Recently, such deep learning algorithms have been applied to mammography and digital breast tomosynthesis (DBT). In this review, the authors explain how deep learning works in the context of mammography and DBT and define the important technical challenges. Subsequently, they discuss the current status and future perspectives of artificial intelligence-based clinical applications for mammography, DBT, and radiomics. Available algorithms are advanced and approach the performance of radiologists-especially for cancer detection and risk prediction at mammography. However, clinical validation is largely lacking, and it is not clear how the power of deep learning should be used to optimize practice. Further development of deep learning models is necessary for DBT, and this requires collection of larger databases. It is expected that deep learning will eventually have an important role in DBT, including the generation of synthetic images. (C) RSNA, 2019	187.9907651127072
254.	Hepatocellular carcinoma (HCC) represents the most frequent form of liver cancer. It evolves from cirrhosis, as the result of a restructuring phase at the end of which dysplastic nodules appear. HCC is the main cause of death in people affected by cirrhosis. The most reliable method for HCC diagnosis, the golden standard, is the needle biopsy, but this is an invasive technique, dangerous for the human body. We develop computerized methods, based on ultrasound images, in order to perform automatic diagnosis of HCC in a noninvasive manner. In our previous research, we elaborated the textural model of HCC, based on classical and advanced texture analysis methods, in combination with traditional classification techniques, which led to a satisfying accuracy. We aim to improve this performance in our current and further research. In this article, we analyzed the role of specific deep learning techniques concerning the automatic recognition of HCC from ultrasound images. We chose the Convolutional Neural Networks (CNN), this method being well known for its performance in the field of image recognition. Thus, CNN are based on artificial neural networks, they also performing image processing operations, such as inner convolutions. In order to evaluate the newly adopted technique, we assessed the classification accuracy achieved in the cases of distinguishing HCC from the cirrhotic parenchyma on which it had evolved, respectively when differentiating HCC from the hemangioma benign liver tumor. We compared the accuracy of CNN with our previous results, based on texture analysis methods and it resulted that CNN yielded better recognition rates than the classical texture analysis techniques, respectively comparable with those provided by the advanced texture analysis methods. However, further improvements will be necessary, which we mention within the last section of this article.	187.9906770894837
255.	We present a deep learning-based method for removing makeup effects (de-makeup) in a face image. This problem poses a major challenge due to obscuring of the underlying facial features by cosmetics, which is very important in multimedia applications in the field of security, entertainment, and social networking. To address this task, we propose the bidirectional tunable de-makeup network (BTD-Net), which jointly learns the makeup process to aid in learning the de-makeup process. For tractable learning of the makeup process, which is a one-to-many mapping determined by the cosmetics that are applied, we introduce a latent variable that reflects the makeup style. This latent variable is extracted in the de-makeup process and used as a condition on the makeup process to constrain the one-to-many mapping to a specific solution. Through extensive experiments, our proposed BTD-Net is found to surpass the state-of-art techniques in estimating realistic non-makeup faces that correspond to the input makeup images. We additionally show that applications such as tuning the amount of makeup can be enhanced through the use of this method.	187.9906593758903
256.	Fault diagnosis of rotating machinery is vital to improve the security and reliability as well as avoid serious accidents. For instance, robust fault features are crucial to achieve a high diagnosis precision. However, traditional feature extraction methods rely on an abundant amount of expertise and human interference. As a breakthrough in fault diagnosis, deep learning holds the potential to automatically extract discriminative features without much prior knowledge and human interference. However, only a few deep learning models are designed to deal with noise and extract robust features. Contractive autoencoder (CAE) is a potential tool to grasp the internal factors and directly obtain the hidden robust features by penalizing the Frobenius norm of the Jacobian matrix of the hidden features with respect to the inputs. Thus, this paper proposes a method based on stacked CAE for automatic robust features extraction and fault diagnosis of rotating machinery. Gearbox and bearing fault diagnosis experiments are conducted, and the testing accuracy of the proposed method is approximately 100% for both two cases and higher than that of other methods, which fully validates the effectiveness and superiority of the proposed method. In addition, experiments and correlation analysis under different signal-to-noise ratios (SNRs) are conducted. Results show that the diagnosis accuracies of the proposed method are higher than those of the stacked autoencoder (AE) network under each SNR, especially when under 0 dB, the testing accuracies of the proposed method are 4.14% and 5.88% higher than those of the stacked AE network in two case studies, and the correlation coefficients of the CAE are higher than those of the AE, which demonstrate the capability of CAE in mining more robust features compared to the regular AE automatically and the superiority of the proposed method in fault diagnosis.	187.9906477309795
257.	In-air signature is a new modality which is essential for user authentication and access control in noncontact mode and has been actively studied in recent years. However, it has been treated as a conventional online signature, which is essentially a 2D spatial representation. Notably, this modality bears a lot more potential due to an important hidden depth feature. Existing methods for in-air signature verification neither capture this unique depth feature explicitly nor fully explore its potential in verification. Moreover, these methods are based on heuristic approaches for fingertip or hand palm center detection, which are not feasible in practice. Inspired by the great progress in deep-learning-based hand pose estimation, we propose a real-time in-air signature acquisition method which estimates hand joint positions in 3D using a single depth image. The predicted 3D position of fingertip is recorded for each frame. We present four different implementations of a verification module, which are based on the extracted depth and spatial features. An ablation study was performed to explore the impact of the depth feature in particular. For matching, we employed the most commonly used multidimensional dynamic time warping (MD-DTW) algorithm. We created a new database which contains 600 signatures recorded from 15 different subjects. Extensive evaluations were performed on our database. Our method, called 3DAirSig, achieved an equal error rate (EER) of 0.46%. Experiments showed that depth itself is an important feature, which is sufficient for in-air signature verification.	187.9905722968955
258.	Technological progress in medicine is constantly garnering pace, requiring that physicians constantly update their knowledge. The new wave of technologies breaking through into clinical practice includes the following: a) mHealth, which allows constant monitoring of biological parameters, anytime, anyplace, of hundreds of patients at the same time; b) artificial intelligence, which, powered by new deep learning techniques, are starting to beat human experts at their own game: diagnosis by imaging or electrocardiography; c) 3-dimensional printing, which may lead to patient-specific prostheses; d) systems medicine, which has arisen from big data, and which will open the way to personalized medicine by bringing together genetic, epigenetic, environmental, clinical and social data into complex integral mathematical models to design highly personalized therapies. This state-of-the-art review aims to summarize in a single document the most recent and most important technological trends that are being applied to cardiology, and to provide and overall view that will allow readers to discern at a glance the direction of cardiology in the next few years.	187.99047791709782
259.	Micro-expression recognition (MER) is a growing field of research which is currently in its early stage of development. Unlike conventional macro-expressions, micro-expressions occur at a very short duration and are elicited in a spontaneous manner from emotional stimuli. While existing methods for solving MER are largely non-deep-learning-based methods, deep convolutional neural network (CNN) has shown to work very well on such as face recognition, facial expression recognition, and action recognition. In this article, we propose applying the 3D flow-based CNNs model for video-based micro-expression recognition, which extracts deeply learned features that are able to characterize fine motion flow arising from minute facial movements. Results from comprehensive experiments on three benchmark datasets-SMIC, CASME/CASME II, showed a marked improvement over state-of-the-art methods, hence proving the effectiveness of our fairly easy CNN model as the deep learning benchmark for facial MER.	187.99017126114154
260.	Super-resolution of facial images, a.k.a. face hallucination, has been intensively studied in the past decades due to the increasingly emerging analysis demands in video surveillance, e.g., face detection, verification, identification. However, the actual performance of most previous hallucination approaches will drop dramatically when a very low-res tiny face is provided, due to the challenging multimodality of the problem as well as lack of an informative prior as a strong semantic guidance. Inspired by the latest progress in deep unsupervised learning, this paper focuses on tiny faces of size 16 x 16 pixels, hallucinating them to their 8 x upsampling versions by exploring the potentials of Wasserstein generative adversarial networks (WGAN). Besides a pixel-wise L2 regularization term imposed to the generative model, it is found that our advocated autoencoding generator with both residual and skip connections is a critical component for WGAN representing the facial contour and semantic content to a reasonable precision. With the additional Lipschitz penalty and architectural considerations for the critic in WGAN, the proposed approach finally achieves state-of-the-art hallucination performance in terms of both visual perception and objective assessment. The cropped CelebA face dataset is primarily used to aid the tuning and analysis of the new method, termed as tfh-WGAN. Experimental results demonstrate that the proposed approach not only achieves realistic hallucination of tiny faces, but also adapts to pose, expression, illuminance and occluded variations to a great degree. (C) 2019 Elsevier B.V. All rights reserved.	187.99012571864367
261.	The quality of an image affects the performance of computer vision applications. The presence of haze often greatly depreciates the visual effect of images. It is a traditional and critical vision challenge to remove haze from a single image. This paper proposes a trainable end-to-end de-hazing connectionist model with a special design. First, feature learning is conducted using hierarchical convolutional layers with nested structures. Cascaded haze-relevant tasks are then sequentially performed via a physics-driven sub-network. In particular, to break the assumption of a homogeneous atmosphere, a branch of the sub-network estimates the scattering factor in the form of a two-dimensional tensor. Finally, a chromatic adaptation layer is proposed for color adjustment, which is often neglected in existing de-hazing methods. In addition, we integrate different training criteria based on the characteristics of the haze-relevant variables in our model. For a fully actionable optimization, an asynchronous learning paradigm is designed for the fusion of different de-hazing tasks, and the joint model is further facilitated by a cyclic restoration. The effectiveness of the proposed de-hazing model was verified via extensive experiments, and most results of our method are remarkable. (C) 2020 Elsevier Inc. All rights reserved.	187.99010625305172
262.	Also after many years of research, stereo matching remains to be a challenging task in photogrammetry and computer vision. Recent work has achieved great progress by formulating dense stereo matching as a pixel-wise learning task to be resolved with a deep convolutional neural network (CNN). However, most estimation methods, including traditional and deep learning approaches, still have difficulty to handle real-world challenging scenarios, especially those including large depth discontinuity and low texture areas. To tackle these problems, we investigate a recently proposed end-to-end disparity learning network, DispNet (Mayer et al., 2015), and improve it to yield better results in these problematic areas. The improvements consist of three major contributions. First, we use dilated convolutions to develop a context pyramidal feature extraction module. A dilated convolution expands the receptive field of view when extracting features, and aggregates more contextual information, which allows our network to be more robust in weakly textured areas. Second, we construct the matching cost volume with patch-based correlation to handle larger disparities. We also modify the basic encoder-decoder module to regress detailed disparity images with full resolution. Third, instead of using post-processing steps to impose smoothness in the presence of depth discontinuities, we incorporate disparity gradient information as a gradient regularizer into the loss function to preserve local structure details in large depth discontinuity areas. We evaluate our model in terms of end-point-error on several challenging stereo datasets including Scene Flow, Sintel and KITTI. Experimental results demonstrate that our model decreases the estimation error compared with DispNet on most datasets (e.g. we obtain an improvement of 46% on Sintel) and estimates better structure-preserving disparity maps. Moreover, our proposal also achieves competitive performance compared to other methods.	187.9900047514078
263.	Transfer learning has achieved a lot of success in deep neural networks to reuse useful knowledge from source domains. However, most of the existing transfer learning strategies on neural networks are for classification tasks or based on simple training strategies, which have limited use in multi-source knowledge regression due to the ineffectiveness of learning common latent features and source information loss in regression. In this paper, we propose transferable Recurrent Neural Network (RNN) units on the Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) to adapt source knowledge in multi-source regression scenarios. Specifically, two knowledge adaptation methods are proposed, the first one utilizes similarity weights as the transfer coefficients of each source, and the other defines a transfer-gate to control the flow of source knowledge. By using the proposed methods, useful source knowledge embedded in both internal state and output is adapted. Extensive experiments on both synthetic data and human motion prediction tasks on the Human 3.6M dataset demonstrate the superiority of our transfer RNN units compared with conventional models. (C) 2019 Elsevier Ltd. All rights reserved.	187.98980817749884
264.	Condition-Based Maintenance (CBM) planning for multi-component systems has been receiving increasing attention in recent years. Most existing research on CBM assumes that preventive maintenances should be conducted when the degradations of system components reach specific threshold levels upon inspection. However, the search of optimal maintenance threshold levels is often efficient for low-dimensional CBM but becomes challenging if the number of components gets large, especially when those components are subject to complex dependencies. To overcome the challenge, in this paper we propose a novel and flexible CBM model based on a customized deep reinforcement learning for multi-component systems with dependent competing risks. Both stochastic and economic dependencies among the components are considered. Specifically, different from the threshold-based decision making paradigm used in traditional CBM, the proposed model directly maps the multi-component degradation measurements at each inspection epoch to the maintenance decision space with a cost minimization objective, and the leverage of deep reinforcement learning enables high computational efficiencies and thus makes the proposed model suitable for both low and high dimensional CBM. Various numerical studies are conducted for model validations.	187.98958967287265
265.	The co-existence of various kinds of devices, protocols, architectures, and applications make Internet of Things (IoT) systems complex to develop, even for experienced programmers. When novice programmers are learning to implement these systems, they are required to deal with areas in which they do not have a deep knowledge. Furthermore, besides becoming proficient in these areas separately, they should integrate them and build a system whose components are heterogeneous from both software and hardware perspectives. The accurate understanding of the most challenging issues that novices face is fundamental to envision strategies aimed at easing the development of IoT systems. This paper focuses on identifying such issues in terms of software development tasks that novice programmers encounter when working on IoT systems. To this end, a survey was conducted among 40 novice developers that worked in groups developing IoT systems during several years of a university course. Based on their own experiences, individually and as a group, the most challenging development tasks were identified and prioritized over a common architecture, in terms of difficulty level and efforts. In addition, qualitative data about the causes of these issues was collected and analyzed. Finally, the paper offers critical insights and points out possible future work. (C) 2019 Elsevier Inc. All rights reserved.	187.9895337105102
266.	Recently, the activities of elder people are monitored to support them live independently and safely, where the embedded hardware systems such as wearable devices are widely used. It is a research challenge to deploy deep learning algorithms on embedded devices to recognize the human activities, with the hardware constraints of limited computing resources and low power consumption. In this paper, human body posture recognition methods are proposed for the wearable embedded systems, where back propagation neural network (BPNN) and binary neural network (BNN) are employed to classify the human body postures. The BNN quantizes the synaptic weights and activation values to +1 or -1 based on the BPNN, and is able to achieve a good trade-off between the performance and cost for the embedded systems. In the experiments, the proposed methods are deployed on embedded device of Raspberry Pi 3 for real application of body postures recognition. Results show that compared with BPNN, the BNN can achieve a better trade-off between classification accuracy and cost including required computing resource, power consumption and processing time, e.g. it uses 85.29% less memory, 8.86% less power consumption, and has 5.19% faster classification speed. Therefore, the BNN is more suitable for deployment to resource constrained embedded hardware devices, which is of great significance for the application of human body posture recognition using wearable devices.	187.9895329670016
267.	This research considers how a fictional allegory can be employed to examine issues of acculturation, displacement and identity transition [Addis and Tippett, 2008]. Using the story of a refugee family, my PhD research by artistic practice explores the implications of reconstructing an identity inside the body of a new culture. The animated short film, Stella, being developed as the final artefact, is designed to serve as a provocative vehicle for considering the social implications of identity loss and transition. Methodologically, the project employs a heuristic inquiry to increase the chances of discovery in a process that is intuitively negotiated [Ings, 2011]. In processing the inquiry, I shape the work and I am shaped by unexpected discoveries. Inside this dynamic, I generate a narrative embodiment of theory. This relationship may result in elevating both the self (the writer/director/animator) and the body of knowledge, though the making process [Moustakas, 1990] Beyond its contribution to understanding processes and implications of acculturation, displacement, and identity transition, the project technological significance lies in its propensity to extend the application and demonstrate the potential of deep learning algorithms, performance capture using motion capture technology, and utilising 3d laser scanning and photogrammetry in digital human development.	187.9895222527047
268.	Heterogeneous Face Recognition (HFR) is a task that matches faces across two different domains such as visible light (VIS), near-infrared (NIR), or the sketch domain. Due to the lack of databases, HFR methods usually exploit the pre-trained features on a large-scale visual database that contain general facial information. However, these pre-trained features cause performance degradation due to the texture discrepancy with the visual domain. With this motivation, we propose a graph-structured module called Relational Graph Module (RGM) that extracts global relational information in addition to general facial features. Because each identity's relational information between intra-facial parts is similar in any modality, the modeling relationship between features can help cross-domain matching. Through the RGM, relation propagation diminishes texture dependency without losing its advantages from the pre-trained features. Furthermore, the RGM captures global facial geometrics from locally correlated convolutional features to identify long-range relationships. In addition, we propose a Node Attention Unit (NAU) that performs node-wise recalibration to concentrate on the more informative nodes arising from relation-based propagation. Furthermore, we suggest a novel conditional-margin loss function (C-softmax) for the efficient projection learning of the embedding vector in HFR. The proposed method outperforms other state-of-the-art methods on five HFR databases. Furthermore, we demonstrate performance improvement on three backbones because our module can be plugged into any pre-trained face recognition backbone to overcome the limitations of a small HFR database.	187.98936925983082
269.	Deep learning methods, especially the RNN based approaches, have been applied to the industrial time-series modeling these years successfully. However, the RNN based methods cannot overcome the enormous amount of iterative calculation. Traditional CNN based methods can calculate much faster; however, the CNN based methods lack in the explanation of the variables. In this paper, we proposed a novel adapted receptive field temporal convolution networks integrating regularly updated multi-region operations based on principal component analysis (PIMRO-ARFTCN). First, the principal component analysis (PCA) method is used to select the most concerned variables. Then, the Levenshtein distance based hierarchical clustering method is used to extract the multi-region operating features in the variables, and the related variables are used as additional input samples. The adapted receptive field decides the primary input samples. Last, the temporal convolution network structure is used to obtain the final results, and the multi-region operations can be regularly updated with various working situations. The proposed regularly updated PIMRO-ARFTCN method can not only take the most useful human experience into consideration but also combine the advantages of both RNN and CNN. The causal relationship between variables and the calculation speed are both considered. The prediction error of the proposed method is 0.1979, and the remaining errors of the other techniques, the MRO-ARFTCN method, the LSTM method, and the traditional RNN method, are 0.2464, 0.2829, and 0.4168, respectively. Compared with other means, the proposed method shows better prediction performance in time-series modeling. (C) 2020 Elsevier Ltd. All rights reserved.	187.98925013343558
270.	Deep Neural Networks (DNNs) have achieved extraordinary success in numerous areas. However, DNNs often carry a large number of weight parameters, leading to the challenge of heavy memory and computation costs. Overfitting is another challenge for DNNs when the training data are insufficient. These challenges severely hinder the application of DNNs in resource-constrained platforms. In fact, many network weights are redundant and can be removed from the network without much loss of performance. In this paper, we introduce a new non-convex integrated transformed l(1) regularizer to promote sparsity for DNNs, which removes redundant connections and unnecessary neurons simultaneously. Specifically, we apply the transformed l(1) regularizer to the matrix space of network weights and utilize it to remove redundant connections. Besides, group sparsity is integrated to remove unnecessary neurons. An efficient stochastic proximal gradient algorithm is presented to solve the new model. To the best of our knowledge, this is the first work to develop a non-convex regularizer in sparse optimization based method to simultaneously promote connection-level and neuron-level sparsity for DNNs. Experiments on public datasets demonstrate the effectiveness of the proposed method. (C) 2019 Elsevier Ltd. All rights reserved.	187.9892294668473
271.	Deep reinforcement learning (DRL) has recently revolutionized the resolution of decision-making and automated control problems. In the context of networking, there is a growing trend in the research community to apply DRL algorithms to optimization problems such as routing. However, existing proposals fail to achieve good results, often under-performing traditional routing techniques. We argue that the reason behind this poor performance is that they use straightforward representations of networks. In this paper, we propose a DRL-based solution for routing in optical transport networks (OTNs). Contrary to previous works, we propose a more elaborate representation of the network state that reduces the level of knowledge abstraction required for DRL agents and easily captures the singularities of network topologies. Our evaluation results show that using our novel representation, DRL agents achieve better performance and learn how to route traffic in OTNs significantly faster compared to state-of-the-art representations. Additionally, we reverse engineered the routing strategy learned by our DRL agent, and as a result, we found a routing algorithm that outperforms well-known traditional routing heuristics. (C) 2019 Optical Society of America.	187.98922602813118
272.	Affective interaction in tutoring environments has been of great interest among several researchers in this community, which has spurred the development of various systems to capture learners' emotional states. Young children are one of the biggest learner groups in digital learning environments, but these studies have rarely targeted them. Our current study leverages computer vision and deep learning to analyze young childrens' learning-related affective states. We developed an effective recognition system to compute the probability for a child to present neutral or positive affective state. Our results showed that the prototype was able to achieve an average affective state prediction accuracy of 93.05%.	187.9892242195769
273.	This paper describes Team Delft's robot winning the Amazon Robotics Challenge 2016. The competition involves automating pick and place operations in semistructured environments, specifically the shelves in an Amazon warehouse. Team Delft's entry demonstrated that the current robot technology can already address most of the challenges in product handling: object recognition, grasping, motion, or task planning; under broad yet bounded conditions. The system combines an industrial robot arm, 3-D cameras and a custom gripper. The robot's software is based on the robot operating system to implement solutions based on deep learning and other state-of-the-art artificial intelligence techniques, and to integrate them with off-the-shelf components. From the experience developing the robotic system, it was concluded that: 1) the specific task conditions should guide the selection of the solution for each capability required; 2) understanding the characteristics of the individual solutions and the assumptions they embed is critical to integrate a performing system from them; and 3) this characterization can be based on "levels of robot automation." This paper proposes automation levels based on the usage of information at design or runtime to drive the robot's behavior, and uses them to discuss Team Delft's design solution and the lessons learned from this robot development experience.	187.98919375463504
274.	Detecting objects and estimating their pose remains as one of the major challenges of the computer vision research community. There exists a compromise between localizing the objects and estimating their viewpoints. The detector ideally needs to be view-invariant, while the pose estimation process should be able to generalize towards the category-level. This work is an exploration of using deep learning models for solving both problems simultaneously. For doing so, we propose three novel deep learning architectures, which are able to perform a joint detection and pose estimation, where we gradually decouple the two tasks. We also investigate whether the pose estimation problem should be solved as a classification or regression problem, being this still an open question in the computer vision community. We detail a comparative analysis of all our solutions and the methods that currently define the state of the art for this problem. We use PASCAL3D+ and ObjectNet3D datasets to present the thorough experimental evaluation and main results. With the proposed models we achieve the state-of-the-art performance in both datasets. (C) 2018 Elsevier B.V. All rights reserved.	187.9891777072677
275.	Long Short Term Memory (LSTM) networks are a class of recurrent neural networks that are widely used for machine learning tasks involving sequences, including machine translation, text generation, and speech recognition. Large-scale LSTMs, which are deployed in many real-world applications, are highly compute intensive. To address this challenge, we propose AxLSTM, an application of approximate computing to improve the execution efficiency of LSTMs. An LSTM is composed of cells, each of which contains a cell state along with multiple gating units that control the addition and removal of information from the state. The LSTM execution proceeds in timesteps, with a new symbol of the input sequence processed at each timestep. AxLSTM consists of two techniques-Dynamic Timestep Skipping (DTS) and Dynamic State Reduction (DSR). DTS identifies, at runtime, input symbols that are likely to have little or no impact on the cell state and skips evaluating the corresponding timesteps. In contrast, DSR reduces the size of the cell state in accordance with the complexity of the input sequence, leading to a reduced number of computations per timestep. We describe how AxLSTM can be applied to the most common application of LSTMs, viz., sequence-to-sequence learning. We implement AxLSTM within the TensorFlow deep learning framework and evaluate it on 3 state-of-the-art sequence-to-sequence models. On a 2.7 GHz Intel Xeon server with 128 GB memory and 32 processor cores, AxLSTM achieves 1.08 x -1.31x speedups with minimal loss in quality, and 1.12 x -1.37x speedups when moderate reductions in quality are acceptable.	187.98911015369754
276.	In online health expert question-answering (HQA) services, it is significant to automatically determine the quality of the answers. There are two prominent challenges in this task. First, the answers are usually written in short text, which makes it difficult to absorb the text semantic information. Second, it usually lacks sufficient labeled data but contains a huge amount of unlabeled data. To tackle these challenges, we propose a novel deep co-training framework based on factorization machines (FM) and deep textual views to intelligently and automatically identify the quality of HQA systems. More specifically, we exploit additional domain-specific semantic information from domain-specific word embeddings to expand the semantic space of short text and apply FM to excavate the non-independent interaction relationships among diverse features within individual views for improving the performance of the base classifier via co-training. Our learned deep textual views, the convolutional neural networks (CNN) view which focuses on extracting local features using convolution filters to locally model short text and the dependency-sensitive convolutional neural networks (DSCNN) view which focuses on capturing long-distance dependency information within the text to globally model short text, can then overcome the challenge of feature sparseness in the short text answers from the doctors. The developed co-training framework can effectively mine the highly non-linear semantic information embedded in the unlabeled data and expose the highly non-linear relationships between different views, which minimizes the labeling effort. Finally, we conduct extensive empirical evaluations and demonstrate that our proposed method can significantly improve the predictive performance of the answer quality in the context of HQA services.	187.98910608067408
277.	Recently, snake-like robots are proposed to assist experts during medical procedures on internal organs via natural orifices. Despite their well-spelt advantages, applications in radiosurgery is still hindered by absence of suitable designs required for spatial navigations within clustered and confined parts of human body, and inexistence of precise and fast inverse kinematics (IK) models. In this study, a deeply-learnt damped least squares method is proposed for solving IK of spatial snake-like robot. The robot's model consists of several modules, and each module has a pair of serial-links connected with orthogonal twists. For precise control of the robot's end-effector, damped least-squares approach is used to minimize error magnitude in a function modeled over analytical Jacobian of the robot. This is iteratively done until an apt joint vector needed to converge the robot to desired positions is obtained. For fast control and singularity avoidance, a deep network is built for prediction of unique damping factor required for each target point in the robot's workspace. The deep network consists of 11 x 15 array of neurons at the hidden layer, and deeply-learnt with a huge dataset of 877,500 data points generated from workspace of the snake robot. Implementation results for both simulated and actual prototype of an eight-link model of the robot show the effectiveness of the proposed IK method. With error tolerance of 0.01 mm, the proposed method has a very high reachability measure of 91.59% and faster mean execution time of 9.20 (+/- 16.92) ms for convergence. In addition, the method requires an average of 33.02 (+/- 39.60) iterations to solve the IK problem. Hence, approximately 3.6 iterations can be executed in 1 ms. Evaluation against popularly used IK methods shows that the proposed method has very good performance in terms of accuracy and speed, simultaneously. (C) 2018 Elsevier Ltd. All rights reserved.	187.98908236794307
278.	Relation extraction between medical concepts from electronic medical records has pervasive applications as well as significance. However, previous researches utilizing machine learning algorithms judge the semantic types of medical concept pair mentions independently. In fact, different concept pair mentions in the same context are of dependencies which can provide beneficial evidences for identifying their relation types. To the best of our knowledge, only one study has considered such dependencies in discharge summaries. However, its hard constraints are not applied effectively to the History of Present Illness (HPI) in electronic Medical Records. According to the writing characteristics of HPI records, we generalize two regularities of dependencies among concept pairs mentioned in an HPI record to enhance the performance of relation extraction. We incorporate the two soft constraints corresponding to the regularities and the posterior probabilities returned by a local classifier into a joint inference process which applies Integer Quadratic Programming method to carry out collective classification for all concept pair mentions in an HPI record. We implement four local classification models including support vector machine, logistics regression, random forest and piecewise convolutional neural networks to examine the performance of our approach. A series of experimental results demonstrate that our collective classification method has made a principal improvement and outperforms the other state-of-the-art methods.	187.98898109011648
279.	Object detection models based on convolutional neural networks (CNN) have achieved state-of-the-art performance by heavily rely on large-scale training samples. They are insufficient when used in specific applications, such as the detection of military objects, as in these instances, a large number of samples is hard to obtain. In order to solve this problem, this paper proposes the use of Gabor-CNN for object detection based on a small number of samples. First of all, a feature extraction convolution kernel library composed of multi-shape Gabor and color Gabor is constructed, and the optimal Gabor convolution kernel group is obtained by means of training and screening, which is convolved with the input image to obtain feature information of objects with strong auxiliary function. Then, the k-means clustering algorithm is adopted to construct several different sizes of anchor boxes, which improves the quality of the regional proposals. We call this regional proposal process the Gabor-assisted Region Proposal Network (Gabor-assisted RPN). Finally, the Deeply-Utilized Feature Pyramid Network (DU-FPN) method is proposed to strengthen the feature expression of objects in the image. A bottom-up and a top-down feature pyramid is constructed in ResNet-50 and feature information of objects is deeply utilized through the transverse connection and integration of features at various scales. Experimental results show that the method proposed in this paper achieves better results than the state-of-art contrast models on data sets with small samples in terms of accuracy and recall rate, and thus has a strong application prospect. Copyright (C) 2020 China Ordnance Society. Publishing Services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd.	187.9889307948492
280.	Person re-identification (person re-ID) is one of the most challenging tasks in the field of computer vision as it involves large variations in human appearances, human poses, background illuminations, camera views, etc. In recent literature, using part-level features for the person re-ID task provides fine-grained information, and has been proven to be effective. Instead of relying on additional skeleton key points or pose estimation models, this paper proposes a Divide-and-Unite Network to obtain feature embedding end-to-end. We design a deep network guided by image contents, which divides pedestrians into parts and obtains the part features with different contributions. These part features and the global feature are united to obtain the pedestrian descriptor for person re-ID. To summarize, the contributions of this work are two-fold. Firstly, a novel architecture of discriminative descriptor learning is proposed, which is based on the global feature and supplemented by part features. Secondly, a Feature Division Network is constructed to generate the part features with different contributions, where the divided parts maintain the consistency of content between different images. Extensive experiments are conducted on three widely-used benchmarks including Market1501, CUHK03, and DukeMTMC-reID. The results have demonstrated that the proposed model can achieve remarkable performance against numerous state-of-the-arts.	187.98891582622673
281.	Current state-of-the-art methods for semantic segmentation use deep neural networks to learn the segmentation mask from the input image signal as an image-to-image mapping. While these methods effectively exploit global image context, the learning and computational complexities are high. We propose shared memory augmented neural network actors as a dynamically scalable alternative. Based on a decomposition of the image into a sequence of local patches, we train such actors to sequentially segment each patch. To further increase the robustness and better capture shape priors, an external memory module is shared between different actors, providing an implicit mechanism for image information exchange. Finally, the patch-wise predictions are aggregated to a complete segmentation mask. We demonstrate the benefits of the new paradigm on a challenging lung segmentation problem based on X-Ray images, as well as on two synthetic tasks based on MNIST. On the X-Ray data, our method achieves state-of-the-art accuracy with a significantly reduced model size, 3-5 times compared to reference methods. In addition, we reduce the number of failure cases by at least half.	187.98886167754978
282.	Discovering imaging biomarkers for autism spectrum disorder (ASD) is critical to help explain ASD and predict or monitor treatment outcomes. Toward this end, deep learning classifiers have recently been used for identifying ASD from functional magnetic resonance imaging (fMRI) with higher accuracy than traditional learning strategies. However, a key challenge with deep learning models is understanding just what image features the network is using, which can in turn be used to define the biomarkers. Current methods extract biomarkers, i.e., important features, by looking at how the prediction changes if "ignoring" one feature at a time. However, this can lead to serious errors if the features are conditionally dependent. In this work, we go beyond looking at only individual features by using Shapley value explanation (SVE) from cooperative game theory. Cooperative game theory is advantageous here because it directly considers the interaction between features and can be applied to any machine learning method, making it a novel, more accurate way of determining instance-wise biomarker importance from deep learning models. A barrier to using SVE is its computational complexity: 2N given N features. We explicitly reduce the complexity of SVE computation by two approaches based on the underlying graph structure of the input data: (1) only consider the centralized coalition of each feature; (2) a hierarchical pipeline which first clusters features into small communities, then applies SVE in each community. Monte Carlo approximation can be used for large permutation sets. We first validate our methods on the MNIST dataset and compare to human perception. Next, to insure plausibility of our biomarker results, we train a Random Forest (RF) to classify ASD/control subjects from fMRI and compare SVE results to standard RF-based feature importance. Finally, we show initial results on ranked fMRI biomarkers using SVE on a deep learning classifier for the ASD/control dataset.	187.988668839393
283.	Background and objective: Cancer has become a complex health problem due to its high mortality. Over the past few decades, with the rapid development of the high-throughput sequencing technology and the application of various machine learning methods, remarkable progress in cancer research has been made based on gene expression data. At the same time, a growing amount of high-dimensional data has been generated, such as RNA-seq data, which calls for superior machine learning methods able to deal with mass data effectively in order to make accurate treatment decision. Methods: In this paper, we present a semi-supervised deep learning strategy, the stacked sparse auto-encoder (SSAE) based classification, for cancer prediction using RNA-seq data. The proposed SSAE based method employs the greedy layer-wise pre-training and a sparsity penalty term to help capture and extract important information from the high-dimensional data and then classify the samples. Results: We tested the proposed SSAE model on three public RNA-seq data sets of three types of cancers and compared the prediction performance with several commonly-used classification methods. The results indicate that our approach outperforms the other methods for all the three cancer data sets in various metrics. Conclusions: The proposed SSAE based semi-supervised deep learning model shows its promising ability to process high-dimensional gene expression data and is proved to be effective and accurate for cancer prediction. (C) 2018 Elsevier B.V. All rights reserved.	187.98862628185447
284.	Web search engines play a significant role in many applications in our everyday lives. Among them, online shopping is one major technological advancement which has made our life easier and comfortable. Currently, most e-commerce websites support either text-based or voice-based search. The problem with text and voice-based approaches is that they need an appropriate item name or description for the search results to be accurate. Also, with the huge variety of items available online, it is not easy to find the desired object in the top results. Lately, some top e-commerce websites started supporting visual search, where the user can submit an image of an item they'd like to find. However, this domain is still in its infancy. In this work, we propose ViSeR, a visual search engine architecture using deep learning and machine learning techniques, with a proof-of-concept implementation focusing on the fashion eretail industry. ViSeR first classifies the query image to the right category using image classification. Then all the images in that category are ranked based on their similarity and the top images are retrieved as recommendations. We present in detail the experimental results with different deep and machine learning algorithms and provide additional details with regards to deploying this model to achieve high accuracy and low latency (in terms of training and recommendation time).	187.9885925216979
285.	Deep neural networks have seen tremendous success for different modalities of data including images, videos, and speech. This success has led to their deployment in mobile and embedded systems for real-time applications. However, making repeated inferences using deep networks on embedded systems poses significant challenges due to constrained resources (e.g., energy and computing power). To address these challenges, we develop a principled co-design approach. Building on prior work, we develop a formalism referred as coarse-to-fine networks (C2F Nets) that allow us to employ classifiers of varying complexity to make predictions. We propose a principled optimization algorithm to automatically configure C2F Nets for a specified tradeoff between accuracy and energy consumption for inference. The key idea is to select a classifier on-the-fly whose complexity is proportional to the hardness of the input example: simple classifiers for easy inputs and complex classifiers for hard inputs. We perform comprehensive experimental evaluation using four different C2F Net architectures on multiple real-world image classification tasks. Our results show that optimized C2F Net can reduce the energy delay product by 27% to 60% with no loss in accuracy when compared to the baseline solution, where all predictions are made using the most complex classifier in C2F Net.	187.98854264626408
286.	Convolutional neural networks have recently demonstrated high-quality reconstruction for single image super-resolution. However, existing methods often require a large number of network parameters and entail heavy computational loads at runtime for generating high-accuracy super-resolution results. In this paper, we propose the deep Laplacian Pyramid Super-Resolution Network for fast and accurate image super-resolution. The proposed network progressively reconstructs the sub-band residuals of high-resolution images at multiple pyramid levels. In contrast to existing methods that involve the bicubic interpolation for pre-processing (which results in large feature maps), the proposed method directly extracts features from the low-resolution input space and thereby entails low computational loads. We train the proposed network with deep supervision using the robust Charbonnier loss functions and achieve high-quality image reconstruction. Furthermore, we utilize the recursive layers to share parameters across as well as within pyramid levels, and thus drastically reduce the number of parameters. Extensive quantitative and qualitative evaluations on benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art methods in terms of run-time and image quality.	187.98854216522616
287.	Image super-resolution (SR) techniques with deep convolutional network (CNN) have achieved significant improvements compared to previous shallow-learning-based methods. Especially for dense connection based networks, these methods have yielded unprecedented achievements but bring the higher complexity and more parameters. To this end, this paper considers both reconstruction performance and efficiency, and advocates a novel hierarchical dense connection network (HDN) for image SR. First of all, we construct a hierarchical dense residual block (HDB) to promote the feature representation while saving the memory footprint with a hierarchical matrix structure design. In this way, it can provide additional interleaved pathways for information fusion and gradient optimization but with a shallower depth compare to the previous networks. In particular, a group of convolutional layers with small size (1 x 1) are embedded in HDB, releasing the computational burden and parameters by rescaling the feature dimensions. Furthermore, HDBs are connected to each other in a sharing manner, thereby allowing the network to fuse the features in different stages. At the final, the multi-scale features from these HDBs are integrated into global fusion module (GFM) for a global fusion and representation, and then the final profile-enriched residual map is obtained by realigning and sub-pixel upsampling the fusion maps. Extensive experimental results on benchmark datasets and really degraded images show that our model outperforms the state-of-the-art methods in terms of quantitative indicators and realistic visual effects, as well as enjoys a fast and accurate reconstruction. (C) 2020 Elsevier Ltd. All rights reserved.	187.98851249031978
288.	High resolution remote sensing (HRRS) image scene classification plays a crucial role in a wide range of applications and has been receiving significant attention. Recently, remarkable efforts have been made to develop a variety of approaches for HRRS scene classification, wherein deep-learning-based methods have achieved considerable performance in comparison with state-of-the-art methods. However, the deep-learning-based methods have faced a severe limitation that a great number of manually annotated HRRS samples are needed to obtain a reliable model. However, there are still not sufficient annotation datasets in the field of remote sensing. In addition, it is a challenge to get a large scale HRRS image dataset due to the abundant diversities and variations in HRRS images. In order to address the problem, we propose a semi-supervised generative framework (SSGF), which combines the deep learning features, a self-label technique, and a discriminative evaluation method to complete the task of scene classification and annotating datasets. On this basis, we further develop an extended algorithm (SSGA-E) and evaluate it by exclusive experiments. The experimental results show that the SSGA-E outperforms most of the fully-supervised methods and semi-supervised methods. It has achieved the third best accuracy on the UCM dataset, the second best accuracy on the WHU-RS, the NWPU-RESISC45, and the AID datasets. The impressive results demonstrate that the proposed SSGF and the extended method is effective to solve the problem of lacking an annotated HRRS dataset, which can learn valuable information from unlabeled samples to improve classification ability and obtain a reliable annotation dataset for supervised learning. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	187.9884930100008
289.	For chemical industry, safety is always primary. A safe and reliable systems are required to ensure the safety of chemical plants. Many data-driven process monitoring methods have been developed and successfully applied to various processes. Autoenocoder is an unsupervised learning algorithm, which can extract the features automatically from the unlabelled data. However, one limitation of autoencoder is that it does not consider any temporal dependency of the data. And autoencoder can not be ensured to get various meaningful features from the raw data. In this work, we proposed Feature Points Distance Dynamic Autoencoder (FPDDAE) to capture the temporal dependency and encourage the autoencoder to get meaningful features. The FPDDAE is constructed by the recurrent neural network (RNN), RNN can capture the time dependency of the process by adding a recurrent hidden state whose activation at each time is dependent on that of the previous time. To make the data points as near as possible in feature space, we define a penalty term FPD that measures the average distance between any two points in feature space. The penalty term FPD is a constraint to encourage the FPDDAE to learn meaningful features. A simple nonlinear simulation example is used to illustrate how the proposed method works. The proposed method is applied to the Tennessee Eastman process (TEP) to demonstrate its performance.	187.98848139877958
290.	Agricultural fields are monitored for the purpose of EU subsidy eligibility checks. A precondition to make automatic monitoring of fields for this purpose possible is that the object geometric boundary is correct. This precondition can be addressed to some extent by performing image time series analysis to identify changes. Accurate object change detection in agricultural fields on satellite images requires separating object class changes such as new ditches, buildings, or roads from other changes, such as crop development, crop management practices, seasonal variation, or shadows from adjacent objects. In this paper we present an approach to identify unchanged agricultural fields using Deep Neural Networks. We propose a combination of CNNs for semantic segmentation and ConvLSTMs for change detection, applied to multi-temporal satellite image time-series of arbitrary length. The neural networks were trained on images acquired over the Netherlands in 2017 by the TripleSat and PlanetScope constellations (0.8 and 3.5m resolution respectively) with RGB and NIR bands. We introduce techniques to create artificial change training data, reducing the need for real training data. The results demonstrate that (1) a neural network is not required to be deep to achieve usable semantic segmentation performance for satellite images for this application, that (2) ConvLSTMs can to some extent compensate imperfect image alignment and pixel misclassification, that (3) longer time series significantly increase the performance of the change detection and that (4) expanding and densifying the time series with lower resolution imagery does not improve accuracy in this particular configuration.	187.9883874740911
291.	Structural damage detection has become an interdisciplinary area of interest for various engineering fields, while the available damage detection methods are being in the process of adapting machine learning concepts. Most machine learning based methods heavily depend on extracted "hand-crafted" features that are manually selected in advance by domain experts and then, fixed. Recently, deep learning has demonstrated remarkable performance on traditional challenging tasks, such as image classification, object detection, etc., due to the powerful feature learning capabilities. This breakthrough has inspired researchers to explore deep learning techniques for structural damage detection problems. However, existing methods have considered either spatial relation (e.g., using convolutional neural network (CNN)) or temporal relation (e.g., using long short term memory network (LSTM)) only. In this work, we propose a novel Hierarchical CNN and Gated recurrent unit (GRU) framework to model both spatial and temporal relations, termed as HCG, for structural damage detection. Specifically, CNN is utilized to model the spatial relations and the short-term temporal dependencies among sensors, while the output features of CNN are fed into the GRU to learn the long-term temporal dependencies jointly. Extensive experiments on IASC-ASCE structural health monitoring benchmark and scale model of three-span continuous rigid frame bridge structure datasets have shown that our proposed HCG outperforms other existing methods for structural damage detection significantly. (c) 2020 Elsevier Inc. All rights reserved.	187.98826904067928
292.	Forensic Odontology deals with identifying humans based on their dental traits because of their robust nature. Classical methods of human identification require more manual effort and are difficult to use for large number of Images. A Novel way of automating the process of human identification by using deep learning approaches is proposed in this paper. Transfer learning using AlexNet is applied in three stages: In the first stage, the features of the query tooth image are extracted and its location is identified as either in the upper or lower Jaw. In the second stage of transfer learning, the tooth is then classified into any of the four classes namely Molar, Premolar, Canine or Incisor. In the last stage, the classified tooth is then numbered according to the universal numbering system and finally the candidate identification is made by using distance as metrics. These three stage transfer learning approach proposed in this work helps in reducing the search space in the process of candidate matching. Also, instead of making the network classify all the 32 teeth into 32 different classes, this approach reduces the number of classes assigned to the classification layer in each stage thereby increasing the performance of the network. This work outperforms the classical approaches in terms of both accuracy and precision. The hit rate in human identification is also higher compared to the other state-of-art methods.	187.98824436517833
293.	The consolidation of encryption and big data in network communications have made deep packet inspection no longer feasible in large networks. Early attack detection requires feature vectors which are easy to extract, process, and analyze, allowing their generation also from encrypted traffic. So far, experts have selected features based on their intuition, previous research, or acritically assuming standards, but there is no general agreement about the features to use for attack detection in a broad scope. We compared five lightweight feature sets that have been proposed in the scientific literature for the last few years, and evaluated them with supervised machine learning. For our experiments, we use the UNSW-NB15 dataset, recently published as a new benchmark for network security. Results showed three remarkable findings: (1) Analysis based on source behavior instead of classic flow profiles is more effective for attack detection; (2) meta-studies on past research can be used to establish satisfactory benchmarks; and (3) features based on packet length are clearly determinant for capturing malicious activity. Our research showed that vectors currently used for attack detection are oversized, their accuracy and speed can be improved, and are to be adapted for dealing with encrypted traffic.	187.9881684984311
294.	Super-resolution (SR) brings an excellent opportunity to improve a wide range of different remote sensing applications. SR techniques are concerned about increasing the image resolution while providing finer spatial details than those captured by the original acquisition instrument. Therefore, SR techniques are particularly useful to cope with the increasing demand remote sensing imaging applications requiring fine spatial resolution. Even though different machine learning paradigms have been successfully applied in SR, more research is required to improve the SR process without the need of external high-resolution (HR) training examples. This paper proposes a new convolutional generator model to super-resolve low-resolution (LR) remote sensing data from an unsupervised perspective. That is, the proposed generative network is able to initially learn relationships between the LR and HR domains throughout several convolutional, downsampling, hatch normalization, and activation layers. Then, the data are symmetrically projected to the target resolution while guaranteeing a reconstruction constraint over the LR input image. An experimental comparison is conducted using 12 different unsupervised SR methods over different test images. Our experiments reveal the potential of the proposed approach to improve the resolution of remote sensing imagery.	187.98809754947095
295.	Deep learning has revolutionized medical image analysis in recent years. Nevertheless, technical, ethical and financial constraints along with confidentiality issues still limit data availability, and therefore the performance of these approaches. To overcome such limitations, data augmentation has proven crucial. Here we propose SMOD, a novel augmentation methodology based on Statistical Models of Deformations, to segment 2D cine scans in cardiac MRI. In brief, the shape variability of the training set space is modelled so new images with the appearance of the original ones but unseen shapes within the space of plausible realistic shapes are generated. SMOD is compared to standard augmentation providing quantitative improvement, especially when the training data available is very limited or the structures to segment are complex and highly variable. We finally propose a state-of-art, deep learning 2D cardiac MRI segmenter for normal and hypertrophic cardiomyopathy hearts with an epicardium and endocardium mean Dice score of 0.968 in short and long axis.	187.98806122199937
296.	This study aims to evaluate a new approach in modeling gully erosion susceptibility (GES) based on a deep learning neural network (DLNN) model and an ensemble particle swarm optimization (PSO) algorithm with DLNN (PSO-DLNN), comparing these approaches with common artificial neural network (ANN) and support vector machine (SVM) models in Shirahan watershed, Iran. For this purpose, 13 independent variables affecting GES in the study area, namely, altitude, slope, aspect, plan curvature, profile curvature, drainage density, distance from a river, land use, soil, lithology, rainfall, stream power index (SPI), and topographic wetness index (TWI), were prepared. A total of 132 gully erosion locations were identified during field visits. To implement the proposed model, the dataset was divided into the two categories of training (70%) and testing (30%). The results indicate that the area under the curve (AUC) value from receiver operating characteristic (ROC) considering the testing datasets of PSO-DLNN is 0.89, which indicates superb accuracy. The rest of the models are associated with optimal accuracy and have similar results to the PSO-DLNN model; the AUC values from ROC of DLNN, SVM, and ANN for the testing datasets are 0.87, 0.85, and 0.84, respectively. The efficiency of the proposed model in terms of prediction of GES was increased. Therefore, it can be concluded that the DLNN model and its ensemble with the PSO algorithm can be used as a novel and practical method to predict gully erosion susceptibility, which can help planners and managers to manage and reduce the risk of this phenomenon.	187.98803015787672
297.	Deep learning has shown great strength in many fields and has allowed people to live more conveniently and intelligently. However, deep learning requires a considerable amount of uniform training data, which introduces difficulties in many application scenarios. On the one hand, in real-time systems, training data are constantly generated, but users cannot immediately obtain this vast amount of training data. On the other hand, training data from heterogeneous sources have different data formats. Therefore, existing deep learning frameworks are not able to train all data together. In this paper, we propose the iFusion framework, which achieves efficient intelligence fusion for deep learning from real-time data and heterogeneous data. For real-time data, we train only newly arrived data to obtain a new discrimination model and fuse the previously trained models to obtain the discrimination result. For heterogeneous data, different types of data are trained separately; then, we fuse the different discrimination models so that it is not necessary to consider heterogeneous data formats. We use a method based on Dempster-Shafer theory (DST) to fuse the discrimination models. We apply iFusion to the deep learning of medical image data, and the results of the experiments show the effectiveness of the proposed method.	187.98793287438588
298.	Computational fluid dynamic (CFD) simulations present numerous challenges in the domain of artificial intelligence. Computational time, resources and cost that can reach disproportional size before leading a simulation to its fully converged solution are one of the central issues in this domain. In this paper, we propose a novel algorithm that finds optimal parameter settings for the numerical solvers of CFD software. Indeed, this research proposes an alternative approach; rather than going deeper in reducing the mathematical complexity, it suggests taking advantage of the history of previous runs in order to estimate the best parameters for numerical equation resolution. In fact, our approach is bio-inspired and based on a genetic algorithm (GA) and evolutionary strategies enhanced with surrogate functions based on machine-learning meta-models. Our research method was tested on 11 different use cases using various configurations of the GA and algorithms of machine learning such as regression trees extra trees regressors and random forest regressors. Our approach has achieved better runtime performance and higher convergence quality (an improvement varying between 8 and 40%) in all of the test cases when compared to a basic approach which requires manually selecting the parameters. Moreover, our approach outperforms in some cases manual selection of parameters by reaching convergent solutions that couldn't otherwise be achieved manually.	187.98790528229276
299.	We propose a fully convolutional neural-network architecture for image denoising which is simple yet powerful. Its structure allows to exploit the gradual nature of the denoising process, in which the shallow layers handle local noise statistics, while deeper layers recover edges and enhance textures. Our method advances the state of the art when trained for different noise levels and distributions (both Gaussian and Poisson). In addition, we show that making the denoiser class-aware by exploiting semantic class information boosts the performance, enhances the textures, and reduces the artifacts.	187.98785800246964
300.	Rapid identification of areas affected by changes is a challenging task in many remote sensing applications. Sentinel-1 (S1) images provided by the European Space Agency (ESA) can be used to monitor such situations due to its high temporal and spatial resolution and indifference to weather. Though a number of deep learning based methods have been proposed in the literature for change detection (CD) in multi-temporal SAR images, most of them require labeled training data. Collecting sufficient labeled multi-temporal data is not trivial, however S1 provides abundant unlabeled data. To this end, we propose a solution for CD in multi-temporal S1 images based on unsupervised training of deep neural networks (DNNs). Unlabeled single-time image patches are used to train a multilayer convolutional-autoencoder (CAE) in unsupervised fashion by minimizing the reconstruction error between the reconstructed output and the input. The trained multilayer CAE is used to extract multi-scale features from both the pre and post change images that are analyzed for CD. The multi-scale features are fused according to a detail-preserving scale-driven approach that allows us to generate change maps by preserving details. The experiments conducted on a S1 dataset from Brumadinho, Brazil confirms the effectiveness of the proposed method.	187.98785742219857
301.	Purpose A vast body of literature has documented the negative consequences of stress on employee performance and well-being. These deleterious effects are particularly pronounced for service agents who need to constantly endure and manage customer emotions. The purpose of this paper is to introduce and describe a deep learning model to predict in real-time service agent stress from emotion patterns in voice-to-voice service interactions. Design/methodology/approach A deep learning model was developed to identify emotion patterns in call center interactions based on 363 recorded service interactions, subdivided in 27,889 manually expert-labeled three-second audio snippets. In a second step, the deep learning model was deployed in a call center for a period of one month to be further trained by the data collected from 40 service agents in another 4,672 service interactions. Findings The deep learning emotion classifier reached a balanced accuracy of 68% in predicting discrete emotions in service interactions. Integrating this model in a binary classification model, it was able to predict service agent stress with a balanced accuracy of 80%. Practical implications Service managers can benefit from employing the deep learning model to continuously and unobtrusively monitor the stress level of their service agents with numerous practical applications, including real-time early warning systems for service agents, customized training and automatically linking stress to customer-related outcomes. Originality/value The present study is the first to document an artificial intelligence (AI)-based model that is able to identify emotions in natural (i.e. nonstaged) interactions. It is further a pioneer in developing a smart emotion-based stress measure for service agents. Finally, the study contributes to the literature on the role of emotions in service interactions and employee stress.	187.98777914116283
302.	Chest X-rays are among the most common modalities in medical imaging. Technical flaws of these images, such as over- or under-exposure or wrong positioning of the patients can result in suboptimal images. We propose an automatic method to detect such technical deficiencies. Images with these deficiencies could still be used in the context of a specific diagnostic process. We use a deep neural network trained on a dataset of 3487 images labeled by two experienced radiologists to detect images with technical defects. The DenseNet121 architecture is used for this classification task. The trained network has an area under the receiver operator curve (AUC) of 0.93. By removing the X-rays with technical quality issues, this technology could potentially provide significant cost savings for hospitals.	187.98775357978536
303.	In smart cities, region-based prediction (e.g. traffic flow and electricity flow) is of great importance to city management and public safety, and it remains a daunting challenge that involves complicated spatial-temporal-related factors such as weather, holidays, events, etc. Region-based forecasting aims to predict the future situation for regions in a city based on historical data. In the existing literature, the state-of-the-art method solve region-based problems with long short-term memory (LSTM) algorithms that extract the temporal view and local convolutional neural network (CNN) algorithms that extract the spatial view (local spatial correlation via local CNN). In this paper, we propose a deep learning-based method for region-based prediction for smart cities. First, we divide the cities into regions based on the space dimension and model the situation of the cities in 3D volumes. Based on the constructed 3D volumes, we design a model called multiple local 3D CNN spatial-temporal residual networks (LMST3D-ResNet) for region-based prediction in smart cities. LMST3D-ResNet can extract multiple temporal dependencies (including trend, period and closeness) for local regions and then predict the future citywide activities according to the learned multiple spatial-temporal features. LMST3D-ResNet can also combine the spatial-temporal features with external factors. LMST3D-ResNet includes 3D CNNs and ResNet mechanisms for processing spatial-temporal information. In particular, 3D CNNs have the ability to model 3-dimensional information due to 3D convolution and 3D pooling operations, while ResNet enables the connection of the convolutional neural network across layers to obtain a deeper network structure. Specifically, in our proposed model, a novel region-based information extraction mechanism and an end-to-end multiple spatial-temporal dependency learning structure are designed for local regions. Extensive experimental results on two datasets, i.e., MLElectricity and BJTaxi demonstrate the superior performance of our proposed method over the exisiting state-of-the-art methods. (C) 2020 Elsevier Inc. All rights reserved.	187.9877452185097
304.	Short duration text-independent speaker verification remains a hot research topic in recent years, and deep neural network based embeddings have shown impressive results in such conditions. Good speaker embeddings require the property of both small intra-class variation and large inter-class difference, which is critical for the ability of discrimination and generalization. Current embedding learning strategies can be grouped into two frameworks: "Cascade embedding learning" with multiple stages and "direct embedding learning" from spectral feature directly. We propose new approaches to achieve more discriminant speaker embeddings. Within the cascade framework, a neural network based deep discriminant analysis (DDA) is proposed to project i-vector to more discriminative embeddings. Within the direct embedding framework, a deep model with more advanced center loss and A-softmax loss is used, the focal loss is also investigated in this framework. Moreover, the traditional i-vector and neural embeddings are finally combined with neural network based DDA to achieve further gain. Main experiments are carried out on a short-duration text-independent speaker verification dataset generated from the SRE corpus. The results show that the newly proposed method is promising for short-duration text-independent speaker verification, and it is consistently better than traditional i-vector and neural embedding baselines. The best embeddings achieve roughly 30% relative EER reduction compared to the i-vector baseline, which could be further enhanced when combined with the i-vector system.	187.9877103119041
305.	Greenhouse crop production is growing throughout the world and early pest detection is of particular importance in terms of productivity and reduction of the use of pesticides. Conventional eye observation methods are nonefficient for large crops. Computer vision and recent advances in deep learning can play an important role in increasing the reliability and productivity. This paper presents the development and comparison of two different approaches for vision based automated pest detection and identification, using learning strategies. A solution that combines computer vision and machine learning is compared against a deep learning solution. The main focus of our work is on the selection of the best approach based on pest detection and identification accuracy. The inspection is focused on the most harmful pests on greenhouse tomato and pepper crops, Bemisia tabaci and Trialeurodes vaporariorum. A dataset with a huge number of infected tomato plants images was created to generate and evaluate machine learning and deep learning models. The results showed that the deep learning technique provides a better solution because (a) it achieves the disease detection and classification in one step, (b) gets better accuracy, (c) can distinguish better between Bemisia tabaci and Trialeurodes vaporariorum, and (d) allows balancing between speed and accuracy by choosing different models.	187.98769295175686
306.	Personality is an important psychological construct accounting for individual differences in people. Computational personality recognition from online social networks is gaining increased research attention in recent years. However, the majority of existing methodologies mainly focused on human-designed shallow statistical features and didn't make full use of the rich semantic information in user-generated texts, while those texts are exactly the most direct way for people to translate their internal thoughts and emotions into a form that others can understand. This paper proposes a deep learning-based approach for personality recognition from text posts of online social network users. We first utilize a hierarchical deep neural network composed of our newly designed AttRCNN structure and a variant of the Inception structure to learn the deep semantic features of each user's text posts. Then we concatenate the deep semantic features with the statistical linguistic features obtained directly from the text posts, and feed them into traditional regression algorithms to predict the real-valued Big Five personality scores. Experimental results show that the deep semantic feature vectors learned from our proposed neural network are more effective than the other four kinds of non-trivial baseline features; the approach that utilizes the concatenation of our deep semantic features and the statistical linguistic features as the input of the gradient boosting regression algorithm achieves the lowest average prediction error among all the approaches tested by us.d	187.98763023338955
307.	Recommender systems enable users to deal with the information overload problem by serving personalized predictions. Traditional recommendation techniques produce referrals for users by considering their overall opinions over items. On the other hand, users may consider several criteria while evaluating an item. Even though overall rating-based evaluations are sufficient for interpreting e-commerce products, they may be less effective for evaluating services provided by hotels, restaurants, etc. Accordingly, multi-criteria-based collaborative filtering systems are introduced to increase the level of personalization. These recommender systems are relatively new extension of traditional collaborative filtering systems, and they utilize multi-criteria-based user preferences provided by individuals considering several aspects of services. There are several studies related to such recommender systems, and according to their results, it is possible to produce more personalized predictions along with accuracy improvement by employing multi-criteria recommender systems. Deep learning techniques employed in many research areas such as pattern recognition and image processing have recently been used frequently in the field of recommender systems. The studies show that deep learning-based approaches can improve the accuracy of the referrals due to their high capability of extracting out nonlinear relations between users and items. Therefore, in order to nonlinearly represent relations among users in terms of multi-criteria preferences, we propose a new multi-criteria collaborative filtering algorithm based on autoencoders. Our empirical results show that the proposed method enhances accuracy levels of produced predictions compared with the state-of-the-art algorithms.	187.98748457330115
308.	This paper explores Bitcoin intraday technical trading based on artificial neural networks for the return prediction. In particular, our deep learning method successfully discovers trading signals through a seven layered neural network structure for given input data of technical indicators, which are calculated by the past time-series data over every 15 min. Under feasible settings of execution costs, the numerical experiments demonstrate that our approach significantly improves the performance of a buy-and-hold strategy. Especially, our model performs well for a challenging period from December 2017 to January 2018, during which Bitcoin suffers from substantial minus returns. Furthermore, various sensitivity analysis is implemented for the change of the number of layers, activation functions, input data and output classification to confirm the robustness of our approach. (C) 2018 Elsevier B.V. All rights reserved.	187.98744358280675
309.	Representation learning plays an important role for building effective deep neural network models. Deep generative probabilistic models have shown to be efficient in the data representation learning task which is usually carried out in an unsupervised fashion. Throughout the past decade, there has been almost exclusive focus on the learning algorithms to improve representation capability of the generative models. However, effective data representation requires improvement in both learning algorithm and architecture of the generative models. Therefore, improvement to the neural architecture is critical for improved data representation capability of deep generative models. Furthermore, the prevailing class of deep generative models such as deep belief network (DBN), deep Boltzman machine (DBM) and deep sigmoid belief network (DSBN) are inherently unidirectional and lack recurrent connections ubiquitous in the biological neuronal structures. Introduction of recurrent connections may offer further improvement in data representation learning performance to the deep generative models. Consequently, for the first time in literature, this work proposes a deep recurrent generative model known as deep simultaneous recurrent belief network (D-SRBN) to efficiently learn representations from unlabeled data. Experimentation on four benchmark datasets: MNIST, Caltech 101 Silhouettes, OCR letters and Omniglot show that the proposed D-SRBN model achieves superior representation learning performance while utilizing less computing resources when compared to the four state-of-the-art generative models such as deep belief network (DBN), DBM, DSBN and VAE (variational auto-encoder). (C) 2018 Elsevier Ltd. All rights reserved.	187.98737889793102
310.	With increased use of electronic medical records (EMRs), data mining on medical data has great potential to improve the quality of hospital treatment and increase the survival rate of patients. Early readmission prediction enables early intervention, which is essential to preventing serious or life-threatening events, and act as a substantial contributor to reduce healthcare costs. Existing works on predicting readmission often focus on certain vital signs and diseases by extracting statistical features. They also fail to consider skewness of class labels in medical data and different costs of misclassification errors. In this paper, we recur to the merits of convolutional neural networks (CNN) to automatically learn features from time series of vital sign, and categorical feature embedding to effectively encode feature vectors with heterogeneous clinical features, such as demographics, hospitalization history, vital signs, and laboratory tests. Then, both learnt features via CNN and statistical features via feature embedding are fed into a multilayer perceptron (MLP) for prediction. We use a cost-sensitive formulation to train MLP during prediction to tackle the imbalance and skewness challenge. We validate the proposed approach on two real medical datasets from Barnes-Jewish Hospital, and all data is taken from historical EMR databases and reflects the kinds of data that would realistically be available at the clinical prediction system in hospitals. We find that early prediction of readmission is possible and when compared with state-of-the-art existing methods used by hospitals, our methods perform significantly better. For example, using the general hospital wards data for 30-day readmission prediction, the area under the curve (AUC) for the proposed model was 0.70, significantly higher than all the baseline methods. Based on these results, a system is being deployed in hospital settings with the proposed forecasting algorithms to support treatment.	187.98729342519317
311.	It is widely known that very small datasets produce overfitting in Deep Neural Networks (DNNs), i.e., the network becomes highly biased to the data it has been trained on. This issue is often alleviated using transfer learning, regularization techniques and/or data augmentation. This work presents a new approach, independent but complementary to the previous mentioned techniques, for improving the generalization of DNNs on very small datasets in which the involved classes share many visual features. The proposed model, called FuCiTNet (Fusion Class inherent Transformations Network), inspired by GANs, creates as many generators as classes in the problem. Each generator, k, learns the transformations that bring the input image into the k-class domain. We introduce a classification loss in the generators to drive the leaning of specific k-class transformations. Our experiments demonstrate that the proposed transformations improve the generalization of the classification model in three diverse datasets.	187.98728455263335
312.	There is increasing evidence that hand gestures and speech synchronize their activity on multiple dimensions and timescales. For example, gesture's kinematic peaks (e.g., maximum speed) are coupled with prosodic markers in speech. Such coupling operates on very short timescales at the level of syllables (200 ms), and therefore requires high-resolution measurement of gesture kinematics and speech acoustics. High-resolution speech analysis is common for gesture studies, given that field's classic ties with (psycho)linguistics. However, the field has lagged behind in the objective study of gesture kinematics (e.g., as compared to research on instrumental action). Often kinematic peaks in gesture are measured by eye, where a "moment of maximum effort" is determined by several raters. In the present article, we provide a tutorial on more efficient methods to quantify the temporal properties of gesture kinematics, in which we focus on common challenges and possible solutions that come with the complexities of studying multimodal language. We further introduce and compare, using an actual gesture dataset (392 gesture events), the performance of two video-based motion-tracking methods (deep learning vs. pixel change) against a high-performance wired motion-tracking system (Polhemus Liberty). We show that the videography methods perform well in the temporal estimation of kinematic peaks, and thus provide a cheap alternative to expensive motion-tracking systems. We hope that the present article incites gesture researchers to embark on the widespread objective study of gesture kinematics and their relation to speech.	187.98727792705697
313.	The Automatic License Plate Recognition has been the subject of several studies, given its applicability in real world situations (e.g. toll collection, identification of vehicles in parking lots or even for safety issues in vehicle control that cross borders between countries). In this work, we propose an analysis of the influence to retraining a plate recognition model and a deep neural network for object detection, using synthetic plates image databases from the Brazilian licence plates. The proposed data set uses variations of rotation, size and noise to evaluate the robustness. Thus, the influence of the use of synthetic plates images on the accuracy of systems responsible for locating real plates, segmenting the characters and recognizing them was evaluated and in the tests performed there was an increase in accuracy (considering a system trained with real plates) of three stages: character segmentation, letter recognition and number recognition (2.54%, 1.09% and 2, 49% respectively). It stands out the accuracy of 62.47% (in the number recognition step) obtained by a neural network trained exclusively with synthetic data and tested on real plates.	187.98724235852745
314.	In the manufacturing industry, the preventive maintenance (PM) is a common practice to reduce random machine failures by replacing/repairing the aged machines or parts. The decision on when and where the preventive maintenance needs to be carried out is nontrivial due to the complex and stochastic nature of a serial production line with intermediate buffers. In order to improve the cost efficiency of the serial production lines, a deep reinforcement learning based approach is proposed to obtain PM policy. A novel modeling method for the serial production line is adopted during the learning process. A reward function is proposed based on the system production loss evaluation. The algorithm based on the Double Deep Q-Network is applied to learn the PM policy. Using the simulation study, the learning algorithm is proved effective in delivering PM policy that leads to an increased throughput and reduced cost. Interestingly, the learned policy is found to frequently conduct "group maintenance" and "opportunistic maintenance", although their concepts and rules are not provided during the learning process. This finding further demonstrates that the problem formulation, the proposed algorithm and the reward function setting in this paper are effective. (c) 2020 Elsevier Ltd. All rights reserved.	187.98702196774934
315.	Motivated by the human way of memorizing images we introduce their functional representation, where an image is represented by a neural network. For this purpose, we construct a hypernetwork which takes an image and returns weights to the target network, which maps point from the plane (representing positions of the pixel) into its corresponding color in the image. Since the obtained representation is continuous, one can easily inspect the image at various resolutions and perform on it arbitrary continuous operations. Moreover, by inspecting interpolations we show that such representation has some properties characteristic to generative models. To evaluate the proposed mechanism experimentally, we apply it to image super-resolution problem. Despite using a single model for various scaling factors, we obtained results comparable to existing super-resolution methods.	187.98694877461347
316.	Over the past few years, detection performance improvements of deep-learning based steganalyzers have been usually achieved through structure expansion. However, excessive expanded structure results in huge computational cost, storage overheads, and consequently difficulty in training and deployment. In this paper we propose CALPA-NET, a ChAnneL-Pruning-Assisted deep residual network architecture search approach to shrink the network structure of existing vast, over-parameterized deep-learning based steganalyzers. We observe that the broad inverted-pyramid structure of existing deep-learning based steganalyzers might contradict the well-established model diversity oriented philosophy, and therefore is not suitable for steganalysis. Then a hybrid criterion combined with two network pruning schemes is introduced to adaptively shrink every involved convolutional layer in a data-driven manner. The resulting network architecture presents a slender bottleneck-like structure. We have conducted extensive experiments on BOSSBase + BOWS2 dataset, more diverse ALASKA dataset and even a large-scale subset extracted from ImageNet CLS-LOC dataset. The experimental results show that the model structure generated by our proposed CALPA-NET can achieve comparative performance with less than two percent of parameters and about one third FLOPs compared to the original steganalytic model. The new model possesses even better adaptivity, transferability, and scalability.	187.98679232666746
317.	The use of deep learning models for the network intrusion detection task has been an active area of research in cybersecurity. Although several excellent surveys cover the growing body of research on this topic, the literature lacks an objective comparison of the different deep learning models within a controlled environment, especially on recent intrusion detection datasets. In this paper, we first introduce a taxonomy of deep learning models in intrusion detection and summarize the research papers on this topic. Then we train and evaluate four key deep learning models - feed-forward neural network, autoencoder, deep belief network and long short-term memory network - for the intrusion classification task on two legacy datasets (KDD 99, NSL-KDD) and two modern datasets (CIC-IDS2017, CIC-IDS2018). Our results suggest that deep feed-forward neural networks yield desirable evaluation metrics on all four datasets in terms of accuracy, F1-score and training and inference time. The results also indicate that two popular semi-supervised learning models, autoencoders and deep belief networks do not perform better than supervised feed-forward neural networks. The implementation and the complete set of results have been released for future use by the research community. Finally, we discuss the issues in the research literature that were revealed in the survey and suggest several potential future directions for research in machine learning methods for intrusion detection.	187.9867496144893
318.	Real-time processing and learning of conflicting data, especially messages coming from different ideas, locations, and time, in a dynamic environment such as Twitter is a challenging task that recently gained lots of attention. This paper introduces a framework for managing, processing, analyzing, detecting, and tracking topics in streaming data. We propose a model selector procedure with a hybrid indicator to tackle the challenge of online topic detection. In this framework, we built an automatic data processing pipeline with two levels of cleaning. Regular and deep cleaning are applied using multiple sources of meta knowledge to enhance data quality. Deep learning and transfer learning techniques are used to classify health-related tweets, with high accuracy and improved F1-Score. In this system, we used visualization to have a better understanding of trending topics. To demonstrate the validity of this framework, we implemented and applied it to health-related twitter data from users originating in the USA over nine months. The results of this implementation show that this framework was able to detect and track the topics at a level comparable to manual annotation. To better explain the emerging and changing topics in various locations over time the result is graphically displayed on top of the United States map.	187.98673089530803
319.	The rapid growth in the transportation sector has led to the emergence of smart vehicles that are equipped with ICT. These modern smart vehicles are connected to the Internet to access various services such as road condition information, infotainment, and energy management. This kind of scenario can be viewed as a vehicular cyber-physical system (VCPS) where the vehicles are at the physical layer and services are at the cyber layer. However, network traffic management is the biggest issue in the modern VCPS scenario as the mismanagement of network resources can degrade the quality of service (QoS) for end users. To deal with this issue, we propose a software defined networking (SDN)-enabled approach, named SeDaTiVe, which uses deep learning architecture to control the incoming traffic in the network in the VCPS environment. The advantage of using deep learning in network traffic control is that it learns the hidden patterns in data packets and creates an optimal route based on the learned features. Moreover, a virtual-controller-based scheme for flow management using SDN in VCPS is designed for effective resource utilization. The simulation scenario comprising 1000 vehicles seeking various services in the network is considered to generate the dataset using SUMO. The data obtained from the simulation study is evaluated using NS-2, and proves that the proposed scheme effectively handles real-time incoming requests in VCPS. The results also depict the improvement in performance on various evaluation metrics like delay, throughput, packet delivery ratio, and network load by using the proposed scheme over the traditional SDN and TCP/IP protocol suite.	187.98669600239512
320.	Water body extraction from remote sensing image data has been becoming a really hot topic. Recently, researchers put forward numerous methods for water body extraction, while most of them rely on elaborative feature selection and enough number of training samples. Convolution Neural Network (CNN), one of the implementation models of deep learning, has strong capability for two-dimension images' classification. A new water body extraction model based on CNNs is established for deep multi-feature learning. Before experiment, image enhancement will be done by Dark Channel Prior. Then we concatenate three kinds of features: spectral information, spatial information that is extracted by Extended Multi-attribute Profile (EMAP) and various water indexes firstly. Next, feature matrixes are acted as the input of CNN-based model for training and classifying. The experimental results showed that the proposed model has better classification performance than Support Vector Machine (SVM) and artificial neural network (ANN). On very limited training set, our model could learn unique and representative features for better water body extraction.	187.9865527589709
321.	The language used by the users in social media nowadays is Code-mixed text, i.e., mixing of two or more languages. This paper describes the application of the code mixed index in Indian social media texts and comparing the complexity to identify language at word level using Bi-directional Long Short Term Memory model. Social media platforms are now widely used by people to express their opinion and interest. The major contribution of the work is to propose a technique for identifying the language of Hindi-English code-mixed data used in three social media platforms namely, Facebook, Twitter, and WhatsApp. We recommend a deep learning framework based on cBoW and Skip gram model that predicts the origin of the word from language perspective in the sequence based on the specific words that have come before it in the sequence. The context capture module of the system gives better accuracy for word embedding model as compared to character embedding.	187.98621227607447
322.	Recurrent neural networks (RNN) are being extensively exploited in industry to address complex predictive tasks by leveraging on the increased availability of data from processes. However, the rationale behind model response is encoded in an implicit way, which is difficult to be explained by practitioners. If revealed, such mechanisms could provide deeper insights into RNN execution, enhancing conventional performance evaluations. We propose a new approach based on the introduction of a model-based clustering layer, constraining the network to operate on a discrete latent state representation. By processing context-input conditioned transitions between clusters, a Moore Machine characterizing the RNN computations is extracted. The proposed approach is demonstrated on both synthetic experiments from an open benchmark problem and via the application to a pilot industrial plant, by the behavior cloning of the flexible conveyor of a Remanufacturing process. The finite-state RNN attains the prediction accuracy of RNN with continuous state, providing in addition a more interpretable structure. (c) 2020 Elsevier B.V. All rights reserved.	187.9861627493808
323.	The accurate prediction of heart disease is essential to efficiently treating cardiac patients before a heart attack occurs. This goal can be achieved using an optimal machine learning model with rich healthcare data on heart diseases. Various systems based on machine learning have been presented recently to predict and diagnose heart disease. However, these systems cannot handle high-dimensional datasets due to the lack of a smart framework that can use different sources of data for heart disease prediction. In addition, the existing systems utilize conventional techniques to select features from a dataset and compute a general weight for them based on their significance. These methods have also failed to enhance the performance of heart disease diagnosis. In this paper, a smart healthcare system is proposed for heart disease prediction using ensemble deep learning and feature fusion approaches. First, the feature fusion method combines the extracted features from both sensor data and electronic medical records to generate valuable healthcare data. Second, the information gain technique eliminates irrelevant and redundant features, and selects the important ones, which decreases the computational burden and enhances the system performance. In addition, the conditional probability approach computes a specific feature weight for each class, which further improves system performance. Finally, the ensemble deep learning model is trained for heart disease prediction. The proposed system is evaluated with heart disease data and compared with traditional classifiers based on feature fusion, feature selection, and weighting techniques. The proposed system obtains accuracy of 98.5%, which is higher than existing systems. This result shows that our system is more effective for the prediction of heart disease, in comparison to other state-of-the-art methods.	187.98613270771546
324.	Antifreeze proteins (AFPs) are the sub-set of ice binding proteins indispensable for the species living in extreme cold weather. These proteins bind to the ice crystals, hindering their growth into large ice lattice that could cause physical damage. There are variety of AFPs found in numerous organisms and due to the heterogeneous sequence characteristics, AFPs are found to demonstrate a high degree of diversity, which makes their prediction a challenging task. Herein, we propose a machine learning framework to deal with this vigorous and diverse prediction problem using the manifolding learning through composition of k-spaced amino acid pairs. We propose to use the deep neural network with skipped connection and ReLU non-linearity to learn the non-linear mapping of protein sequence descriptor and class label. The proposed antifreeze protein prediction method called AFP-CKSAAP has shown to outperform the contemporary methods, achieving excellent prediction scores on standard dataset. The main evaluator for the performance of the proposed method in this study is Youden's index whose high value is dependent on both sensitivity and specificity. In particular, AFP-CKSAAP yields a Youden's index value of 0.82 on the independent dataset, which is better than previous methods.	187.98609874767803
325.	The extraction of oil is accompanied by water and sediments that, mixed with the oil, cause the formation of scale depositions in the pipelines walls promoting the reduction of the inner diameter of the pipes, making it difficult for the fluids to pass through interest. In this sense, there is a need to control the formation of these depositions to evaluate preventive and corrective measures regarding the waste management of these materials, as well as the optimization of oil extraction and transport processes. Noninvasive techniques such as gamma transmission and scattering can support the determination of the thickness of these deposits in pipes. This paper presents a novel methodology for prediction of scale with eccentric deposition in pipes used in the offshore oil industry and its approach is based on the principles of gamma densitometry and deep artificial neural networks (DNNs). To determine deposition thicknesses, a detection system has been developed that utilizes a 1 mm narrow beam geometry of collimation aperture comprising a source of Cs-137 and three properly positioned 2 '' x 2 '' NaI(Tl) detectors around the system, pipe-scale-fluid. Crude oil was considered in the study, as well as eccentric deposits formed by barium sulfate, BaSO4. The theoretical models adopted a static flow regime and were developed using the MCNPX mathematical code and, secondly, used for the training and testing of the developed DNN model, a 7-layers deep rectifier neural network (DRNN). In addition, the hyperparameters of the DRNN were defined using a Baysian optimization method and its performance was validated via 10 experiments based on the K-Fold cross-validation technique. Following the proposed methodology, the DRNN was able to achieve, for the test sets (untrained samples), an average mean absolute error of 0.01734, mean absolute relative error of 0.29803% and R2 Score of 0.9998813 for the scale thickness prediction and an average accuracy of 100% for the scale position prediction. Therefore, the results show that the 7-layers DRNN presents good generalization capacity and is able to predict scale thickness with great precision, regardless of its position inside the tube.	187.98608980090646
326.	The local level has gained prominence in climate policy and governance in recent years as it is increasingly perceived as a privileged arena for policy experimentation and social and institutional innovation. However, the success of local climate governance in industrialized countries has been limited. One reason may be that local communities focus too much on strategies of technology-oriented ecological modernization and individual behavior change and too little on strategies that target unsustainable social practices and their embeddedness in complex socioeconomic patterns. In this paper we assess and compare the strategies of low-carbon municipalities (top-down initiatives) and those of intentional communities (bottom-up initiatives). We were interested to determine to what extent and in which ways each community type intervenes in social practices to curb carbon emissions and to explore the scope for further and deeper interventions on the local level. Using an analytical framework based on social practice theory we identify characteristic patterns of intervention for each community type. We find that low-carbon municipalities face difficulties in transforming carbon-intensive social practices. While offering some additional low-carbon choices, their ability to reduce carbon-intensive practices is very limited. Their focus on efficiency and individual choice shows little transformative potential. Intentional communities, by contrast, have more institutional and organizational options to intervene in the web of social practices. Finally, we explore to what extent low-carbon municipalities can learn from intentional communities and propose strategies of hybridization for policy innovation to combine the strengths of both models.	187.98604097394679
327.	The quantization error in a fixed-size Self-Organizing Map (SOM) with unsupervised winner-take-all learning has previously been used successfully to detect, in minimal computation time, highly meaningful changes across images in medical time series and in time series of satellite images. Here, the functional properties of the quantization error in SOM are explored further to show that the metric is capable of reliably discriminating between the finest differences in local contrast intensities and contrast signs. While this capability of the QE is akin to functional characteristics of a specific class of retinal ganglion cells (the so-called Y-cells) in the visual systems of the primate and the cat, the sensitivity of the QE surpasses the capacity limits of human visual detection. Here, the quantization error in the SOM is found to reliably signal changes in contrast or colour when contrast information is removed from or added to the image, but not when the amount and relative weight of contrast information is constant and only the local spatial position of contrast elements in the pattern changes. While the RGB Mean reflects coarser changes in colour or contrast well enough, the SOM-QE is shown to outperform the RGB Mean in the detection of single-pixel changes in images with up to five million pixels. This could have important implications in the context of unsupervised image learning and computational building block approaches to large sets of image data (big data), including deep learning blocks, and automatic detection of contrast change at the nanoscale in Transmission or Scanning Electron Micrographs (TEM, SEM), or at the subpixel level in multispectral and hyper-spectral imaging data. (C) 2019 Elsevier Ltd. All rights reserved.	187.98602931162543
328.	Retrieval of similar cases is an important approach for the design of an automated system to support the radiologist decision making process. The ability to utilize machine learning for the task of image retrieval is limited by the availability of ground truth on similarity between dataset elements (e.g. between nodules). Consequently, past approaches have focused on manual feature extraction and unsupervised approaches. Currently, medical retrieval studies have focused on learning similarity from a binary classification task (e.g. malignancy), and the performance evaluation was also based on a binary classification framework. Such similarity measure is far from being adequate and fails to capture true retrieval performance. Current study explores the task of similarity learning in the context of lung nodule retrieval, using LIDC's public dataset. LIDC offers annotations of nodules that include ratings of 9 characteristics per each nodule. These rating are used as our golden-standard similarity measure. Four architectures that utilize the same core network are being explored. These architectures correspond to four unique tasks: binary classification, binary similarity, rating regression and similarity regression. Results show clear discrepancy between classic performance measures and the correlation to the reference similarity measure: all methods had precision in the range of 0.73-0.75, while rating correlation ranged 0.22 to 0.51, with the highest correlation achieved with the rating-regression approach. Additionally, a measure of the uniformity of the embedding space (Hubness) is introduced. The importance of Hubness, as an independent success criteria, is explained, and the measure is evaluated for all architectures. Our rating-regression network has reached state-of-the-art result in several tasks.	187.98585491180376
329.	Recent advancements in human-robot collaboration have enabled human operators and robots to work together in a shared manufacturing environment. However, current distance-based collision-free human-robot collaboration system can only ensure human safety but not assembly efficiency. In this paper, the authors present a context awareness-based collision-free human-robot collaboration system that can provide human safety and assembly efficiency at the same time. The system can plan robotic paths that avoid colliding with human operators while still reach target positions in time. Human operators' poses can also be recognised with low computational expenses to further improve assembly efficiency. To support the context-aware collision-free system, a complete collision sensing module with sensor calibration algorithms is proposed and implemented. An efficient transfer learning-based human pose recognition algorithm is also adapted and tested. Two experiments are designed to test the performance of the proposed human pose recognition algorithm and the overall system. The results indicate an efficiency improvement of the overall system.	187.98583342031952
330.	BACKGROUND AND OBJECTIVE: Traditional machine learning methods assume that both training and test data come from the same distribution. In this way, it becomes possible to achieve high successes when modelling on the same domain. Unfortunately, in real-world problems, direct transfer between domains is adversely affected due to differences in the data collection process and the internal dynamics of the data. In order to cope with such drawbacks, researchers use a method called "domain adaptation", which enables the successful transfer of information learned in one domain to other domains. In this study, a model that can be used in the classification of white blood cells (WBC) and is not affected by domain differences was proposed. METHODS: Only one data set was used as source domain, and an adaptation process was created that made possible the learned knowledge to be used effectively in other domains (multi-target domain adaptation). While constructing the model, we employed data augmentation, data generation and fine-tuning processes, respectively. RESULTS: The proposed model has been able to extract "domain-invariant" features and achieved high success rates in the tests performed on nine different data sets. Multi-target domain adaptation accuracy was measured as %98.09. CONCLUSIONS: At the end of the study, it has been observed that the proposed model ignores the domain differences and it can adapt in a successful way to target domains. In this way, it becomes possible to classify unlabeled samples rapidly by using only a few number of labeled ones.	187.98571182018821
331.	In this paper we propose two novel deep learning-based terrain classification methods robust to illumination changes. The use of cameras is challenged by a variety of factors, of most importance being the changes in illumination. On the other hand, since the temperature of various types of terrains depends on the thermal characteristics of the terrain, the terrain classification can be aided by utilizing the thermal information in addition to visible information. Thus we propose 'TU-Net (Two U-Net)' based on the U-Net and 'TDeepLab (Two DeepLab)' based on DeepLab, which combine visible and thermal images and train the network robust to illumination changes implicitly. To improve the network's learning capability, we expand the proposed methods to the Siamese-based method, which explicitly trains the network to be robust to illumination changes. We also investigate multiple options to fuse the visible and thermal images at at the bottom layer, middle layer, or the top layer of the network. We evaluate the proposed methods with a challenging new dataset consisting of visible and thermal images, which were collected from 10 am till 5 pm (after sunset), and we show the effectiveness of the proposed methods.	187.98556340373077
332.	The article deals with the problems of motion detection, object recognition, and scene description using deep learning in the framework of granular computing and Z-numbers. Since deep learning is computationally intensive, whereas granular computing, on the other hand, leads to computation gain, a judicious integration of their merits is made so as to make the learning mechanism computationally efficient. Further, it is shown how the concept of z-numbers can be used to quantify the abstraction of semantic information in interpreting a scene, where subjectivity is of major concern, through recognition of its constituting objects. The system, thus developed, involves recognition of both static objects in the background and moving objects in foreground separately. Rough set theoretic granular computing is adopted where rough lower and upper approximations are used in defining object and background models. During deep learning, instead of scanning the entire image pixel by pixel in the convolution layer, we scan only the representative pixel of each granule. This results in a significant gain in computation time. Arbitrary-shaped and sized granules, as expected, perform better than regular-shaped rectangular granules or fixed-sized granules. The method of tracking is able to deal efficiently with various challenging cases, e.g., tracking partially overlapped objects and suddenly appeared objects. Overall, the granulated system shows a balanced trade-off between speed and accuracy as compared to pixel level learning in tracking and recognition. The concept of using Z-numbers, in providing a granulated linguistic description of a scene, is unique. This gives a more natural interpretation of object recognition in terms of certainty toward scene understanding.	187.98555522799626
333.	Most prior approaches to the problem of stereoscopic 3D (S3D) visual discomfort prediction (VDP) have focused on the extraction of perceptually meaningful handcrafted features based on models of visual perception and of natural depth statistics. Toward advancing performance on this problem, we have developed a deep learning-based VDP model named deep visual discomfort predictor (DeepVDP). The DeepVDP uses a convolutional neural network (CNN) to learn features that are highly predictive of experienced visual discomfort. Since a large amount of reference data is needed to train a CNN, we develop a systematic way of dividing the S3D image into local regions defined as patches and model a patch-based CNN using two sequential training steps. Since it is very difficult to obtain human opinions on each patch, instead a proxy ground-truth label that is generated by an existing S3D visual discomfort prediction algorithm called 3D-VDP is assigned to each patch. These proxy ground-truth labels are used to conduct the first stage of training the CNN. In the second stage, the automatically learned local abstractions are aggregated into global features via a feature aggregation layer. The learned features are iteratively updated via supervised learning on subjective 3D discomfort scores, which serve as ground-truth labels on each S3D image. The patch-based CNN model that has been pretrained on proxy ground-truth labels is subsequently retrained on true global subjective scores. The global S3D visual discomfort scores predicted by the trained DeepVDP model achieve the state-of-the-art performance as compared with previous VDP algorithms.	187.9855399855986
334.	PURPOSE OF REVIEW: Over the last decade, major advancements in artificial intelligence technology have emerged and revolutionized the extent to which physicians are able to personalize treatment modalities and care for their patients. Artificial intelligence technology aimed at mimicking/simulating human mental processes, such as deep learning artificial neural networks (ANNs), are composed of a collection of individual units known as 'artificial neurons'. These 'neurons', when arranged and interconnected in complex architectural layers, are capable of analyzing the most complex patterns. The aim of this systematic review is to give a comprehensive summary of the contemporary applications of deep learning ANNs in urological medicine. RECENT FINDINGS: Fifty-five articles were included in this systematic review and each article was assigned an 'intermediate' score based on its overall quality. Of these 55 articles, nine studies were prospective, but no nonrandomized control trials were identified. SUMMARY: In urological medicine, the application of novel artificial intelligence technologies, particularly ANNs, have been considered to be a promising step in improving physicians' diagnostic capabilities, especially with regards to predicting the aggressiveness and recurrence of various disorders. For benign urological disorders, for example, the use of highly predictive and reliable algorithms could be helpful for the improving diagnoses of male infertility, urinary tract infections, and pediatric malformations. In addition, articles with anecdotal experiences shed light on the potential of artificial intelligence-assisted surgeries, such as with the aid of virtual reality or augmented reality.	187.98549548580365
335.	BACKGROUND: Our previous work classified a taxonomy of needle driving gestures during a vesicourethral anastomosis of robotic radical prostatectomy in association with tissue tears and patient outcomes. Herein, we train deep learning-based computer vision to automate the identification and classification of suturing gestures for needle driving attempts. METHODS: Two independent raters manually annotated live suturing video clips to label timepoints and gestures. Identification (2,395 videos) and classification (511 videos) datasets were compiled to train computer vision models to produce 2- and 5-class label predictions, respectively. Networks were trained on inputs of raw red/blue/green pixels as well as optical flow for each frame. We explore the effect of different recurrent models (long short-term memory versus convolutional long short-term memory). All models were trained on 80/20 train/test splits. RESULTS: We observe that all models are able to reliably predict either the presence of a gesture (identification, area under the curve: 0.88) as well as the type of gesture (classification, area under the curve: 0.87) at significantly above chance levels. For both gesture identification and classification datasets, we observed no effect of recurrent classification model choice on performance. CONCLUSION: Our results demonstrate computer vision's ability to recognize features that not only can identify the action of suturing but also distinguish between different classifications of suturing gestures. This demonstrates the potential to utilize deep learning computer vision toward future automation of surgical skill assessment.	187.98538265199193
336.	Although massive data is quickly accumulating on protein sequence and structure, there is a small and limited number of protein architectural types (or structural folds). This study is addressing the following question: how well could one reveal underlying sequence-structure relationships and design protein sequences for an arbitrary, potentially novel, structural fold? In response to the question, we have developed novel deep generative models, namely, semisupervised gcWGAN (guided, conditional, Wasserstein Generative Adversarial Networks). To overcome training difficulties and improve design qualities, we build our models on conditional Wasserstein GAN (WGAN) that uses Wasserstein distance in the loss function. Our major contributions include (1) constructing a low-dimensional and generalizable representation of the fold space for the conditional input, (2) developing an ultrafast sequence-to-fold predictor (or oracle) and incorporating its feedback into WGAN as a loss to guide model training, and (3) exploiting sequence data with and without paired structures to enable a semisupervised training strategy. Assessed by the oracle over 100 novel folds not in the training set, gcWGAN generates more successful designs and covers 3.5 times more target folds compared to a competing data-driven method (cVAE). Assessed by sequence- and structure-based predictors, gcWGAN designs are physically and biologically sound. Assessed by a structure predictor over representative novel folds, including one not even part of basis folds, gcWGAN designs have comparable or better fold accuracy yet much more sequence diversity and novelty than cVAE. The ultrafast data-driven model is further shown to boost the success of a principle-driven de novo method (RosettaDesign), through generating design seeds and tailoring design space. In conclusion, gcWGAN explores uncharted sequence space to design proteins by learning generalizable principles from current sequence-structure data. Data, source codes, and trained models are available at https://github.com/Shen-Lab/gcWGAN.	187.9853237446161
337.	We present DANTE, a novel method for training neural networks using the alternating minimization principle. DANTE provides an alternate perspective to traditional gradient-based backpropagation techniques commonly used to train deep networks. It utilizes an adaptation of quasi-convexity to cast training a neural network as a bi-quasi-convex optimization problem. We show that for neural network configurations with both differentiable (e.g. sigmoid) and non-differentiable (e.g. ReLU) activation functions, we can perform the alternations effectively in this formulation. DANTE can also be extended to networks with multiple hidden layers. In experiments on standard datasets, neural networks trained using the proposed method were found to be promising and competitive to traditional backpropagation techniques, both in terms of quality of the solution, as well as training speed.	187.9851827924919
338.	With the rapid growth of data and computing power, deep learning based approaches have become the main solution for many artificial intelligence problems such as image classification, speech recognition and computer vision. Several excellent deep learning (DL) frameworks including Tensorflow, MxNet and PyTorch have been made open-sourced, further accelerating the advance of the community. However, existing DL frameworks are not designed for applications involving high-dimensional sparse data, which exists widely in many successful online businesses such as search engine, recommender systems and online advertising. In these industrial scenarios, deep models are typically trained on large scale datasets with up to billions of sparse features and hundreds of billions of samples, bringing great challenges to DL framework. In this paper, we introduce a high-performance, large-scale and distributed DL framework named XDL which provides an elegant solution to fill the gap between general design of existing DL frameworks and industrial requirements arising from high-dimensional sparse data. Since 2016, XDL has been successfully deployed in Alibaba, serving many productions such as online advertising and recommender system. Running on hundreds of GPU cards in parallel, XDL can train deep models with tens of billions parameters within only several hours. Besides its excellent performance and flexibility, XDL is also friendly to developers. Algorithm scientists in Alibaba can develop and deploy new deep models with only several lines of simple codes. The XDL API and a reference implementation were released as an open-source package under the Apache 2.0 license in December, 2018 and are available at https://github.com/alibaba/xdeeplearning.	187.98517209999565
339.	One important issue that needs to be addressed in order to provide effective massive deployments of IoT devices is access control. In 5G cellular networks, the Access Class Barring (ACB) method aims at increasing the total successful access probability by delaying randomly access requests. This mechanism can be controlled through the barring rate, which can be easily adapted in networks where Human-to-Human (H2H) communications are prevalent. However, in scenarios with massive deployments such as those found in IoT applications, it is not evident how this parameter should be set, and how it should adapt to dynamic traffic conditions. We propose a double deep reinforcement learning mechanism to adapt the barring rate of ACB under dynamic conditions. The algorithm is trained with simultaneous H2H and Machine-to-Machine (M2M) traffic, but we perform a separate performance evaluation for each type of traffic. The results show that our proposed mechanism is able to reach a successful access rate of 100 % for both H2H and M2M UEs and reduce the mean number of preamble transmissions while slightly affecting the mean access delay, even for scenarios with very high load. Also, its performance remains stable under the variation of different parameters. (C) 2019 Elsevier B.V. All rights reserved.	187.98498465785707
340.	Prognostics and Health Management (PHM) is an integrated technique for improving the availability and efficiency of high-value industry equipment and reducing the maintenance cost. One of the most challenging problems in PHM is how to effectively process the raw monitoring signal into the information-rich features that are readable enough for PHM modeling. In this paper, we propose an integrated hierarchical learning framework, which is capable to perform the unsupervised feature learning, diagnostics and prognostics modeling together. The proposed method is based on Auto-Encoders (trained by considering the Li-norm penalty) and Extreme Learning Machines (trained by considering the L-2-norm penalty). The proposed method is applied on two different case studies considering the diagnostics of motor bearings and prognostics of turbofan engines, also the performances are compared with other commonly applied PHM approaches and machine learning tools. The obtained results demonstrate the superiority of the proposed method, especially the ability of extracting the relevant features from the non-informative and noisy signals and maintaining their efficiencies. (C) 2018 Elsevier B.V. All rights reserved.	187.9847848124825
341.	Artificial neural networks (ANNs) have been widely used for the analysis of remotely sensed imagery. In particular, convolutional neural networks (CNNs) are gaining more and more attention in this field. CNNs have proved to be very effective in areas such as image recognition and classification, especially for the classification of large sets composed by two-dimensional images. However, their application to multi spectral and hyperspectral images faces some challenges, especially related to the processing of the high-dimensional information contained in multidimensional data cubes. This results in a significant increase in computation time. In this paper, we present a new CNN architecture for the classification of hyperspectral images. The proposed CNN is a 3-D network that uses both spectral and spatial information. It also implements a border mirroring strategy to effectively process border areas in the image, and has been efficiently implemented using graphics processing units (CPUs). Our experimental results indicate that the proposed network performs accurately and efficiently, achieving a reduction of the computation time and increasing the accuracy in the classification of hyperspectral images when compared to other traditional ANN techniques. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	187.98465989827918
342.	This paper concerns the issue of monitoring elderly behavior in the context of ambient assisted living (AAL). Under the framework of online daily habit modeling (ODHM), we employ the emergent representation for activities of daily living (ADLs) with position-based stigmergy, and then combine it with convolution neural networks (CNNs) to accomplish the tasks of recognizing ADLs. In addition, we propose a new paradigm of activity summarization with the robustness to break interruptions. Radio tomographic imaging (RTI) is promoted as a simple yet flexible way of facilitating the required position-based stigmergy. Such position-based AAL systems can benefit the advantages of having no need any sophisticated domain models in analyzing and understanding ADLs while no burden training is involved in ODHM. Moreover, the emergent based data aggregation and deep learning of CNN together allow the recognition of ADLs at a fine-grained level, which contributes to the performance improvement of ODHM. Experimental results demonstrate the effectiveness of the proposed approach.	187.9845860167221
343.	Crowd behaviour analysis is an emerging research area. Due to its novelty, a proper taxonomy to organise its different sub-tasks is still missing. This paper proposes a taxonomic organisation of existing works following a pipeline, where sub-problems in last stages benefit from the results in previous ones. Models that employ Deep Learning to solve crowd anomaly detection, one of the proposed stages, are reviewed in depth, and the few works that address emotional aspects of crowds are outlined. The importance of bringing emotional aspects into the study of crowd behaviour is remarked, together with the necessity of producing real-world, challenging datasets in order to improve the current solutions. Opportunities for fusing these models into already functioning video analytics systems are proposed.	187.9845841436864
344.	Many existing learning algorithms suffer from limited architectural depth and the locality of estimators, making it difficult to generalize from the test set and providing inefficient and biased estimators. Deep architectures have been shown to appropriately learn correlation structures in time series data. This paper compares the effectiveness of a deep feedforward Neural Network (DNN) and shallow architectures (e.g., Support Vector Machine (SVM) and one-layer NN) when predicting a broad cross-section of stock price indices in both developed and emerging markets. An extensive evaluation is undertaken, using daily, hourly, minute and tick level data related to thirty-four financial indices from 32 countries across six years. Our evaluation results show a considerable advantage from training deep (cf. shallow) architectures, using a rectifier linear (RELU) activation function, across all thirty-four markets when 'minute' data is used. However, the predictive performance of DNN was not significantly better than that of shallower architectures when using tick level data. This result suggests that when training a DNN algorithm, the predictive accuracy peaks, regardless of training size. We also examine which activation function works best for stock price index data. Our results demonstrate that the RELU activation function performs better than TANH across all markets and time horizons when using DNN to predict stock price indices. (C) 2019 Elsevier Ltd. All rights reserved.	187.98447404460643
345.	Former comparisons of human speech recognition (HSR) and automatic speech recognition (ASR) have shown that humans outperform ASR systems in nearly all speech recognition tasks. However, recent progress in ASR has led to substantial improvements of recognition accuracy, and it is therefore unclear how large the task-dependent human-machine gap still remains. This paper investigates this gap between HSR and ASR based on deep neural networks (DNNs) in different acoustic conditions, with the aim of comparing differences and identifying processing strategies that should be considered in ASR. We find that DNN-based ASR reaches human performance for single-channel, small-vocabulary tasks in the presence of speech-shaped noise and in multi talker babble noise, which is an important difference to previous human-machine comparisons: The speech reception threshold, i.e., the signal-to-noise ratio with 50% word recognition rate is at about 7 to 8 dB both for HSR and ASR. However, in more complex spatial scenes with diffuse noise and moving talkers, the SRT gap amounts to approximately 12 dB. Based on cross comparisons that use oracle knowledge (e.g., the speakers' true position), incorrect responses are attributed to localization errors or missing pitch information to distinguish between speakers with different gender. In terms of the SRT, localization errors and missing spectral information amount to 2.1 and 3.2 dB, respectively. The comparison hence identifies specific components in ASR that can profit from learning from auditory signal processing. (C) 2018 Elsevier Ltd. All rights reserved.	187.98434994194616
346.	We consider machine-learning-based thyroid-malignancy prediction from cytopathology whole-slide images (WSI). Multiple instance learning (MIL) approaches, typically used for the analysis of WSIs, divide the image (bag) into patches (instances), which are used to predict a single bag-level label. These approaches perform poorly in cytopathology slides due to a unique bag structure: sparsely located informative instances with varying characteristics of abnormality. We address these challenges by considering multiple types of labels: bag-level malignancy and ordered diagnostic scores, as well as instance-level informativeness and abnormality labels. We study their contribution beyond the MIL setting by proposing a maximum likelihood estimation (MLE) framework, from which we derive a two-stage deep-learning-based algorithm. The algorithm identifies informative instances and assigns them local malignancy scores that are incorporated into a global malignancy prediction. We derive a lower bound of the MLE, leading to an improved training strategy based on weak supervision, that we motivate through statistical analysis. The lower bound further allows us to extend the proposed algorithm to simultaneously predict multiple bag and instance-level labels from a single output of a neural network. Experimental results demonstrate that the proposed algorithm provides competitive performance compared to several competing methods, achieves (expert) human-level performance, and allows augmentation of human decisions.	187.98433285293865
347.	RNA post-transcriptional modifications play a crucial role in a myriad of biological processes and cellular functions. To date, more than 160 RNA modifications have been discovered; therefore, accurate identification of RNA-modification sites is fundamental for a better understanding of RNA-mediated biological functions and mechanisms. However, due to limitations in experimental methods, systematic identification of different types of RNA-modification sites remains a major challenge. Recently, more than 20 computational methods have been developed to identify RNA-modification sites in tandem with high-throughput experimental methods, with most of these capable of predicting only single types of RNA-modification sites. These methods show high diversity in their dataset size, data quality, core algorithms, features extracted and feature selection techniques and evaluation strategies. Therefore, there is an urgent need to revisit these methods and summarize their methodologies, in order to improve and further develop computational techniques to identify and characterize RNA-modification sites from the large amounts of sequence data. With this goal in mind, first, we provide a comprehensive survey on a large collection of 27 state-of-the-art approaches for predicting N1-methyladenosine and N6-methyladenosine sites. We cover a variety of important aspects that are crucial for the development of successful predictors, including the dataset quality, operating algorithms, sequence and genomic features, feature selection, model performance evaluation and software utility. In addition, we also provide our thoughts on potential strategies to improve the model performance. Second, we propose a computational approach called DeepPromise based on deep learning techniques for simultaneous prediction of N1-methyladenosine and N6-methyladenosine. To extract the sequence context surrounding the modification sites, three feature encodings, including enhanced nucleic acid composition, one-hot encoding, and RNA embedding, were used as the input to seven consecutive layers of convolutional neural networks (CNNs), respectively. Moreover, DeepPromise further combined the prediction score of the CNN-based models and achieved around 43% higher area under receiver-operating curve (AUROC) for m1A site prediction and 2-6% higher AUROC for m6A site prediction, respectively, when compared with several existing state-of-the-art approaches on the independent test. In-depth analyses of characteristic sequence motifs identified from the convolution-layer filters indicated that nucleotide presentation at proximal positions surrounding the modification sites contributed most to the classification, whereas those at distal positions also affected classification but to different extents. To maximize user convenience, a web server was developed as an implementation of DeepPromise and made publicly available at http://DeepPromise.erc.monash.edu/, with the server accepting both RNA sequences and genomic sequences to allow prediction of two types of putative RNA-modification sites.	187.98430920781107
348.	Deep learning models have been widely studied in fault diagnosis recently. A mainstream application is to recognize patterns in spectrograms of faults. However, some common drawbacks still remain as following: a) Preprocess to improve the quality of spectrograms is rarely explored; b) Computing cost of a conventional CNN far exceeds the requirements of fast analysis in industry; c) Adequate labeled data cannot be acquired to train a comprehensive diagnosis model for varying working conditions. In this paper, an Adaptive Logarithm Normalization (ALN) is proposed to realize preprocess considering data distribution, it attempts to improve the quality of spectrograms via eliminating truncation phenomenon and enriching details simultaneously; Meanwhile, simplified lightweight models are built on the basis of present lightweight building blocks to reduce parameters, while maintaining high performances; Furthermore, an adaptation architecture is proposed by integrating Deep Adaptation Network (DAN) idea with simplified lightweight models, aiming at enhancing the generalization capability of models. Experiments have been carried out to implement the proposed methods with two different datasets. The overall success not only proves the methods feasible, but also indicates a possible diagnosis prospect for real industrial scenarios. (C) 2020 Elsevier Ltd. All rights reserved.	187.98427362002377
349.	Trading strategies are constantly being employed in the financial markets in order to increase consistency, reduce human errors of judgment and boost the probability of taking profitable market positions. In this work, we attempt to transfer the knowledge of several different types of trading strategies to deep learning models. The trading strategies are applied on price data of foreign exchange trading pairs and are actual strategies used in production trading environments. Along with our approach to transfer the strategy knowledge, we introduce a preprocessing method of the original price candles making it suitable for use with Neural Networks. Our results suggest that the deep models that are tested perform better than simpler models and they can accurately learn a variety of trading strategies.	187.98423372865352
350.	This paper develops a conditional quantile model that can learn long term and short term memories of sequential data. It builds on sequential neural networks and yet outputs interpretable dynamics. We apply the model to asset return time series across eleven asset classes using historical data from the 1960s to 2018. Our results reveal that it extracts not only the serial dependence structure in conditional volatility but also the memories buried deep in the tails of historical prices. We further evaluate its Value-at-Risk forecasts against a wide range of prevailing models. Our model outperforms the GARCH family as well as models using filtered historical simulation, conditional extreme value theory, and dynamic quantile regression. These studies indicate that conditional quantiles of asset return have persistent sources of risk that are not coming from those responsible for volatility clustering. These findings could have important implications for risk management in general and tail risk forecasts in particular. (C) 2019 Elsevier B.V. All rights reserved.	187.9842163283237
351.	COVID-19 is a deadly viral infection that has brought a significant threat to human lives. Automatic diagnosis of COVID-19 from medical imaging enables precise medication, helps to control community outbreak, and reinforces coronavirus testing methods in place. While there exist several challenges in manually inferring traces of this viral infection from X-ray, Convolutional Neural Network (CNN) can mine data patterns that capture subtle distinctions between infected and normal X-rays. To enable automated learning of such latent features, a custom CNN architecture has been proposed in this research. It learns unique convolutional filter patterns for each kind of pneumonia. This is achieved by restricting certain filters in a convolutional layer to maximally respond only to a particular class of pneumonia/COVID-19. The CNN architecture integrates different convolution types to aid better context for learning robust features and strengthen gradient flow between layers. The proposed work also visualizes regions of saliency on the X-ray that have had the most influence on CNN's prediction outcome. To the best of our knowledge, this is the first attempt in deep learning to learn custom filters within a single convolutional layer for identifying specific pneumonia classes. Experimental results demonstrate that the proposed work has significant potential in augmenting current testing methods for COVID-19. It achieves an F1-score of 97.20% and an accuracy of 99.80% on the COVID-19 X-ray set.	187.98419936697712
352.	Plant identification is now attracting considerable attention due to its important applications in agriculture automation and ecosystems. Recently, deep learning-based plant identification methods have drawn increasing interest and shown favorable performance. However, existing methods do not consider plant spatial structure and their similarities explicitly. In this paper, we propose a robust spatial-structure siamese network (3SN) for plant identification, which has the following advantages: (1) It models the spatial structure of a plant by recurrent neural networks exploiting their capability to capture long-range dependencies among sequential data, which enables it to capture even a slight difference between a specific plant and distractors. (2) The plant similarity modeling is achieved effectively by a siamese network with large numbers of image pairs. In this way, the plant classification task and siamese learning task are learned jointly in a unified framework, where both can enhance and complement each other. Extensive experimental results show that the proposed 3SN method outperforms the state-of-the-art methods consistently.	187.9841280274831
353.	Solar observation is the branch of astronomy devoted to the study of the Sun. When the light wavefront that comes from the Sun penetrates the atmosphere, it suffers some distortions caused by optically turbulent layers that change the wavefront's shape and morphology. Therefore, in order to obtain a good-quality image, it is necessary to correct the induced error. This is done by applying adaptive optics (AO) techniques. In the case of the present research, it is performed with the help of a Single Conjugate Adaptive Optics System (SCAO). The reconstruction technique proposed in this research is a SCAO based on convolutional neural networks (CNNs). This research develops and assesses a real-time tomographic reconstructor based on CNN, able to correct the error introduced by the atmosphere in the light wavefront received from the Sun. The CNN was trained and validated using data from the Durham AO Simulation Platform as input information. This platform incorporates certain solar functionalities that have been employed in the present research, allowing us to simulate a solar telescope. The normalized errors obtained for both ReLu and Leaky ReLu kernels were promising, without showing statistically significant differences among kernels in the value of RMSE volts of the deformable mirror commands. When different kernel dimensions are compared, statistically significant differences are found, showing that RMSE volts of the deformable mirror commands are lower for 3 x 3 kernels when compared with those of dimensions 5 x 5 and 7 x 7. As far as the authors know, this is the first time that an AO system based on CNN has been developed for solar telescopes.	187.98408117255468
354.	Convolutional Neural Networks (CNNs), also known as deep learners have seen much success in the last few years due to the availability of large amounts of data and high-performance computational resources. A CNN can be trained effectively if large amounts of data are available as it enables a CNN to find the optimal set of features and weights that can achieve the highest generalization performance. However, due to the requirement of large data size, CNNs require a lot of resources for example running time and computational resources to achieve a reasonable performance. Additionally, unbalanced data makes it difficult to train a CNN effectively that can achieve good generalization performance. In order to alleviate these limitations, in this paper, we propose a novel ensemble of deep learners that learns by combining multiple deep learners trained on small strongly class associated input data effectively. We propose a novel methodology of generating random subspace through clustering input data and propose a measure which can classify each cluster as a strong data cluster and a balanced data cluster. A methodology is also proposed that balances all strong data clusters in the pool so that an architecturally simple CNN can be trained on all balanced data clusters simultaneously. Classification decisions on all trained CNNs are then fused through majority voting to generate class decisions of the ensemble. The performance of the proposed ensemble approach is evaluated on UCI benchmark datasets, and results are compared with existing state-of-the-art ensemble approaches. Significance testing was conducted to further validate the efficacy of the results and a significance test analysis is presented. (C) 2020 Elsevier Ltd. All rights reserved.	187.9840500270517
355.	Federated learning (FL) is a distributed deep learning method that enables multiple participants, such as mobile and IoT devices, to contribute a neural network while their private training data remains in local devices. This distributed approach is promising in the mobile systems where have a large corpus of decentralized data and require high privacy. However, unlike the common datasets, the data distribution of the mobile systems is imbalanced which will increase the bias of model. In this article, we demonstrate that the imbalanced distributed training data will cause an accuracy degradation of FL applications. To counter this problem, we build a self-balancing FL framework named Astraea, which alleviates the imbalances by 1) Z-score-based data augmentation, and 2) Mediator-based multi-client rescheduling. The proposed framework relieves global imbalance by adaptive data augmentation and downsampling, and for averaging the local imbalance, it creates the mediator to reschedule the training of clients based on Kullback-Leibler divergence (KLD) of their data distribution. Compared with FedAvg, the vanilla FL algorithm, Astraea shows +4.39 and +6.51 percent improvement of top-1 accuracy on the imbalanced EMNIST and imbalanced CINIC-10 datasets, respectively. Meanwhile, the communication traffic of Astraea is reduced by 75 percent compared to FedAvg.	187.9839663168658
356.	Most of the previous studies for bark recognition have focused on the extraction of LBP-like statistical features. Deep learning approach was not well studied because of the difficulty of acquiring large volume of bark image dataset. To overcome the bark dataset problem, this study utilizes the MobileNet which was trained with the ImageNet dataset. This study proposes two approaches. One is to extract features by the pixel-wise convolution and classify the features with SVM. The other is to tune the weights of the MobileNet by flexibly freezing layers. The experimental results with two public bark datasets, BarkTex and Trunk12, show that the proposed methods are effective in bark recognition. Especially the results of the flexible tunning method outperform state-of-the-art methods. In addition, it can be applied to mobile devices because the MobileNet is compact compared to other deep learning models.	187.98391844786488
357.	3-D pose estimation for texture-less objects remains a challenging problem. Previous works either focus on a template matching method to find the nearest template as a candidate, or construct a Hough forest, which utilizes the offset of patches to vote for the object location and pose. By contrast, in this paper, we propose a comprehensive framework to directly regress 3-D poses for the candidates, in which a convolutional neural network-based triplet network is trained to extract discriminating features from the binary images. To make the features suitable for the regression task, a pose-guided method and a regression constraint are employed with the constructed triplet network. We show that the constraint reaches the goal of creating the correlation between the features and 3-D poses. Once the expected features are obtained, the object pose could be efficiently regressed, by training a regression network with a simple structure. For symmetric objects, depth images are treated as an additional channel to feed the triplet network. Experiments on the LineMOD and our own datasets demonstrate our method with high regression precision and efficiency.	187.98388697362927
358.	Interest is increasing in the use of neural networks and deep-learning for on-board processing tasks in the space industry [1]. However development has lagged behind terrestrial applications for several reasons: space qualified computers have significantly less processing power than their terrestrial equivalents, reliability requirements are more stringent than the majority of applications deep-learning is being used for. The long requirements, design and qualification cycles in much of the space industry slows adoption of recent developments. GPUs are the first hardware choice for implementing neural networks on terrestrial computers, however no radiation hardened equivalent parts are currently available. Field Programmable Gate Array devices are capable of efficiently implementing neural networks and radiation hardened parts are available, however the process to deploy and validate an inference network is non-trivial and robust tools that automate the process are not available. We present an open source tool chain that can automatically deploy a trained inference network from the TensorFlow framework directly to the LEON 3, and an industrial case study of the design process used to train and optimise a deep-learning model for this processor. This does not directly change the three challenges described above however it greatly accelerates prototyping and analysis of neural network solutions, allowing these options to be more easily considered than is currently possible. Future improvements to the tools are identified along with a summary of some of the obstacles to using neural networks and potential solutions to these in the future.	187.98379050135605
359.	Recent advancements of performance-based wind design of tall buildings have placed increasing importance on effectively modeling of the nonlinear structural dynamic response under extreme storms. However, the numerical estimation of wind-induced nonlinear structural response based on the high-fidelity finite element model is computationally intensive due to its small time-step size and long simulation duration. To this end, the reduced-order modeling methodology using either physics-based analytical models or data-driven metamodels is widely applied to the simulation of nonlinear structural dynamics. With the rapid developments of machine learning techniques, the deep neural networks have recently become a popular data-driven approach for the efficient and accurate estimation of nonlinear structural responses. Due to a high demand on the quality and quantity of data, training the deep neural networks can become intractable. In this study, a knowledge-enhanced deep learning (KEDL) algorithm is proposed to simulate the wind-induced linear/nonlinear structural dynamic response. More specifically, the machine-readable knowledge in terms of both physics-based equations and/or semiempirical formulas is leveraged to enhance regularization mechanism during training of deep networks for structural dynamics. The KEDL methodology is data-efficient and robust to noise by effectively utilizing both the available input-output data and the prior knowledge on the structure of interest. In addition, the KEDL methodology is coupled with the wavelet-domain projection to simplify the input-output relationship, and hence to accelerate the training process. The data-efficient and noise-resistant characteristics of the KEDL methodology have been comprehensively investigated based on a single-degree-of-freedom (SDOF) system. Finally, it is clearly demonstrated that the trained knowledge-enhanced deep neural network presents both high simulation accuracy and computational efficiency in estimating the nonlinear dynamic response of a multidegree-of-freedom (MDOF) system under wind excitations. (c) 2020 American Society of Civil Engineers.	187.98370812006672
360.	Groundwater supports essential societal and ecological functions by acting as a reservoir that buffers against natural variability. Increasing water scarcity and climate variability have resulted in more intensive management of groundwater resources, but groundwater often remains difficult to understand and manage. With this in mind, we develop a simple platform that provides a straightforward, web-based user interface applicable to a wide variety of end-user scenarios. Groundwater behavior is modeled using the method of images in a new R package, anem, which serves as the engine for the web platform, anem-app, produced using R Shiny. Both tools allow users to define aquifer properties and pumping wells, view maps of hydraulic head, and simulate particle tracking under steady-state conditions. These tools have the advantage of being platform independent and open source, so that they are freely available to anyone with a web browser and internet connection (anem-app) or computing platform with R installed (anem). We designed both tools to lower the learning curve and up-front costs to building simple groundwater models. The simplicity of the web application allows exploration of groundwater behavior under various conditions, and should be especially valuable in low-budget applications where advanced analysis may not be practical or necessary. Integration with the R language allows for advanced analysis and deeper exploration of groundwater dynamics. In this manuscript, we describe how anem and anem-app are built in the R environment and demonstrate how they might be used by planners or stakeholders.	187.98367145075093
361.	In many real-world applications, an object can be described from multiple views or styles, leading to the emerging multi-view analysis. To eliminate the complicated (usually highly nonlinear) view discrepancy for favorable cross-view recognition and retrieval, we propose a Multi-view Linear Discriminant Analysis Network (MvLDAN) by seeking a nonlinear discriminant and view-invariant representation shared among multiple views. Unlike existing multi-view methods which directly learn a common space to reduce the view gap, our MvLDAN employs multiple feedforward neural networks (one for each view) and a novel eigenvalue-based multi-view objective function to encapsulate as much discriminative variance as possible into all the available common feature dimensions. With the proposed objective function, the MvLDAN could produce representations possessing: 1) low variance within the same class regardless of view discrepancy, 2) high variance between different classes regardless of view discrepancy, and 3) high covariance between any two views. In brief, in the learned multi-view space, the obtained deep features can be projected into a latent common space in which the samples from the same class are as close to each other as possible (even though they are from different views), and the samples from different classes are as far from each other as possible (even though they are from the same view). The effectiveness of the proposed method is verified by extensive experiments carried out on five databases, in comparison with the 19 state-of-the-art approaches.	187.9836535952458
362.	Optical Mark Recognition (OMR) is the process of electronically extracting intended data from marked fields, such as squares and bubbles fields, on printed forms. OMR is useful for applications in which large numbers of hand-filled forms need to be processed quickly and with a high degree of accuracy, for instance, reading the answer sheets of high-stakes tests. Nowadays, image processing techniques and advancement in computing could help to read the answer sheets, quickly and reducing operational costs. This work introduces a systematic procedure of image processing with two segmentation steps that conclude in the extraction and recognition of marks of answer sheets of Colombian High-Stakes Tests. Some preliminary results show that the accuracy is 99.83%, on average, in the first calibration stage, with 4 blocks of about 400 images, each one. A sampling procedure was performed to determine an adequate number of images to verify the performance of the method in the scenario of the application Saber 11 in the second semester of 2018. The conclusion of the exercise, with around 65.000 images, was 99.7% of accuracy, which was run in an 8 logical processors pc architecture, getting an average speed of 8 sheets per second. Thus making it suitable for real applications or for performing a labeling process for deep learning training.	187.98351074318077
363.	In this research, we propose a methodology for advert value calculation in CPM, CPC and CPA networks. Accurately estimating this value increases the three previous networks' incomes by selecting the most profitable advert. By increasing income, publishers are better paid and improved services are afforded to advertisers. To develop this methodology, we propose a system based on traditional Machine Learning methods and Deep Learning methods. The system has two inputs and one output. The inputs are the user visit and the data about the advertiser. The output is the advert value expressed in dollars. Deep Learning predicts model behavior more precisely for many supervised problems. The three experiments carried out allow us to conclude that DL is a supervised method that is very efficient in the classification of spam adverts and in the estimation of the CTR. In the prediction of online sales, DLNN have shown, on average, worse performance than cubist and random forest methods, although better performance than model tree, model rules and linear regression methods.	187.983486850058
364.	Single image superresolution has been a popular research topic in the last two decades and has recently received a new wave of interest due to deep neural networks. In this paper, we approach this problem from a different perspective. With respect to a downsampled low resolution image, we model a high resolution image as a combination of two components, a deterministic component and a stochastic component. The deterministic component can be recovered from the low-frequency signals in the downsampled image. The stochastic component, on the other hand, contains the signals that have little correlation with the low resolution image. We adopt two complementary methods for generating these two components. While generative adversarial networks are used for the stochastic component, deterministic component reconstruction is formulated as a regression problem solved using deep neural networks. Since the deterministic component exhibits clearer local orientations, we design novel loss functions tailored for such properties for training the deep regression network. These two methods are first applied to the entire input image to produce two distinct high-resolution images. Afterwards, these two images are fused together using another deep neural network that also performs local statistical rectification, which tries to make the local statistics of the fused image match the same local statistics of the groundtruth image. Quantitative results and a user study indicate that the proposed method outperforms existing state-of-the-art algorithms with a clear margin.	187.98348185753338
365.	Hyperspectral image (HSI) classification is an active and important research task driven by many practical applications. To leverage deep learning models especially convolutional neural networks (CNNs) for HSI classification, this paper proposes a simple yet effective method to extract hierarchical deep spatial feature for HSI classification by exploring the power of off-the-shelf CNN models, without any additional retraining or fine-tuning on the target data set. To obtain better classification accuracy, we further propose a unified metric learning-based framework to alternately learn discriminative spectral-spatial features, which have better representation capability and train support vector machine (SVM) classifiers. To this end, we design a new objective function that explicitly embeds a metric learning regularization term into SVM training. The metric learning regularization term is used to learn a powerful spectral-spatial feature representation by fusing spectral feature and deep spatial feature, which has small intraclass scatter but big between class separation. By transforming HSI data into new spectral-spatial feature space through CNN and metric learning, we can pull the pixels from the same class closer, while pushing the different class pixels farther away. In the experiments, we comprehensively evaluate the proposed method on three commonly used HSI benchmark data sets. State-of-the-art results are achieved when compared with the existing HSI classification methods.	187.98346531974892
366.	Contrary to the growing zest for bringing in place a complex detection methodology, aiming at improvement in performance of existing methodologies for detecting vehicles in aerial images, this novel piece of work sets forward a much simpler approach with superior results. It was found that methods that showed exemplary performance on common benchmark datasets otherwise, their performance dropped remarkably on aerial images. To achieve performance at par or comparable with the state-of-the-art methods on common benchmark datasets, several adaptations have been suggested in literature to existing methods, for detecting small vehicle instances in aerial images. This ranges from adaptations to the object proposal methods to introduction of more complex deep learning-based classifiers such as fast RCNN and faster RCNN. However, these methods have their own limitations along with the growing increase in system complexity. In this work, a novice, simple and accurate method has been proposed for the detection of small vehicles from aerial images. The experiments have been performed on the publicly accessible and diverse Vehicle Detection in Aerial Imagery (VEDAI) database. This novice technique utilizes Selective Search algorithm as the object proposal method in combination with a deep learning-based framework for classification, which comprises of a simple Convolutional Neural Network (CNN) architecture proposed in combination with a simple Deep Neural Network (DNN) architecture. The DNN utilizes Histogram of Oriented Gradients (HoG) feature input to generate output features that combine with the CNN feature map for final classification. This method is much simpler and achieves a significant accuracy of 96% in vehicle detection, which is much superior to any of the methods tried for aerial images in literature so far.	187.98332915942603
367.	COVID-19 is a novel virus, which has a fast spreading rate, and now it is seen all around the world. The case and death numbers are increasing day by day. Some tests have been used to determine the COVID-19. Chest X-ray and chest computerized tomography (CT) are two important imaging tools for determination and monitoring of COVID-19. And new methods have been searching for determination of the COVID-19. In this paper, the investigation of various multiresolution approaches in detection of COVID-19 is carried out. Chest X-ray images are used as input to the proposed approach. As recent trend in machine learning shifts toward the deep learning, we would like to show that the traditional methods such as multiresolution approaches are still effective. To this end, the well-known multiresolution approaches namely Wavelet, Shearlet and Contourlet transforms are used to decompose the chest X-ray images and the entropy and the normalized energy approaches are employed for feature extraction from the decomposed chest X-ray images. Entropy and energy features are generally accompanied with the multiresolution approaches in texture recognition applications. The extreme learning machines (ELM) classifier is considered in the classification stage of the proposed study. A dataset containing 361 different COVID-19 chest X-ray images and 200 normal (healthy) chest X-ray images are used in the experimental works. The performance evaluation is carried out by employing various metric namely accuracy, sensitivity, specificity and precision. As deep learning is mentioned, a comparison between proposed multiresolution approaches and deep learning approaches is also carried out. To this end, deep feature extraction and fine-tuning of pretrained convolutional neural networks (CNNs) are considered. For deep feature extraction, pretrained, ResNet50 model is employed. For classification of the deep features, the Support Vector Machines (SVM) classifier is used. The ResNet50 model is also used in the fine-tuning. The experimental works show that multiresolution approaches produced better performance than the deep learning approaches. Especially, Shearlet transform outperformed at all. 99.29% accuracy score is obtained by using Shearlet transform.	187.98328075082864
368.	We present an approach for safe, and object-independent human-to-robot handovers using real time robotic vision, and manipulation. We aim for general applicability with a generic object detector, a fast grasp selection algorithm, and by using a single gripper-mounted RGB-D camera, hence not relying on external sensors. The robot is controlled via visual servoing towards the object of interest. Putting a high emphasis on safety, we use two perception modules: human body part segmentation, and hand/finger segmentation. Pixels that are deemed to belong to the human are filtered out from candidate grasp poses, hence ensuring that the robot safely picks the object without colliding with the human partner. The grasp selection, and perception modules run concurrently in real-time, which allows monitoring of the progress. In experiments with 13 objects, the robot was able to successfully take the object from the human in 81.9% of the trials.	187.98319850214997
369.	The success of CNNs is accompanied by deep models and heavy storage costs. For compressing CNNs, we propose an efficient and robust pruning approach, cross-entropy pruning (CEP). Given a trained CNN model, connections were divided into groups in a group-wise way according to their corresponding output neurons. All connections with their cross-entropy errors below a grouping threshold were then removed. A sparse model was obtained and the number of parameters in the baseline model significantly reduced. This letter also presents a highest cross-entropy pruning (HCEP) method that keeps a small portion of weights with the highest CEP. This method further improves the accuracy of CEP. To validate CEP, we conducted the experiments on low redundant networks that are hard to compress. For the MNIST data set, CEP achieves an 0.08% accuracy drop required by LeNet-5 benchmark with only 16% of original parameters. Our proposed CEP also reduces approximately 75% of the storage cost of AlexNet on the ILSVRC 2012 data set, increasing the top-1 errorby only 0.4% and top-5 error by only 0.2%. Compared with three existing methods on LeNet-5, our proposed CEP and HCEP perform significantly better than the existing methods in terms of the accuracy and stability. Some computer vision tasks on CNNs such as object detection and style transfer can be computed in a high-performance way using our CEP and HCEP strategies.	187.98305065730756
370.	It is quite challenging to correctly identify entities such as disease names, symptoms, and drugs from Chinese online medical inquiry texts. On the one hand, traditional natural language related methods cannot be directly applied to the field of online medical inquiry. Although supervised or unsupervised learning algorithms provide an entity recognition strategy for medical inquiries on online platforms, these methods either rely extensively on specific knowledge sources or artificially-designed features, or have a strong self-adaptivity, can barely obtain fairly good entity recognition outcomes, and consequently have weak generalization. On the other hand, Chinese online medical inquiry data is characterized by a large volume and excessively rich unstructured data, medical entities are indeed distributed in a sparse way, and the Chinese characters and words are quite complicated. It is difficult to establish a robust model for the recognition of entities in Chinese online medical inquiry texts. Therefore, establishing a new deep neural network (OMINer-CE) is the attempt of this paper. First, in order to form a proper feature strategy, the basic features of other tasks are introduced, while extended features, such as continuous bag of word cluster (CBOWC) feature, are constructed. Second, the feature vectors of Chinese character and word fusion are introduced to reserve all the Chinese character information of original sequences while introducing Chinese word-based semantic information. Third, a context encoding layer and a label decoding layer are introduced; On the basis of the recurrent neural network model BiLSTM, a convolutional neural network (CNN) is added to learn more key local features of Chinese word context, and the attention mechanism is used to obtain the long-distance dependency of the Chinese words to form a OMINer model. Finally, the basic and extended feature vectors are integrated into the OMINer model, and the grammatical and semantic information contained in the labeled texts is obtained from different perspectives. Therefore, it considers the feature strategies of Chinese online medical platforms, and realizes a strong self-adaptivity by utilizing the deep neural network. It is showed by the experiments that preferably good performances can be realized by combining the CE basic and extended feature vectors in the BiLSTM of the OMINer model, suggesting that the OMINer-CE model improves the performance of recognizing entities in Chinese online medical inquiry texts. (C) 2020 Published by Elsevier B.V.	187.98291528312075
371.	Hyperspectral change detection (CD) can be effectively performed using deep-learning networks. Although these approaches require qualified training samples, it is difficult to obtain ground-truth data in the real world. Preserving spatial information during training is difficult due to structural limitations. To solve such problems, our study proposed a novel CD method for hyperspectral images (HSIs), including sample generation and a deep-learning network, called the recurrent three-dimensional (3D) fully convolutional network (Re3FCN), which merged the advantages of a 3D fully convolutional network (FCN) and a convolutional long short-term memory (ConvLSTM). Principal component analysis (PCA) and the spectral correlation angle (SCA) were used to generate training samples with high probabilities of being changed or unchanged. The strategy assisted in training fewer samples of representative feature expression. The Re3FCN was mainly comprised of spectral-spatial and temporal modules. Particularly, a spectral-spatial module with a 3D convolutional layer extracts the spectral-spatial features from the HSIs simultaneously, whilst a temporal module with ConvLSTM records and analyzes the multi-temporal HSI change information. The study first proposed a simple and effective method to generate samples for network training. This method can be applied effectively to cases with no training samples. Re3FCN can perform end-to-end detection for binary and multiple changes. Moreover, Re3FCN can receive multi-temporal HSIs directly as input without learning the characteristics of multiple changes. Finally, the network could extract joint spectral-spatial-temporal features and it preserved the spatial structure during the learning process through the fully convolutional structure. This study was the first to use a 3D FCN and a ConvLSTM for the remote-sensing CD. To demonstrate the effectiveness of the proposed CD method, we performed binary and multi-class CD experiments. Results revealed that the Re3FCN outperformed the other conventional methods, such as change vector analysis, iteratively reweighted multivariate alteration detection, PCA-SCA, FCN, and the combination of 2D convolutional layers-fully connected LSTM.	187.98291344064944
372.	The industrial process involving gas liquid flows is one of the most frequently encountered phenomena in the energy sectors. However, traditional methods are practically unable to reliably identify flow patterns if additional independent variables/parameters are to be considered rather than gas and liquid superficial velocities. In this paper, we reported an approach to predict flow pattern along upward inclined pipes (0-90 degrees) via deep learning neural networks, using accessible parameters as inputs, namely, superficial velocities of individual phase and inclination angles. The developed approach is equipped with deep learning neural network for flow pattern identification by experimental datasets that were reported in the literature. The predictive model was further validated by comparing its performance with well-established flow regime forecasting methods based on conventional flow regime maps. Besides, the intensity of key features in flow pattern prediction was identified by the deep learning algorithm, which is difficult to be captured by commonly used correlation approaches. (C) 2020 Elsevier Ltd. All rights reserved.	187.98287903240427
373.	Although great progress has been made in automatic speech recognition (ASR), significant performance degradation is still observed when recognizing multi-talker mixed speech. In this paper, we propose and evaluate several architectures to address this problem under the assumption that only a single channel of mixed signal is available. Our technique extends permutation invariant training (PIT) by introducing the front-end feature separation module with the minimum mean square error (MSE) criterion and the back-end recognition module with the minimum cross entropy (CE) criterion. More specifically, during training we compute the average MSE or CE over the whole utterance for each possible utterance-level output-target assignment, pick the one with the minimum MSE or CE, and optimize for that assignment. This strategy elegantly solves the label permutation problem observed in the deep learning based multi-talker mixed speech separation and recognition systems. The proposed architectures are evaluated and compared on an artificially mixed AMI dataset with both two- and three-talker mixed speech. The experimental results indicate that against the state-of-the-art single-talker speech recognition system our proposed architectures can cut the word error rate (WER) by relative 45.0% and 25.0% across all speakers when their energies are comparable, for two- and three-talker mixed speech, respectively. To our knowledge, this is the first work on the single-channel multi-talker mixed speech recognition on the challenging speaker-independent spontaneous large vocabulary continuous speech task.	187.98284802243876
374.	To reduce occurrences of emergency situations in large-scale interconnected power systems with large continuous disturbances, a preventive strategy for the automatic generation control (AGC) of power systems is proposed. To mitigate the curse of dimensionality that arises in conventional reinforcement learning algorithms, deep forest is applied to reinforcement learning. Therefore, deep forest reinforcement learning (DFRL) as a preventive strategy for AGC is proposed in this paper. The DFRL method consists of deep forest and multiple subsidiary reinforcement learning. The deep forest component of the DFRL is applied to predict the next systemic state of a power system, including emergency states and normal states. The multiple subsidiary reinforcement learning component, which includes reinforcement learning for emergency states and reinforcement learning for normal states, is applied to learn the features of the power system. The performance of the DFRL algorithm was compared to that of 10 other conventional AGC algorithms on a two-area load frequency control power system, a three-area power system, and the China Southern Power Grid. The DFRL method achieved the highest control performance. With this new method, both the occurrences of emergency situations and the curse of dimensionality can be simultaneously reduced.	187.98283137940828
375.	Measuring students performance and observing their learning behaviors are challenging tasks that can assist students and teachers in keeping track of progress in academic performance. Predicting student performance in mathematics has gained considerable attention from many researchers. Because a single tool may not be easily scalable from one context to another, several learning algorithms have been observed and compared for selecting an optimized prediction model. In this paper, we proposed a comparative study of the statistical analysis (SA) technique, machines learning (ML) algorithms, and a deep learning architecture for predicting student performance in mathematics. A proposed predictive structural equation modeling of SA, five superior classifiers in ML, and a graphical model for deep learning were executed and compared. Three datasets named, DS1, DS2, and DS3 were used in this analysis. We applied two main evaluation metrics, accuracy and predictive mean square error (PMSE), to measure the performance of the proposed models. On the three datasets, random forest produced the highest accuracy and the smallest PMSE which shows its potential as the best prediction model for the problem.	187.9827489079244
376.	Originated from distributed learning, federated learning enables privacy-preserved collaboration on a new abstracted level by sharing the model parameters only. While the current research mainly focuses on optimizing learning algorithms and minimizing communication overhead left by distributed learning, there is still a considerable gap when it comes to the real implementation on mobile devices. In this article, we start with an empirical experiment to demonstrate computation heterogeneity is a more pronounced bottleneck than communication on the current generation of battery-powered mobile devices, and the existing methods are haunted by mobile stragglers. Further, non-identically distributed data across the mobile users makes the selection of participants critical to the accuracy and convergence. To tackle the computational and statistical heterogeneity, we utilize data as a tuning knob and propose two efficient polynomial-time algorithms to schedule different workloads on various mobile devices, when data is identically or non-identically distributed. For identically distributed data, we combine partitioning and linear bottleneck assignment to achieve near-optimal training time without accuracy loss. For non-identically distributed data, we convert it into an average cost minimization problem and propose a greedy algorithm to find a reasonable balance between computation time and accuracy. We also establish an offline profiler to quantify the runtime behavior of different devices, which serves as the input to the scheduling algorithms. We conduct extensive experiments on a mobile testbed with two datasets and up to 20 devices. Compared with the common benchmarks, the proposed algorithms achieve 2-100x speedup epoch-wise, 2-7 percent accuracy gain and boost the convergence rate by more than 100 percent on CIFAR10.	187.98259648954314
377.	Item features play an important role in movie recommender systems, where recommendations can be generated by using explicit or implicit preferences of users on traditional features (attributes) such as tag, genre, and cast. Typically, movie features are human-generated, either editorially (e.g., genre and cast) or by leveraging the wisdom of the crowd (e.g., tag), and as such, they are prone to noise and are expensive to collect. Moreover, these features are often rare or absent for new items, making it difficult or even impossible to provide good quality recommendations. In this paper, we show that users' preferences on movies can be well or even better described in terms of the mise-en-scene features, i.e., the visual aspects of a movie that characterize design, aesthetics and style (e.g., colors, textures). We use bothMPEG-7 visual descriptors and Deep Learning hidden layers as examples of mise-en-scene features that can visually describe movies. These features can be computed automatically from any video file, offering the flexibility in handling new items, avoiding the need for costly and error-prone human-based tagging, and providing good scalability. We have conducted a set of experiments on a large catalog of 4K movies. Results show that recommendations based on mise-en-scene features consistently outperform traditional metadata attributes (e.g., genre and tag).	187.9824813046838
378.	This work explores the integration of airborne Light Detection and Ranging (LiDAR) data and WorldView-2 (WV2) images to classify the land cover of a subtropical forest area in Southern Brazil. Different deep and machine learning methods were used: one based on convolutional neural network (CNN) and three ensemble methods. We adopted both pixel- (in the case of CNN) and object-based approaches. The results demonstrated that the integration of LiDAR and WV2 data led to a significant increase (7% to 16%) in accuracies for all classifiers, with kappa coefficient (kappa) ranging from 0.74 for the random forest (RF) classifier associated with the WV2 dataset, to 0.92 for the forest by penalizing attributes (FPA) with the full (LiDAR + WV2) dataset. Using the WV2 dataset solely, the best kappa was 0.81 with CNN classifier, while for the LiDAR dataset, the best kappa was 0.8 with the rotation forest (RotF) algorithm. The use of LiDAR data was especially useful for the discrimination of vegetation classes because of the different height properties among them. In its turn, the WV2 data provided better performance for classes with less structure variation, such as field and bare soil. All the classification algorithms had a nearly similar performance: the results vary slightly according to the dataset used and none of the methods achieved the best accuracy for all classes. It was noticed that both datasets (WV2 and LiDAR) even when applied alone achieved good results with deep and machine learning methods. However, the advantages of integrating active and passive sensors were evident. All these methods provided promising results for land cover classification experiments of the study area in this work.	187.9824286455265
379.	Experimental performance on the task of relation extraction/classification has generally improved using deep neural network architectures. In which, data representation has been proven to be one of the most influential factors to the model's performance but still has many limitations. In this work, we take advantage of compressed information in the shortest dependency path (SDP) between two corresponding entities to classify the relation between them. We propose (i) a compositional embedding that combines several dominant linguistic as well as architectural features and (ii) dependency tree normalization techniques for generating rich representations for both words and dependency relations in the SDP. We also present a Convolutional Neural Network (CNN) model to process the proposed SDP enriched representation. Experimental results for both general and biomedical data demonstrate the effectiveness of compositional embedding, dependency tree normalization technique as well as the suitability of the CNN model.	187.98229778583334
380.	Buildings along riverbanks are likely to be affected by rising water levels, therefore the acquisition of accurate building information has great importance not only for riverbank environmental protection but also for dealing with emergency cases like flooding. UAV-based photographs are flexible and cloud-free compared to satellite images and can provide very high-resolution images up to centimeter level, while there exist great challenges in quickly and accurately detecting and extracting building from UAV images because there are usually too many details and distortions on UAV images. In this paper, a deep learning (DL)-based approach is proposed for more accurately extracting building information, in which the network architecture, SegNet, is used in the semantic segmentation after the network training on a completely labeled UAV image dataset covering multi-dimension urban settlement appearances along a riverbank area in Chongqing. The experiment results show that an excellent performance has been obtained in the detection of buildings from untrained locations with an average overall accuracy more than 90%. To verify the generality and advantage of the proposed method, the procedure is further evaluated by training and testing with another two open standard datasets which have a variety of building patterns and styles, and the final overall accuracies of building extraction are more than 93% and 95%, respectively.	187.98229209982497
381.	The laborious manual person ID annotation results in limited training data and increased difficulty in learning discriminative representations. Meanwhile, high dimensional deep features are not ready for fast indexing and matching. Those challenges hinder the application of person Re-Identification (ReID) in large-scale data. To conquer those challenges, we propose a novel training strategy to learn compact binary hash codes. To facilitate feature learning, person images are decomposed into body parts, which are then composed across images into new positive and negative training samples. Binary code quality restrictions are also applied the during training procedure. Requiring no extra annotation costs, our algorithm iteratively generates hard training samples by itself and makes discriminative hash code learning with a limited number of labeled data possible. We hence use "self-guided" to describe this training procedure. Extensive experiments are conducted on two large-scale person ReID datasets, i.e., Market1501 and MSMT17 with distractors, showing our method is competitive compared with recent works.	187.9822803444199
382.	Under efficiency improvement of road networks by utilizing advanced traffic signal control methods, intelligent transportation systems intend to characterize a smart city. Recently, due to significant progress in artificial intelligence, machine learning-based framework of adaptive traffic signal control has been highly concentrated. In particular, deep Q-learning neural network is a model-free technique and can be applied to optimal action selection problems. However, setting variable green time is a key mechanism to reflect traffic fluctuations such that time steps need not be fixed intervals in reinforcement learning framework. In this study, the authors proposed a dynamic discount factor embedded in the iterative Bellman equation to prevent from a biased estimation of action-value function due to the effects of inconstant time step interval. Moreover, action is added to the input layer of the neural network in the training process, and the output layer is the estimated action-value for the denoted action. Then, the trained neural network can be used to generate action that leads to an optimal estimated value within a finite set as the agents' policy. The preliminary results show that the trained agent outperforms a fixed timing plan in all testing cases with reducing system total delay by 20%..	187.98222933363718
383.	Finding potential security weaknesses in any complex IT system is an important and often challenging task best started in the early stages of the development process. We present a method that transforms this task for FPGA designs into a reinforcement learning (RL) problem. This paper introduces a method to generate a Markov Decision Process based RL model from a formal, high-level system description (formulated in the domain-specific language) of the system under review and different, quantified assumptions about the system's security. Probabilistic transitions and the reward function can be used to model the varying resilience of different elements against attacks and the capabilities of an attacker. This information is then used to determine a plausible data exfiltration strategy. An example with multiple scenarios illustrates the workflow. A discussion of supplementary techniques like hierarchical learning and deep neural networks concludes this paper.	187.98220077414
384.	Solar radiation (SR) is an important data for various applications such as climate, energy and engineering. Because of this, determination and estimation of temporal and spatial variability of SR has critical importance in order to make plans and organizations for the present and the future. In this study, a deep learning method is employed for estimating the SR over 30 stations located in Turkey. The astronomical factor, extraterrestrial radiation and climatic variables, sunshine duration, cloud cover, minimum temperature and maximum temperature were used as input attributes and the output was obtained as SR. The datasets of 34 stations, spanning the dates from 2001 to 2007, were used for training and testing the model, respectively, and simulated values were compared with ground-truth values. The overall coefficient of determination, root mean square error and mean absolute error were calculated as 0.980, 0.78 MJm(-2)day(-1) and 0.61 MJm(-2)day(-1), respectively. Consequently, DL model has yielded very precise and comparable results for estimating daily global SR. These results are generally better than or they are comparable to many previous studies reported in literature, so one can conclude that the method can be a good alternative and be successfully applied to similar regions. (C) 2018 Elsevier Ltd. All rights reserved.	187.98210552030054
385.	Background: A seizure prediction system can detect seizures prior to their occurrence and allow clinicians to provide timely treatment for patients with epilepsy. Research on seizure prediction has progressed from signal processing analyses to machine learning. However, most prediction methods are hand-engineered and have high computational complexity, increasing the difficulty of obtaining real-time predictions. Some forecasting and early warning methods have achieved good results in the short term but have low applicability in practical situations over the long term. New methods: First, electroencephalogram (EEG) time series were converted into two-dimensional images for multichannel fusion. A feasible method, a long-term recurrent convolutional network (LRCN), was proposed to create a spatiotemporal deep learning model for predicting epileptic seizures. The convolutional network block was used to automatically extract deep features from the data. The long short-term memory (LSTM) block was incorporated into learning a time sequence for identifying the preictal segments. New network settings and a postprocessing strategy were proposed in the seizure prediction model. Results: The deep seizure prediction model achieved an accuracy of 93.40%, prediction sensitivity of 91.88% and specificity of 86.13% in segment-based evaluations. For the event-based evaluations, 164 seizures were predicted. The proposed method provides high sensitivity and a low false prediction rate (FPR) of 0.04 F P/h. Comparison with existing methods: We employed different methods, including the LRCN, deep learning and traditional machine learning methods, and compared them using the same data in this paper. Overall, the LRCN offers approximately 5-9% increased sensitivity and specificity. Conclusion: This study describes the LRCN network for analyzing EEG data to predict epileptic seizures, thereby enabling the implementation of an early warning system that detects epileptic seizures before they occur in clinical applications.	187.98210212092516
386.	Adaptive radiotherapy (RT) planning requires segmentation of organs for adapting the RT treatment plan to changes in the patient's anatomy. Daily imaging is often done using cone-beam CT (CBCT) imaging devices which produce images of considerably lower quality than CT images, due to scatter and artifacts. Involuntary patient motion during the comparably long CBCT image acquisition may cause misalignment artifacts. In the pelvis, most severe artifacts stem from motion of air and soft tissue boundaries in the bowel, which appear as streaking in the reconstructed images. In addition to low soft tissue contrast, this makes segmentation of organs close to the bowel such as bladder and uterus even more difficult. Deep learning (DL) methods have shown to be promising for difficult segmentation tasks. In this work, we investigate different, artifact-driven sampling schemes that incorporate domain knowledge into the DL training. However, global evaluation metrics such as the Dice score, often used in DL segmentation research, reveal little information about systematic errors and no clear perspective how to improve the training. Using slice-wise Dice scores, we find a clear difference in performance on slices with and without air detected. Moreover, especially when applied in a curriculum training scheme, the specific sampling of slices on which air has been detected might help to increase robustness of deep neural networks towards artifacts while maintaining performance on artifact-free slices.	187.98206790700937
387.	Deep learning based methods have been widely used in industrial recommendation systems (RSs). Previous works adopt an Embedding&MLP paradigm: raw features are embedded into low-dimensional vectors, which are then fed on to MLP for final recommendations. However, most of these works just concatenate different features, ignoring the sequential nature of users' behaviors. In this paper, we propose to use the powerful Transformer model to capture the sequential signals underlying users' behavior sequences for recommendation in Alibaba. Experimental results demonstrate the superiority of the proposed model, which is then deployed online at Taobao and obtain significant improvements in online Click-Through-Rate (CTR) comparing to two baselines.	187.98200984075206
388.	Magnetic resonance imaging (MRI) is widely used to get the information of anatomical structure and physiological function with the advantages of high resolution and non-invasive scanning. But the long acquisition time limits its application. To reduce the time consumption of MRI, compressed sensing (CS) theory has been proposed to reconstruct MRI images from undersampled k-space data. But conventional CS methods mostly use iterative methods that take lots of time. Recently, deep learning methods are proposed to achieve faster reconstruction, but most of them only pay attention to a single domain, such as the image domain or k-space. To take advantage of the feature representation in different domains, we propose a cross-domain method based on deep learning, which first uses convolutional neural networks (CNNs) in the image domain, k-space and wavelet domain simultaneously. The combined order of the three domains is also first studied in this work, which has a significant effect on reconstruction. The proposed IKWI-net achieves the best performance in various combinations, which utilizes CNNs in the image domain, k-space, wavelet domain and image domain sequentially. Compared with several deep learning methods, experiments show it also achieves mean improvements of 0.91 dB in peak signal-to-noise ratio (PSNR) and 0.005 in structural similarity (SSIM).	187.98192259166171
389.	Person Re-Identification has received extensive study in the past few years and achieves impressive progress. Recent outstanding methods extract discriminative features by slicing feature maps of deep neural network into several stripes. Still there have improvement on feature fusion and metric learning strategy which can help promote slice-based methods. In this paper, we propose a novel framework that is end-to-end trainable, called Multi-level Slice-based Network (MSN), to capture features both in different levels and body parts. Our model consists of a dual-branch network architecture, one branch for global feature extraction and the other branch for local ones. Both branches process multi-level features using pyramid feature alike module. By concatenating the global and local features, distinctive features are exploited and properly compared. Also, our proposed method creatively introduces a triplet-center loss to elaborate combined loss function, which helps train the joint-learning network. By demonstrating the comprehensive experiments on the mainstream evaluation datasets including Market-1501, DukeMTMC, CUHK03, it indicates that our proposed model robustly achieves excellent performance and outperforms many of existing approaches. For example, on DukeMTMC dataset in single-query mode, we obtain a great result of Rank-1/mAP = 85.9%(+1.0%)/74.2%(+4.7%).	187.98192059526812
390.	Review sentiment influences purchase decisions and indicates user satisfaction. Inferring the sentiment from reviews is an essential task in Natural Language Processing and has managerial implications for improving customer satisfaction and item quality. Traditional approaches to polarity classification use bag-of-words techniques and lexicons combined with machine learning. These approaches suffer from an inability to capture semantics and context. We propose a Deep Learning solution called OSLCFit (Organic Simultaneous LSTM and CNN Fit). In our architecture, we include all the components of a CNN until but not including the final fully connected layer and do the same in case of a bi-directional LSTM. The final fully connected layer in our architecture consists of fixed length features from the CNN, and features for both variable length and temporal dependencies from the bi-directional LSTM. The solution fine-tunes Language Model embeddings for the specific task of polarity classification using transfer learning, enabling the capture of semantics and context. The key contribution of this paper is the combination of features from both a CNN and a bi-directional LSTM into a single architecture with a single optimizer. This combination forms an organic combination and uses embeddings fine-tuned to the reviews for the specific purpose of sentiment polarity classification. The solution is benchmarked on six different datasets such as SMS Spam, YouTube Spam, Large Movie Review Corpus, Stanford Sentiment Treebank, Amazon Cellphone & Accessories and Yelp, where it beats existing benchmarks and scales to large datasets. The source code is available for the purposes of reproducible research on GitHub. (C) 2020 Elsevier Ltd. All rights reserved.	187.9818332317132
391.	We present a novel theoretical framework for computing large, adaptive learning rates. Our framework makes minimal assumptions on the activations used and exploits the functional properties of the loss function. Specifically, we show that the inverse of the Lipschitz constant of the loss function is an ideal learning rate. We analytically compute formulas for the Lipschitz constant of several loss functions, and through extensive experimentation, demonstrate the strength of our approach using several architectures and datasets. In addition, we detail the computation of learning rates when other optimizers, namely, SGD with momentum, RMSprop, and Adam, are used. Compared to standard choices of learning rates, our approach converges faster, and yields better results.	187.9818237625244
392.	In interactive e-learning environments such as Intelligent Tutoring Systems, there are pedagogical decisions to make at two main levels of granularity: whole problems and single steps. Recent years have seen growing interest in data-driven techniques for such pedagogical decision making, which can dynamically tailor students' learning experiences. Most existing data-driven approaches, however, treat these pedagogical decisions equally, or independently, disregarding the long-term impact that tutor decisions may have across these two levels of granularity. In this paper, we propose and apply an offline, off-policy Gaussian Processes based Hierarchical Reinforcement Learning (HRL) framework to induce a hierarchical pedagogical policy that makes decisions at both problem and step levels. In an empirical classroom study with 180 students, our results show that the HRL policy is significantly more effective than a Deep Q-Network (DQN) induced policy and a random yet reasonable baseline policy.	187.9817780052913
393.	Deep learning techniques have received much attention in the area of image denoising. However, there are substantial differences in the various types of deep learning methods dealing with image denoising. Specifically, discriminative learning based on deep learning can ably address the issue of Gaussian noise. Optimization models based on deep learning are effective in estimating the real noise. However, there has thus far been little related research to summarize the different deep learning techniques for image denoising. In this paper, we offer a comparative study of deep techniques in image denoising. We first classify the deep convolutional neural networks (CNNs) for additive white noisy images; the deep CNNs for real noisy images; the deep CNNs for blind denoising and the deep CNNs for hybrid noisy images, which represents the combination of noisy, blurred and low-resolution images. Then, we analyze the motivations and principles of the different types of deep learning methods. Next, we compare the state-of-the-art methods on public denoising datasets in terms of quantitative and qualitative analyses. Finally, we point out some potential challenges and directions of future research.	187.98172503572272
394.	Automatic dense labeling of multispectral satellite images facilitates faster map update process. Water objects are essential elements of a geographic map. While modern dense labeling methods perform robust segmentation of such objects like roads, buildings, and vegetation, dense labeling of hydrographic regions remains a challenging problem. Water objects change their surface albedo, color, and reflection in different weather and different seasons. Moreover, rivers and lakes can change their boundaries after floods or d roughts. Robust documentation of such seasonal changes is an essential task in the field of analysis of satellite imagery. Due to the high variance in water object appearance, their segmentation is usually performed manually by a human operator. Recent advances in machine learning have made possible robust segmentation of static objects such as buildings and roads. To the best of our knowledge, there is little research in the modern literature regarding dense labeling of water regions. This paper is focused on the development of a deep-learning-based method for dense labeling of hydrographic in aerial and satellite imagery. We use the GeoGAN framework(1) and MobileNetV2(2) as the starting point for our research. The GeoGAN framework uses an aerial image as an input to generate pixel-level annotations of five object c lasses: building, low vegetation, high vegetation, road, and car. The GeoGAN framework leverages two deep learning approaches to ensure robust labeling: a generator with skip connections(3) and Generative Adversarial Networks.(4) A generator with skip connections performs image -> label translation using feed-forward connections between convolutional and deconvolutional layers of the same depth. A GAN framework consists of two competing networks: a generator and a discriminator. The adversarial loss improves the quality of the resulting dense labeling. We made the following contributions to the GeoGAN framework: (1) new MobileNetV2-based generator, (2) adversarial loss function. We term the resulting framework as HydroGAN. We evaluate our HydroGAN model using a new HydroViews dataset focused on dense labeling of areas that are subject to severe flooding during the spring season. The evaluation results are encouraging and demonstrate that our HydroGAN model competes with the state-of-the-art models for dense labeling of aerial and satellite imagery. The evaluation demonstrates that our model can generalize from the training data to previously unseen samples. The developed HydroGAN model is capable of performing dense labeling of water objects in different seasons. We made our model publicly available*.	187.9815875950787
395.	Deep learning is well-known for extracting high-level abstract features from a large amount of raw data without relying on prior knowledge, which is potentially attractive in forecasting financial time series. Long short-term memory (LSTM) networks are deemed as state-of-the-art techniques in sequence learning, which are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We propose a novel methodology of deep learning prediction, and based on this, construct a deep learning hybrid prediction model for stock markets-CEEMD-PCA-LSTM. In this model, complementary ensemble empirical mode decomposition (CEEMD), as a sequence smoothing and decomposition module, can decompose the fluctuations or trends of different scales of time series step by step, generating a series of intrinsic mode functions (IMFs) with different characteristic scales. Then, with retaining the most of information on raw data, PCA reduces dimension of the decomposed IMFs component, eliminating the redundant information and improving prediction response speed. After that, high-level abstract features are separately fed into LSTM networks to predict closing price of the next trading day for each component. Finally, synthesizing the predicted values of individual components is utilized to obtain a final predicted value. The empirical results of six representative stock indices from three types of markets indicate that our proposed model outperforms benchmark models in terms of predictive accuracy, i.e., lower test error and higher directional symmetry. Leveraging key research findings, we perform trading simulations to validate that the proposed model outperforms benchmark models in both absolute profitability performance and risk-adjusted profitability performance. Furthermore, model robustness test unveils the more stable robustness compared to benchmark models. (C) 2020 Elsevier Ltd. All rights reserved.	187.98157653806246
396.	Analysis of untargeted gas-chromatographic data is time consuming. With the earlier introduction of the PARAFAC2 (PARAllel FACtor analysis 2) based PARADISe (PARAFAC2 based Deconvolution and Identification System) approach in 2017, this task was made considerably more time-efficient. However, there are still a number of manual steps in the analysis which require data analytical expertise. One of these is the need to define whether or not each PARAFAC2 resolved component represents a peak suitable for integration. As the peaks may change in both shape and location on the elution time-axis, this presents a problem which cannot be readily solved by applying a linear classifier, such as PLS-DA (Partial Least Squares regression for Discriminant Analysis). As part of our ongoing efforts to further automate analysis of Gas Chromatography with Mass Spectrometry (GC-MS), we therefore explore a convolutional neural network classifier, capable of handling these shifts and variations in shape. The theory of convolutional neural networks and application on vector samples is briefly explained, and the performance is tested against a PLS-DA classifier, a shallow artificial neural network and a locally weighted regression model. The models are built on a training set with PARAFAC2 resolved components from eight different aroma related GC-MS runs with a total of over 70,000 elution profile samples, and validated using another, independent, GC-MS dataset. Based on Receiver Operating Characteristic curves (ROC) and manual analysis of the misclassified cases, it is shown that the convolutional network consistently outperforms the competing models, yielding an Area Under the Curve (AUC) value of 0.95 for peak classification. Examples are given illustrating that this new approach provides convincing means to automatically assess and evaluate modelled elution profiles of chromatographic data and thereby remove this laborious manual step.	187.9815498439863
397.	Health-related data is stored in a number of repositories that are managed and controlled by different entities. For instance, Electronic Health Records are usually administered by governments. Electronic Medical Records are typically controlled by health care providers, whereas Personal Health Records are managed directly by patients. Recently, Blockchain-based health record systems largely regulated by technology have emerged as another type of repository. Repositories for storing health data differ from one another based on cost, level of security and quality of performance. Not only has the type of repositories increased in recent years, but the quantum of health data to be stored has increased. For instance, the advent of wearable sensors that capture physiological signs has resulted in an exponential growth in digital health data. The increase in the types of repository and amount of data has driven a need for intelligent processes to select appropriate repositories as data is collected. However, the storage allocation decision is complex and nuanced. The challenges are exacerbated when health data are continuously streamed, as is the case with wearable sensors. Although patients are not always solely responsible for determining which repository should be used, they typically have some input into this decision. Patients can be expected to have idiosyncratic preferences regarding storage decisions depending on their unique contexts. In this paper, we propose a predictive model for the storage of health data that can meet patient needs and make storage decisions rapidly, in real-time, even with data streaming from wearable sensors. The model is built with a machine learning classifier that learns the mapping between characteristics of health data and features of storage repositories from a training set generated synthetically from correlations evident from small samples of experts. Results from the evaluation demonstrate the viability of the machine learning technique used.	187.9815486295455
398.	High resolution magnetic resonance (MR) imaging is desirable in many clinical applications due to its contribution to more accurate subsequent analyses and early clinical diagnoses. Single image super-resolution (SISR) is an effective and cost efficient alternative technique to improve the spatial resolution of MR images. In the past few years, SISR methods based on deep learning techniques, especially convolutional neural networks (CNNs), have achieved the state-of-the-art performance on natural images. However, the information is gradually weakened and training becomes increasingly difficult as the network deepens. The problem is more serious for medical images because lacking high quality and effective training samples makes deep models prone to underfitting or overfitting. Nevertheless, many current models treat the hierarchical features on different channels equivalently, which is not helpful for the models to deal with the hierarchical features discriminatively and targetedly. To this end, we present a novel channel splitting network (CSN) to ease the representational burden of deep models. The proposed CSN model divides the hierarchical features into two branches, i.e., residual branch and dense branch, with different information transmissions. The residual branch is able to promote feature reuse, while the dense branch is beneficial to the exploration of new features. Besides, we also adopt the merge and run mapping to facilitate information integration between different branches. The extensive experiments on various MR images, including proton density (PD), T1, and T2 images, show that the proposed CSN model achieves superior performance over other state-of-the-art SISR methods.	187.98152072904114
399.	Deep learning (DL) methods and architectures have been the state-of-the-art classification algorithms for computer vision and natural language processing problems. However, the successful application of these methods in motor imagery (MI) brain-computer interfaces (BCIs), in order to boost classification performance, is still limited. In this paper, we propose a classification framework for MI data by introducing a new temporal representation of the data and also utilizing a convolutional neural network (CNN) architecture for classification. The new representation is generated from modifying the filter-bank common spatial patterns method, and the CNN is designed and optimized accordingly for the representation. Our framework outperforms the best classification method in the literature on the BCI competition IV-2a 4-class MI data set by 7% increase in average subject accuracy. Furthermore, by studying the convolutional weights of the trained networks, we gain an insight into the temporal characteristics of EEG.	187.98151885845454
400.	In this paper, we focused on designing a system that can guide and train a user in painting an art work. Initially, we aim to develop a system which can guide a user with basic strokes of Korean language calligraphy. The proposed system is implemented in a sequence of three steps. Firstly, we collected the data from the surfaces of the canvas and different orientations of a painting brush. Then based on the data, a relationship is established among the collected parameters by building a machine learning model. Finally, actuators attached with the handle of the brush provides the vibrotactile and force feedback based on the built model. The actuator guides the user in order to paint the required object.	187.98142649258864
401.	The novel coronavirus (COVID-19) has significantly spread over the world and comes up with new challenges to the research community. Although governments imposing numerous containment and social distancing measures, the need for the healthcare systems has dramatically increased and the effective management of infected patients becomes a challenging problem for hospitals. Thus, accurate short-term forecasting of the number of new contaminated and recovered cases is crucial for optimizing the available resources and arresting or slowing down the progression of such diseases. Recently, deep learning models demonstrated important improvements when handling time-series data in different applications. This paper presents a comparative study of five deep learning methods to forecast the number of new cases and recovered cases. Specifically, simple Recurrent Neural Network (RNN), Long short-term memory (LSTM), Bidirectional LSTM (BiLSTM), Gated recurrent units (GRUs) and Variational AutoEncoder (VAE) algorithms have been applied for global forecasting of COVID-19 cases based on a small volume of data. This study is based on daily confirmed and recovered cases collected from six countries namely Italy, Spain, France, China, USA, and Australia. Results demonstrate the promising potential of the deep learning model in forecasting COVID-19 cases and highlight the superior performance of the VAE compared to the other algorithms.	187.98124708942782
402.	Deep neural network is an important and effective approach to discover patterns inside data. Most existing neural networks, like deep neural network and convolutional neural network, have a fixed network connection among neurons. This will cause overfitting problems and long training time. This article discusses an algorithm to combat these problems, through creating and removing connections during training, leading to faster training and fewer symmetric problems. This enables the network to adapt itself to the proper number of neurons according to the dataset. It greatly speeds up training process, so it is useful for large datasets and deep networks. This method is simple to implement and requires less memory and computing power than existing machine learning algorithm. It also has good results in machine learning problems.	187.98116468193484
403.	Zero-shot learning (ZSL) aims to recognize objects without seeing any visual instances by learning knowledge transfer between seen and unseen classes. Attributes, which denote high-level visual entities or visual characteristics, have been widely utilized as intermediate embedding space for knowledge transfer in a majority of existing ZSL approaches and have shown impressive performance. Attribute based ZSL approaches, which introduce an intermediate embedding space of attributes for knowledge transfer, have shown impressive performance. However, providing attribute annotations for unseen classes at test time is time-consuming and labor-intensive. Besides, directly using attributes as intermediation (embedding space) for knowledge transfer and zero-shot prediction inevitably leads to the projection domain shift and hubness problems. In this paper, we propose a novel multi-view deep neural network, termed Fusion by Synthesis (FS), which leverages word embeddings of classes as complementary for attributes and performs zero-shot prediction by fusing the word embeddings of unseen classes and the synthesized attributes in the visual feature space. Specifically, in the training phase, by considering the visual features, attributes and word embeddings as three different views of visual instances, FS allocates each view with a denoising auto-encoder to simultaneously ensures robust view-specific reconstructions and cross-view synthesizing, while preserving the discrimination of class labels. During testing, FS can synthesize the absent attributes for unseen classes and fuse them with word embeddings to the visual feature space to perform zero-shot prediction. Besides, FS is flexible to learn with partial views, where either attribute view or word embedding view is missing during training. Moreover, FS is flexible to synthesize either the missing view of attributes or word embeddings from the provided view. Extensive experiments on six benchmark datasets on both image classification and action recognition show that FS is advantaged to fuse multi-view data by synthesis and achieves superior performance compared with the state-of-the-art ZSL methods. (C) 2019 Elsevier B.V. All rights reserved.	187.98115414112934
404.	We present a generic unsupervised method to increase the discriminative power of image vectors obtained from a broad family of deep neural networks for object retrieval. This goal is accomplished by simultaneously selecting and weighting informative deep convolutional features using the replicator equation, commonly used to capture the essence of selection in evolutionary game theory. The proposed method includes three major steps: First, efficiently detecting features within Regions of Interest (ROIs) using a simple algorithm, as well as trivially collecting a subset of background features. Second, assigning unassigned features by optimizing a standard quadratic problem using the replicator equation. Finally, using the replicator equation again in order to partially address the issue of feature burstiness. We provide theoretical time complexity analysis to show that our method is efficient. Experimental results on several common object retrieval benchmarks using both pre-trained and fine-tuned deep networks show that our method compares favorably to the state-of-the-art. We also publish an easy-to-use Matlab implementation of the proposed method for reproducing our results. (C) 2018 Elsevier Ltd. All rights reserved.	187.98109532820285
405.	Long short-term memory (LSTM) networks have recently shown remarkable performance in several tasks that are dealing with natural language generation, such as image captioning or poetry composition. Yet, only few works have analyzed text generated by LSTMs in order to quantitatively evaluate to which extent such artificial texts resemble those generated by humans. We compared the statistical structure of LSTM-generated language to that of written natural language, and to those produced by Markov models of various orders. In particular, we characterized the statistical structure of language by assessing word-frequency statistics, long-range correlations, and entropy measures. Our main finding is that while both LSTM- and Markov-generated texts can exhibit features similar to real ones in their word-frequency statistics and entropy measures, LSTM-texts are shown to reproduce long-range correlations at scales comparable to those found in natural language. Moreover, for LSTM networks, a temperature-like parameter controlling the generation process shows an optimal value-for which the produced texts are closest to real language-consistent across different statistical features investigated.	187.98108670476242
406.	Deep learning has been successfully applied to surprisingly different domains. Researchers and practitioners are employing trained deep learning models to enrich our knowledge. Transcription factors (TFs) are essential for regulating gene expression in all organisms by binding to specific DNA sequences. Here, we designed a deep learning model named SemanticCS (Semantic ChIP-seq) to predict TF binding specificities. We trained our learning model on an ensemble of ChIP-seq datasets (Multi-TF-cell) to learn useful intermediate features across multiple TFs and cells. To interpret these feature vectors, visualization analysis was used. Our results indicate that these learned representations can be used to train shallow machines for other tasks. Using diverse experimental data and evaluation metrics, we show that SemanticCS outperforms other popular methods. In addition, from experimental data, SemanticCS can help to identify the substitutions that cause regulatory abnormalities and to evaluate the effect of substitutions on the binding affinity for the RXR transcription factor. The online server for SemanticCS is freely available at http://qianglab.scst.suda.edu.cn/semanticCS/.	187.98105168037074
407.	Pointly-supervised learning is an important topic for scene parsing, as dense annotation is extremely expensive and hard to scale. The state-of-the-art method harvests pseudo labels by applying thresholds upon softmax outputs (logits). There are two issues with this practice: (1) Softmax output does not necessarily reflect the confidence of the network output. (2) There is no principled way to decide on the optimal threshold. Tuning thresholds can be time-consuming for deep neural networks. Our method, by contrast, builds upon uncertainty measures instead of logits and is free of threshold tuning. We motivate the method with a large-scale analysis of the distribution of uncertainty measures, using strong models and challenging databases. This analysis leads to the discovery of a statistical phenomenon called uncertainty mixture. Specifically speaking, for each independent category, the distribution of uncertainty measures for unlabeled points is a mixture of two components (certain v.s. uncertain samples). The phenomenon of uncertainty mixture is surprisingly ubiquitous in real-world datasets like PascalContext and ADE20k. Inspired by this discovery, we propose to decompose the distribution of uncertainty measures with a Gamma mixture model, leading to a principled method to harvest reliable pseudo labels. Beyond that, we assume the uncertainty measures for labeled points are always drawn from the certain component. This amounts to a regularized Gamma mixture model. We provide a thorough theoretical analysis of this model, showing that it can be solved with an EM-style algorithm with convergence guarantee. Our method is also empirically successful. On PascalContext and ADE20k, we achieve clear margins over the baseline, notably with no threshold tuning in the pseudo label generation procedure. On the absolute scale, since our method collaborates well with strong baselines, we reach new state-of-the-art performance on both datasets.	187.9810237304914
408.	Single-image super-resolution (SISR) is a classic problem in the image processing community, which aims at generating a high-resolution image from a low-resolution one. In recent years, deep learning based SISR methods emerged and achieved a performance leap than previous methods. However, because the evaluation metrics of SISR methods is peak signal-to-noise ratio (PSNR), previous methods usually choose L2-norm as the loss function. This leads to a significant improvement in the final PSNR value but little improvement in perceptual quality. In this paper, in order to achieve better results in both perceptual quality and PSNR values, we propose an objective quality assessment driven SISR method. First, we propose a novel full-reference image quality assessment approach for SISR and employ it as a loss function, namely super-resolution image quality assessment (SR-IQA) loss. Then, we combine SR-IQA loss with L2-norm to guide our proposed SISR method to achieve better results. Besides that, our proposed SISR method consists of several proposed highway units. Furthermore, in order to verify the generalization ability of our new kind of loss function, we integrate SR-IQA loss to generative adversarial networks based SR method and achieve better perceptual quality. Experimental results prove that our proposed SISR method achieves better performance than other methods both qualitatively and quantitatively in most of the cases.	187.9810141986788
409.	Unexpected falls can result in severe injuries to disabled individuals who can barely maintain the balance of themselves. In this paper, a deep learning-based method for fall detection on the rehabilitation walking-aid robot was proposed. The goal of this method is to provide a real-time detector for the walking-aid robot so it can take prevention measures when the fall happened. The deep neural network with error back propagation to update the weight of each feature. The data set used in this paper was obtained upon the prototype of a walking-aid robot. The real-time motion data of the user's waist can be obtained by multiple sensors mounted on the walking-aid robot. Extract the motion features from the acquired data and tag it as normal or abnormal (potential to falling) feature, these two parts of data compose to a sample. Divide the whole data set into two parts to train and test the neural network. It turns out the accuracy of this trained neural network can be 95.8%. In the end, the effect of the parameter and hyper-parameters of the neural network was discussed.	187.98085227152168
410.	The article deals with mass media techniques based on the algorithms of artificial intelligence, principles of machine learning and deep learning based on neural networks, and recommenders. The authors provide an analytical review of experiences of applying these techniques in various spheres, namely, data processing and analysis, automated production of reports on current events and facts, interactive communication with audience, tracking newsworthy events, fact-checking, visual discovery, video content production, and others. The mass media techniques are demonstrated by the list of examples of Reuters News Tracer, Wordsmith, Heliograf, Perspective (an interface of applied programming), Newswhip, Quackbot, Guardian Chatbot, Wibbitz, Factmata, et al. Factmata is given special attention to as a complex approach to algorithmization of the Media that includes such methods as contextualization of statements, arguments and stories, and keeping a blacklist of domains which the algorithms mark as hateful, hyperpartisan, toxic, or fake news. The authors note that machine learning of algorithms for generating and analyzing texts is becoming easily accessible. Moreover, the new generation of algorithms based on artificial intelligence is able to identify text sentiment. The analysis of the impact of the media environment, including such factors as echo chamber and filter bubble, on information users shows that information can now be compared to a drug which is almost legal and easily available for use by any social group, and its users, due to targeting and personalization, are transforming into its "ideal consumers".	187.98079651490733
411.	Depth image super-resolution (DISR) is an effective solution to improve the quality of depth images captured by real world low-cost cameras. In this paper, we propose a multi-scale symmetric network with the correlation-controlled color guidance block (CCGB) for DISR. The proposed network consists of two multi-scale sub-networks to respectively provide guidance and estimate depth. A symmetric unit (SU), which is a mini-encoder-decoder structure with residual learning, is designed and used as a basic network atom. The encoder part in SU aims to extract essential features, while the decoder part works to restore edge details. The way the SU processes information matches well with the textureless and sharpedge characteristics of depth images. The two sub-networks present a high-level symmetric structure connected by dense guidance links in between. Based on the correlation analyses between the two subnetworks, each guidance link will transfer information trough a CCGB designed to implement channel-wise re-weighting mechanism. The accurate color guidance from CCGB helps avoiding artifacts introduced by non-co-occurrence of depth discontinuities and color edges. Experimental results demonstrate the superiority of the proposed method over several state-of-the-art DISR works. (C) 2020 Elsevier Ltd. All rights reserved.	187.9807077770709
412.	Geometric deep learning provides a principled and versatile manner for integration of imaging and non-imaging modalities in the medical domain. Graph Convolutional Networks (GCNs) in particular have been explored on a wide variety of problems such as disease prediction, segmentation, and matrix completion by leveraging large, multi-modal datasets. In this paper, we introduce a new spectral domain architecture for deep learning on graphs for disease prediction. The novelty lies in defining geometric 'inception modules' which are capable of capturing intra- and inter-graph structural heterogeneity during convolutions. We design filters with different kernel sizes to build our architecture. We show our disease prediction results on two publicly available datasets. Further, we provide insights on the behaviour of regular GCNs and our proposed model under varying input scenarios on simulated data.	187.9806835113333
413.	In recent years, deep reinforcement learning (DRL) has made impressive achievements in many fields. However, existing DRL algorithms usually require a large amount of exploration to obtain a good action policy. In addition, in many complex situations, the reward function cannot be well designed to meet task requirements. These two problems will make it difficult for DRL to learn a good action policy within a relatively short period. The use of expert data can provide effective guidance and avoid unnecessary exploration. This study proposes a deep imitation reinforcement learning (DIRL) algorithm that uses a certain amount of expert demonstration data to speed up the training of DRL. In the proposed method, the learning agent imitates the experts action policy by learning from demonstration data. After imitation learning, DRL is used to optimise the action policy in a self-learning way. By experimental comparison on a video game called the Mario racing game, it is shown that the proposed DIRL algorithm with expert demonstration data can obtain much better performance than previous DRL algorithms without expert guidance.	187.98060363684135
414.	Characterization of a parallel application's communication patterns can be useful for performance analysis, debugging, and system design. However, obtaining and interpreting a characterization can be difficult. AChax implements an approach that uses search and a library of known communication patterns to automatically characterize communication patterns. Our approach has some limitations that reduce its effectiveness for the patterns and pattern combinations used by some real-world applications. By viewing AChax's pattern recognition problem as an image recognition problem, it may be possible to use deep learning to address these limitations. In this position paper, we present our current ideas regarding the benefits and challenges of integrating deep learning into AChax and our conclusion that a hybrid approach combining deep learning classification, regression, and the existing AChax approach may be the best long-term solution to the problem of parameterizing recognized communication patterns.	187.9804819244274
415.	a Automated 3D reconstruction of urban models from satellite images remains a challenging research topic, with many interesting outcoming applications, such as telecommunications and urban simulation. To reconstruct 3D city from stereo pairs of satellite images, semi-automatic strategies are typically applied, which are based either on procedural modeling, or on the use of both image processing and machine learning methods to infer scene geometries together with semantics. In both cases, human interaction still plays a key role, in particular for the rooftop buildings extraction. In the last decade, the use of deep learning algorithms, notably convolutional neural networks (CNNs), has shown a remarkable success for automatic image interpretation. We propose an approach using CNN architecture to automatize the procedure of building contour extraction with the final purpose to automatize 3D urban reconstruction chain and improve the quality of the generated city models. The developed algorithm consists of three steps: 1) We apply a mask-based normalization technique to the input image. 2) CNN network is applied to obtain a raster map of buildings. 3) A polygonization algorithm is designed, which processes a raster map of building to output an ensemble of building contours. We have adopted a U-Net neural network for building segmentation task. We compare the use of several U-Net architectures with the purpose to retain the best suited model. To train models, we have built a dataset of high-resolution satellite images over 15 different cities, and the corresponding building masks. The experimental results show that the proposed approach succeeds in predicting building polygons in a short time, and exhibits good generalization properties to be applied on diverse Earth areas. The developed algorithm combined with the existing LuxCarta reconstruction chain improves 3D urban scene modeling results, and thus supplies an important step towards the automatic reconstruction of 3D city scenes.	187.98042821136
416.	Face age estimation, a computer vision task facing numerous challenges due to its potential applications in identity authentication, human-computer interface, video retrieval and robot vision, has been attracting increasing attention. In recent years, the deep convolutional neural networks (DCNN) have achieved state-of-the-art performance in age classification of face images. We propose a deep hybrid framework for age classification by exploiting DCNN as the raw feature extractor along with several effective methods, including fine-tuning the DCNN into a fine-tuned deep age feature extraction (FDAFE) model, introducing a new method of feature extracting, applying the maximum joint probability classifier to age classification and a strategy to incorporate information from face images more effectively to improve estimation capabilities further. In addition, we pre-process the original image to represent age information more accurately. Based on the discriminative and compact framework, state-of-the-art performance on several face image data sets has been achieved in terms of classification accuracy.	187.98042217993446
417.	Deep learning based methods have been widely applied to predict various kinds of molecular properties in the pharmaceutical industry with increasingly more success. In this study, we propose two novel models for aqueous solubility predictions, based on the Multilevel Graph Convolutional Network (MGCN) and SchNet architectures, respectively. The advantage of the MGCN lies in the fact that it could extract the graph features of the target molecules directly from the (3D) structural information; therefore, it doesn't need to rely on a lot of intra-molecular descriptors to learn the features, which are of significance for accurate predictions of the molecular properties. The SchNet performs well in modelling the interatomic interactions inside a molecule, and such a deep learning architecture is also capable of extracting structural information and further predicting the related properties. The actual accuracy of these two novel approaches was systematically benchmarked with four different independent datasets. We found that both the MGCN and SchNet models performed well for aqueous solubility predictions. In the future, we believe such promising predictive models will be applicable to enhancing the efficiency of the screening, crystallization and delivery of drug molecules, essentially as a useful tool to promote the development of molecular pharmaceutics.	187.98021851613944
418.	Constructing predictive models with neural networks has always been the focus of research in chaotic time series prediction. Since Hinton proposed the concept of deep learning in 2006, the development of neural networks is getting faster and faster, and a variety of neural networks appear. Among them, RNN neural network and LSTM neural network are applied to all fields of our daily life for the property of well-processed time series. Therefore, we use LSTM neural network to construct our model, and optimize the model by Attention mechanism to establish an Attention-LSTM hydrological time series prediction model. The experimental results show that the Attention-LSTM model has better improvement in the mean square error and absolute error of the predicted values than the common LSTM model and the traditional BP model. And due to the introduction of the Attention mechanism, it can highlight the key factors to some extent. influences.The experimental results show that the Attention-LSTM model has the advantages of high prediction accuracy and small lag error, which is helpful for the application of deep learning algorithm in hydrological time series prediction.	187.9802031360976
419.	In this work, we present a local intrinsic rule that we developed, dubbed IP, inspired by the Infomax rule. Like Infomax, this rule works by controlling the gain and bias of a neuron to regulate its rate of fire. We discuss the biological plausibility of the IP rule and compare it to batch normalisation. We demonstrate that the IP rule improves learning in deep networks, and provides networks with considerable robustness to increases in synaptic learning rates. We also sample the error gradients during learning and show that the IP rule substantially increases the size of the gradients over the course of learning. This suggests that the IP rule solves the vanishing gradient problem. Supplementary analysis is provided to derive the equilibrium solutions that the neuronal gain and bias converge to using our IP rule. An analysis demonstrates that the IP rule results in neuronal information potential similar to that of Infomax, when tested on a fixed input distribution. We also show that batch normalisation also improves information potential, suggesting that this may be a cause for the efficacy of batch normalisation-an open problem at the time of this writing.	187.98015791339907
420.	This work presents a deep learning approach based on autoencoder to improve the detection of architectural distortion (AD) in digital mammography. AD can be the earliest sign of breast cancer, appearing before the formation of any mass or calcification. However, it is very difficult to be detected and almost 50% of the cases are missed by the radiologists. Thus, we designed an autoencoder, based on a convolutional neural network (CNN), to work as a feature descriptor in a computer-aided detection (CAD) pipeline with the objective of detecting AD in digital mammography. This model was trained with 140,000 regions-of-interest (ROI) extracted from clinical mammograms. These samples were divided in two groups, with and without AD, according to the radiologist's report. Validation was done comparing the classifier performance when using the proposed autoencoder and other well-known feature descriptors, commonly used for the task of detecting AD in digital mammograms. The results showed that the performance of the autoencoder is slightly higher than that of other descriptors. However, the complexity and the computational cost of the autoencoder is much higher when compared to the hand-crafted descriptors.	187.9801179036019
421.	Considering the high random and non-static property of the rainfall-runoff process, lots of models are being developed in order to learn about such a complex phenomenon. Recently, Machine learning techniques such as the Artificial Neural Network (ANN) and other networks have been extensively used by hydrologists for rainfall-runoff modelling as well as for other fields of hydrology. However, deep learning methods such as the state-of-the-art for LSTM networks are little studied in hydrological sequence time-series predictions. We deployed ANN and LSTM network models for simulating the rainfall-runoff process based on flood events from 1971 to 2013 in Fen River basin monitored through 14 rainfall stations and one hydrologic station in the catchment. The experimental data were from 98 rainfall-runoff events in this period. In between 86 rainfall-runoff events were used as training set, and the rest were used as test set. The results show that the two networks are all suitable for rainfall-runoff models and better than conceptual and physical based models. LSTM models outperform the ANN models with the values of R-2 and NSE beyond 0.9, respectively. Considering different lead time modelling the LSTM model is also more stable than ANN model holding better simulation performance. The special units of forget gate makes LSTM model better simulation and more intelligent than ANN model. In this study, we want to propose new data-driven methods for flood forecasting.	187.98010598777358
422.	Recently, wind speed forecasting as an effective computing technique plays an important role in advancing industry informatics, while dealing with these issues of control and operation for renewable power systems. However, it is facing some increasing difficulties to handle the large-scale dataset generated in these forecasting applications, with the purpose of ensuring stable computing performance. In response to such limitation, this paper proposes a more practical approach through the combination of extreme-learning machine (ELM) method and deep-learning model. ELM is a novel computing paradigm that enables the neural network (NN) based learning to be achieved with fast training speed and good generalization performance. The stacked ELM (SELM) is an advanced ELM algorithm under deep-learning framework, which works efficiently on memory consumption decrease. In this paper, an enhanced SELM is accordingly developed via replacing the Euclidean norm of the mean square error (MSE) criterion in ELM with the generalized correntropy criterion to further improve the forecasting performance. The advantage of the enhanced SELM with generalized correntropy to achieve better forecasting performance mainly relies on the following aspect. Generalized correntropy is a stable and robust nonlinear similarity measure while employing machine learning method to forecast wind speed, where the outliers may exist in some industrially measured values. Specifically, the experimental results of short-term and ultra-short-term forecasting on real wind speed data show that the proposed approach can achieve better computing performance compared with other traditional and more recent methods.	187.98009048952818
423.	Accurately recognizing the rich variety of geometric spaces with different functions is an indispensable but difficult task in modern artificial intelligence systems. In this work, we propose a novel city geometric space classification system, which is inspired by human visual perception toward different geometries within each city. First, we extract multiple subgraphs from different sub-regions inside each city's aerial photo. We call these subgraphs graphlets and they can optimally capture the geometric feature inside each city. Subsequently, it is observable that there are an exponential number of graphlets within each region. And thereby we designed a ranking algorithm to select a few highly discriminative graphlets for city space recognition. Such selection process follows human visual attention, where only a small proportion of visually/semantically salient regions are selected for human visual cognition. Based on the selected graphlets from each city subspace, we integrate them into an image kernel for city subspace recognition. Comprehensive experimental results as well as several visualization results have demonstrated the efficiency and effectiveness of our method. (c) 2020 Elsevier B.V. All rights reserved.	187.98006611144058
424.	We introduce a novel conditional generative model for unsupervised learning of anatomical shapes based on a conditional variational autoencoder (CVAE). Our model is specifically designed to learn latent, low-dimensional shape embeddings from point clouds of large datasets. By using a conditional framework, we are able to introduce side information to the model, leading to accurate reconstructions and providing a mechanism to control the generative process. Our network design provides invariance to similarity transformations and avoids the need to identify point correspondences between shapes. Contrary to previous discriminative approaches based on deep learning, our generative method does not only allow to produce shape descriptors from a point cloud, but also to reconstruct shapes from the embedding. We demonstrate the advantages of this approach by: (i) learning low-dimensional representations of the hippocampus and showing low reconstruction errors when projecting them back to the shape space, and (ii) demonstrating that synthetic point clouds generated by our model capture morphological differences associated to Alzheimer's disease, to the point that they can be used to train a discriminative model for disease classification.	187.98000194187907
425.	Semantic segmentation models based on deep learning have shown remarkable performance in road extraction from high-resolution aerial images. However, it is still a difficult task to segment multiscale roads with high completeness and accuracy from complex backgrounds. To deal with this problem, this letter proposes an end to end network named Multiple features integrated with convolutional long-short time memory unit network (MFI-CLSTMN). First, in MFI-CLSTMN, the ConvLSTM unit is designed to explore and integrate the sequential correlations among features, which can alleviate the feature loss caused by the max-pooling operation. Second, the structure of dense concatenation and multiscale up-sampling combines detailed features with semantic information to preserve road details. At last, at the optimization stage, a self-adaptive composite loss function is added to handle class imbalance, such that MFI-CLSTMN can effectively train hard examples and avoids local optimum. Experiments demonstrate that MFI-CLSTMN has higher segmentation accuracy and lower computational complexity than four comparative state-of-the-art models in a consistent environment. Moreover, MFI-CLSTMN can especially protect road segmentation from netsplit and brokenness, which is hard for other models to achieve.	187.97996776427618
426.	Many videos depict people, and it is their interactions that inform us of their activities, relation to one another and the cultural and social setting. With advances in human action recognition, researchers have begun to address the automated recognition of these human-human interactions from video. The main challenges stem from dealing with the considerable variation in recording setting, the appearance of the people depicted and the coordinated performance of their interaction. This survey provides a summary of these challenges and datasets to address these, followed by an in-depth discussion of relevant vision-based recognition and detection methods. We focus on recent, promising work based on deep learning and convolutional neural networks (CNNs). Finally, we outline directions to overcome the limitations of the current state-of-the-art to analyze and, eventually, understand social human actions.	187.97978148594038
427.	A large and balanced training data are the foremost requirement in proper convergence of a deep convolutional neural network (CNN). Medical data always suffer from the problem of unbalancing and inadequacy that makes it difficult to train CNN from scratch. It is known that the transfer learning approach provides great potential to deal with inadequate dataset besides the benefit of faster training. The efficient transfer of knowledge from natural images to histopathological images has yet to be achieved. In view of the foregoing, an attempt has been made toward the classification of BreakHis dataset using pre-trained 'AlexNet' model with a suitable fine-tuning approach. The effective depth of fine-tuning is also determined at different levels of magnification (40x, 100x, 200x and 400x). The experimental trials conform that the moderate level of fine-tuning is an optimum choice for the classification of magnification-dependent histology images in contrast to the shallow and deep tuning of the pre-trained network which in turn depends on the size and relative distribution of a dataset. Additionally, the layer-wise fine-tuning approach provides a neck-to-neck performance with the latest state-of-the-art developments.	187.9797280143671
428.	The special epistemic characteristics of the COVID-19, such as the long incubation period and the infection through asymptomatic cases, put severe challenge to the containment of its outbreak. By the end of March 2020, China has successfully controlled the within- spreading of COVID-19 at a high cost of locking down most of its major cities, including the epicenter, Wuhan. Since the low accuracy of outbreak data before the mid of Feb. 2020 forms a major technical concern on those studies based on statistic inference from the early outbreak. We apply the supervised learning techniques to identify and train NP-Net-SIR model which turns out robust under poor data quality condition. By the trained model parameters, we analyze the connection between population flow and the cross-regional infection connection strength, based on which a set of counterfactual analysis is carried out to study the necessity of lock-down and substitutability between lock-down and the other containment measures. Our findings support the existence of non-lock-down-typed measures that can reach the same containment consequence as the lock-down, and provide useful guideline for the design of a more flexible containment strategy.	187.97970891565018
429.	In human processed AI, HP-AI, we build our AI systems based on knowledge learned by human experts rather then that learned by artificial neural networks such as in the case of deep learning. The information provided by these human experts is typically linguistically expressed. In support of HP-AI we look at the properties of an ordinal scale, S, needed to model linguistically expressed quantitative information. Since fuzzy measures provide a very general structure for modeling uncertainty we look at ordinal fuzzy measures. We look at the Sugeno integral based on this ordinal S scale. We discuss the modeling of information about an uncertain variable using an ordinal scale. We look at the problem of multi-source in this ordinal environment.	187.97967766896537
430.	Image super-resolution aims to increase the resolution of images with good visual experience. Over the past decades, there have been many image super-resolution algorithms proposed for various multimedia processing applications. However, how to evaluate the visual quality of high-resolution images generated by image super-resolution methods is still challenging. In this paper, a Convolutional Neural Network is designed to predict the visual quality of image super-resolution. The proposed network consists of two convolutional layers, two pooling layers including average, min and max pooling, three fully connected layers and one regression layer. The contribution of the proposed method is twofold. The first one is that we propose a the deep convolutional neural network to extract the high-level intrinsic features more effectively than the hand-crafted features for super-resolution images, which can be used to estimate the image quality accurately. The other is that we divide the super-resolution image into small patches, to consider the local information for the visual quality assessment of super-resolution image as well as increase the number of training data for the deep neural network. Experimental results show that the proposed metric can obtain better performance than other existing ones in visual quality assessment of image super-resolution.	187.97952663249842
431.	Convolutional Neural Network (CNN) is one of the successful deep learning algorithms that have shown its effectiveness in a variety of vision tasks. The performance of this network depends directly on its hyperparameters. Although, designing CNN architectures require expert knowledge of their intrinsic structure or a lot of trial and error. To overcome these issues, there is a need to automatically design the optimal architecture of CNNs without any human intervention. So, we try to eliminate the constraints on the number of convolutional layers and pooling layers and their type etc. from traditional architecture. Biologically inspired approaches have not been extensively exploited for this task. This paper attempts to automatically optimize CNN architecture's hyperparameters for speech recognition task based on particle swarm optimization (PSO) which is a population based stochastic optimization technique. The proposed method is evaluated by designing CNN architecture for speech recognition task on Hindi dataset. The experimental results show that the proposed method significantly designs the competitive CNN architecture which performs similar as other state-of-the-art methods.	187.97950619756375
432.	Diabetic retinopathy (DR) is a common complication of diabetes and one of the major causes of blindness in the active population. Many of the complications of DR can be prevented by blood glucose control and timely treatment. Since the varieties and the complexities of DR, it is really difficult for DR detection in the time-consuming manual diagnosis. This paper is to attempt towards finding an automatic way to classify a given set of fundus images. We bring convolutional neural networks (CNNs) power to DR detection, which includes 3 major difficult challenges: classification, segmentation and detection. Coupled with transfer learning and hyper-parameter tuning, we adopt AlexNet, VggNet, GoogleNet, ResNet, and analyze how well these models do with the DR image classification. We employ publicly available Kaggle platform for training these models. The best classification accuracy is 95.68% and the results have demonstrated the better accuracy of CNNs and transfer learning on DR image classification. (C) 2018 Elsevier Ltd. All rights reserved.	187.97948604329878
433.	The hot intracluster medium (ICM) surrounding the heart of galaxy clusters is a complex medium that comprises various emitting components. Although previous studies of nearby galaxy clusters, such as the Perseus, the Coma, or the Virgo cluster, have demonstrated the need for multiple thermal components when spectroscopically fitting the ICM's X-ray emission, no systematic methodology for calculating the number of underlying components currently exists. In turn, underestimating or overestimating the number of components can cause systematic errors in the emission parameter estimations. In this paper, we present a novel approach to determining the number of components using an amalgam of machine learning techniques. Synthetic spectra containing a various number of underlying thermal components were created using well-established tools available from the Chandra X-ray Observatory. The dimensions of the training set was initially reduced using principal component analysis and then categorized based on the number of underlying components using a random forest classifier. Our trained and tested algorithm was subsequently applied to Chandra X-ray observations of the Perseus cluster. Our results demonstrate that machine learning techniques can efficiently and reliably estimate the number of underlying thermal components in the spectra of galaxy clusters, regardless of the thermal model (MEKAL versus APEC). We also confirm that the core of the Perseus cluster contains a mix of differing underlying thermal components. We emphasize that although this methodology was trained and applied on Chandra X-ray observations, it is readily portable to other current (e.g., XMM-Newton, eROSITA) and upcoming (e.g., Athena, Lynx, XRISM) X-ray telescopes. The code is publicly available at https://github.com/XtraAstronomy/Pumpkin.	187.97948511944938
434.	Small, imperceptible perturbations of the input data can lead to DNNs making egregious errors during inference, such as misclassifying an image of a dog as a cat with high probability. Thus, defending against adversarial examples for deep neural networks (DNNs) is of great interest to sensing technologies and the machine learning community to ensure the security of practical systems where DNNs are used. Whereas many approaches have been explored for defending against adversarial attacks, few have made use of the full state of the entire network, opting instead to only consider the output layer and gradient information. We develop several motivated techniques that make use of the full network state, improving adversarial robustness. We provide principled motivation of our techniques via analysis of attractor dynamics, shown to occur in the highly recurrent human brain, and validate our improvements via empirical results on standard datasets and white-box attacks.	187.97927734959245
435.	Electroencephalogram (EEG), obtained by wearable devices, can realize effective human health monitoring. Traditional methods based on artificially designed features have achieved valid results in EEG-based recognition, and numerous studies start to apply deep learning techniques in this area. In this article, we propose a coincidence-filtering-based method to build a connection between artificial-features-based methods and convolutional neural networks (CNNs), and design CNNs through simulating the information extraction pattern of artificial-features-based methods. Based on this method, we propose a novel, simple, and effective CNNs structure for EEG-based classification. We implement two experiments to obtain EEG data, and perform experiments based on the two health monitoring tasks. The results illustrate that the proposed network can achieve a prominent average accuracy on the emotion recognition and fatigue driving detection task. Due to its generality, the proposed framework design of CNNs is expected to be useful for broader applications in health monitoring areas.	187.9792161334729
436.	CNN-based steganalysis has recently achieved very good performance in detecting content-adaptive steganography. At the same time, recent works have shown that, by adopting an approach similar to that used to build adversarial examples, a steganographer can adopt an adversarial embedding strategy to effectively counter a target CNN steganalyzer. In turn, the good performance of the steganalyzer can be restored by retraining the CNN with adversarial stego images. A problem with this model is that, arguably, at training time the steganalyzer is not aware of the exact parameters used by the steganographer for adversarial embedding and, vice versa, the steganographer does not know how the images that will be used to train the steganalyzer are generated. In order to exit this apparent deadlock, we introduce a game theoretic framework wherein the problem of setting the parameters of the steganalyst and the steganographer is solved in a strategic way. More specifically, we propose two slightly different game-theoretic formulations of the above problem, the difference between the two games corresponding to the way the output of the steganalyzer network is thresholded to make the final decision. In both cases, the goal of the steganographer is to increase the missed detection probability, while the steganalyst aims at reducing the overall error probability in the first case, and the missed detection probability for a given false alarm rate, in the second one. We instantiated the two games by considering a specific adversarial embedding scheme (namely a modified version of the adversarial embedding scheme proposed by Tang a al. (2019), and we run several experiments to derive the equilibrium points and the corresponding payoff for the two versions of the game. By comparing the error probabilities at the equilibrium, with those obtained by using other strategies, like the adoption of a worst case assumption or the use of the adversarial embedding scheme by Tang a al. (2019), the benefits of addressing the interplay between the steganographer and the steganalyst in a game-theoretic fashion come out.	187.97916299449997
437.	The challenge of non-invasive Electrocardiographic Imaging (ECGI) is to re-create the electrical activity of the heart using body surface potentials. Specifically, there are numerical difficulties due to the ill-posed nature of the problem. We propose a novel method based on Conditional Variational Autoencoders using Deep generative Neural Networks to overcome this challenge. By conditioning the electrical activity on heart shape and electrical potentials, our model is able to generate activation maps with good accuracy on simulated data (mean square error, MSE = 0.095). This method differs from other formulations because it naturally takes into account spatio-temporal correlations as well as the imaging substrate through convolutions and conditioning. We believe these features can help improving ECGI results.	187.97914036727454
438.	Covid-19 is a highly contagious virus which almost freezes the world along with its economy. Its ability of human-to-human and surface-to-human transmission turns the world into catastrophic phase. In this study, our aim is to predict the future conditions of novel Coronavirus to recede its impact. We have proposed deep learning based comparative analysis of Covid-19 cases in India and USA. The datasets of confirmed and death cases of Covid-19 are taken into consideration. The recurrent neural network (RNN) based variants of long short term memory (LSTM) such as Stacked LSTM, Bi-directional LSTM and Convolutional LSTM are used to design the proposed methodology and forecast the Covid-19 cases for one month ahead. Convolution LSTM outperformed the other two models and predicts the Covid-19 cases with high accuracy and very less error for all four datasets of both countries. Upward/downward trend of forecasted Covid-19 cases are also visualized graphically, which would be helpful for researchers and policy makers to mitigate the mortality and morbidity rate by streaming the Covid-19 into right direction.	187.97910456242676
439.	We present data-driven coarse-grained (CG) modeling for polymers in solution, which conserves the dynamic as well as structural properties of the underlying atomistic system. The CG modeling is built upon the framework of the generalized Langevin equation (GLE). The key is to determine each term in the GLE by directly linking it to atomistic data. In particular, we propose a two-stage Gaussian processbased Bayesian optimization method to infer the non-Markovian memory kernel from the data of the velocity autocorrelation function (VACF). Considering that the long-time behaviors of the VACF and memory kernel for polymer solutions can exhibit hydrodynamic scaling (algebraic decay with time), we further develop an active learning method to determine the emergence of hydrodynamic scaling, which can accelerate the inference process of the memory kernel. The proposed methods do not rely on how the mean force or CG potential in the GLE is constructed. Thus, we also compare two methods for constructing the CG potential: a deep learning method and the iterative Boltzmann inversion method. With the memory kernel and CG potential determined, the GLE is mapped onto an extended Markovian process to circumvent the expensive cost of directly solving the GLE. The accuracy and computational efficiency of the proposed CG modeling are assessed in a model star-polymer solution system at three representative concentrations. By comparing with the reference atomistic simulation results, we demonstrate that the proposed CG modeling can robustly and accurately reproduce the dynamic and structural properties of polymers in solution.	187.97906235393629
440.	In recent years, deep learning has been successfully applied to diverse multimedia research areas, with the aim of learning powerful and informative representations for a variety of visual recognition tasks. In this work, we propose convolutional fusion networks (CFN) to integrate multi-level deep features and fuse a richer visual representation. Despite recent advances in deep fusion networks, they still have limitations due to expensive parameters and weak fusion modules. Instead, CFN uses 1 x 1 convolutional layers and global average pooling to generate side branches with few parameters, and employs a locally-connected fusion module, which can learn adaptive weights for different side branches and form a better fused feature. Specifically, we introduce three key components of the proposed CFN, and discuss its differences from other deep models. Moreover, we propose fully convolutional fusion networks (FCFN) that are an extension of CFN for pixel-level classification applied to several tasks, such as semantic segmentation and edge detection. Our experiments demonstrate that CFN (and FCFN) can achieve promising performance by consistent improvements for both image-level and pixel-level classification tasks, compared to a plain CNN. We release our codes on https://github.com/yuLiu24/CFN. Also, we make a live demo (goliath.liacs.nl) using a CFN model trained on the ImageNet dataset.	187.97898452421606
441.	Building extraction from very high resolution (VHR) imagery plays an important role in urban planning, disaster management, navigation, updating geographic databases, and several other geospatial applications. Compared with the traditional building extraction approaches, deep learning networks have recently shown outstanding performance in this task by using both high-level and low-level feature maps. However, it is difficult to utilize different level features rationally with the present deep learning networks. To tackle this problem, a novel network based on DenseNets and the attention mechanism was proposed, called the dense-attention network (DAN). The DAN contains an encoder part and a decoder part which are separately composed of lightweight DenseNets and a spatial attention fusion module. The proposed encoder-decoder architecture can strengthen feature propagation and effectively bring higher-level feature information to suppress the low-level feature and noises. Experimental results based on public international society for photogrammetry and remote sensing (ISPRS) datasets with only red-green-blue (RGB) images demonstrated that the proposed DAN achieved a higher score (96.16% overall accuracy (OA), 92.56% F1 score, 90.56% mean intersection over union (MIOU), less training and response time and higher-quality value) when compared with other deep learning methods.	187.97869884968597
442.	Machine learning and artificial intelligence (AI) applications often rely on performing many small matrix operations-in particular general matrix-matrix multiplication (GEMM). These operations are usually performed in a reduced precision, such as the 16-bit floating-point format (i.e., half precision or FP16). The GEMM operation is also very important for dense linear algebra algorithms, and half -precision GEMM operations can be used in mixed-precision linear solvers. Therefore, high-performance batched GEMM operations in reduced precision are significantly important, not only for deep learning frameworks, but also for scientific applications that rely on batched linear algebra, such as tensor contractions and sparse direct solvers. This paper presents optimized batched GEMM kernels for graphics processing units (GPUs) in FP16 arithmetic. The paper addresses both real and complex half-precision computations on the GPU. The proposed design takes advantage of the Tensor Core technology that was recently introduced in CUDA-enabled GPUs. With eight tuning parameters introduced in the design, the developed kernels have a high degree of flexibility that overcomes the limitations imposed by the hardware and software (in the form of discrete configurations for the Tensor Core APIs). For real FP16 arithmetic, performance speedups are observed against cuBLAS for sizes up to 128, and range between 1.5x and 2.5x. For the complex FP16 GEMM kernel, the speedups are between 1.7x and 7x thanks to a design that uses the standard interleaved matrix layout, in contrast with the planar layout required by the vendor's solution. The paper also discusses special optimizations for extremely small matrices, where even higher performance gains are achievable. (C) 2020 Elsevier Inc. All rights reserved.	187.97863687605252
443.	Due to increase in complexity of modelling human behaviour in virtual environment, traditional or conventional didactic learning is limited in providing flexible or dynamic e-learning environment to students. Adaption of e-learning content with respect to several e-learning problems is open research problem in front of all of us. The purpose of this study is to review the learning styles having different classification methods associated with different e-learning problems. The open problems, challenges and prospective direction of e-learning research have also been described. Research papers from distinguished resources: Elsevier, Springer, Wiley, PubMed are reviewed and analyzed. The study examined the effectiveness of learning style and different classification methods in various e-learning problems. Different research papers have been classified based on learning style theories, adaptive classification methods, specific features and challenges faced in individual e-learning problems. 129 articles were studied and reviewed for meta-analysis. When adaptive and dynamic learning, blended with different learning styles and problems, then it's found effective, which enhances learner's performance and knowledge compared to traditional or conventional learning. This study supports researchers, academicians and practitioners in effectively adopting learning styles and method correspond to learning problems and provides a deep insight into its state of art.	187.97852068734005
444.	Computer-aided detection aims to improve breast cancer screening programs by helping radiologists to evaluate digital mammography (DM) exams. DM exams are generated by devices from different vendors, with diverse characteristics between and even within vendors. Physical properties of these devices and postprocessing of the images can greatly influence the resulting mammogram. This results in the fact that a deep learning model trained on data from one vendor cannot readily be applied to data from another vendor. This paper investigates the use of tailored transfer learning methods based on adversarial learning to tackle this problem. We consider a database of DM exams (mostly bilateral and two views) generated by Hologic and Siemens vendors. We analyze two transfer learning settings: 1) unsupervised transfer, where Hologic data with soft lesion annotation at pixel level and Siemens unlabelled data are used to annotate images in the latter data; 2) weak supervised transfer, where exam level labels for images from the Siemens mammograph are available. We propose tailored variants of recent state-of-the-art methods for transfer learning which take into account the class imbalance and incorporate knowledge provided by the annotations at exam level. Results of experiments indicate the beneficial effect of transfer learning in both transfer settings. Notably, at 0.02 false positives per image, we achieve a sensitivity of 0.37, compared to 0.30 of a baseline with no transfer. Results indicate that using exam level annotations gives an additional increase in sensitivity.	187.97851882430535
445.	Research in medical imaging has yet to do to achieve precision oncology. Over the past 30 years, only the simplest imaging biomarkers (RECIST, SUV,) have become widespread clinical tools. This may be due to our inability to accurately characterize tumors and monitor intratumoral changes in imaging. Artificial intelligence, through machine learning and deep learning, opens a new path in medical research because it can bring together a large amount of heterogeneous data into the same analysis to reach a single outcome. Supervised or unsupervised learning may lead to new paradigms by identifying unrevealed structural patterns across data. Deep learning will provide human-free, undefined upstream, reproducible, and automated quantitative imaging biomarkers. Since tumor phenotype is driven by its genotype and thus indirectly defines tumoral progression, tumor characterization using machine learning and deep learning algorithms will allow us to monitor molecular expression noninvasively, anticipate therapeutic failure, and lead therapeutic management. To follow this path, quality standards have to be set: standardization of imaging acquisition as it has been done in the field of biology, transparency of the model development as it should be reproducible by different institutions, validation, and testing through a high-quality process using large and complex open databases and better interpretability of these algorithms.	187.97839508760836
446.	Pitch detection is a fundamental problem in speech processing as F0 is used in a large number of applications. Recent papers have proposed deep learning for robust pitch tracking. In this letter, we consider voicing detection as a classification problem and F0 contour estimation as a regression problem. For both tasks, acoustic features from multiple domains and traditional machine learning methods are used. The discrimination power of existing and proposed features is assessed through mutual information. Multiple supervised and unsupervised approaches are compared. A significant relative reduction of voicing errors over the best baseline is obtained-20% with the best clustering method (K-means) and 45% with a multi-layer perceptron. For F0 contour estimation, the benefits of regression techniques are limited though. We investigate whether those objective gains translate in a parametric synthesis task. Clear perceptual preferences are observed for the proposed approach over two widely used baselines (robust algorithm for pitch tracking (RAPT) and distributed inline-filter operation (DIO)).	187.97830785518042
447.	There is much interest in developing algorithms based on 3D convolutional neural networks (CNNs) for performing regression and classification with brain imaging data and more generally, with biomedical imaging data. A standard assumption in learning is that the training samples are independently drawn from the underlying distribution. In computer vision, where we have millions of training examples, this assumption is violated but the empirical performance may remain satisfactory. But in many biomedical studies with just a few hundred training examples, one often has multiple samples per participant and/or data may be curated by pooling datasets from a few different institutions. Here, the violation of the independent samples assumption turns out to be more significant, especially in small-to-medium sized datasets. Motivated by this need, we show how 3D CNNs can be modified to deal with dependent samples. We show that even with standard 3D CNNs, there is value in augmenting the network to exploit information regarding dependent samples. We present empirical results for predicting cognitive trajectories (slope and intercept) from morphometric change images derived from multiple time points. With terms which encode dependency between samples in the model, we get consistent improvements over a strong baseline which ignores such knowledge.	187.97823914212452
448.	With the rapid development of mechanical equipment, mechanical health monitoring field has entered the era of big data. Deep learning has made a great achievement in the processing of large data of image and speech due to the powerful modeling capabilities, this also brings influence to the mechanical fault diagnosis field. Therefore, according to the characteristics of motor vibration signals (nonstationary and difficult to deal with) and mechanical 'big data', combined with deep learning, a motor fault diagnosis method based on stacked de-noising auto-encoder is proposed. The frequency domain signals obtained by the Fourier transform are used as input to the network. This method can extract features adaptively and unsupervised, and get rid of the dependence of traditional machine learning methods on human extraction features. A supervised fine tuning of the model is then carried out by backpropagation. The Asynchronous motor in Drivetrain Dynamics Simulator system was taken as the research object, the effectiveness of the proposed method was verified by a large number of data, and research on visualization of network output, the results shown that the SDAE method is more efficient and more intelligent.	187.97821873336144
449.	With the biomedical field generating large quantities of time series data, there has been a growing interest in developing and refining machine learning methods that allow its mining and exploitation. Classification is one of the most important and challenging machine learning tasks related to time series. Many biomedical phenomena, such as the brain's activity or blood pressure, change over time. The objective of this chapter is to provide a gentle introduction to time series classification. In the first part we describe the characteristics of time series data and challenges in its analysis. The second part provides an overview of common machine learning methods used for time series classification. A real-world use case, the early recognition of sepsis, demonstrates the applicability of the methods discussed.	187.97819017836113
450.	Construction safety is a matter of great concern for practitioners and researchers worldwide. Even after risk assessments have been conducted and adequate controls have been implemented, workers are still subject to safety hazards in construction work environments. The need for personal protective equipment (PPE) is important in this context. Automatic and real-time detection of the non-compliance of workers in using PPE is an important concern. Developments in the field of computer vision and data analytics, especially using deep learning algorithms have the potential to address this challenge in construction. This study developed a framework to sense in real-time, the safety compliance of construction workers with respect to PPE, which is intended to be integrated into the safety workflow of an organization. The study makes use of the Convolutional Neural Networks model, which was developed by applying transfer learning to a base version of the YOLOv3 deep learning network. Taking into account the presence of hardhat and safety jackets, the model predicts compliance in four categories such as NOT SAFE, SAFE, NoHardHat, and NoJacket. A data set of 2,509 images was collected from video recordings from several construction sites and this web-based collection was used to train the model. The model reported an F1 score of 0.96 with an average precision and recall rate at 96% on the test data set. Once a non "SAFE" category is detected by the model, an alarm and a time-stamped report are also incorporated to enable a real-time integration and adoption on the construction sites. Overall, the study provides evidence on the feasibility and utility of computer vision-based techniques in automating the safety-related compliance processes at construction sites.	187.97801457214382
451.	Language identification of social media text still remains a challenging task due to properties like code-mixing and inconsistent phonetic transliterations. In this paper, we present a supervised learning approach for language identification at the word level of low resource Bengali-English code-mixed data taken from social media. We employ two methods of word encoding, namely character based and root phone based to train our deep LSTM models. Utilizing these two models we created two ensemble models using stacking and threshold technique which gave 91.78% and 92.35% accuracies respectively on our testing data.	187.97799926306635
452.	The coronavirus COVID-19 is affecting 213 countries and territories around the world. Iran was one of the first affected countries by this virus. Isfahan, as the third most populated province of Iran, experienced a noticeable epidemic. The prediction of epidemic size, peak value, and peak time can help policymakers in correct decisions. In this study, deep learning is selected as a powerful tool for forecasting this epidemic in Isfahan. A combination of effective Social Determinant of Health (SDH) and the occurrences of COVID-19 data are used as spatiotemporal input by using time-series information from different locations. Different models are utilized, and the best performance is found to be for a tailored type of long short-term memory (LSTM). This new method incorporates the mutual effect of all classes (confirmed/ death / recovered) in the prediction process. The future trajectory of the outbreak in Isfahan is forecasted with the proposed model. The paper demonstrates the positive effect of adding SDHs in pandemic prediction. Furthermore, the effectiveness of different SDHs is discussed, and the most effective terms are introduced. The method expresses high ability in both short- and long- term forecasting of the outbreak. The model proves that in predicting one class (like the number of confirmed cases), the effect of other accompanying numbers (like death and recovered cases) cannot be ignored. In conclusion, the superiorities of this model (particularity the long term predication ability) turn it into a reliable tool for helping the health decision-makers.	187.97796480414996
453.	Various classification methods have been developed to extract meaningful information from Airborne Laser Scanner (ALS) point clouds. However, the accuracy and the computational efficiency of the existing methods need to be improved, especially for the analysis of large datasets (e.g., at regional or national levels). In this paper, we present a novel deep learning approach to ground classification for Digital Terrain Model (DTM) extraction as well as for multi-class land-cover classification, delivering highly accurate classification results in a computationally efficient manner. Considering the top-down acquisition angle of ALS data, the point cloud is initially projected on the horizontal plane and converted into a multi-dimensional image. Then, classification techniques based on Fully Convolutional Networks (FCN) with dilated kernels are designed to perform pixel-wise image classification. Finally, labels are transferred from pixels to the original ALS points. We also designed a Multi-Scale FCN (MS-FCN) architecture to minimize the loss of information during the point-to-image conversion. In the ground classification experiment, we compared our method to a Convolutional Neural Network (CNN)-based method and LAStools software. We obtained a lower total error on both the International Society for Photogrammetry and Remote Sensing (ISPRS) filter test benchmark dataset and AHN-3 dataset in the Netherlands. In the multi-class classification experiment, our method resulted in higher precision and recall values compared to the traditional machine learning technique using Random Forest (RF); it accurately detected small buildings. The FCN achieved precision and recall values of 0.93 and 0.94 when RF obtained 0.91 and 0.92, respectively. Moreover, our strategy significantly improved the computational efficiency of state-of-the-art CNN-based methods, reducing the point-to-image conversion time from 47 h to 36 min in our experiments on the ISPRS filter test dataset. Misclassification errors remained in situations that were not included in the training dataset, such as large buildings and bridges, or contained noisy measurements.	187.97791993107643
454.	Background: Artificial intelligence methods for the classification of melanoma have been studied extensively. However, few studies compare these methods under the same standards. Objective: To seek the best artificial intelligence method for diagnosis of melanoma. Methods: The contrast test used 2200 dermoscopic images. Image segmentations, feature extractions, and classifications were performed in sequence for evaluation of traditional machine learning algorithms. The recent popular convolutional neural network frameworks were used for transfer learning training classification. Results: The region growing algorithm has the best segmentation performance, with an intersection over union of 70.06% and a false-positive rate of 17.67%. Classification performance was better with logistic regression, with a sensitivity of 76.36% and a specificity of 87.04%. The Inception V3 model (Google, Mountain View, CA) worked best in deep learning algorithms: the accuracy was 93.74%, the sensitivity was 94.36%, and the specificity was 85.64%. Limitations: There was no division in the severity of melanoma samples used in this experiment. The data set was relatively small for deep learning. Conclusion: The performance of traditional machine learning is satisfactory for the small data set of melanoma dermoscopic images, and the potential for deep learning in the future big data era is enormous.	187.97778453489923
455.	Momentum is a pervasive and persistent phenomenon in financial economics that has been found to generate abnormal returns not explainable by the traditional asset pricing models. This paper investigates some variations of the existing momentum strategies to increase profit and gain other desirable properties such as low kurtosis, small negative skewness and small maximum drawdown. We investigate these by using regression that is based on the latest techniques from deep learning such as stacked autoencoders and denoising autoencoders. Empirical results indicate that our regression-based variations can generate increased returns, and improved higher-order moments and maximum drawdown characteristics. Furthermore, our results reveal such improved performance can only be attained through the use of the latest deep learning technologies.	187.97777624279422
456.	Hospital readmission shortly after discharge is threatening to plague the quality of inpatient care. Readmission is a severe episode that leads to increased medical care costs. Federal regulations and early readmission penalties have created an incentive for healthcare facilities to reduce their readmission rates by predicting patients at a high risk of readmission. Scientists have developed prediction models by using rule-based assessment scores and traditional statistical methods, and most have focused on structured patient records. Recently, a few researchers utilized unstructured clinical notes. However, they achieved moderate prediction accuracy by making predictions of a single diagnosis subpopulation via extensive feature engineering. This study proposes the use of machine learning to learn deep representation of patient notes for the identification of high-risk readmission in a hospital-wide population. We describe and train several predictive models (standard machine learning and neural network), to which several setups have not been applied. Results show that complex deep learning models significantly outperform (P<0.001) conventionally applied simple models in terms of discrimination ability. We also demonstrate a simple feature evaluation using a standard model, which allows the determination of potential clinical conditions/procedures for targeting. Unlike modeling using structured patient information with considerable variability in structure when different templates or databases are adopted, this study shows that the machine learning approach can be applied to prognosticate readmission with clinical free text in various healthcare settings. Using minimum feature engineering, the trained models perform comparably well or better than other predictive models established in previous literature.	187.9777685974189
457.	The lack of reliable and up-to-date data in developing countries is a major obstacle to sustainable development. In Morocco, where groundwater withdrawals by farmers are very intensive and informal, maps describing and monitoring the extension of irrigated areas are scarce and labor-intensive to obtain. In this paper a novel transfer learning algorithm is proposed to map irrigated areas at different stages of an agricultural cycle from Landsat 8 images. The results obtained displays satisfactory performance over traditional machine learning algorithms.On a small dataset, we initially tested three well known deep learning architectures (SegNet, DenseNet and Unet). The results obtained were not satisfactory. So, to get high performance, we rely on a transfer learning architecture combining UNet with ResNet50 backbone (trained on 2012 ILSVRC ImageNet dataset) as a baseline after a phase where different configurations were tested.In the first part of this study, we compared the use of three optimization methods: Adam and two variants of Stochastic Gradient Descent (SGD) associated with two techniques (Cyclical Learning Rate and Warm Restart) to find the optimal learning rate and then test the impact of data augmentation on the overall accuracies.Data augmentation had improved the overall accuracy for the three methods. Adam based method from 94% to 97% with mean IoU of 0,79 (for all land cover classes) and 0,86 for irrigated areas class. For SGD based methods, the overall accuracy had increased from 91% to 94% with mean IoU of 0,75 (for all land cover classes) and 0,82 for irrigated areas class. As we are interested in having irrigated areas maps at different key periods of the agricultural cycle, we also explored, in the second part of this study, the temporal generalization of the best model.	187.97775366055862
458.	As one of the most important paradigms of recurrent neural networks, the echo state network (ESN) has been applied to a wide range of fields, from robotics to medicine, finance, and language processing. A key feature of the ESN paradigmis its reservoir-a directed and weighted network of neurons that projects the input time series into a high-dimensional space where linear regression or classification can be applied. By analyzing the dynamics of the reservoir we show that the ensemble of eigenvalues of the network contributes to the ESN memory capacity. Moreover, we find that adding short loops to the reservoir network can tailor ESN for specific tasks and optimize learning. We validate our findings by applying ESN to forecast both synthetic and real benchmark time series. Our results provide a simple way to design task-specific ESN and offer deep insights for other recurrent neural networks.	187.97767903113942
459.	Predictive process monitoring has recently become one of the main enablers of data-driven insights in process mining. As an application of predictive analytics, process prediction is mainly concerned with predicting the evolution of running traces based on models extracted from historical event logs. This paper presents a process mining approach, which uses convolutional neural networks to equip the execution scenario of a business process with a means to predict the next activity in a running trace. The basic idea is to convert the temporal data enclosed in the historical event log of a business process into spatial data so as to treat them as images. To this purpose, every trace of the event log is first transformed into the set of its prefix traces (i.e. sequences of events that represent the prefix of a trace). These prefix traces are mapped into 2D image-like data structures. Created spatial data are finally used to train a Convolutional Neural Network, in order to learn a deep learning model capable to predict the next activity (i.e. the activity associated to the event occurring after the last event in the considered prefix trace). This predictive deep model can be employed as a powerful service to support participants in performing business processes since it guarantees a higher utilization by acting proactively in anticipation. Preliminary tests with two benchmark logs are carried out to investigate the viability of the proposed approach.	187.97766382348783
460.	Robustly tracking various objects within a video stream with complex objects and backgrounds is a useful technique in next generation computer vision systems. However, in practice, it is difficult to design a successful video-based object tracking system due to the varied light conditions, possible occlusions, and fast-moving objects. In this work, a novel weakly-supervised and quality-guided visual object tracking model is proposed, wherein the key is a bidirectional long short-term memory recurrent neural network (BLSTM-RNN) that captures the feature sequence and predicts the quality score of each candidate window. More specifically, given a rich set of training videos annotated with the target objects, a weakly-supervised learning algorithm is first used to project all the candidate window features onto the semantic space. Next, we propose a two-stage algorithm to select the key frames from the video sequences, where both the shallow and deep filtering operations are conducted. Subsequently, the so-called BLSTM-RNN is proposed to characterize the feature sequence temporally, based on which the maximally possible object window can be calculated and finally output. In our experiment, a large video dataset containing 2045 NBA regular seasons and playoff basketball games was compiled. Based on this, a comparative study is conducted between the proposed algorithm and state-of-the-art video tracking methods. Extensive visualization results and comparative tracking precisions show the competitiveness of the proposed method. (C) 2020 Elsevier B.V. All rights reserved.	187.97765317086578
461.	The task of person re-identification has recently received rising attention due to the high performance achieved by new methods based on deep learning. In particular, in the context of video-based re-identification, many state-of-the-art works have explored the use of Recurrent Neural Networks (RNNs) to process input sequences. In this work, we revisit this tool by deriving an approximation which reveals the small effect of recurrent connections, leading to a much simpler feed-forward architecture. Using the same parameters as the recurrent version, our proposed feed-forward architecture obtains very similar accuracy. More importantly, our model can be combined with a new training process to significantly improve re-identification performance. Our experiments demonstrate that the proposed models converge substantially faster than recurrent ones, with accuracy improvements by up to 5% on two datasets. The performance achieved is better or on par with other RNN-based person re-identification techniques.	187.97764809083418
462.	Accurate and robust state of charge estimation of lithium-ion battery is a challenging task in battery management system. In this paper, a novel data-driven SOC estimation approach for Lithium-ion (Li-ion) batteries is proposed based on the Gaussian process regression framework. Kernel function selection and hyperparameters optimization are critical for Gaussian process regression due to the reason that kernel function could capture rich structure of data. By integrating the structural properties of deep learning with the flexibility of kernel methods, a new deep learning technology called deep recurrent kernel that fully encapsulates GRU structure is introduced to capture ordering matters and recurrent structures in sequential data. The proposed method could not only learn the mapping relationship from one sequence of measured quantities such as voltage, current, temperature to SOC, but also quantify estimation uncertainty which is essential for making informed decisions for battery management system. The performance of proposed methods is evaluated by two experimental datasets, one under a series of electric vehicle drive cycles and another under high rate pulse discharge test. We demonstrate the proposed method achieves satisfactory performance, as well as performs strong robustness against unknown initial SOC and outliers occurred in voltage, current and temperature.	187.97762649481228
463.	In recent years, with the development of machine learning, especially after the rise of deep learning, time series clustering has been proven to effectively provide useful information in cloud computing and big data. However, many modern clustering algorithms are difficult to mine the complex features of time series, which is important for further analysis. Convolutional neural network provides powerful feature extraction capabilities and has excellent performance in classification tasks, but it is hard to be applied to clustering. Therefore, a similarity measurement method based on convolutional neural networks is proposed. This algorithm converts the number of output changes of the convolutional neural network in the same direction into the similarity of time series, so that the convolutional neural network can mine unlabeled data features in the clustering process. Especially by preferentially collecting a small amount of high similarity data to create labels, a classification algorithm based on the convolutional neural network can be used to assist clustering. The effectiveness of the proposed algorithm is proved by extensive experiments on the UCR time series datasets, and the experimental results show that its superior performance than other leading methods. Compared with other clustering algorithms based on deep networks, the proposed algorithm can output intermediate variables, and visually explain the principle of the algorithm. The application of financial stock linkage analysis provides an auxiliary mechanism for investment decision-making.	187.97755469181055
464.	The research of semi-supervised learning (SSL) is of great significance because it is very expensive to collect a large quantity of data with labels in some fields. Two recent deep learning-based SSL algorithms, temporal ensembling and virtual adversarial training (VAT), have achieved state-of-the-art accuracy in some classical SSL tasks, while both of them have shortcomings. Because of simply adding random noise to training data, temporal ensembling is not fully utilized. In addition, VAT has considerable time costs because there are two inferences in each epoch for unlabeled samples. In this paper, we propose the use of virtual adversarial perturbations (VAP) in temporal ensembling rather than random noises to improve performance. Moreover, we also find that reusing VAP can accelerate the training process of VAT without losing obvious accuracy. The two methods are validated on MNIST, FashionMNIST and SVHN.	187.97745226504165
465.	Healthcare studies in the information and communication technology for development (ICT4D) domain have attempted to understand how technology can be used to support healthcare organisations in developing countries; organisations whose performance is negatively impacted by resource constraints. Current studies - predominantly informed by positivist and interpretivist paradigms - produce analyses and prescriptions designed without an in-depth understanding of the underlying mechanisms influencing performance. The result is limited ability to explain how organisational performance is enabled by ICT. Critical realism as a philosophy of science provides a deeper ontological and broader epistemological approach that makes it possible to theorise the micro-level mechanisms that hold potential for explaining observed outcomes. The study reported here, informed by the critical realism paradigm, uses interviews, observation and organisational data collected from a single case study to identify the resource optimisation micro-level generative mechanisms that have improved emergency medical services. The study integrates the technological affordances lens to explain ICT-enabled organisational performance. Additionally, the paper proposes and tests an understanding of the Bygstad, Munkvold, and Volkoff stepwise framework as a methodology for doing critical realist research using affordances.	187.9773482840357
466.	We propose a general approach to the gaze redirection problem in images that utilizes machine learning. The idea is to learn to re-synthesize images by training on pairs of images with known disparities between gaze directions. We show that such learning-based re-synthesis can achieve convincing gaze redirection based on monocular input, and that the learned systems generalize well to people and imaging conditions unseen during training. We describe and compare three instantiations of our idea. The first system is based on efficient decision forest predictors and redirects the gaze by a fixed angle in real-time (on a single CPU), being particularly suitable for the videoconferencing gaze correction. The second system is based on a deep architecture and allows gaze redirection by a range of angles. The second system achieves higher photorealism, while being several times slower. The third system is based on real-time decision forests at test time, while using the supervision from a "teacher" deep network during training. The third system approaches the quality of a teacher network in our experiments, and thus provides a highly realistic real-time monocular solution to the gaze correction problem. We present in-depth assessment and comparisons of the proposed systems based on quantitative measurements and a user study.	187.97732202066155
467.	The seminal model by Laurent Itti and Cristoph Koch demonstrated that we can compute the entire flow of visual processing from input to resulting fixations. Despite many replications and follow-ups, few have matched the impact of the original model-so what made this model so groundbreaking? We have selected five key contributions that distinguish the original salience model by Itti and Koch; namely, its contribution to our theoretical, neural, and computational understanding of visual processing, as well as the spatial and temporal predictions for fixation distributions. During the last 20 years, advances in the field have brought up various techniques and approaches to salience modelling, many of which tried to improve or add to the initial Itti and Koch model. One of the most recent trends has been to adopt the computational power of deep learning neural networks; however, this has also shifted their primary focus to spatial classification. We present a review of recent approaches to modelling salience, starting from direct variations of the Itti and Koch salience model to sophisticated deep-learning architectures, and discuss the models from the point of view of their contribution to computational cognitive neuroscience.	187.97711810283278
468.	Molecular evolution offers an insightful theory to interpret the genomic consequences of thermal adaptation to previous events of climate change beyond range shifts. However, disentangling often mixed footprints of selective and demographic processes from those due to lineage sorting, recombination rate variation, and genomic constrains is not trivial. Therefore, here we condense current and historical population genomic tools to study thermal adaptation and outline key developments (genomic prediction, machine learning) that might assist their utilization for improving forecasts of populations' responses to thermal variation. We start by summarizing how recent thermal-driven selective and demographic responses can be inferred by coalescent methods and in turn how quantitative genetic theory offers suitable multi-trait predictions over a few generations via the breeder's equation. We later assume that enough generations have passed as to display genomic signatures of divergent selection to thermal variation and describe how these footprints can be reconstructed using genome-wide association and selection scans or, alternatively, may be used for forward prediction over multiple generations under an infinitesimal genomic prediction model. Finally, we move deeper in time to comprehend the genomic consequences of thermal shifts at an evolutionary time scale by relying on phylogeographic approaches that allow for reticulate evolution and ecological parapatric speciation, and end by envisioning the potential of modern machine learning techniques to better inform long-term predictions. We conclude that foreseeing future thermal adaptive responses requires bridging the multiple spatial scales of historical and predictive environmental change research under modern cohesive approaches such as genomic prediction and machine learning frameworks.	187.9770513162099
469.	Manufacturers of printed circuit boards (PCBs) typically use automated optical inspection (AOI) machines to test their PCBs. However, AOI machines employ conventional image-processing methods. If the integrated circuit (IC) components are not identical to the golden samples, then the AOI machine registers those IC components as flaws. Conventional image-processing methods cause misjudgments and increase the cost of manual reviews. Character-verification and image-classification systems are proposed in this paper for detecting misplaced, missing, and reversed-polarity parts. The regions of IC components can be identified on PCBs by using the contour border-detection method. Through the proposed convolutional neural network (CNN) structure and refinement mechanism, the characters can be successfully recognized. The image-classification system was applied only to images with blurry characters. Different CNN learning structures were used in both systems, and the refinement mechanism was used in both systems to improve the results. The proposed character-verification and image-classification methods achieved 98.84% and 99.48% passing rates, and the amount of required training time was less than that of other methods, demonstrating the proposed methods' greater effectiveness.	187.97705062020086
470.	Purpose Bone age assessment is not only an important means of assessing maturity of adolescents, but also plays an indispensable role in the fields of orthodontics, kinematics, pediatrics, forensic science, etc. Most studies, however, do not take into account the impact of background noise on the results of the assessment. In order to obtain accurate bone age, this paper presents an automatic assessment method, for bone age based on deep convolutional neural networks. Method Our method was divided into two phases. In the image segmentation stage, the segmentation network U-Net was used to acquire the mask image which was then compared with the original image to obtain the hand bone portion after removing the background interference. For the classification phase, in order to further improve the evaluation performance, an attention mechanism was added on the basis of Visual Geometry Group Network (VGGNet). Attention mechanisms can help the model invest more resources in important areas of the hand bone. Result The assessment model was tested on the RSNA2017 Pediatric Bone Age dataset. The results show that our adjusted model outperforms the VGGNet. The mean absolute error can reach 9.997 months, which outperforms other common methods for bone age assessment. Conclusion We explored the establishment of an automated bone age assessment method based on deep learning. This method can efficiently eliminate the influence of background interference on bone age evaluation, improve the accuracy of bone age evaluation, provide important reference value for bone age determination, and can aid in the prevention of adolescent growth and development diseases.	187.9770217704007
471.	Recent developments in convolutional neural networks (CNNs) have introduced new ways to model the complex processes of human vision. To date, the comparison of human vision and CNNs has focused on internal representations (i.e., receptive fields), with behavioral comparisons left largely unexplored. Here, we probe the influence of cognitive strategy on the similarity between CNN output and human behavior. We gave study participants a superstitious perception task (i.e., we asked them to detect an assigned target in white noise) while asking them to engage in either an active or passive attentional strategy. Previous research has shown that an active attentional strategy tends to engage central executive functions, whereas a passive strategy allows perceptual processes to unfold with limited central control. The results showed that the pattern of human responses in the superstitious perception task depended significantly on task strategy. Specifically, detecting targets superstitiously (i.e., false alarms) was correlated with evidence of a target's presence in the passive condition, but not in the active condition.Human data were compared to the performance of a CNN performing the same task, with the decision criterion of the CNN set to match the false alarm rates observed in the two strategy conditions of the human participants. CNN responses resembled those of human participants in the passive condition more closely than those in the active condition. This observation suggests that the CNN does a better job of mimicking human behavior when central executive functions are not engaged than when they are engaged. This, in turn, has important implications for what human participants are doing in the superstitious perception task. Namely, it implies that superstitious perception may have two important ingredients that are somewhat dissociable. First, there is the ability to detect weak signals in noise that correspond to the target image. This appears to be what participants are doing under passive strategy conditions; they allow externally generated signals to dominate their perceptual experience. Second, there is the ability to ignore the noise in favor of basing responses solely on internally generated signals. This seems to correspond more closely to what participants are doing under active strategy conditions, when attention is controlled by representations in memory. This research emphasizes the importance of modeling the full range of human responsiveness in even a simple noisy detection task.	187.97694194079534
472.	Sum-Product Networks (SPN) are deep probabilistic models with demonstrated excellent performance in several machine learning tasks. As with many other probabilistic models, performing Maximum-A-Posteriori inference in SPNs is NP-hard. Selective SPNs are a subclass of SPNs that allow for efficient Maximum-A-Posteriori inference and closed-form parameter learning. Due to the high number of parameters, SPNs learned from data can produce unreliable and overconfident inferences, especially for instances with low statistical support. This issue can be partially mitigated by performing a robustness analysis of inferences with respect to small changes in the parameters. In this work, we address the problem of assessing the robustness of Maximum-A-Posteriori inferences produced with Selective SPNs to global perturbations of the parameters. We consider such an inference robust if it remains the single maximizer under small perturbations of the model parameters. We present efficient algorithms and an empirical analysis with realistic problems involving missing data completion and multilabel classification. The experiments show that our criteria are informative with respect to the inference accuracy, suggesting that it indeed discriminate robust and non-robust instances. (C) 2020 Elsevier Inc. All rights reserved.	187.97677888618375
473.	Dialogue-based tutoring platforms have shown great promise in helping individual students improve mastery. Short answer grading is a crucial component of such platforms. However, generative short answer grading using the same platform for diverse disciplines and titles is a crucial challenge due to data distribution variations across domains and a frequent occurrence of non-sentential answers. Recent NLP research has introduced novel deep learning architectures such as the Transformer, which merely uses self-attention mechanisms. Pre-trained models based on the Transformer architecture have been used to produce impressive results across a range of NLP tasks. In this work, we experiment with fine-tuning a pre-trained self-attention language model, namely Bidirectional Encoder Representations from Transformers (BERT) applying it to short answer grading, and show that it produces superior results across multiple domains. On the benchmarking dataset of SemEval-2013, we report up to 10% absolute improvement in macro-average-F1 over state-of-the-art results. On our two psychology domain datasets, the fine-tuned model yields classification almost up to the human-agreement levels. Moreover, we study the effectiveness of fine-tuning as a function of the size of the task-specific labeled data, the number of training epochs, and its generalizability to cross-domain and join-domain scenarios.	187.97671459808947
474.	Peer-to-Peer (P2P) lending transactions take place by the lenders choosing a borrower and lending money. It is important to predict whether a borrower can repay because the lenders must bear the credit risk when the borrower defaults, but it is difficult to design feature extractors with very complex information about borrowers and loan products. In this paper, we present an architecture of deep convolutional neural network (CNN) for predicting the repayment in P2P social lending to extract features automatically and improve the performance. CNN is a deep learning model for classifying complex data, which extracts discriminative features automatically by convolution operation on lending data. We classify the borrower's loan status by capturing the robust features and learning the patterns. Experimental results with 5-fold cross-validation show that our method automatically extracts complex features and is effective in repayment prediction on Lending Club data. In comparison with other machine learning methods, the standard CNN has achieved the highest performance with 75.86%. Exploiting various CNN models such as Inception, ResNet, and Inception-ResNet results in the state-of-the-art performance of 77.78%. We also demonstrate that the features extracted by our model are better performed by projecting the samples into the feature space.	187.97660959407867
475.	Metallography is the study of the structure of metals and alloys. Metallographic analysis can be regarded as a detection tool to assist in identifying a metal or alloy, to evaluate whether an alloy is processed correctly, to inspect multiple phases within a material, to locate and characterize imperfections such as voids or impurities, or to find the damaged areas of metallographic images. However, the defect detection of metallography is evaluated by human experts, and its automatic identification is still a challenge in almost every real solution. Deep learning has been applied to different problems in computer vision since the proposal of AlexNet in 2012. In this study, we propose a novel convolutional neural network architecture for metallographic analysis based on a modified residual neural network (ResNet). Multi-scale ResNet (M-ResNet), the modified method, improves efficiency by utilizing multi-scale operations for the accurate detection of objects of various sizes, especially small objects. The experimental results show that the proposed method yields an accuracy of 85.7% (mAP) in recognition performance, which is higher than existing methods. As a consequence, we propose a novel system for automatic defect detection as an application for metallographic analysis.	187.9766030333141
476.	Label free imaging of oxygenation distribution in tissues is highly desired in numerous biomedical applications, but is still elusive, in particular in sub-epidermal measurements. Eigenspectra multispectral optoacoustic tomography (eMSOT) and its Bayesian-based implementation have been introduced to offer accurate label-free blood oxygen saturation (sO2) maps in tissues. The method uses the eigenspectra model of light fluence in tissue to account for the spectral changes due to the wavelength dependent attenuation of light with tissue depth. eMSOT relies on the solution of an inverse problem bounded by a number of ad hoc hand-engineered constraints. Despite the quantitative advantage offered by eMSOT, both the non-convex nature of the optimization problem and the possible sub-optimality of the constraints may lead to reduced accuracy. We present herein a neural network architecture that is able to learn how to solve the inverse problem of eMSOT by directly regressing from a set of input spectra to the desired fluence values. The architecture is composed of a combination of recurrent and convolutional layers and uses both spectral and spatial features for inference. We train an ensemble of such networks using solely simulated data and demonstrate how this approach can improve the accuracy of sO2 computation over the original eMSOT, not only in simulations but also in experimental datasets obtained from blood phantoms and small animals (mice) in vivo. The use of a deep-learning approach in optoacoustic sO2 imaging is confirmed herein for the first time on ground truth sO2 values experimentally obtained in vivo and ex vivo.	187.97650082546346
477.	Recognizing human activities using automated methods has emerged recently as a pivotal research theme for security-related applications. In this research paper, an optical flow descriptor is proposed for the recognition of human actions by considering only features derived from the motion. The signature for the human action is composed as a histogram containing kinematic features which include the local and global traits. Experimental results performed on the Weizmann and UCF101 databases confirmed the potentials of the proposed approach with attained classification rates of 98.76% and 70%, respectively, to distinguish between different human actions. For comparative and performance analysis, different types of classifiers including Knn, decision tree, SVM and deep learning are applied to the proposed descriptors. Further analysis is performed to assess the proposed descriptors under different resolutions and frame rates. The obtained results are in alignment with the early psychological studies reporting that human motion is adequate for the perception of human activities.	187.97630662642894
478.	Deep learning approaches have demonstrated remarkable progress in automatic Chest X-ray analysis. The data-driven feature of deep models requires training data to cover a large distribution. Therefore, it is substantial to integrate knowledge from multiple datasets, especially for medical images. However, learning a disease classification model with extra Chest X-ray (CXR) data is yet challenging. Recent researches have demonstrated that performance bottleneck exists in joint training on different CXR datasets, and few made efforts to address the obstacle. In this paper, we argue that incorporating an external CXR dataset leads to imperfect training data, which raises the challenges. Specifically, the imperfect data is in two folds: domain discrepancy, as the image appearances vary across datasets; and label discrepancy, as different datasets are partially labeled. To this end, we formulate the multi-label thoracic disease classification problem as weighted independent binary tasks according to the categories. For common categories shared across domains, we adopt task-specific adversarial training to alleviate the feature differences. For categories existing in a single dataset, we present uncertainty-aware temporal ensembling of model predictions to mine the information from the missing labels further. In this way, our framework simultaneously models and tackles the domain and label discrepancies, enabling superior knowledge mining ability. We conduct extensive experiments on three datasets with more than 360,000 Chest X-ray images. Our method outperforms other competing models and sets state-of-the-art performance on the official NIH test set with 0.8349 AUC, demonstrating its effectiveness of utilizing the external dataset to improve the internal classification.	187.97622474540393
479.	Division of attention (DA) at the time of learning has large detrimental effects on subsequent memory performance, but DA at retrieval has much smaller effects (Baddeley, Lewis, Eldridge,& Thomson, 1984, Journal of Experimental Psychology: General, 113, 518-540; Craik, Govoni, Naveh-Benjamin, & Anderson, 1996, Journal of Experimental Psychology: General, 125, 159-180). Experiment 1 confirmed the relatively small effects of DA on retrieval and also showed that retrieval operations do consume processing resources. The experiment also found that the effect is not attributable to a trade-off in performance with the concurrent task or to recognition decisions made on the basis of familiarity judgments. Participants made levels-of-processing (LOP) judgments during encoding to check whether deeper semantic judgments were differentially vulnerable to the effects of DA. In fact DA did not interact with LOP. Experiment 2 explored reports that the comparatively slight effect of DA on recognition accuracy is accompanied by a compensatory increase in recognition latency (Baddeley et al., 1984). The experiment replicated findings that neither DA nor differential emphasis between recognition and a concurrent continuous reaction time (CRT) task affected recognition accuracy, but also found evidence for a lawful trade-off in decision latencies between recognition and CRT performance. Further analysis showed that the relationship between response rates on the two tasks was well described by a linear function, and that this function was demonstrated by the majority of individual participants. It is concluded that the small effect of DA on recognition performance is attributable to a trade-off within the recognition task itself; accuracy is maintained by a compensatory increase in decision latency.	187.97621765048132
480.	This article reviews developments at the confluence of two transformational technologies, namely, the fifth generation of wireless communication systems (5G) and machine learning (ML) or artificial intelligence. Although the evolutionary parts of 5G have made significant progress, the fundamental solutions to ultrareliable and low-latency communication (URLLC), one of the major tenets of 5G, are yet to be fully prepared. Breakthroughs in ML, especially deep learning, have transformed many aspects of our lives from face recognition and medical diagnosis to natural language processing. The progress in ML techniques has been made possible by the accessibility to more data and computing power in recent years. However, classical ML relies heavily on the availability of significant memory and computing power for it to function properly.	187.97620419707755
481.	There has been much hype, over the past few years, about the recent progress of artificial intelligence (AI), especially through machine learning. If one is to believe many of the headlines that have proliferated in the media, as well as in an increasing number of scientific publications, it would seem that AI is now capable of creating and learning in ways that are starting to resemble what humans can do. And so that we should start to hope - or fear - that the creation of fully cognisant machine might be something we will witness in our life time. However, much of these beliefs are based on deep misconceptions about what AI can do, and how. In this paper, I start with a brief introduction to the principles of AI, machine learning, and neural networks, primarily intended for psychologists and social scientists, who often have much to contribute to the debates surrounding AI but lack a clear understanding of what it can currently do and how it works. I then debunk four common myths associated with AI: 1) it can create, 2) it can learn, 3) it is neutral and objective, and 4) it can solve ethically and/ or culturally sensitive problems. In a third and last section, I argue that these misconceptions represent four main dangers: 1) avoiding debate, 2) naturalising our biases, 3) deresponsibilising creators and users, and 4) missing out some of the potential uses of machine learning. I finally conclude on the potential benefits of using machine learning in research, and thus on the need to defend machine learning without romanticising what it can actually do.	187.97619644773653
482.	In this paper, a novel benchmark is introduced for evaluating local image descriptors. We demonstrate limitations of the commonly used datasets and evaluation protocols, that lead to ambiguities and contradictory results in the literature. Furthermore, these benchmarks are nearly saturated due to the recent improvements in local descriptors obtained by learning from large annotated datasets. To address these issues, we introduce a new large dataset suitable for training and testing modern descriptors, together with strictly defined evaluation protocols in several tasks such as matching, retrieval and verification. This allows for more realistic, thus more reliable comparisons in different application scenarios. We evaluate the performance of several state-of-the-art descriptors and analyse their properties. We show that a simple normalisation of traditional hand-crafted descriptors is able to boost their performance to the level of deep learning based descriptors once realistic benchmarks are considered. Additionally we specify a protocol for learning and evaluating using cross validation. We show that when training state-of-the-art descriptors on this dataset, the traditional verification task is almost entirely saturated.	187.9761531684845
483.	Forecasting stock market indexes is an important issue for market participants, because even a small improvement in forecast accuracy may lead to better trading decisions than those of other participants. Rising interest in deep learning has led to its application in stock market forecasting. However, it is still challenging to use market-size time-series data to predict composite index prices. In this study, we propose a new stock market forecasting framework, NuNet, which can successfully learn high-level features from super-high dimensional time-series data. NuNet is an end-to-end integrated neural network framework consisting of two feature extractor modules, a super-high dimensional market information feature extractor and a target index feature extractor. In addition, we propose a mini-batch sampling technique, trend sampling, which probabilistically samples more recent data when training. Furthermore, we propose a novel regularization method, called column-wise random shuffling, which is a data augmentation technique that can be applied to convolutional neural networks. The experiments are comprehensively carried out in three aspects for three indexes, namely S&P500, KOSPI200, and FTSE100. The results demonstrate that the proposed model outperforms all baseline models. Specifically, for the S&P500, KOSPI200, and FTSE100, the overall mean squared error of our proposed model NuNet(DA, T) is 60.79%, 51.29%, and 43.36% lower than that of the baseline model SingleNet(R), respectively. Moreover, we employ trading simulations with realistic transaction costs. Our proposed model outperforms the buy-and-hold strategy being an average of 2.57 times more profitable in three indexes. (c) 2020 Elsevier Ltd. All rights reserved.	187.97602081981643
484.	The use of Very High Spatial Resolution (VHSR) imagery in remote sensing applications is nowadays a current practice whenever fine-scale monitoring of the earth's surface is concerned. VHSR Land Cover classification, in particular, is currently a well-established tool to support decisions in several domains, including urban monitoring, agriculture, biodiversity, and environmental assessment. Additionally, land cover classification can be employed to annotate VHSR imagery with the aim of retrieving spatial statistics or areas with similar land cover. Modern VHSR sensors provide data at multiple spatial and spectral resolutions, most commonly as a couple of a higher-resolution single-band panchromatic (PAN) and a coarser multispectral (MS) imagery. In the typical land cover classification workflow, the multi-resolution input is preprocessed to generate a single multispectral image at the highest resolution available by means of a pan-sharpening process. Recently, deep learning approaches have shown the advantages of avoiding data preprocessing by letting machine learning algorithms automatically transform input data to best fit the classification task. Following this rationale, we here propose a new deep learning architecture to jointly use PAN and MS imagery for a direct classification without any prior image sharpening or resampling process. Our method, namely MultiResoLCC, consists of a two-branch end-to-end network which extracts features from each source at their native resolution and lately combine them to perform land cover classification at the PAN resolution. Experiments are carried out on two real-world scenarios over large areas with contrasted land cover characteristics. The experimental results underline the quality of our method while the characteristics of the proposed scenarios underline the applicability and the generality of our strategy in operational settings.	187.97598528973643
485.	Sequence labeling models with recurrent neural network variants, such as long short-term memory (LSTM) and gated recurrent units, show promising performance in several natural language processing tasks, such as named entity recognition (NER). Most current models use unidirectional decoders, which reason only about the past and remain limited to retaining future contexts while generating predictions. Therefore, these models suffer from their generation of unbalanced outputs. Moreover, most existing NER models utilize word embeddings for capturing similarities between words but sustain when handling previously unobserved or infrequently used words. We propose a bidirectional encoder-decoder model for addressing the problem of Arabic NER on the basis of recent work in deep learning, in which the encoder and decoder are bidirectional LSTMs. In addition to word-level embeddings, character-level embeddings are adopted, and they are combined via an embedding-level attention mechanism. Our model can dynamically determine the information that must be utilized from a word- or character-level component through this attention mechanism. Experimental results on the ANERCorp and AQMAR datasets show that the model with a bi-encoder-decoder network and embedding attention layer achieves a high F-score measure of approximately 92%.	187.97594769754403
486.	Automatic modulation classification (AMC), which plays critical roles in both civilian and military applications, is investigated in this paper through a deep learning approach. Conventional AMCs can be categorized into maximum likelihood (ML) based (ML-AMC) and feature-based AMC. However, the practical deployment of ML-AMCs is difficult due to its high computational complexity, and the manually extracted features require expert knowledge. Therefore, an end-to-end convolution neural network (CNN) based AMC (CNN-AMC) is proposed, which automatically extracts features from the long symbol-rate observation sequence along with the estimated signal-to-noise ratio (SNR). With CNN-AMC, a unit classifier is adopted to accommodate the varying input dimensions. The direct training of CNN-AMC is challenging with the complicated model and complex tasks, so a novel two-step training is proposed, and the transfer learning is also introduced to improve the efficiency of retraining. Different digital modulation schemes have been considered in distinct scenarios, and the simulation results show that the CNN-AMC can outperform the feature-based method, and obtain a closer approximation to the optimal ML-AMC. Besides, CNN-AMCs have the certain robustness to estimation error on carrier phase offset and SNR. With parallel computation, the deep-learning-based approach is about 40 to 1700 times faster than the ML-AMC regarding inference speed.	187.97582359380937
487.	Machine Learning and Deep Learning algorithms have become a great revolution in many research fields such as Robotics and Artificial Intelligence. They have applications in such different areas as Meteorology, Cybersecurity, Biology, etc.; though their use in these areas is not so extended. High-performance Computing (HPC) is the most powerful solution to get the best results by using these algorithms. HPC requires various skills to use, such as parallel programming and shell scripting on linux system which may require a long time to acquire and might be intimidating for research with small or no background in Information and Communications Technology (ICT) such as meteorologists or biologists. This work intends to encourage the use of HPC techniques among non-ICT researchers. In order to do so, we plan to analyze the response of such researchers when they are presented some new techniques and possibilities. A set of experiments are being carried out with a group of ethology researchers at Eotvos Lorand University. We will use a three-step methodology. First, researchers will fill out a questionnaire about their knowledge about and attitude towards HPC techniques. Then, they will attend an introductory talk about HPC in general and some specific use cases which may aid them in their research, after which they will receive a follow up questionnaire. After this a subset of the attendees will receive hands-on training in the use of specific HPC applications. Finally, a last round of questionnaires will be carried out with the participants. We expect to identify some key indicators which allow us to identify the main advantages and drawbacks that non-ICT researchers face when discovering High-performance Computing.	187.97580955459762
488.	The Local Climate Zone (LCZ) scheme is a classification system providing a standardization framework to present the characteristics of urban forms and functions, especially for urban heat island (UHI) research. Landsat-based 100 m resolution LCZ maps have been classified by the World Urban Database and Portal Tool (WUDAPT) method using a random forest (RF) machine learning classifier. Some studies have proposed modified RF and convolutional neural network (CNN) approaches. This study aims to compare CNN with an RF classifier for LCZ mapping in great detail. We designed five schemes (three RF-based schemes (S1-S3) and two CNN-based ones (S4-S5)), which consist of various combinations of input features from bitemporal Landsat 8 data over four global mega cities: Rome, Hong Kong, Madrid, and Chicago. Among the five schemes, the CNN-based one with the incorporation of a larger neighborhood information showed the best classification performance. When compared to the WUDAPT workflow, the overall accuracies for entire land cover classes (OA) and for urban LCZ types (i.e., LCZ1-10; OA(urb)) increased by about 6-8% and 10-13%, respectively, for the four cities. The transferability of LCZ models for the four cities were evaluated, showing that CNN consistently resulted in higher accuracy (increased by about 7-18% and 18-29% for OA and OA(urb), respectively) than RF. This study revealed that the CNN classifier classified particularly well for the specific LCZ classes in which buildings were mixed with trees or buildings or plants were sparsely distributed. The research findings can provide a basis for guidance of future LCZ classification using deep learning.	187.97572989886697
489.	Many face recognition systems boost the performance using deep learning models, but only a few researches go into the mechanisms for dealing with online registration. Although we can obtain discriminative facial features through the state-of-the-art deep model training, how to decide the best threshold for practical use remains a challenge. We develop a technique of adaptive threshold mechanism to improve the recognition accuracy. We also design a face recognition system along with the registering procedure to handle online registration. Furthermore, we introduce a new evaluation protocol to better evaluate the performance of an algorithm for real-world scenarios. Under our proposed protocol, our method can achieve a 22% accuracy improvement on the LFW dataset.	187.97569396229724
490.	Biomimetics is a known innovation paradigm of the twenty-first century with significant impact on science, society, economy, and challenges of sustainability. As such, it can be understood as a mindset for creative thinking and as a methodology or technique for effective knowledge transfer between disciplines, mainly biology and technology. As biomimetics is relevant to practitioners in various fields of application, understanding the teaching and training of biomimetics for different audiences is important. With this article, we aim to give a holistic view of teaching and training practices and opportunities. First, we offer a set of learning objectives based on an analysis of various courses worldwide and we give recommendations for the design of future curricula. Second, based on an audience analysis and interviews, we developed a set of personas of the users of biomimetics, and as such, we offer a deeper understanding of their needs for the design of the process, including tools and methods.	187.97566251791676
491.	In machine learning, one-class classification tries to classify data of a specific category amongst all data, by learning from a training set containing only the data of that unique category. In the field of medical imaging, one-class learning can be developed to model only normality (similar to semi-supervised classification or anomaly detection), since the samples of all possible abnormalities are not always available, as some forms of anomaly are very rare. The one-class learning approach can be naturally adapted to the way radiologists identify anomalies in medical images: usually they are able to recognize lesions by comparing them with normal images and surroundings. Inspired by the traditional one-class learning approach, we propose an end-to-end deep adversarial one-class learning (DAOL) approach for semi-supervised normal and abnormal chest radiograph (X-ray) classification, by training only from normal X-ray images. The DAOL framework consists of deep convolutional generative adversarial networks (DCGAN) and an encoder at each end of the DCGAN. The DAOL generator is able to reconstruct the normal X-ray images while not adequate for well reconstructing the abnormalities in abnormal X-rays in the testing phase, since only the normal X-rays were used for training the network, and the abnormal images with various abnormalities were unseen during training. We propose three adversarial learning objectives which optimize the training of DAOL. The proposed network achieves an encouraging result (AUC 0.805) in classifying normal and abnormal chest X-rays on the challenging NIH Chest X-ray dataset in a semi-supervised setting.	187.97542584324555
492.	Anatomy, has in history, been linked to helpful ways to remember structures, branches of nerves, structures passing through foramina, etc. Scalp is even a mnemonic in itself (Skin, Connective tissue, Aponeurosis, Loose areolar tissue, Pericranium). There has been concern by some educators that using mnemonics or rhymes promotes a surface approach to learning and is unhelpful in establishing long-term and meaningful deep learning. This article argues that mnemonics and rhyme can be used, in the appropriate way, at the right time, by students as an important learning strategy. That strategy can help lay a foundation of knowledge to be developed and later built upon, or simply recall information more easily. Mnemonics, like all information that is to be recalled, is consolidated by rehearsal. In examining the neuroanatomy of learning theories, it is therefore possible to suggest that when students begin to learn an area of anatomy, such as the cranial nerves, using a mnemonic or rhyme, it can help students remember the names and facilitate the engagement of the working memory processes assisting the student to build a construct for subsequent deeper layers of knowledge. Modern approaches to anatomy education involve a myriad of learning opportunities, but educators must assess the value of each one before recommending them to students. It appears that using mnemonics and rhyme is as valid today as it has been for centuries.	187.97540198675995
493.	The effective data mining of social media has become increasingly recognized for its value in informing decision makers of public welfare. However, existing studies do not fully exploit the underlying merit of big data. In this study, we develop a data-driven framework that integrates machine learning with spatial statistics, and then use it on Xiamen Island, China to delineate urban population dynamic patterns based on hourly Baidu heat map data collected from August 25 to September 3, 2017. The results showed that hot grids are primarily clustered along the main street through the downtown area during working days, whereas cold grids are often observed at the edge of the city during the weekend. The mixed use (of commercial and life services, restaurants and snack bars, offices, leisure areas and sports complexes) is the most significant contributing factor. A new cold grid emerged near conference venues before the Brazil, Russia, India, China, and South Africa Summit, revealing the strong effects of regulations on population dynamics and its evolving patterns. This study demonstrates that the proposed data-driven framework might offer new insights into urban population dynamics and its driving mechanism in support of sustainable urban development.	187.97536561154428
494.	While the human brain presents natural structural asymmetries between left and right hemispheres in MR images, most neurological diseases are associated with abnormal brain asymmetries. Due to the great variety of such anomalies, we present a framework to model normal structural brain asymmetry from control subjects only, independent of the neurological disease. The model dismisses data annotation by exploiting generative deep neural networks and one-class classifiers. We also propose a patch-based model to localize volumes of interest with reduced background sizes around selected brain structures and a one-class classifier based on an optimum-path forest. This model makes the framework independent of segmentation, which may fail, especially in abnormal images, or may not be available for a given structure. We validate the first method to the detection of abnormal hippocampal asymmetry using distinct groups of Epilepsy patients and testing controls. The results of validation using the original feature space and a two-dimensional space based on non-linear projection show the potential to extend the framework for abnormal asymmetry detection in other parts of the brain and develop intelligent and interactive virtual environments. For instance, the approach can be used for screening, inspection, and annotation of the detected anomaly type, allowing the development of CADx systems.	187.97535033799033
495.	We present ChromAlignNet, a deep learning model for alignment of peaks in Gas Chromatography-Mass Spectrometry (GC-MS) data. In GC-MS data, a compound's retention time (RT) may not stay fixed across multiple chromatograms. To use GC-MS data for biomarker discovery requires alignment of identical analyte's RT from different samples. Current methods of alignment are all based on a set of formal, mathematical rules. We present a solution to GC-MS alignment using deep learning neural networks, which are more adept at complex, fuzzy data sets. We tested our model on several GC-MS data sets of various complexities and analysed the alignment results quantitatively. We show the model has very good performance (AUC similar to 1 for simple data sets and AUC similar to 0.85 for very complex data sets). Further, our model easily outperforms existing algorithms on complex data sets. Compared with existing methods, ChromAlignNet is very easy to use as it requires no user input of reference chromatograms and parameters. This method can easily be adapted to other similar data such as those from liquid chromatography. The source code is written in Python and available online. Crown Copyright (C) 2019 Published by Elsevier B.V. All rights reserved.	187.97528592728915
496.	Studies have shown that shotgun metagenomics sequencing facilitates the evaluation of diverse viruses, bacteria, and eukaryotic microbes and assists in exploring their abundances in complex samples. Due to the challenges of processing a substantial amount of sequences and overall computational complexity, it is time-consuming to analyze these data through traditional database sequence comparison approaches. Deep learning has been widely used to solve many classification problems, including those in the bioinformatics field, and has demonstrated its accuracy and efficiency for analyzing large-scale datasets. The purpose of this work is to explore how a long short-term memory (LSTM) network can be used to learn sequential genome patterns through pathogen detection from metagenome data. Our experimental result showed that we can obtain similar accuracy to the conventional BLAST method, but at a speed that is about 36 times faster.	187.97517715760057
497.	Feeding is a major factor that determines the production costs and water quality of aquaculture. Analysis of fish feeding behavior forms an important part of the feeding optimization. Fish feeding has generally been performed with automatic feeding machines which can lead to excessive or insufficient feeding. Recognition of fish feeding behavior can provide valuable input for optimizing feeding quantity. Due to the complexity of the environment and the uncertainty of fish behavior, the correlation and accuracy of behavior recognition are generally low. The accurate identification of fish feeding behavior till faces substantial challenges. This paper reviews the technical methods that have been used to identify fish feeding behavior in aquaculture over the past 30 years. The ad-vantages and disadvantages of each method under different experimental conditions and applications are ana-lyzed. Many methods are effective at evaluating and quantifying fish feeding intensity, but the recognition accuracy still needs further improvement. It is proposed by this paper that technologies such as data fusion and deep learning has great potential for improving the recognition of fish feeding behavior.	187.97505809668948
498.	Nowadays, analyzing, detecting, and visualizing abnormal power consumption behavior of householders are among the principal challenges in identifying ways to reduce power consumption. This paper introduces a new solution to detect energy consumption anomalies based on extracting micro-moment features using a rule-based model. The latter is used to draw out load characteristics using daily intent-driven moments of user consumption actions. Besides micro-moment features extraction, we also experiment with a deep neural network architecture for efficient abnormality detection and classification. In the following, a novel anomaly visualization technique is introduced that is based on a scatter representation of the micro-moment classes, and hence providing consumers an easy solution to understand their abnormal behavior. Moreover, in order to validate the proposed system, a new energy consumption dataset at appliance level is also designed through a measurement campaign carried out at Qatar University Energy Lab, namely, Qatar University dataset. Experimental results on simulated and real datasets collected at two regions, which have extremely different climate conditions, confirm that the proposed deep micro-moment architecture outperforms other machine learning algorithms and can effectively detect anomalous patterns. For example, 99.58% accuracy and 97.85% F1 score have been achieved under Qatar University dataset. These promising results establish the efficacy of the proposed deep micro-moment solution for detecting abnormal energy consumption, promoting energy efficiency behaviors, and reducing wasted energy.	187.97503696085028
499.	Semantic segmentation and single-view depth estimation are two fundamental problems in computer vision. They exploit the semantic and geometric properties of images, respectively, and are thus complementary in scene understanding. In this paper, we propose a collaborative deconvolutional neural network (C-DCNN) to jointly model these two problems for mutual promotion. The C-DCNN consists of two DCNNs, of which each is for one task. The DCNNs provide a finer resolution reconstruction method and are pretrained with hierarchical supervision. The feature maps from these two DCNNs are integrated via a pointwise bilinear layer, which fuses the semantic and depth information and produces higher order features. Then, the integrated features are fed into two sibling classification layers to simultaneously learn for semantic segmentation and depth estimation. In this way, we combine the semantic and depth features in a unified deep network and jointly train them to benefit each other. Specifically, during network training, we process depth estimation as a classification problem where a soft mapping strategy is proposed to map the continuous depth values into discrete probability distributions and the cross entropy loss is used. Besides, a fully connected conditional random field is also used as postprocessing to further improve the performance of semantic segmentation, where the proximity relations of pixels on position, intensity, and depth are jointly considered. We evaluate our approach on two challenging benchmarks: NYU Depth V2 and SUN RGB-D. It is demonstrated that our approach effectively utilizes these two kinds of information and achieves state-of-the-art results on both the semantic segmentation and depth estimation tasks.	187.975033519433
500.	Recently years, convolutional neural networks (CNNs) have proven to be powerful tools for a broad range of computer vision tasks. However, training a CNN from scratch is difficult because it requires a large amount of labeled training data, which remains a challenge in medical imaging domain. To this end, deep transfer learning (TL) technique is widely used for many medical image tasks. In this paper, we propose a novel multisource transfer learning CNN model for lymph node detection. The mechanism behind it is straightforward. Point-wise (1 x 1) convolution is used to fuse multisource transfer learning knowledge. Concretely, we view the transferred features as priori domain knowledge and 1 x 1 convolutional operation is implemented after pre-trained convolution layers to adaptively combine the transfer information for target task. In order to learn non-linear transferred features and prevent over-fitting, we present an encode process for the pre-trained convolution kernels. At last, based on convolutional factorization technique, we train the proposed CNN model and the encoder process jointly, which improves the feasibility of our approach. The effectiveness of the proposed method is verified on lymph node (LN) dataset: 388 mediastinal LNs labeled by radiologists in 90 patient CT scans, and 595 abdominal LNs in 86 patient CT scans for LN detection. Our method demonstrates sensitivities of about 85%/71% at 3 FP/vol. and 92%/85% at 6 FP/vol. for mediastinum and abdomen respectively, which compares favorably to previous methods.	187.97485058768808
501.	Multicenter magnetic resonance imaging is gaining more popularity in large-sample projects. Since both varying hardware and software across different centers cause unavoidable data heterogeneity across centers, its impact on reliability in study outcomes has also drawn much attention recently. One fundamental issue arises in how to derive model parameters reliably from image data of varying quality. This issue is even more challenging for advanced diffusion methods such as diffusion kurtosis imaging (DKI). Recently, deep learning-based methods have been demonstrated with their potential for robust and efficient computation of diffusion-derived measures. Inspired by these approaches, the current study specifically designed a framework based on a three-dimensional hierarchical convolutional neural network, to jointly reconstruct and harmonize DKI measures from multicenter acquisition to reformulate these to a state-of-the-art hardware using data from traveling subjects. The results from the harmonized data acquired with different protocols show that: 1) the inter-scanner variation of DKI measures within white matter was reduced by 51.5% in mean kurtosis, 65.9% in axial kurtosis, 53.7% in radial kurtosis, and 61.5% in kurtosis fractional anisotropy, respectively; 2) data reliability of each single scanner was enhanced and brought to the level of the reference scanner; and 3) the harmonization network was able to reconstruct reliable DKI values from high data variability. Overall the results demonstrate the feasibility of the proposed deep learning-based method for DKI harmonization and help to simplify the protocol setup procedure for multicenter scanners with different hardware and software configurations.	187.97480269973454
502.	Shortage of fully annotated datasets has been a limiting factor in developing deep learning based image segmentation algorithms and the problem becomes more pronounced in multi-organ segmentation. In this paper, we propose a unified training strategy that enables a novel multi-scale deep neural network to be trained on multiple partially labeled datasets for multi-organ segmentation. In addition, a new network architecture for multi-scale feature abstraction is proposed to integrate pyramid input and feature analysis into a U-shape pyramid structure. To bridge the semantic gap caused by directly merging features from different scales, an equal convolutional depth mechanism is introduced. Furthermore, we employ a deep supervision mechanism to refine the outputs in different scales. To fully leverage the segmentation features from all the scales, we design an adaptive weighting layer to fuse the outputs in an automatic fashion. All these mechanisms together are integrated into a Pyramid Input Pyramid Output Feature Abstraction Network (PIPO-FAN). Our proposed method was evaluated on four publicly available datasets, including BTCV, LiTS, KiTS and Spleen, where very promising performance has been achieved. The source code of this work is publicly shared at https://github.com/DIAL-RPI/PIPO-FAN to facilitate others to reproduce the work and build their own models using the introduced mechanisms.	187.97479114431576
503.	The mental health rating scales combined with psychological expert consultation are easily influenced by subjective factors from psychological experts and lack objectivity and scientificalness. Due to the serious influence of depression tendency on learning and living of college students, a novel DNN network model framework based on context emotion information is designed to achieve the automatic auxiliary emotion classification. More corpus training sample can be received by heightening the sample length without reducing samples' number. Firstly, the existing sample feature is input into the recognition model to encode depression related features, and then the MADN features of the samples in the two adjacent segments are input into the above trained model in order for fine-tuning and optimization. Compared with the existing optimal method, the proposed model improves the recognition accuracy in the diagnosis of depression. From the analysis of the experimental results, it is known that deep learning network can monitor the emotional state of college students with high precision, which can accurately identify the patients with depression. The deep learning model can take effective measures to prevent the depression of college students, and discover the depression of college students, alleviate and treat the depression of college students, reduce the depression rate of college students.	187.97478258079516
504.	Lake water-level fluctuation is a complex and dynamic process, characterized by high stochasticity and nonlinearity, and difficult to model and forecast. In recent years, applications of machine learning (ML) models have yielded substantial progress in forecasting lake water-level fluctuations. This paper presents a comprehensive review of the applications of ML models for modeling water-level dynamics in lakes. Among the many existing ML models, seven popular ML model types are reviewed: (1) artificial neural network (ANN); (2) support vector machine (SVM); (3) artificial neuro-fuzzy inference system (ANFIS); (4) hybrid models, such as hybrid wavelet-artificial neural network (WA-ANN) model, hybrid wavelet-artificial neuro-fuzzy inference system (WA-ANFIS) model, and hybrid wavelet-support vector machine (WA-SVM) model; (5) evolutionary models, such as gene expression programming (GEP) and genetic programming (GP); (6) extreme learning machine (ELM); and (7) deep learning (DL). Model inputs, data split, model performance criteria, and model inter-comparison as well as the associated issues are discussed. The advantages and limitations of the established ML models are also discussed. Some specific directions for future research are also offered. This review provides a new vision for hydrologists and water resources planners for sustainable management of lakes.	187.9747791333687
505.	Problem: Classical systems of automatic speech recognition are traditionally built using an acoustic model based on hidden Markov models and a statistical language model. Such systems demonstrate high recognition accuracy, but consist of several independent complex parts, which can cause problems when building models. Recently, an end-to-end recognition method has been spread, using deep artificial neural networks. This approach makes it easy to implement models using just one neural network. End-to-end models often demonstrate better performance in terms of speed and accuracy of speech recognition. Purpose: Implementation of end-to-end models for the recognition of continuous Russian speech, their adjustment and comparison with hybrid base models in terms of recognition accuracy and computational characteristics, such as the speed of learning and decoding. Methods: Creating an encoderdecoder model of speech recognition using an attention mechanism; applying techniques of stabilization and regularization of neural networks; augmentation of data for training; using parts of words as an output of a neural network. Results: An encoder-decoder model was obtained using an attention mechanism for recognizing continuous Russian speech without extracting features or using a language model. As elements of the output sequence, we used parts of words from the training set. The resulting model could not surpass the basic hybrid models, but surpassed the other baseline end-to-end models, both in recognition accuracy and in decoding/ learning speed. The word recognition error was 24.17% and the decoding speed was 0.3 of the real time, which is 6% faster than the baseline end-to-end model and 46% faster than the basic hybrid model. We showed that end-to-end models could work without language models for the Russian language, while demonstrating a higher decoding speed than hybrid models. The resulting model was trained on raw data without extracting any features. We found that for the Russian language the hybrid type of an attention mechanism gives the best result compared to location-based or context-based attention mechanisms. Practical relevance: The resulting models require less memory and less speech decoding time than the traditional hybrid models. That fact can allow them to be used locally on mobile devices without using calculations on remote servers.	187.97468632165481
506.	In recent times, many efforts have been made to improve remote sensing image scene classification, especially using popular deep convolutional neural networks. However, most of these methods do not consider the specific scene orientation of the remote sensing images. In this letter, we propose the improved oriented response network (IORN), which is based on the ORN, to handle the orientation problem in remote sensing image scene classification. We propose average active rotating filters (A-ARFs) in the IORN. While IORNs are being trained, A-ARFs are updated by a method that is different from the ARFs of the ORN, without additional computations. This change helps IORN improve its ability to encode orientation information and speeds up optimization during training. We also propose Squeeze-ORAlign (S-ORAlign) by adding a squeeze layer to ORAlign of ORN. With the squeeze layer, S-ORAlign can address large-scale images, unlike ORAlign. An ablation study and comparison experiments are designed on a public remote sensing image scene classification data set. The experimental results demonstrate the effectiveness and better performance of the proposed model over that of other state-of-the-art models.	187.97451836774775
507.	We present an ideal mixed-integer programming (MIP) formulation for a rectified linear unit (ReLU) appearing in a trained neural network. Our formulation requires a single binary variable and no additional continuous variables beyond the input and output variables of the ReLU. We contrast it with an ideal "extended" formulation with a linear number of additional continuous variables, derived through standard techniques. An apparent drawback of our formulation is that it requires an exponential number of inequality constraints, but we provide a routine to separate the inequalities in linear time. We also prove that these exponentially-many constraints are facet-defining under mild conditions. Finally, we study network verification problems and observe that dynamically separating from the exponential inequalities (1) is much more computationally efficient and scalable than the extended formulation, (2) decreases the solve time of a state-of-the-art MIP solver by a factor of 7 on smaller instances, and (3) nearly matches the dual bounds of a state-of-the-art MIP solver on harder instances, after just a few rounds of separation and in orders of magnitude less time.	187.97444798750476
508.	The number and diversity of machine learning applications causes an increasing need for understanding computational models and used data. This paper deals with a framework design of easily interpretable rules of the Takagi-Sugeno-Kang (TSK) fuzzy model. The proposed framework aggregates TSK fuzzy rules and association rules by calculating overlapping value intervals of variables appearing in both antecedent and consequent parts of fuzzy and association rules. Besides a simple insight into rule interconnections of the rule-based models, the framework provides an assessment of fuzzy rule importance, and in accordance with other rules and the complete TSK fuzzy model. The proposed framework is developed and illustrated by analysing traffic accidents with pedestrian involvement. It provides a deeper understanding of the built rule-based model, as well as more readable identification of significant accident causes. The framework can be used in many domains of analysis modelling and decision making processes where computational model understanding is crucial.	187.9743552946788
509.	In this work we present our results designing a deep neural network (DNN) to act as a surrogate model for costly HPC simulations. In order to determine a ground vehicle's gap crossing ability in extreme weather scenarios, several HPC simulations are currently used. Hydrologic models are first run to determine the environmental conditions over an area of interest. Once these conditions are known they are given, along with the terrain data, to a vehicle simulation which determines if a particular vehicle can cross a stream at a given point. Every point of interest must be evaluated independently, which quickly becomes infeasible for a large numbers of crossing points. In order to accelerate this phase of the process, we have created a DNN that acts as a surrogate model for the vehicle simulator. Despite several challenges converting irregular data into a form that can be used with a DNN, and incorporating scalars into the models, we were able to produce DNN models that predicted the gap crossing ability of all vehicle types with over 95% accuracy.	187.97432281182915
510.	Face video retrieval is an attractive research topic in computer vision. However, it remains challenges to overcome because of the significant variation in pose changes, illumination conditions, occlusions, and facial expressions. In video content analysis, face recognition has been playing a vital role. Besides, deep neural networks are being actively studied, and deep learning models have been widely used for object detection, especially for face recognition. Therefore, this study proposes a cloud-based face video retrieval system with deep learning. First, a dataset is collected and pre-processed. To produce a useful dataset for the CNN models, blurry images are removed, and face alignment is implemented on the remaining images. Then the final dataset is constructed and used to pre-train the CNN models (VGGFace, ArcFace, and FaceNet) for face recognition. We compare the results of these three models and choose the most efficient one to develop the system. To implement a query, users can type in the name of a person. If the system detects a new person, it performs enrolling that person. Finally, the result is a list of images and time associated with those images. In addition, a system prototype is implemented to verify the feasibility of the proposed system. Experimental results demonstrate that this system outperforms in terms of recognition accuracy and computational time.	187.97429652438416
511.	In many practical visual recognition scenarios, feature distributions between source domain and the target domain are quite different, which results in the emergence of general cross-domain visual recognition problems. To address the problems of visual domain mismatch, we propose a novel shallow semi-supervised adversarial transfer learning network, which is called Coupled adversarial transfer Domain Adaptation (CatDA), for distribution alignment between two domains. The proposed CatDA approach is inspired by cycleGAN, but leveraging multiple shallow multilayer perceptrons (MLPs) instead of deep networks. Specifically, our CatDA comprises of two symmetric and slim sub-networks, such that the coupled adversarial learning framework is formulated. With such symmetry of two generators, the input data from source/target domain can be fed into the MLP network for target/source domain generation, supervised by two confrontation oriented coupled discriminators. Notably, in order to avoid the critical flaw of high-capacity of the feature extraction function during domain adversarial training, domain specific loss and domain knowledge fidelity loss are proposed in each generator, such that the effectiveness of the proposed transfer network is guaranteed. Additionally, the essential difference from cycleGAN is that our method aims to generate domain-agnostic and aligned features for domain adaptation and transfer learning rather than synthesize realistic images. We show experimentally on a number of benchmark datasets and the proposed approach achieves competitive performance over state-of-the-art domain adaptation and transfer learning approaches. (C) 2020 Elsevier B.V. All rights reserved.	187.9742843966028
512.	Many researchers and practitioners have attempted to predict financial market trends for excess returns using multiple information sources including social media. Recent studies have investigated the relation between public sentiment and stock price movements and demonstrated that investment decisions are affected by public opinion. In this paper, we design a novel framework that combines the wisdom of crowds and technical analysis for financial market prediction using a new fusion strategy. A machine learning technique called deep random subspace ensembles (DRSE), which integrates deep learning algorithms and ensemble learning methods, is proposed according to the characteristics of the prediction task. Based on collected real-world datasets, the experimental results show that our proposed method outperforms the baseline models in predicting stock market by at least 14.2% in terms of AUC value, indicating the efficacy of DRSE as a viable mechanism for financial market prediction. (C) 2018 Elsevier B.V. All rights reserved.	187.97425622060342
513.	Direct observation of morphological plant traits is tedious and a bottleneck for high-throughput phenotyping. Hence, interest in image-based analysis is increasing, with the requirement for software that can reliably extract plant traits, such as leaf count, preferably across a variety of species and growth conditions. However, current leaf counting methods do not work across species or conditions and therefore may lack broad utility. In this paper, we present Pheno-Deep Counter, a single deep network that can predict leaf count in two-dimensional (2D) plant images of different species with a rosette-shaped appearance. We demonstrate that our architecture can count leaves from multi-modal 2D images, such as visible light, fluorescence and near-infrared. Our network design is flexible, allowing for inputs to be added or removed to accommodate new modalities. Furthermore, our architecture can be used as is without requiring dataset-specific customization of the internal structure of the network, opening its use to new scenarios. Pheno-Deep Counter is able to produce accurate predictions in many plant species and, once trained, can count leaves in a few seconds. Through our universal and open source approach to deep counting we aim to broaden utilization of machine learning-based approaches to leaf counting. Our implementation can be downloaded at .	187.9741248803952
514.	Over the last few years, completely automated public turing test to tell computers and humans apart (CAPTCHA) has been used as an effective method to prevent websites from malicious attacks, however, CAPTCHA designers failed to reach a balance between good usability and high security. In this study, the authors apply neural style transfer to enhance the security for CAPTCHA design. Two image-based CAPTCHAs, Grid-CAPTCHA and Font-CAPTCHA, based on neural style transfer are proposed. Grid-CAPTCHA offers nine stylized images to users and requires users to select all corresponding images according to a short description, and Font-CAPTCHA asks users to click Chinese characters presented in the image in sequence according to the description. To evaluate the effectiveness of this techniques on enhancing CAPTCHA security, they conducted a comprehensive field study and compared them to similar mechanisms. The comparison results demonstrated that the neural style transfer decreased the success rate of automated attacks. Human beings have achieved a successful solving rate of 75.04 and 84.49% on the Grid-CAPTCHA and Font-CAPTCHA schemes, respectively, indicating good usability. The results prove deep learning can have a positive effect on enhancing CAPTCHA security and provides a promising direction for future CAPTCHA study.	187.9740710292474
515.	Sentiment analysis is a key component in various text mining applications. Numerous sentiment classification techniques, including conventional and deep-learning-based methods, have been proposed in the literature. In most existing methods, a high-quality training set is assumed to be given. Nevertheless, constructing a high-quality training set that consists of highly accurate labels is challenging in real applications. This difficulty stems from the fact that text samples usually contain complex sentiment representations, and their annotation is subjective. We address this challenge in this study by leveraging a new labeling strategy and utilizing a two-level long short-term memory network to construct a sentiment classifier. Lexical cues are useful for sentiment analysis, and they have been utilized in conventional studies. For example, polar and negation words play important roles in sentiment analysis. A new encoding strategy, that is, rho-hot encoding, is proposed to alleviate the drawbacks of one-hot encoding and, thus, effectively incorporate useful lexical cues. Moreover, the sentimental polarity of a word may change in different sentences due to label noise or context. A flipping model is proposed to model the polar flipping of words in a sentence. We compile three Chinese datasets on the basis of our label strategy and proposed methodology. Experiments demonstrate that the proposed method outperforms state-of-the-art algorithms on both benchmark English data and our compiled Chinese data.	187.97404030196805
516.	Tree-related microhabitats (TreMs) play an important role in maintaining forest biodiversity and have recently received more attention in ecosystem conservation, forest management and research. However, TreMs have until now only been assessed by experts during field surveys, which are time-consuming and difficult to reproduce. In this study, we evaluate the potential of close-range terrestrial laser scanning (TLS) for semi-automated identification of different TreMs (bark, bark pockets, cavities, fungi, ivy and mosses) in dense TLS point clouds using machine learning algorithms, including deep learning. To classify the TreMs, we applied: (1) the Random Forest (RF) classifier, incorporating frequently used local geometric features and two additional self-developed orientation features, and (2) a deep Convolutional Neural Network (CNN) trained using rasterized multiview orthographic projections (MVOPs) containing top view, front view and side view of the point's local 3D neighborhood. The results confirmed that using local geometric features is beneficial for identifying the six groups of TreMs in dense tree-stem point clouds, but the rasterized MVOPs are even more suitable. Whereas the overall accuracy of the RF was 70%, that of the deep CNN was substantially higher (83%). This study reveals that close-range TLS is promising for the semi-automated identification of TreMs for forest monitoring purposes, in particular when applying deep learning techniques.	187.97401144657422
517.	Object detection in aerial images plays an important role for a wide range of applications. Although many efforts have been done in the last decade, it is still an active and challenging problem because of the highly complex backgrounds and the large variations in the visual appearance of objects caused by viewpoint variation, occlusion, illumination, etc. Recently, many object detectors based on deep learning demonstrate the great advantages for significantly improving the detection performance in aerial images. However, the most accuracy neural networks usually have hundreds of layers and thousands of channels, thus requiring huge computation and memory consumption. Besides, the state-of-the-art object detectors are usually fined-tuned from the models pretrained on classification dataset ImageNet, which limits the modification of network architecture and also leads to learning bias because of the different domains. In this paper we trained a lightweight convolutional neural network from scratch to perform object detection in aerial images. When designing the lightweight network, Concatenated Rectified Linear Units (CReLU) and depthwise separable convolution operation were employed to reduce the computation cost and model size. When training the lightweight network from scratch, we employ Group Normalization (GN) in each convolution layer, which makes smoother optimization landscape and has more stable gradients. A serial of ablation experiments is conducted on the recently published large-scale Dataset for Object detection in Aerial images (DOTA), and the results show that the proposed object detection methods with lightweight network trained from scratch achieves competitive performance but has smaller model size and lower computation cost.	187.97396659962655
518.	The unconstrained binary quadratic programming (UBQP) problem is a difficult combinatorial optimization problem that has been intensively studied in the past decades. Due to its NP-hardness, many heuristic algorithms have been developed for the solution of the UBQP. These algorithms are usually problem-tailored, which lack generality and scalability. To address these issues, a heuristic algorithm based on deep reinforcement learning (DRLH) is proposed in this paper. It features in inputting specific features and using a neural network model called NN to guild the selection of variable at each solution construction step. Also, to improve the algorithm speed and efficiency, two algorithm variants named simplified DRLH (DRLS) and DRLS with hill climbing (DRLS-HC) are developed as well. These three algorithms are examined through extensive experiments in comparison with famous heuristic algorithms from the literature. Experimental results show that the DRLH, DRLS, and DRLS-HC outperform their competitors in terms of both solution quality and computational efficiency. Precisely, the DRLH achieves the best-quality results, while DRLS offers a high-quality solution in a very short time. By adding a hill-climbing procedure to DRLS, the resulting DRLS-HC algorithm is able to obtain almost the same quality result as DRLH with however 5 times less computing time on average. We conducted additional experiments on large-scale instances and various data distributions to verify the generality and scalability of the proposed algorithms, and the results on benchmark instances indicate the ability of the algorithms to be applied to practical problems. (C) 2020 Elsevier B.V. All rights reserved.	187.9739618731321
519.	The paper addresses the further advance in our complex research in the field of multisensory image fusion based on generative adversarial models [1-2] and their application to such practical tasks as visual representation of fused images, acquired in different spectral ranges (e.g. TV and IR), and changes detection on images, acquired in different conditions (e.g. season-varying images). A developed architecture of a neural network based on pix2pix model is presented, which can solve the both tasks mentioned above. A technique for generating training and test datasets including data augmentation process is described. The results are demonstrated on real-world images.	187.9737139245867
520.	The superiority of deeply learned pedestrian representations has been reported in very recent literature of person re-identification (re-ID). In this article, we consider the more pragmatic issue of learning a deep feature with no or only a few labels. We propose a progressive unsupervised learning (PUL) method to transfer pretrained deep representations to unseen domains. Our method is easy to implement and can be viewed as an effective baseline for unsupervised re-ID feature learning. Specifically, PUL iterates between (1) pedestrian clustering and (2) fine-tuning of the convolutional neural network (CNN) to improve the initialization model trained on the irrelevant labeled dataset. Since the clustering results can be very noisy, we add a selection operation between the clustering and fine-tuning. At the beginning, when the model is weak, CNN is fine-tuned on a small amount of reliable examples that locate near to cluster centroids in the feature space. As the model becomes stronger, in subsequent iterations, more images are being adaptively selected as CNN training samples. Progressively, pedestrian clustering and the CNN model are improved simultaneously until algorithm convergence. This process is naturally formulated as self-paced learning. We then point out promising directions that may lead to further improvement. Extensive experiments on three large-scale re-ID datasets demonstrate that PUL outputs discriminative features that improve the re-ID accuracy. Our code has been released at https://github.com/hehefan/Unsupervised- Person- Re- identification- Clustering- and- Fine- tuning.	187.97369319044986
521.	Visual and audiovisual speech recognition are witnessing a renaissance which is largely due to the advent of deep learning methods. In this paper, we present a deep learning architecture for lipreading and audiovisual word recognition, which combines Residual Networks equipped with spatiotemporal input layers and Bidirectional LSTMs. The lipreading architecture attains 11.92% misclassification rate on the challenging Lipreading-In-The-Wild database, which is composed of excerpts from BBC-TV, each containing one of the 500 target words. Audiovisual experiments are performed using both intermediate and late integration, as well as several types and levels of environmental noise, and notable improvements over the audio-only network are reported, even in the case of clean speech. A further analysis on the utility of target word boundaries is provided, as well as on the capacity of the network in modeling the linguistic context of the target word. Finally, we examine difficult word pairs and discuss how visual information helps towards attaining higher recognition accuracy.	187.97361607933627
522.	Recently, the use of social networks such as Facebook, Twitter, and Sina Weibo has become an inseparable part of our daily lives. It is considered as a convenient platform for users to share personal messages, pictures, and videos. However, while people enjoy social networks, many deceptive activities such as fake news or rumors can mislead users into believing misinformation. Besides, spreading the massive amount of misinformation in social networks has become a global risk. Therefore, misinformation detection (MID) in social networks has gained a great deal of attention and is considered an emerging area of research interest. We find that several studies related to MID have been studied to new research problems and techniques. While important, however, the automated detection of misinformation is difficult to accomplish as it requires the advanced model to understand how related or unrelated the reported information is when compared to real information. The existing studies have mainly focused on three broad categories of misinformation: false information, fake news, and rumor detection. Therefore, related to the previous issues, we present a comprehensive survey of automated misinformation detection on (i) false information, (ii) rumors, (iii) spam, (iv) fake news, and (v) disinformation. We provide a state-of-the-art review on MID where deep learning (DL) is used to automatically process data and create patterns to make decisions not only to extract global features but also to achieve better results. We further show that DL is an effective and scalable technique for the state-of-the-art MID. Finally, we suggest several open issues that currently limit real-world implementation and point to future directions along this dimension.	187.97361054939216
523.	Deep learning is an effective approach to solving image recognition problems. People draw intuitive conclusions from trading charts. This study uses the characteristics of deep learning to train computers in imitating this kind of intuition in the context of trading charts. The main goal of our approach is combining the time-series modeling and convolutional neural networks (CNNs) to build a trading model. We propose three steps to build the trading model. First, we preprocess the input data from quantitative data to images. Second, we use a CNN, which is a type of deep learning, to train our trading model. Third, we evaluate the model's performance in terms of the accuracy of classification. The experimental results show that if the strategy is clear enough to make the images obviously distinguishable the CNN model can predict the prices of a financial asset. Hence, our approach can help devise trading strategies and help clients automatically obtain personalized trading strategies.	187.97353719928566
524.	A method based on the theory of deep learning and feature extraction and a fault diagnosis model of a rolling bearing based on deep belief network are proposed in this study considering the complex, nonlinear, and non-stationary vibration signal of the rolling bearing. To some extent, the method avoids the complex structure of deep neural network and can be easily trained. Experimental results show that the recognition rate of the method reaches 100 %. The method can identify various types of faults accurately and has good fault diagnosis capability, which can provide the convenience for maintenance.	187.97347828931424
525.	With the advent of social media and cell phones, news is now far more reaching and impactful than ever before. This comes with the exponential increase in fake news that blurs the lines of reality and holds the power to sway public opinion. To counter the impact of fake news, several research groups have developed novel algorithms that could fact check news as a human would do. Unfortunately, natural language processing (NLP) is a complicated task because of the underlying hidden meanings in human communication. In this paper, we propose a novel method that builds a latent representation of natural language to capture its underlying hidden meanings accurately and classify fake news. Our approach connects the high-level semantic concepts in the news content with their low-level deep representations so that the complex news text consisting of satire, sarcasm, and purposeful misleading content can be translated into quantifiable latent spaces. This allows us to achieve very high accuracy, surpassing the scores of all winners of the fake news challenge.	187.97347694756485
526.	We present a simple, modular graph-based convolutional neural network that takes structural information from protein-ligand complexes as input to generate models for activity and binding mode prediction. Complex structures are generated by a standard docking procedure and fed into a dual-graph architecture that includes separate subnetworks for the ligand bonded topology and the ligand-protein contact map. Recent work has indicated that data set bias drives many past promising results derived from combining deep learning and docking. Our dual-graph network allows contributions from ligand identity that give rise to such biases to be distinguished from effects of protein-ligand interactions on classification. We show that our neural network is capable of learning from protein structural information when, as in the case of binding mode prediction, an unbiased data set is constructed. We next develop a deep learning model for binding mode prediction that uses docking ranking as input in combination with docking structures. This strategy mirrors past consensus models and outperforms a baseline docking program (AutoDock Vina) in a variety of tests, including on cross-docking data sets that mimic real-world docking use cases. Furthermore, the magnitudes of network predictions serve as reliable measures of model confidence.	187.97340536981824
527.	A universal rule-based self-learning approach using deep reinforcement learning (DRL) is proposed for the first time to solve nonlinear ordinary differential equations and partial differential equations. The solver consists of a deep neural network-structured actor that outputs candidate solutions, and a critic derived only from physical rules (governing equations and boundary and initial conditions). Solutions in discretized time are treated as multiple tasks sharing the same governing equation, and the current step parameters provide an ideal initialization for the next owing to the temporal continuity of the solutions, which shows a transfer learning characteristic and indicates that the DRL solver has captured the intrinsic nature of the equation. The approach is verified through solving the Schrodinger, Navier-Stokes, Burgers', Van der Pol, and Lorenz equations and an equation of motion. The results indicate that the approach gives solutions with high accuracy, and the solution process promises to get faster.	187.97338055342078
528.	Nowadays, tracking objects has become one of the basic needs of security systems. Deep learning based methods has dramatically improved results in tracking objects. Meanwhile, the quality of the videos captured by camera is effective on the accuracy of the trackers. All images captured by camera inevitably contain noise. The noise is usually created due to various reasons such as the underlying media, weather condition, and camera vibrations in the wind and so on. This paper deals with the issue. In this paper, tracking objects is performed by Yolu 3 architecture in deep learning. Cycle spinning method is also employed to eliminate noise.	187.9732744607244
529.	As an important source of unconventional natural gas, tight sandstone reservoirs have attracted considerable attention. The accurate identification of lithological and fluid-bearing zones is a limiting factor for exploring such reservoirs effectively. Log data, which provide abundant and high precision geological information, are always used for this task. Here, we combined a deep neural network with an oversampling approach named MAHAKIL for lithology and fluid identification using log data from a tight sandstone gas reservoir. MAHAKIL was adopted to solve the class imbalance problem resulting from imbalanced training samples, and the outputs were then fed into a deep neural network to learn the complex and abstract geological patterns related to the lithology and fluid in a layer-by-layer manner. We first demonstrated the unsatisfactory performance of a typical classification algorithm on a simulated data which conforms to the normal distribution and is imbalanced. Then, the performance of our method was compared with that of a support vector machine and a deep neural network on the imbalanced actual data, and the F-beta score which is the weighted harmonic mean of precision and recall was used as the evaluation criterion. The results show that the F-beta score of our method was generally higher than that of the other two methods, which indicates the superiority of the proposed method for lithology and fluid identification of tight sandstone gas reservoirs when the learning samples are imbalanced.	187.9732689973817
530.	Waterflooding, during which water is injected in the reservoir to increase pressure and therefore boost oil production, is extensively used as a secondary oil recovery technology. Tracking the extent and efficacy of waterflooding (i.e., fluid distributions) is a primary task of reservoir engineers and is traditionally achieved by running full reservoir models. In this work, we design and implement a proxy model using a conditional deep convolutional generative neural network (cDC-GAN), which can be used to quickly calculate the dynamic fluid distribution of a heterogeneous reservoir under waterflooding. Zero-sum game theory is the basis for the cDC-GAN, which includes a pair of generative discriminative models. The generative model tries to learn the relationship between input and output and makes the generated output as close as possible to the training data, while the discriminative model tries to distinguish the fake output and the real data used for training, such that the cDC-GAN learns the real data distribution at the end. In our cDC-GAN formulation, the reservoir properties (permeability distribution in this research) and forecast time information are treated as input, and water saturation is the desired output. The reservoir fluid production rate can be calculated based on the material balance principle. The most significant contribution of this work resides in training a cDC-GAN proxy model to accurately predict fluid saturation. A cDC-GAN has several advantages over the traditional full-model based workflow. First, the model parameters estimated from history matching help to improve reservoir characterization. Second, this proposed proxy model can predict the water and oil saturation distributions simultaneously, which can be used to calculate the water and oil flow rates. Third, this proposed proxy model can be used for waterflooding optimization and uncertainty analysis with far less computational effort than with the traditional method, which uses a reservoir simulator.	187.97319805338515
531.	In recent years, deep learning has been successfully used in order to classify partial discharges (PDs) for assessing the condition of insulation systems in different electrical equipment. However, fault diagnosis using deep learning is still challenging, as it requires a large amount of training data, which is difficult and expensive to obtain in the real world. This paper proposes a novel one-shot learning method for fault diagnosis using a small dataset of phase-resolved PDs (PRPDs) in a gas-insulated switchgear (GIS). The proposed method is based on a Siamese network framework, which employs a distance metric function for predicting sample pairs from the same PRPD class or different PRPD classes. Experimental results over the small PRPD dataset that was obtained from an ultra-high-frequency sensor in the GIS show that the proposed method achieves outstanding performance for PRPD fault diagnosis as compared with the previous methods.	187.9731340725284
532.	Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.	187.97299569949018
533.	Artificial intelligence (AI) is transforming healthcare delivery. The digital revolution in medicine and healthcare information is prompting a staggering growth of data intertwined with elements from many digital sources such as genomics, medical imaging and electronic health records. Such massive growth has sparked the development of an increasing number of AI-based applications that can be deployed in clinical practice. Pulmonary specialists who are familiar with the principles of AI and its applications will be empowered and prepared to seize future practice and research opportunities. The goal of this review is to provide pulmonary specialists and other readers with information pertinent to the use of AI in pulmonary medicine. First, we describe the concept of AI and some of the requisites of machine learning and deep learning. Next, we review some of the literature relevant to the use of computer vision in medical imaging, predictive modelling with machine learning, and the use of AI for battling the novel severe acute respiratory syndrome-coronavirus-2 pandemic. We close our review with a discussion of limitations and challenges pertaining to the further incorporation of AI into clinical pulmonary practice.	187.97294968628944
534.	Semantic segmentation on satellite images is used to automatically detect and classify objects of interest over very large areas. Training a neural network for this task generally requires a lot of human-made ground truth classification masks for each object class of interest. We aim to reduce the time spent by humans in the whole process of image segmentation by learning generic features in an unsupervised manner. Those features are then used to leverage sparse human annotations to compute a dense segmentation of the image. This is achieved by essentially labeling groups of semantically similar pixels at once, instead of labeling each pixel almost individually using strokes. While we apply this method to satellite images, our approach is generic and can be applied to any image and to any class of objects on that image.	187.9728709341283
535.	Production and comprehension have long been viewed as inseparable components of language. The study of vision, by contrast, has centered almost exclusively on comprehension. Here we investigate drawingthe most basic form of visual production. How do we convey concepts in visual form, and how does refining this skill, in turn, affect recognition? We developed an online platform for collecting large amounts of drawing and recognition data, and applied a deep convolutional neural network model of visual cortex trained only on natural images to explore the hypothesis that drawing recruits the same abstract feature representations that support natural visual object recognition. Consistent with this hypothesis, higher layers of this model captured the abstract features of both drawings and natural images most important for recognition, and people learning to produce more recognizable drawings of objects exhibited enhanced recognition of those objects. These findings could explain why drawing is so effective for communicating visual concepts, they suggest novel approaches for evaluating and refining conceptual knowledge, and they highlight the potential of deep networks for understanding human learning.	187.97286903634898
536.	The application of deep neural networks to finance has received a great deal of attention from researchers because no assumption about a suitable mathematical model has to be made prior to forecasting and they are capable of extracting useful information from large sets of data, which is required to describe nonlinear input-output relations of financial time series. The paper presents a new deep neural network model where single layered autoencoder and 4 layered neural network are serially coupled for stock price forecasting. The autoencoder extracts deep features, which are fed into multi-layer neural networks to predict the next day's stock closing prices. The proposed deep neural network is progressively learned layer by layer ahead of the final learning of the total network. The proposed model to predict daily close prices of KOrea composite Stock Price Index (KOSPI) is built, and its performance is demonstrated.	187.97284012812574
537.	As deep running and big data technologies evolve; technologies that pre-process a huge amount of raw data and thus facilitate the analysis of such data have started receiving much attention.In this paper, we propose a novel method called Data Digest, which transforms heterogeneous and multidimensional data into an image. Using our proposed method, we are able to easily pre-process and integrate different types of data, resulting in creating the possibility for the application of such transformed images in well-known deep learning techniques. To demonstrate the validity of our proposed method, in the present work, we present practical applications such as the internal and outdoor positioning system and the peak power consumption prediction problem using data imagification.	187.97282390917587
538.	In recent years, deep learning based methods have attracted broad attention in the field of hyperspectral image classification. However, due to the massive parameters and the complex network structure, deep learning methods may not perform well when only few training samples are available. In this paper, we propose a small-scale data based method, multi-grained network (MugNet), to explore the application of deep learning approaches in hyperspectral image classification. MugNet could be considered as a simplified deep learning model which mainly targets at limited samples based hyperspectral image classification. Three novel strategies are proposed to construct MugNet. First, the spectral relationship among different bands, as well as the spatial correlation within neighboring pixels, are both utilized via a multi-grained scanning approach. The proposed multi-grained scanning strategy could not only extract the joint spectral-spatial information, but also combine different grains' spectral and spatial relationship. Second, because there are abundant unlabeled pixels available in hyperspectral images, we take full advantage of these samples, and adopt a semi-supervised manner in the process of generating convolution kernels. At last, the MugNet is built upon the basis of a very simple network which does not include many hyperparameters for tuning. The performance of MugNet is evaluated on a popular and two challenging data sets, and comparison experiments with several state-of-the-art hyperspectral image classification methods are revealed. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	187.9728084562996
539.	A new Reduced Order Deep Data Assimilation (RODDA) model combining Reduced order models (ROM), Data Assimilation (DA) and Machine Learning is proposed in this paper. The RODDA model aims to improve the accuracy of Computational Fluid Dynamics (CFD) simulations. The DA model ingests information from observed data in the simulation provided by the CFD model. The results of the DA are used to train a neural network learning a function which predicts the misfit between the results of the CFD model and the DA model. Thus, the trained function is combined with the original CFD model in order to generate forecasts with implicit DA given by neural network. Due to the time complexity of the numerical models used to implement DA and the neural network, and due to the scale of the forecasting area considered for forecasting problems in real case scenarios, the implementation of RODDA mandated the introduction of opportune reduced spaces. Here, RODDA is applied to a CFD simulation for air pollution, using the CFD software Fluidity, in South London (UK). We show that, using this framework, the data forecasted by the coupled model CFD+RODDA are closer to the observations with a gain in terms of execution time with respect to the classic prediction-correction cycle given by coupling CFD with a standard DA. Additionally, RODDA predicts future observations, if not available, since these are embedded in the data assimilated state in which the network is trained on. The RODDA framework is not exclusive to air pollution, Fluidity, or the study area in South London, and therefore the workflow could be applied to different physical models if enough temporal data are available. (C) 2020 Elsevier B.V. All rights reserved.	187.97277367718328
540.	Introduction: Student radiographers have expressed difficulty in performing image appraisal tasks. The purpose of this study was to investigate the value of a workshop delivered to level 4 undergraduate students. All students completed an image appraisal activity, inputting their appraisal into software that displayed their response alongside an expert opinion. They were asked to identify and discuss any discrepancy. Methods: All Level 4 students participated in an image appraisal workshop and were subsequently invited to take part in a focus group immediately after the activity. Twenty-three students took part in three focus groups (n = 7; n = 8; n = 8). A thematic analysis of transcripts was performed alongside validation from observations during the image appraisal activity. Results: Findings demonstrate that despite teaching and resources being available, students had focused on learning a generic checklist for image appraisal, had not appreciated the application of projection specific criteria and felt underprepared. The use of specific criteria and repetition within the task was considered useful. They identified learning needs and misconceptions through peer discussion and via the expert opinion, highlighting the value of feedback. Students enjoyed the workshop and made suggestions for implementation into the curriculum. Conclusion: Educators must not assume that the provision of resources will result in students developing deep knowledge. Teaching and learning strategies that are task specific are recommended to avoid a surface approach to learning. Time, repetition and appropriate feedback are essential to enable learners to develop competence and confidence for complex visual tasks, such as image appraisal. (C) 2019 The College of Radiographers. Published by Elsevier Ltd. All rights reserved.	187.97277199785378
541.	The paper proposes a novel approach for learning kernel Support Vector Machines (SVM) from large scale data with reduced computation time. The proposed approach, termed as Subclass Reduced Set SVM (SRS-SVM), utilizes the subclass structure of data to effectively estimate the candidate support vector set. Since the candidate support vector set cardinality is only a fraction of the training set cardinality, learning SVM from the former requires less time without significantly changing the decision boundary. SRS-SVM depends on a domain knowledge related input parameter, i.e., number of subclasses. To reduce the domain knowledge dependency and to make the approach less sensitive to the subclass parameter, we extend the proposed SRS-SVM to create a robust and improved hierarchical model termed as the Hierarchical Subclass Reduced Set SVM (HSRS-SVM). Since SRS-SVM and HSRS-SVM splits non-linear optimization problem into multiple (smaller) linear optimization problems, both of them are amenable to parallelization. The effectiveness of the proposed approaches is evaluated on four synthetic and six real-world datasets. The performance is also compared with traditional solver (LibSVM) and state-of-the-art approaches such as divide-and-conquer SVM, FastFood, and LLSVM. The experimental results demonstrate that the proposed approach achieves similar classification accuracies while requiring fewer folds of reduced computation time as compared to existing solvers. We further demonstrate the suitability and improved performance of the proposed HSRS-SVM with deep learning features for face recognition using Labeled Faces in the Wild (LFW) dataset. (C) 2019 Published by Elsevier Ltd.	187.9726434754083
542.	Latent Factor Model(LFM), as an effective feature mapping method, is widely applied in recommender systems. One challenge of LFM is previous methods usually use the inner product to calculate the similarity between users and items in the latent space, which cannot characterize different impacts of various latent factors. Another challenge is the performance of LFM will be negatively affected when facing data sparsity problem. In this paper, we propose a model named DLFM-HSM(Deep Latent Factor Model with Hierarchical Similarity Measure) to overcome the challenges above. More specifically, we introduce a hierarchical similarity measure to calculate an impact score which can better represent the similarity between a user and an item than the inner product. Also, in order to ease the data sparsity problem, we extract latent representations of users and items using deep neural networks from items' content information instead of only from user-item rating records. By representing users with items they purchased, our model guarantees that users and items are mapped into a common space and thus they are directly comparable. Extensive experiments on five real-world datasets show significant improvements of DLFM-HSM over the state-of-the-art methods and demonstrate the effectiveness of our model for alleviating the data sparsity problem. (C) 2019 Elsevier Inc. All rights reserved.	187.9726095537125
543.	Panoramic video provides immersive and interactive experience by enabling humans to control the field of view (FoV) through head movement (HM). Thus, HM plays a key role in modeling human attention on panoramic video. This paper establishes a database collecting subjects' HM in panoramic video sequences. From this database, we find that the HM data are highly consistent across subjects. Furthermore, we find that deep reinforcement learning (DRL) can be applied to predict HM positions, via maximizing the reward of imitating human HM scanpaths through the agent's actions. Based on our findings, we propose a DRL-based HM prediction (DHP) approach with offline and online versions, called offline-DHP and online-DHP. In offline-DHP, multiple DRL workflows are run to determine potential HM positions at each panoramic frame. Then, a heat map of the potential HM positions, named the HM map, is generated as the output of offline-DHP. In online-DHP, the next HM position of one subject is estimated given the currently observed HM position, which is achieved by developing a DRL algorithm upon the learned offline-DHP model. Finally, the experiments validate that our approach is effective in both offline and online prediction of HM positions for panoramic video, and that the learned offline-DHP model can improve the performance of online-DHP.	187.9725528969581
544.	With the advent of the era of deep Internet, the huge scientific and economic value of big data is gradually highlighted. However, there are high technical barriers in its data analysis methods. In order to explore the value space of large data, we need to abandon the traditional scheme and adopt new analysis methods. Strategies such as strengthening the overall framework of intelligent traffic standard system, the development and use of key technologies, and breaking down information barriers are of reference value for other cities to build intelligent traffic. The deep neural network algorithm integrates huge heterogeneous data with bionic learning algorithm, supports multi-source information screening, and achieves dynamic capture of time series, thus building a bridge between large data and value information. The article analyzes the current situation of traffic in multiple cities, and starts with the traffic under big data and cloud computing, and studies the application of big data and cloud computing in intelligent transportation system, in order to provide some reference for the development of smart Wuhan. With reference. The analysis results show that the infinite neural network has more powerful computational efficiency and performance advantages in data processing.	187.97253784605135
545.	BACKGROUND: Deep learning models have attracted significant interest from health care researchers during the last few decades. There have been many studies that apply deep learning to medical applications and achieve promising results. However, there are three limitations to the existing models: (1) most clinicians are unable to interpret the results from the existing models, (2) existing models cannot incorporate complicated medical domain knowledge (eg, a disease causes another disease), and (3) most existing models lack visual exploration and interaction. Both the electronic health record (EHR) data set and the deep model results are complex and abstract, which impedes clinicians from exploring and communicating with the model directly. OBJECTIVE: The objective of this study is to develop an interpretable and accurate risk prediction model as well as an interactive clinical prediction system to support EHR data exploration, knowledge graph demonstration, and model interpretation. METHODS: A domain-knowledge-guided recurrent neural network (DG-RNN) model is proposed to predict clinical risks. The model takes medical event sequences as input and incorporates medical domain knowledge by attending to a subgraph of the whole medical knowledge graph. A global pooling operation and a fully connected layer are used to output the clinical outcomes. The middle results and the parameters of the fully connected layer are helpful in identifying which medical events cause clinical risks. DG-Viz is also designed to support EHR data exploration, knowledge graph demonstration, and model interpretation. RESULTS: We conducted both risk prediction experiments and a case study on a real-world data set. A total of 554 patients with heart failure and 1662 control patients without heart failure were selected from the data set. The experimental results show that the proposed DG-RNN outperforms the state-of-the-art approaches by approximately 1.5%. The case study demonstrates how our medical physician collaborator can effectively explore the data and interpret the prediction results using DG-Viz. CONCLUSIONS: In this study, we present DG-Viz, an interactive clinical prediction system, which brings together the power of deep learning (ie, a DG-RNN-based model) and visual analytics to predict clinical risks and visually interpret the EHR prediction results. Experimental results and a case study on heart failure risk prediction tasks demonstrate the effectiveness and usefulness of the DG-Viz system. This study will pave the way for interactive, interpretable, and accurate clinical risk predictions.	187.97248555484697
546.	Social media is an inseparable part of our daily life where we post and share photos and media related to our life and in some cases we intend to share them between specific people. This intended and cherry picked sharing of media needs a better solution rather than simply picking users. Some social media platforms do not restrict other users from sharing timeline posts of others; meaning, one can simply forward a post from another person to a third one and no data preservation has been applied. In most cases we do not intend to secure the whole media and only important parts of it are intended to be secured. In this work we propose a novel method based on YoloV3 object detection and chaotic image encryption to overcome the issue of user intended data preservation in social media platforms. Our proposed method is capable of both automatic image encryption on full or user selected regions. Statistical and cryptographic analysis show superiority of our method compared to other state-of-the-art methods while it keeps the speed as high as possible for online and realtime use cases. (C) 2020 Elsevier Inc. All rights reserved.	187.97244892207974
547.	Recently, generative adversarial network (GAN) has been widely employed in single image super-resolution (SISR), achieving favorably good perceptual effects. However, the SR outputs generated by GAN still have some fictitious details, which are quite different from the ground-truth images, resulting in a low PSNR value. In this paper, we leverage the ground-truth high-resolution (HR) image as a useful guide to learn an effective conditional GAN (CGAN) for SISR. Among it, we design the generator network via residual learning, which introduces dense connections to the residual blocks to effectively fuse low and high-level features across different layers. Extensive evaluations show that our proposed SR method performs much better than state-of-the-art methods in terms of PSNR, SSIM, and visual perception.	187.97244301834576
548.	We study the foot plantar sensor placement by a deep reinforcement learning algorithm without using any prior knowledge of the foot anatomical area. To apply a reinforcement learning algorithm, we propose a sensor placement environment and reward system that aims to optimize fitting the center of pressure (COP) trajectory during the self-selected speed running task. In this environment, the agent considers placing eight sensors within a 7 * 20 grid coordinate system, and then the final pattern becomes the result of sensor placement. Our results show that this method (1) can generate a sensor placement, which has a low mean square error in fitting ground truth COP trajectory, and (2) robustly discovers the optimal sensor placement in a large number of combinations, which is more than 116 quadrillion. This method is also feasible for solving different tasks, regardless of the self-selected speed running task.	187.97224461155713
549.	The identification of different types of human actions in videos is a major computer vision task, with capital applications in e.g. surveillance, control, and analysis. Deep learning achieved remarkable results, but remains hard to train in practice. Here, we propose a photonic reservoir computer for recognition of video-based human actions. Our experiment comprises off-the-shelf components and implements an easy-to-train neural network, scalable up to 16,384 nodes, and performing with a near state-of-the-art accuracy. Our findings pave the way towards photonic information processing systems for real-time video processing.	187.9721936520345
550.	Deep learning algorithms are one of most rapid developing fields into the modern computation technologies. One of the bottlenecks into the implementation of such advaced algorithms is their requirement for a large amount of manually-labelled data for training. For the general-purpose tasks, such as general purpose image classification/detection the huge images datasets are already labelled and collected. For more subject specific tasks (such as electron microscopy images treatment), no labelled data available. Here I demonstrate that a deep learning network can be successfully trained for nanoparticles detection using semi-synthetic data. The real SEM images were used as a textures for rendered nanoparticles at the surface. Training of RetinaNet architecture using transfer learning can be helpful for the large-scale particle distribution analysis. Beyond such applications, the presented approach might be applicable to other tasks, such as image segmentation.	187.9721486992421
551.	X-Ray computed tomography (CT) is one of the most popular imaging modality in the medical image analysis for clinical application. Meanwhile, the potential risk of X-Ray radiation dose to patients has attracted the public attention. Over the past decades, extensive efforts have been made for developing low-dose CT. However, X-Ray radiation dose reduction may result in increased noise and artifacts, which can significantly compromise the image quality and deteriorate the diagnostic performance. Hence, restoring CT image from low-dose CT and improving the diagnostic performance is a challenging for the vast researchers and developers. In this paper, a method based on deep learning techniques is proposed for low-dose CT noise reduction. Our method integrates convolutional neural network (CNN) blocks, residual learning, exponential linear units (ELUs) into a deep learning framework. Especially, loss of structural similarity index (SSIM) is combines to the final objective function to improve the image quality. Differs from general deep learning based denoising method, our deep CNN blocks architecture learning noise directly from original low-dose CT images, then restores denoised CT image by subtracting the obtained noise image from the original low-dose CT. After training patch by patch, the proposed method attains promising performance compared to state of the art traditional methods (non-local means and Block-matching 3D) and representative deep learning methods (primary three layers convolutional neural networks and residual encoder-decoder convolutional neural network) in visual effects and quantitative measurements. Extensive experiments was implemented for how choosing the coefficients of overall loss function and the number of CNN blocks. The experimental results demonstrate that our noise reduction method is effective for low-dose CT and potential clinic application.	187.97212722084765
552.	The availability of naturally occurring educational discourse data within educational platforms presents a golden opportunity to make advances in understanding online learner ecologies and enabling new kinds of personalized interventions focused on increasing inclusivity and equity. However, to gain a more substantive view of how peer interaction is influenced by group composition and gender, learning and computational sciences require new automated methodological approaches that will provide a deeper understanding of learners' communication patterns and interaction dynamics across digitally-meditated group learning platforms. In the current research, we explore learners' discourse by employing Group Communication Analysis (GCA), a computational linguistics methodology for quantifying and characterizing the discourse sociocognitive processes between learners in online interactions. The aim of this study is to use GCA to investigate the influence of gender and gender pairing on students' intra- and interpersonal discourse processes in online environments. Students were randomly assigned to one of three groups of varying gender composition: 75% women, 50% women, or 25% women. Our results suggest that the sociocognitive discourse patterns, as captured by the GCA, reveal deeper level patterns in the way individuals interact within online environments along gender and group composition lines. The scalability of the methodology opens the door for future research efforts directed towards understanding, and creating more equitable and inclusive online peer-interactions.	187.97212526997657
553.	Recent advancements in deep learning for automated image processing and classification have accelerated many new applications for medical image analysis. However, most deep learning algorithms have been developed using reconstructed, human-interpretable medical images. While image reconstruction from raw sensor data is required for the creation of medical images, the reconstruction process only uses a partial representation of all the data acquired. Here, we report the development of a system to directly process raw computed tomography (CT) data in sinogram-space, bypassing the intermediary step of image reconstruction. Two classification tasks were evaluated for their feasibility of sinogram-space machine learning: body region identification and intracranial hemorrhage (ICH) detection. Our proposed SinoNet, a convolutional neural network optimized for interpreting sinograms, performed favorably compared to conventional reconstructed image-space-based systems for both tasks, regardless of scanning geometries in terms of projections or detectors. Further, SinoNet performed significantly better when using sparsely sampled sinograms than conventional networks operating in image-space. As a result, sinogram-space algorithms could be used in field settings for triage (presence of ICH), especially where low radiation dose is desired. These findings also demonstrate another strength of deep learning where it can analyze and interpret sinograms that are virtually impossible for human experts.	187.9720782748921
554.	As technology advances, the amount of fake news is increasing more and more by various reasons such as political issues and advertisement exaggeration. However, there have been very few research works on fake news detection, especially which uses grammatical transformation on deep neural network. In this paper, we shall present a new Fake News Detection Model, called FAGON(Fake news detection model using Grammatical transformation On deep Neural network) which determines efficiently if the proposition is true or not for the given article by learning grammatical transformation on neural network. Especially, our model focuses the Korean language. It consists of two modules: sentence generator and classification. The former generates multiple sentences which have the same meaning as the proposition, but with different grammar by training the grammatical transformation. The latter classifies the proposition as true or false by training with vectors generated from each sentence of the article and the multiple sentences obtained from the former model respectively. We shall show that our model is designed to detect fake news effectively by exploiting various grammatical transformation and proper classification structure.	187.97206104341527
555.	Pairs Trading is one of the most valuable market-neutral strategies used by hedge funds. It is particularly interesting because it overcomes the arduous process of valuing securities by focusing on relative pricing. By buying a relatively undervalued security and selling a relatively overvalued one, a profit can be made upon the pair's price convergence. However, with the growing availability of data, it became increasingly harder to find rewarding pairs. In this work, we address two problems: (i) how to find profitable pairs while constraining the search space and (ii) how to avoid long decline periods due to prolonged divergent pairs. To manage these difficulties, the application of promising Machine Learning techniques is investi-gated in detail. We propose the integration of an Unsupervised Learning algorithm, OPTICS, to handle problem (i). The results obtained demonstrate the suggested technique can outperform the common pairs' search methods, achieving an average portfolio Sharpe ratio of 3.79, in comparison to 3.58 and 2.59 obtained by standard approaches. For problem (ii), we introduce a forecasting-based trading model, capable of reducing the periods of portfolio decline by 75%. Yet, this comes at the expense of decreasing overall profitability. The proposed strategy is tested using an ARMA model, an LSTM and an LSTM Encoder-Decoder. This work's results are simulated during varying periods between January 2009 and December 2018, using 5-min price data from a group of 208 commodity-linked ETFs, and accounting for transaction costs. (c) 2020 Elsevier Ltd. All rights reserved.	187.9720569656539
556.	Algorithms that can determine the type of physical activity (PA) and quantify the intensity can allow precision medicine approaches, such as automated insulin delivery systems that modulate insulin administration in response to PA. In this work, data from a multi-sensor wristband is used to design classifiers to distinguish among five different physical states (PS) (resting, activities of daily living, running, biking, and resistance training), and to develop models to estimate the energy expenditure (EE) of the PA for diabetes therapy. The data collected are filtered, features are extracted from the reconciled signals, and the extracted features are used by machine learning algorithms, including deep-learning techniques, to obtain accurate PS classification and EE estimation. The various machine learning techniques have different success rates ranging from 75.7% to 94.8% in classifying the five different PS. The deep neural network model with long short-term memory has 94.8% classification accuracy. We achieved 0.5 MET (Metabolic Equivalent of Task) root-mean-square error for EE estimation accuracy, relative to indirect calorimetry with randomly selected testing data (10% of collected data). We also demonstrate a 5% improvement in PS classification accuracy and a 0.34 MET decrease in the mean absolute error when using multi-sensor approach relative to using only accelerometer data.	187.9720190035358
557.	As nontechnical losses in power systems have recently become a global concern, electricity fraud detection models attracted increasing academic interest. The wide application of smart meters has offered more possibility to detecting fraud from user's consumption patterns. However, the performances of existing consumption-based electricity fraud detection models are still not satisfactory enough for practice, partly due to their limited ability to handle high-dimensional data. In this paper, a deep-learning-based model is developed for detecting electricity fraud in the advanced metering infrastructure, namely, the multitask feature extracting fraud detector (MFEFD). The deep architecture has brought MFEFD a powerful ability to handle high-dimensional input, through which consumption patterns inside load profiles can be effectively extracted. Another challenge is that the insufficiency of labeled data has restricted the generalization of existing models since they are mostly based on supervised learning and labeled data. MFEFD is trained in a semisupervised manner, in which multitask training was implemented to combine the supervised and unsupervised training, so that both the knowledge from unlabeled and labeled data can be made use of. Real-world-data-based case studies have demonstrated MFEFD's high detection performance, robustness, privacy preservation, and practicability.	187.97200286734707
558.	In computer vision, the research community has been looking to how to benefit from weakly supervised learning that utilizes easily obtained image-level labels to train neural network models. The existing deep convolutional neural networks for weakly supervised learning, however, generally do not fully exploit the label dependencies in an image. To make full use of this information, in this paper, we propose a new framework for weakly supervised learning of deep convolutional neural networks, introducing graph convolutional networks to capture the semantic label co-occurrence in an image. Moreover, we propose a novel initialization method for label embedding in graph convolutional networks, which enables a smoother optimization for interrelationships learning. Extensive experiments and comparisons on four public benchmark datasets (PASCAL VOC 2007, PASCAL VOC 2012, Microsoft COCO, and NUS-WIDE) show the superior performance of our approach in both image classification and weakly supervised pointwise object localization. These results lead us to conclude that the label dependencies in the input image can provide valuable evidence for learning strongly localized features. (C)20 Elsevier Ltd. All rights reserved.	187.97199537502098
559.	Advances in Deep Convolutional Neural Networks (DCNN) provide new opportunities for computational neuroscience to pose novel questions regarding the function of biological visual systems. Some attempts have been made to utilize advances in machine learning to answer neuroscientific questions, but how to appropriately make comparisons between the biological systems and artificial neural network structure is an open question. This analysis quantifies network properties of the mouse visual system and a common DCNN model (VGG16), to determine if this comparison is appropriate. Utilizing weighted graph-theoretic measures of node density (weighted node-degree), path length, local clustering coefficient, and betweenness, differences in functional connectivity patterns in the modern artificial computer vision system and the biological vision system are quantified. Results show that the mouse exhibits network measure distributions more similar to Poisson than normal, whereas the VGG16 exhibits network measure distributions with a more Gaussian shape than the sampled biological network. The artificial network shows higher density measures and shorter path lengths in comparison to the biological network. These results show that training a VGG16 for an object recognition task is unlikely to produce a network whose functional connectivity is similar to the mammalian visual system.	187.97183071386422
560.	Document images captured in natural scenes with a hand-held camera often suffer from geometric distortions and cluttered backgrounds. In this paper, we propose a simple yet efficient deep model named Adversarial Gated Unwarping Network (AGUN) to rectify these images. In this model, the rectification task is recast as a dense grid prediction problem. We thereby develop a pyramid encoder-decoder architecture to predict the unwarping grid at multiple resolutions in a coarse-to-fine fashion. Based on the observation that the structural visual cues, e.g., text-lines, text blocks, lines in tables, which are critical for the estimation of unwarping mapping, are non-uniformly distributed in the images, three gated modules are introduced to guide the network focusing on these informative cues rather than other interferences such as blank areas and complex backgrounds. To generate more visually pleasing rectification results, we further adopt adversarial training mechanism to implicitly constrain the unwarping grid estimation. Our model can rectify arbitrarily distorted document images with complicated page layouts and cluttered backgrounds. Experiments on the public benchmark dataset and the synthetic dataset demonstrate that our approach outperforms the state-of-the-art methods in terms of OCR accuracy and several widely used quantitative evaluation metrics. (C) 2020 Elsevier Ltd. All rights reserved.	187.97182364966312
561.	Autoencoders are computing architectures encountered in various schemes of deep learning and realizing an efficient way of representing data in a compact way by forming a set of features. In this study, a concept, architecture, and algorithmic developments of logic-driven autoencoders are presented. In such structures, encoding and the decoding processes realized at the consecutive layers of the autoencoder are completed with the aid of some fuzzy logic operators (namely, OR, AND, NOT operations) and the ensuing encoding and decoding processing is carried out with the aid of fuzzy logic processing. The optimization of the autoencoder is completed through a gradient-based learning. The transparent knowledge representation delivered by autoencoders is facilitated by the involvement of logic processing, which implies that the encoding mechanism comes with the generalization abilities delivered by OR neurons while the specialization mechanism is achieved by the AND-like neurons forming the decoding layer. A series of illustrative examples is also presented. (C) 2019 Elsevier B.V. All rights reserved.	187.97180066371868
562.	In this work, we demonstrates the feasibility of employing the biometric photoplethysmography (PPG) signal for human verification applications. The PPG signal has dominance in terms of accessibility and portability which makes its usage in many applications such as user access control very appealing. Therefore, we developed robust time-stable features using signal analysis and deep learning models to increase the robustness and performance of the verification system with the PPG signal. The proposed system focuses on utilizing different stretching mechanisms namely Dynamic Time Warping, zero padding and interpolation with Fourier transform, and fuses them at the data level to be then deployed with different deep learning models. The designed deep models consist of Convolutional Neural Network (CNN) and Long-Short Term Memory (LSTM) which are considered to build a user specific model for the verification task. We collected a dataset consisting of 100 participants and recorded at two different time sessions using Plux pulse sensor. This dataset along with another two public databases are deployed to evaluate the performance of the proposed verification system in terms of uniqueness and time stability. The final result demonstrates the superiority of our proposed system tested on the built dataset and compared with other two public databases. The best performance achieved from our collected two-sessions database in terms of accuracy is 98% for the single-session and 87.1% for the two-sessions scenarios.	187.97168842150495
563.	Identifying a suitable set of descriptors for modeling physical systems often utilizes either deep physical insights or statistical methods such as compressed sensing. In statistical learning, a class of methods known as structured sparsity regularization seeks to combine both physics- and statistics-based approaches. Used in bioinformatics to identify genes for the diagnosis of diseases, group lasso is a well-known example. Here in physics, we present group lasso as an efficient method for obtaining robust cluster expansions (CEs) of multicomponent systems, a popular computational technique for modeling such systems and studying their thermodynamic properties. Via convex optimization, group lasso selects the most predictive set of atomic clusters as descriptors in accordance with the physical insight that if a cluster is selected, its subclusters should be too. These selection rules avoid spuriously large fitting parameters by redistributing them among lower-order terms, resulting in more physical, accurate, and robust CEs. We showcase these features of group lasso using the CE of the bcc ternary alloyMo-V-Nb. These results are timely given the growing interest in applying CE to increasingly complex systems, which demand a more reliable machine learning methodology to handle the larger parameter space.	187.97163696124818
564.	Learning urban community structures refers to the efforts of quantifying, summarizing, and representing an urban community's (i) static structures, e.g., Point-Of-Interests (POIs) buildings and corresponding geographic allocations, and (ii) dynamic structures, e.g., human mobility patterns among POIs. By learning the community structures, we can better quantitatively represent urban communities and understand their evolutions in the development of cities. This can help us boost commercial activities, enhance public security, foster social interactions, and, ultimately, yield livable, sustainable, and viable environments. However, due to the complex nature of urban systems, it is traditionally challenging to learn the structures of urban communities. To address this problem, in this article, we propose a collective embedding framework to learn the community structure from multiple periodic spatial-temporal graphs of human mobility. Specifically, we first exploit a probabilistic propagation-based approach to create a set of mobility graphs from periodic human mobility records. In these mobility graphs, the static POIs are regarded as vertexes, the dynamic mobility connectivities between POI pairs are regarded as edges, and the edge weights periodically evolve over time. A collective deep auto-encoder method is then developed to collaboratively learn the embeddings of POIs from multiple spatial-temporal mobility graphs. In addition, we develop a Unsupervised Graph based Weighted Aggregation method to align and aggregate the POI embeddings into the representation of the community structures. We apply the proposed embedding framework to two applications (i.e., spotting vibrant communities and predicting housing price return rates) to evaluate the performance of our proposed method. Extensive experimental results on real-world urban communities and human mobility data demonstrate the effectiveness of the proposed collective embedding framework.	187.9716312294476
565.	Deep learning networks have shown state-of-the-art performance in many image reconstruction problems. However, it is not well understood what properties of representation and learning may improve the generalization ability of the network. In this paper, we propose that the generalization ability of an encoder-decoder network for inverse reconstruction can be improved in two means. First, drawing from analytical learning theory, we theoretically show that a stochastic latent space will improve the ability of a network to generalize to test data outside the training distribution. Second, following the information bottleneck principle, we show that a latent representation minimally informative of the input data will help a network generalize to unseen input variations that are irrelevant to the output reconstruction. Therefore, we present a sequence image reconstruction network optimized by a variational approximation of the information bottleneck principle with stochastic latent space. In the application setting of reconstructing the sequence of cardiac transmembrane potential from body-surface potential, we assess the two types of generalization abilities of the presented network against its deterministic counterpart. The results demonstrate that the generalization ability of an inverse reconstruction network can be improved by stochasticity as well as the information bottleneck.	187.97158341773968
566.	In order to rapidly build an automatic and precise system for image recognition and categorization, deep learning is a vital technology. Handwritten character classification also gaining more attention due to its major contribution in automation and specially to develop applications for helping visually impaired people. Here, the proposed work highlighting on fine-tuning approach and analysis of state-of-the-art Deep Convolutional Neural Network (DCNN) designed for Devanagari Handwritten characters classification. A new Devanagari handwritten characters dataset is generated which is publicly available. Datasets consist of total 5800 isolated images of 58 unique character classes: 12 vowels, 36 consonants and 10 numerals. In addition to this database, a two-stage VGG16 deep learning model is implemented to recognize those characters using two advanced adaptive gradient methods. A two-stage approach of deep learning is developed to enhance overall success of the proposed Devanagari Handwritten Character Recognition System (DHCRS). The first model achieves 94.84% testing accuracy with training loss of 0.18 on new dataset. Moreover, the second fine-tuned model requires very fewer trainable parameters and notably less training time to achieve state-of-the-art performance on a very small dataset. It achieves 96.55% testing accuracy with training loss of 0.12. We also tested the proposed model on four different benchmark datasets of isolated characters as well as digits of Indic scripts. For all the datasets tested, we achieved the promising results.	187.97158076531855
567.	Automatic cost learning for steganography based on deep neural networks is receiving increasing attention. Steganographic methods under such a framework have been shown to achieve better security performance than methods adopting hand-crafted costs. However, they still exhibit some limitations that prevent a full exploitation of their potentiality, including using a function-approximated neural-network-based embedding simulator and a coarse-grained optimization objective without explicitly using pixel-wise information. In this article, we propose a new embedding cost learning framework called SPAR-RL (Steganographic Pixel-wise Actions and Rewards with Reinforcement Learning) that overcomes the above limitations. In SPAR-RL, an agent utilizes a policy network which decomposes the embedding process into pixel-wise actions and aims at maximizing the total rewards from a simulated steganalytic environment, while the environment employs an environment network for pixel-wise reward assignment. A sampling process is utilized to emulate the message embedding of an optimal embedding simulator. Through the iterative interactions between the agent and the environment, the policy network learns a secure embedding policy which can be converted into pixel-wise embedding costs for practical message embedding. Experimental results demonstrate that the proposed framework achieves state-of-the-art security performance against various modern steganalyzers, and outperforms existing cost learning frameworks with regard to learning stability and efficiency.	187.97155826674634
568.	Retail sales forecasting often requires forecasts for thousands of products for many stores. We present a meta-learning framework based on newly developed deep convolutional neural networks, which can first learn a feature representation from raw sales time series data automatically, and then link the learnt features with a set of weights which are used to combine a pool of base-forecasting methods. The experiments which are based on IRI weekly data show that the proposed meta-learner provides superior forecasting performance compared with a number of state-of-art benchmarks, though the accuracy gains over some more sophisticated meta ensemble benchmarks are modest and the learnt features lack interpretability. When designing a meta-learner in forecasting retail sales, we recommend building a pool of base-forecasters including both individual and pooled forecasting methods, and target finding the best combination forecasts instead of the best individual method. (C) 2020 Elsevier B.V. All rights reserved.	187.97155400239808
569.	Neural networks (NNs) have become the go-to tool for solving many real-world recognition and classification tasks with massive and complex data sets. These networks require large data sets for training, which is usually performed on GPUs and CPUs in either a cloud or edge computing setting. No matter where the training is performed, it is subject to tight power/energy and data storage/transfer constraints. While these issues can be mitigated by replacing SRAM/DRAM with nonvolatile memories (NVMs) which offer near-zero leakage power and high scalability, the massive weight updates performed during training shorten NVM endurance and engender high write energy. In this paper, an NVM-friendly NN training approach is proposed. Weight update is redesigned to reduce bit flips in NVM cells. Moreover, two techniques, namely, filter exchange and bitwise rotation, are proposed to respectively balance writes to different weights and to different bits of one weight. The proposed techniques are integrated and evaluated in Caffe. Experimental results show significant power savings and endurance improvements, while maintaining high inference accuracy.	187.97154207661478
570.	Deep convolutional neural networks (CNN) have recently achieved superior performance at the task of medical image segmentation compared to classic models. However, training a generalizable CNN requires a large amount of training data, which is difficult, expensive, and time-consuming to obtain in medical settings. Active Learning (AL) algorithms can facilitate training CNN models by proposing a small number of the most informative data samples to be annotated to achieve a rapid increase in performance. We proposed a new active learning method based on Fisher information (FI) for CNNs for the first time. Using efficient backpropagation methods for computing gradients together with a novel low-dimensional approximation of FI enabled us to compute FI for CNNs with a large number of parameters. We evaluated the proposed method for brain extraction with a patch-wise segmentation CNN model in two different learning scenarios: universal active learning and active semi-automatic segmentation. In both scenarios, an initial model was obtained using labeled training subjects of a source data set and the goal was to annotate a small subset of new samples to build a model that performs well on the target subject(s). The target data sets included images that differed from the source data by either age group (e.g. newborns with different image contrast) or underlying pathology that was not available in the source data. In comparison to several recently proposed AL methods and brain extraction baselines, the results showed that FI-based AL outperformed the competing methods in improving the performance of the model after labeling a very small portion of target data set (0.25).	187.97144743085357
571.	Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.	187.97143651299382
572.	Metric learning has attracted significant attention in the past decades, because of its appealing advances in various real-world tasks, e.g., person re-identification and face recognition. Traditional supervised metric learning attempts to seek a discriminative metric, which could minimize the pairwise distance of within-class data samples, while maximizing the pairwise distance of data samples from various classes. However, it is still a challenge to build a robust and discriminative metric, especially for corrupted data in the real-world application. In this paper, we propose a Robust Discriminative Metric Learning algorithm through fast low-rank representation and denoising strategy. To be specific, the metric learning problem is guided by a discriminative regularization by incorporating the pair-wise or class-wise information. Moreover, the low-rank basis learning is jointly optimized with the metric to better uncover the global data structure and remove noise. Furthermore, the fast low-rank representation is implemented to mitigate the computational burden and ensure the scalability on large-scale datasets. Finally, we evaluate our learned metric on several challenging tasks, e.g., face recognition/verification, object recognition, image clustering, and person re-identification. The experimental results verify the effectiveness of our proposed algorithm in comparison to many metric learning algorithms, even deep learning ones.	187.97135310639828
573.	Early and effective network intrusion detection is deemed to be a critical basis for cybersecurity domain. In the past decade, although a significant amount of work has focused on network intrusion detection, it is still a challenge to establish an intrusion detection system with a high detection rate and a relatively low false alarm rate. In this paper, we have performed a comprehensive empirical study on network intrusion detection as a multiclass classification task, not just to detect a suspicious connection but also to assign the correct type as well. To surpass the previous studies, we have utilized four deep learning models, namely, deep neural networks, long short-term memory recurrent neural networks, gated recurrent unit recurrent neural networks, and deep belief networks. Our approach relies on the pretraining of the models by exploiting a particle swarm optimization-based algorithm for their hyperparameters selection. In order to investigate the performance differences, we also included two well-known shallow learning methods, namely, decision forest and decision jungle. Furthermore, we used in our experiments four datasets, which are dedicated to intrusion detection systems to explore various environments. These datasets are KDD CUP 99, NSL-KDD, CIDDS, and CICIDS2017. Moreover, 22 evaluation metrics are used to assess the model's performance in each of the datasets. Finally, intensive quantitative, Friedman test, and ranking methods analyses of our results are provided at the end of this paper. The results show a significant improvement in the detection of network attacks with our recommended approach.	187.97113410535314
574.	The fuel economy of a hybrid electric vehicle(HEV) is vastly influenced by the manner power is distributed. A dynamic, programming-based power distribution strategy can provide a global optimal solution, but it is not applicable to an actual vehicle because it requires further driving information. On the other hand, the reinforcement learning-based power distribution strategy is highly applicable to an actual vehicle because it requires only the current state to construct the policy.Recently, deep Q-networks(DQN) have been developed by applying a deep neural network to reinforcement learning, leading to significant change in the field of reinforcement learning. DQN could solve complex tasks efficiently based on different studies. In this particular study, we developed an energy management strategy for HEVs that is applicable to actual vehicles, and can achieve high efficiency through the DQN.	187.9711166526253
575.	Stress has become an increasingly serious problem in the current society, threatening mankind's well-beings. With the ubiquitous deployment of video cameras in surroundings, detecting stress based on the contact-free camera sensors becomes a cost-effective and mass-reaching way without interference of artificial traits and factors. In this study, we leverage users' facial expressions and action motions in the video and present a two-leveled stress detection network (TSDNet). TSDNet firstly learns face- and action-level representations separately, and then fuses the results through a stream weighted integrator with local and global attention for stress identification. To evaluate the performance of TSDNet, we constructed a video dataset containing 2092 labeled video clips, and the experimental results on the built dataset show that: (1) TSDNet outperformed the hand-crafted feature engineering approaches with detection accuracy 85.42% and F1-Score 85.28%, demonstrating the feasibility and effectiveness of using deep learning to analyze one's face and action motions; and (2) considering both facial expressions and action motions could improve detection accuracy and F1-Score of that considering only face or action method by over 7%.	187.97106814881255
576.	Currently, the surveillance camera-based person re-identification is still challenging because of diverse factors such as people's changing poses and various illumination. The various poses make it hard to conduct feature matching across images, and the illumination changes make color-based features unreliable. In this article, we present SKEPRID,(1) a skeleton-based person re-identification method that handles strong pose and illumination changes jointly. To reduce the impacts of pose changes on re-identification, we estimate the joints' positions of a person based on the deep learning technique and thus make it possible to extract features on specific body parts with high accuracy. Based on the skeleton information, we design a set of local color comparison-based cloth-type features, which are resistant to various lighting conditions. Moreover, to better evaluate SKEPRID, we build the PO&LI2 dataset, which has large pose and illumination diversity. Our experimental results show that SKEPRID outperforms state-of-the-art approaches in the case of strong pose and illumination variation.	187.97104937610646
577.	Adversarial examples of deep neural networks are receiving ever increasing attention because they help in understanding and reducing the sensitivity to their input. This is natural given the increasing applications of deep neural networks in our everyday lives. When white-box attacks are almost always successful, it is typically only the distortion of the perturbations that matters in their evaluation. In this work, we argue that speed is important as well, especially when considering that fast attacks are required by adversarial training. Given more time, iterative methods can always find better solutions. We investigate this speed-distortion trade-off in some depth and introduce a new attack called boundary projection (BP) that improves upon existing methods by a large margin. Our key idea is that the classification boundary is a manifold in the image space: we therefore quickly reach the boundary and then optimize distortion on this manifold.	187.97093057771318
578.	Surface monitoring, vertical atmospheric column observation, and simulation using chemical transportation models are three dominant approaches for perception of fine particles with diameters less than 2.5 micrometers (PM2.5) concentration. Here we explored an image-based methodology with a deep learning approach and machine learning approach to extend the ability on PM2.5 perception. Using 6976 images combined with daily weather conditions and hourly time data in Shanghai (2016), trained by hourly surface monitoring concentrations, an end-to-end model consisting of convolutional neural network and gradient boosting machine (GBM) was constructed. The mean absolute error, the root-mean-square error and the R-squared for PM2.5 concentration estimation using our proposed method is 3.56, 10.02, and 0.85 respectively. The transferability analysis showed that networks trained in Shanghai, fine-tuned with only 10% of images in other locations, achieved performances similar to ones from trained on data from target locations themselves. The sensitivity of different regions in the image to PM2.5 concentration was also quantified through the analysis of feature importance in GBM. All the required inputs in this study are commonly available, which greatly improved the accessibility of PM2.5 concentration for placed and period with no surface observation. And this study makes an exploratory attempt on pollution monitoring using graph theory and deep learning approach.	187.97083605432496
579.	Deep learning algorithms produces state-of-the-art results for different machine learning and computer vision tasks. To perform well on a given task, these algorithms require large dataset for training However, deep learning algorithms lack generalization and suffer from over-fitting whenever trained on small dataset, especially when one is dealing with medical images. For supervised image analysis in medical imaging, having image data along with their corresponding annotated ground-truths is costly as well as time consuming since annotations of the data is done by medical experts manually. In this paper, we propose a new Generative Adversarial Network for Medical Imaging (MI-GAN). The MI-GAN generates synthetic medical images and their segmented masks, which can then be used for the application of supervised analysis of medical images. Particularly, we present MI-GAN for synthesis of retinal images. The proposed method generates precise segmented images better than the existing techniques. The proposed model achieves a dice coefficient of 0.837 on STARE dataset and 0.832 on DRIVE dataset which is state-of-the-art performance on both the datasets.	187.97080764283265
580.	In this work we analyze the effect of label noise in training and test data when performing classification experiments on chest radiographs (CXRs) with modern deep learning architectures. We use ChestXRay14, the largest publicly available CXR dataset. We simulate situs inversus by horizontal flipping of the CXRs, allowing us to precisely control the amount of label noise. We also perform experiments in classifying emphysema using the ChestXRay14 provided labels that are known to be noisy. Our situs inversus experiments confirm results from the computer vision literature that deep learning architectures are relatively robust but not completely insensitive to label noise in the training data: without or with very low noise, classification results are near perfect; 16% and 32% training label noise only lead to a 1.5% and 4.6% drop in accuracy. We investigate two metrics that could be used to identify test samples that have an incorrect label: model confidence and model uncertainty. We show, in an observer study with an experienced chest radiologist, that both measures are effective in identifying samples in ChestXRay14 that are erroneously labeled for the presence of emphysema.	187.970774905533
581.	Non-invasive load monitoring (NILM) is a vital step to realize the smart grid. Although the existing various NILM algorithms have made significant progress in energy consumption feedback, there are still some problems need to further addressed, such as the exponential growth of state space with the increase of the number of multi-state devices, which leads to the dimension disaster; and it is difficult to capture the power fluctuation information effectively because of the neglect of time-dependency problem load disaggregation; traditional disaggregation involves a process of one sequence to one sequence optimization, which is inefficient. In our study, a composite deep LSTM is proposed for load disaggregation. The proposed algorithm considers the process of load disaggregation as a signal separation process and establishes regression learning from a single sequence to multiple sequences to avoid dimension disaster. In addition, an encoder-separation-decoder structure is introduced for load disaggregation. Encoder completes the effective encoding of the mains power and differential power information, the time dependency of the encoding process implemented by a deep LSTM, separation realizes the disaggregation process by separating the encoded information, and decoder decode the separated signal into the sequences of corresponding electrical appliances. Compared with the one sequence to one sequence disaggregation method, the proposed method simplified disaggregation complexity and improves the efficiency of disaggregation. The experimental results on WikiEnergy and REDD datasets show that the proposed method can reduce the disaggregation error and improve the comprehensive performance of event detection. Besides, our study can provide conditions for the realization of the bidirectional interaction of the smart grid and the improvement of the smart grid scheduling. (c) 2020 Elsevier Ltd. All rights reserved.	187.97076808204702
582.	Pedestrians' gender is a soft attribute which is useful in many areas of computer vision including human robot interaction, intelligent surveillance and human behavior analysis. Apart from its importance, pedestrians' gender prediction is one of the challenging methodologies in image processing. In this article, a deep learning approach is presented to classify a pedestrian as a male or a female. As a preprocessing step, pedestrian parsing is performed by a deep decompositional neural network method. The outcome of this network is a binary mask that maps the pedestrian full body from the input image. The pedestrian body image is then extracted by applying the generated pedestrian mask to the input image. This pre-processed image is then supplied to the stacked sparse auto encoder with soft max classifier for prediction. The proposed network is trained and tested separately on different pedestrians' views such as frontal views, back views and mixed views. The training is performed on PETA dataset. The experiments for testing are performed on MIT and PETA datasets (containing images other than train images). The accuracy values on MIT dataset are calculated as 82.9%, 81.8% and 82.4% on frontal, back and mixed views respectively. The mean AUC value by proposed scheme on PETA dataset is found as 91.5%+/- 4. The performance measures and comparisons with existing works depict the robustness and applicability of proposed methodology. (C) 2018 Elsevier B.V. All rights reserved.	187.97071522144384
583.	Learning fine-grained details is a key issue in image aesthetic assessment. Most of the previous methods extract the fine-grained details via random cropping strategy, which may undermine the integrity of semantic information. Extensive studies show that humans perceive fine-grained details with a mixture of foveal vision and peripheral vision. Fovea has the highest possible visual acuity and is responsible for seeing the details. The peripheral vision is used for perceiving the broad spatial scene and selecting the attended regions for the fovea. Inspired by these observations, we propose a gated peripheral-foveal convolutional neural network. It is a dedicated double-subnet neural network (i.e., a peripheral subnet and a foveal subnet). The former aims to mimic the functions of peripheral vision to encode the holistic information and provide the attended regions. The latter aims to extract fine-grained features on these key regions. Considering that the peripheral vision and foveal vision play different roles in processing different visual stimuli, we further employ a gated information fusion network to weigh their contributions. The weights are determined through the fully connected layers followed by a sigmoid function. We conduct comprehensive experiments on the standard Aesthetic Visual Analysis (AVA) dataset and Photo.net dataset for unified aesthetic prediction tasks: 1) aesthetic quality classification; 2) aesthetic score regression; and 3) aesthetic score distribution prediction. The experimental results demonstrate the effectiveness of the proposed method.	187.97066015438907
584.	Kernel-based home range models are widely-used to estimate animal habitats and develop conservation strategies. They provide a probabilistic measure of animal space use instead of assuming the uniform utilization within an outside boundary. However, this type of models estimates the home ranges from animal relocations, and the inadequate locational data often prevents scientists from applying them in long-term and large-scale research. In this paper, we propose an end-to-end deep learning framework to simulate kernel home range models. We use the conditional adversarial network as a supervised model to learn the home range mapping from time-series remote sensing imagery. Our approach enables scientists to eliminate the persistent dependence on locational data in home range analysis. In experiments, we illustrate our approach by mapping the home ranges of Bar-headed Geese in Qinghai Lake area. The proposed framework outperforms all baselines in both qualitative and quantitative evaluations, achieving visually recognizable results and high mapping accuracy. The experiment also shows that learning the mapping between images is a more effective way to map such complex targets than traditional pixel-based schemes.	187.97061950204056
585.	This work introduces a classification model using neural networks on the severity for asthma exacerbations [1] from patients who seek the Brazilian healthcare system in order to get a first treatment of their condition. Healthcare specialists, who work on related databases, usually have access to the information about whether these events need a critical handling or not. However, in many situations, these databases present missing data, which usually demands a manual evaluation of this data and, therefore, time. Hence, the aim of this work is to automate the classification process on the asthma emergency cases - by training and testing neural networks - and compare its performance with other classifiers. The results will be part of the analysis and assessments routines performed by specialists of a healthcare company.	187.9705016590374
586.	Human Action Recognition (HAR) involves human activity monitoring task in different areas of medical, education, entertainment, visual surveillance, video retrieval, as well as abnormal activity identification, to name a few. Due to an increase in the usage of cameras, automated systems are in demand for the classification of such activities using computationally intelligent techniques such as Machine Learning (ML) and Deep Learning (DL). In this survey, we have discussed various ML and DL techniques for HAR for the years 2011-2019. The paper discusses the characteristics of public datasets used for HAR. It also presents a survey of various action recognition techniques along with the HAR applications namely, content-based video summarization, human-computer interaction, education, healthcare, video surveillance, abnormal activity detection, sports, and entertainment. The advantages and disadvantages of action representation, dimensionality reduction, and action analysis methods are also provided. The paper discusses challenges and future directions for HAR.	187.970500308778
587.	We propose building-scale virtual reality (VR), a real-world extension method different from augmented reality (AR), that uses automatically generated indoor 3D point cloud maps. To make the entire indoor area a pose tracking area, we attach an RGB-D camera to a VR headset, collect data with it, and use deep learning to build a model learned from the data. This method is more accurate than the conventional RGB-D SLAM method. Furthermore, to modify the VR space according to the purpose, segmentation and replacement of the 3D point cloud are performed. This is hard to do in AR, but it is essential technology for VR to be used in actual real-world work. We describe a disaster simulation including virtual evacuation drills and virtual work environments as application examples.	187.97038900000018
588.	Railway turnouts require high-performance condition monitoring to prevent disastrous railway accidents. In industrial practice, turnouts' monitoring is usually done by railway workers who visually inspect the operating current curves. This results in huge labor costs and prone to human mistakes. Thus, automating the process of turnouts' monitoring via fault-detection algorithms is imperative. The available turnout field data bring three difficulties to fault detection: 1) large amounts of data do not have any labels; 2) data collected in normal condition have multiple unknown modes; and 3) there are only a small number of samples in some modes. To address these difficulties, this article develops a novel unsupervised fault-detection method by using deep autoencoders, which is composed of an unknown modes' mining stage and a multimode fault-detection stage. First, unknown modes are identified through clustering and employing engineer expertise. Then, an ensemble monitoring model, consisting of local monitoring models developed with individual fault-free modes and a global monitoring model developed by merging the data in all fault-free modes, is proposed to improve the overall fault-detection performance. In addition, to construct local models for the modes with a small number of samples, a one-class transfer learning algorithm is presented. In online monitoring, the decision of a newly arrived sample exploits both local models and the global model. Using both the simulated turnout data and the field data collected from a high-speed railway in China, the efficacy and robustness of the proposed approach are demonstrated by comparisons with other methods.	187.97037835514234
589.	A deep learning (DL) based digital backpropagation (DBP) method with a 1 dB SNR gain over a conventional 1 step per span DBP is demonstrated in a 32 GBd 16QAM transmission across 1200 km. The new DL-DPB is shown to require 6 times less computational power over the conventional DBP scheme. The achievement is possible due to a novel training method in which the DL-DBP is blind to timing error, state of polarization rotation, frequency offset and phase offset. An analysis of the underlying mechanism is given. The applied method first undoes the dispersion, compensates for nonlinear effects in a distributed fashion and reduces the out of band nonlinear modulation due to compensation of the nonlinearities by having a low pass characteristic. We also show that it is sufficient to update the elements of the DL network using a signal with high nonlinearity when dispersion or nonlinearity conditions changes. Lastly, simulation results indicate that the proposed scheme is suitable to deal with impairments from transmission over longer distances.	187.9702113673286
590.	The experimental design of high-strength concrete (HSC) requires deep analysis to get the target strength. In this study, machine learning approaches and artificial intelligence python-based approaches have been utilized to predict the mechanical behaviour of HSC. The data to be used in the modelling consist of several input parameters such as cement, water, fine aggregate, and coarse aggregate in combination with a superplasticizer. Empirical relation with mathematical expression has been proposed using engineering programming. The efficiency of the models is assessed by statistical analysis with the error by using MAE, RRMSE, RSE, and comparisons were made between regression models. Moreover, variable intensity and correlation have shown that deep learning can be used to know the exact amount of materials in civil engineering rather than doing experimental work. The expression tree, as well as normalization of the graph, depicts significant accuracy between target and output values. The results reveal that machine learning proposed adamant accuracy and has elucidated performance in the prediction aspect.	187.97016927287973
591.	The Internet of Things equips citizens with a phenomenal new means for online participation in sharing economies. When agents self-determine options from which they choose, for instance, their resource consumption and production, while these choices have a collective systemwide impact, optimal decision-making turns into a combinatorial optimization problem known as NP-hard. In such challenging computational problems, centrally managed (deep) learning systems often require personal data with implications on privacy and citizens' autonomy. This article envisions an alternative unsupervised and decentralized collective learning approach that preserves privacy, autonomy, and participation of multi-agent systems self-organized into a hierarchical tree structure. Remote interactions orchestrate a highly efficient process for decentralized collective learning. This disruptive concept is realized by I-EPOS, the Iterative Economic Planning and Optimized Selections, accompanied by a paradigmatic software artifact. Strikingly, I-EPOS outperforms related algorithms that involve non-local brute-force operations or exchange full information. This article contributes new experimental findings about the influence of network topology and planning on learning efficiency as well as findings on techno-socio-economic tradeoffs and global optimality. Experimental evaluation with real-world data from energy and bike sharing pilots demonstrates the grand potential of collective learning to design ethically and socially responsible participatory sharing economies.	187.97016329490623
592.	Clustering is widely used in unsupervised learning method that deals with unlabeled data. Deep clustering has become a popular study area that relates clustering with Deep Neural Network (DNN) architecture. Deep clustering method downsamples high dimensional data, which may also relate clustering loss. Deep clustering is also introduced in semi-supervised learning (SSL). Most SSL methods depend on pairwise constraint information, which is a matrix containing knowledge if data pairs can be in the same cluster or not. This paper introduces a novel embedding system named AutoEmbedder, that downsamples higher dimensional data to clusterable embedding points. To the best of our knowledge, this is the first research endeavor that relates to traditional classifier DNN architecture with a pairwise loss reduction technique. The training process is semi-supervised and uses Siamese network architecture to compute pairwise constraint loss in the feature learning phase. The AutoEmbedder outperforms most of the existing DNN based semi-supervised methods tested on famous datasets. (C) 2020 Elsevier B.V. All rights reserved.	187.97016270347126
593.	Multi-task learning (MTL), which optimizes multiple related learning tasks at the same time, has been widely used in various applications, including natural language processing, speech recognition, computer vision, multimedia data processing, biomedical imaging, socio-biological data analysis, multi-modality data analysis, etc. MTL sometimes is also referred to as joint learning, and is closely related to other machine learning subfields like multi-class learning, transfer learning, and learning with auxiliary tasks, to name a few. In this paper, we provide a brief review on this topic, discuss the motivation behind this machine learning method, compare various MTL algorithms, review MTL methods for incomplete data, and discuss its application in deep learning. We aim to provide the readers with a simple way to understand MTL without too many complicated equations, and to help the readers to apply MTL in their applications.	187.9699147722254
594.	Today, most activities and important data are placed on Internet websites, so attempts to intrude into these websites have grown exponentially. Intrusion detection systems (IDS) of web attacks are an approach to protect users. But, these systems are suffering from such drawbacks as low accuracy in detecting new attacks. To tackle this problem, various machine learning methods have been developed in recent years. Since attack requests differ from normal requests slightly, these anomaly detection methods have failed to exhibit good accuracy in new attack detection. In web requests and responses, a great deal of interconnected data is usually moved, and anomaly detection attempts need to consider all these connections, but this is a very complicated task. Thus, some research works on attack detection are confined to the analysis of just URL and a part of the request. This paper presents a new method for web attack detection using seq2seq networks using attention. The method is shown to successfully classify the traffic by predicting the possible responses and calculating differences from real responses of the webserver. The higher accuracy of this method versus similar methods shows that the use of the attention mechanism can cope with the challenge of analyzing long web requests and responses to a great extent. The proposed model exhibited a high result in terms of the specificity criterion when it came to such attacks as SQL Injection and XSS whose success highly depends on the server's response. This can be attributed to the inclusion of the link between the request and response in identifying web attacks in the proposed method. (C) 2020 ISC. All rights reserved.	187.96989177969914
595.	Self-esteem is among the most frequently examined constructs in psychology. For a long time, research on self-esteem followed a variable-centered approach, considering mostly the individual facets of self-esteem to be relevant. In this article, we investigate different combinations of self-esteem level, stability, and contingency as well as their relations with learning and performance. Across three online-studies (n total = 2 499), latent profile analyses revealed four self-esteem profiles beside the profile of "optimal self-esteem" (Kernis, 2003). These profiles are associated with different consequences. For example, the profile "optimal self-esteem" yields the most favorable results pattern, such as the use of deep processing strategies. Overall, our findings suggest that a multidimensional view of self-esteem allows for more precise predictions of learning-related behaviors. Implications for future research and practice are discussed.	187.96977297877606
596.	Data augmentation is a widely used technique for enhancing the generalization ability of deep neural networks for skeleton-based human action recognition (HAR) tasks. Most existing data augmentation methods generate new samples by means of handcrafted transforms. However, these methods often cannot be trained and then are discarded during testing because of the lack of learnable parameters. To solve those problems, a novel type of data augmentation network called a sample fusion network (SFN) is proposed. Instead of using handcrafted transforms, an SFN generates new samples via a long short-term memory (LSTM) autoencoder (AE) network. Therefore, an SFN and HAR network can be cascaded together to form a combined network that can be trained in an end-to-end manner. Moreover, an adaptive weighting strategy is employed to improve the complementarity between a sample and the new sample generated from it by an SFN, thus allowing the SFN to more efficiently improve the performance of the HAR network during testing. The experimental results on various datasets verify that the proposed method outperforms state-of-the-art data augmentation methods. More importantly, the proposed SFN architecture is a general framework that can be integrated with various types of networks for HAR. For example, when a baseline HAR model with three LSTM layers and one fully connected (FC) layer was used, the classification accuracy was increased from 79.53% to 90.75% on the NTU RGB+D dataset using a cross-view protocol, thus outperforming most other methods.	187.96962603173097
597.	In clinical scenarios, there is an increasing interest in complex computational experiments, as for example the training of Deep Learning models. Reproducibility is an essential property of such experiments, especially if the result contributes to a patient's treatment. This paper introduces Curious Containers, a software framework for computational reproducibility that treats data, software and runtime environment as decentralized network resources. All experiment resources are described in a single file, using a new format that is compatible with a subset of the Common Workflow Language. Docker is used to deploy the experiment software in a container image, including arbitrary data transmission programs to connect with existing storage solutions. The framework supports Deep Learning applications, that have a high demand in storage and processing capabilities. Large datasets can be mounted inside containers via network filesystems like SSHFS based on the filesystem in user-space technology. The Nvidia-Container-Toolkit enables GPU usage. Curious Containers has been tested in two biomedical scenarios. The first use case is a Deep Learning application for tumor classification in images that requires a large dataset and a GPU. In this context, a prototypical integration of the framework with the existing Data Version Control system for exploratory Deep Learning modeling has been developed. The second use case extends an existing container image, including a scientific workflow for detection and comparison of human protein in mass spectrography data. The container image was originally developed for an archiving platform and could be extended to be compatible with both Curious Containers and cwltool, the Common Workflow Language reference implementation. The presented solution allows for consistent description and execution of computational experiments, while trying to be both flexible and interoperable with existing software and standards. Support for Deep Learning experiments is gaining importance as such systems are increasingly validated as medical decision support systems. (C) 2020 Elsevier B.V. All rights reserved.	187.96961084048272
598.	The amount, distribution, and morphology of the impurities in a marble block determine both its aesthetic quality and compressive strength (CS). Although the former property has been studied extensively, CS prediction is rarely investigated. The existing approaches either use expensive and tedious laboratory tests or employ image processing to individual surface images, which are shown to achieve limited performance. In this paper, a new electromechanical system is designed for full automatic prediction of CS of a marble block on a conveyor belt using all visible surface images, which are acquired by a three-dimensional (3-D) printed robotic arm. The images are used to generate unique reconstructions, which can represent the 3-D structure of the marbles in two-dimensional (2-D) via developed warped stitching based visualizations. Moreover, a novel feature set is proposed for taking advantage of these reconstructions. A total of 157 cubic marble blocks are collected to test the performance of the system using both conventional (neural networks) and emerging (deep) machine learning tools. Adverse effects of small sample size are compensated with data augmentation and transfer learning. It is shown that the system achieves the state-of-the-art prediction results.	187.96958839411826
599.	Computer Tomography (CT) imaging of the chest is a valid diagnosis tool to detect COVID-19 promptly and to control the spread of the disease. In this work we propose a light Convolutional Neural Network (CNN) design, based on the model of the SqueezeNet, for the efficient discrimination of COVID-19 CT images with respect to other community-acquired pneumonia and/or healthy CT images. The architecture allows to an accuracy of 85.03% with an improvement of about 3.2% in the first dataset arrangement and of about 2.1% in the second dataset arrangement. The obtained gain, though of low entity, can be really important in medical diagnosis and, in particular, for Covid-19 scenario. Also the average classification time on a high-end workstation, 1.25s, is very competitive with respect to that of more complex CNN designs, 13.41s, witch require pre-processing. The proposed CNN can be executed on medium-end laptop without GPU acceleration in 7.81s: this is impossible for methods requiring GPU acceleration. The performance of the method can be further improved with efficient pre-processing strategies for witch GPU acceleration is not necessary.	187.9695843015627
600.	We present a deep learning approach for the core digital libraries task of parsing bibliographic reference strings. We deploy the state-of-the-art long short-term memory (LSTM) neural network architecture, a variant of a recurrent neural network to capture long-range dependencies in reference strings. We explore word embeddings and character-based word embeddings as an alternative to handcrafted features. We incrementally experiment with features, architectural configurations, and the diversity of the dataset. Our final model is an LSTM-based architecture, which layers a linear chain conditional random field (CRF) over the LSTM output. In extensive experiments in both English in-domain (computer science) and out-of-domain (humanities) test cases, as well as multilingual data, our results show a significant gain over the reported state-of-the-art CRF-only-based parser.	187.96954679671325
601.	Chest X-rays (CXRs) are among the most commonly used medical image modalities. They are mostly used for screening, and an indication of disease typically results in subsequent tests. As this is mostly a screening test used to rule out chest abnormalities, the requesting clinicians are often interested in whether a CXR is normal or not. A machine learning algorithm that can accurately screen out even a small proportion of the "real normal" exams out of all requested CXRs would be highly beneficial in reducing the workload for radiologists. In this work, we report a deep neural network trained for classifying CXRs with the goal of identifying a large number of normal (disease-free) images without risking the discharge of sick patients. We use an ImageNet-pretrained Inception-ResNet-v2 model to provide the image features, which are further used to train a model on CXRs labelled by expert radiologists. The probability threshold for classification is optimized for 100% precision for the normal class, ensuring no sick patients are released. At this threshold we report an average recall of 50%. This means that the proposed solution has the potential to cut in half the number of disease-free CXRs examined by radiologists, without risking the discharge of sick patients.	187.96952240182972
602.	A deep learning approach based on a proposed artificial neural network (ANN) is exploited to predict the filtered drag force, which is a desirable term for coarse-grid simulations of gas-solid flows. The proposed ANN model includes one input layer, five hidden layers and one output layer. The hidden layers are composed of three convolutional layers and two fully-connected layers. The results show that the proposed ANN model is superior to the multi-layered perceptron (MLP) model and the best available traditional functional model over a wide range of the filter size. The results also indicate that the use of the information on neighboring coarse grids is necessary for accurate estimation of the filtered drag force at the considered filter sizes. This finding is substantiated by a budget analysis which demonstrates that the diffusion of the Reynolds stress and solid phase stress significantly affects the filtered drag force. (c) 2020 Elsevier Ltd. All rights reserved.	187.96950593031875
603.	Single-particle cryo-electron microscopy (cryo-EM) has recently become a mainstream technique for the structural determination of macromolecules. Typical cryo-EM workflows collect hundreds of thousands of single-particle projections from thousands of micrographs using particle-picking algorithms. However, the number of false positives selected by these algorithms is large, so that a number of different 'cleaning steps' are necessary to decrease the false-positive ratio. Most commonly employed techniques for the pruning of false-positive particles are time-consuming and require user intervention. In order to overcome these limitations, a deep learning-based algorithm named Deep Consensus is presented in this work. Deep Consensus works by computing a smart consensus over the output of different particle-picking algorithms, resulting in a set of particles with a lower false-positive ratio than the initial set obtained by the pickers. Deep Consensus is based on a deep convolutional neural network that is trained on a semi-automatically generated data set. The performance of Deep Consensus has been assessed on two well known experimental data sets, virtually eliminating user intervention for pruning, and enhances the reproducibility and objectivity of the whole process while achieving precision and recall figures above 90%.	187.96949723522832
604.	Recent studies show that research on single image super-resolution (SISR) has achieved great success by using deep convolutional neural network (CNN). Different types of features obtained in deep CNN have different contribution. However, most of the previous models ignore the distinction between different features and deal with them in the same way, which affects the representational capacity of the models. On the other hand, receptive fields with different size capture diverse features from the input. Based on the above considerations, we propose a dual residual attention module (DRAM) network which concentrates on recovering the high-frequency details and sharing the information between two receptive fields of different sizes. We construct local information integration (LFI) module as the basic module to make full use of the local information. The LFI module is a cascade of several dual residual attention fusion (DRAF) blocks with a dense connection structure. The feature modulation can focus on important features and suppress unimportant ones. The evaluation results on five benchmark datasets demonstrate the superiority of our DRAM network against the state-of-the-art algorithms. (C) 2019 Elsevier B.V. All rights reserved.	187.9694726562384
605.	In this paper, we raise a method to find certain motion segments in the video using a Multi-2d pose estimation model. Several types of angles are extracted. We draw a continuous curve based on the entire video for all required angle values and smooth the angle curve to reduce the influence of human detection errors on motion recognition. After the smoothing process, the curve is again processed into a change curve as analysis and then search for two kinds of movements with a reasonable threshold. We also handle the noise in the recognition result to get more accurate motion fragments. By comparing and analyzing different parameters, the optimal parameters to achieve lower error is found. We coded the system and carried out a large number of experimental analysis mainly through the analysis of the characters in the video to turn around and get up, and the following results are achieved: 1)Be able to use effectively optimized data for effective analysis. 2)In a multi-person situation, the classification of each person's data based on time series is achieved. 3)Fragments of two motion states are detected more accurately.	187.96943802193397
606.	The obstacle of imaging through multimode fibers (MMFs) is encountered due to the fact that the inherent mode dispersion and mode coupling lead the output of the MMF to be scattered and bring about image distortions. As a result, only noise-like speckle patterns can be formed on the distal end of the MMF. We propose a deep learning model exploited for computational imaging through an MMF, which contains an autoencoder (AE) for feature extraction and image reconstruction and self-normalizing neural networks (SNNs) sandwiched and employed for high-order feature representation. It was demonstrated both in simulations and in experiments that the proposed AE-SNN combined deep learning model could reconstruct image information from various binary amplitude-only targets going through a 5-meter-long MMF. Simulations indicate that our model works effectively even in the presence of system noise, and the experimental results prove that the method is valid for image reconstruction through the MMF. Enabled by the spatial variability and the self-normalizing properties, our model can be generalized to solve varieties of other computational imaging problems.	187.96930579020807
607.	Measurement of anatomical structures from ultrasound images requires the expertise of experienced clinicians. Moreover, there are artificial factors that make an automatic measurement complicated. In this paper, we aim to present a novel end-to-end deep learning network to automatically measure the fetal head circumference (HC), biparietal diameter (BPD), and occipitofrontal diameter (OFD) length from 2D ultrasound images. Fully convolutional neural networks (FCNNs) have shown significant improvement in natural image segmentation. Therefore, to overcome the potential difficulties in automated segmentation, we present a novelty FCNN and add a regression branch for predicting OFD and BPD in parallel. In the segmentation branch, a feature pyramid inside our network is built from low-level feature layers for a variety of fetal head in ultrasound images, which is different from traditional feature pyramid building methods. In order to select the most useful scale and reduce scale noise, attention mechanism is taken for the feature's filter. In the regression branch, for the accurate estimation of OFD and BPD length, a new region of interest (ROI) pooling layer is proposed to extract the elliptic feature map. We also evaluate the performance of our method on large dataset: HC18. Our experimental results show that our method can achieve better performance than the existing fetal head measurement methods.	187.96903033231885
608.	Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.	187.9689834097158
609.	This article describes the development and calibration of the student opportunities for deeper learning instrument (SODLI). The SODLI is designed to measure the amount of learning opportunities intended to support higher-order thinking that students are exposed to through student self-report, and is expected to be widely useful in psychological research in schools. Here, the psychometric functioning of the SODLI is investigated in a relatively large sample of U.S. high-school students (N = 963). Using multidimensional item-response theory methods, a nine-factor correlated model is determined to fit the data best, and to produce reliable estimates of SODLI dimensions. The SODLI is also shown to exhibit scalar-invariant measurement properties across sex, race/ethnicity, and language-background groups, although latent mean differences on some of the SODLI dimensions across those groups were identified.	187.96896212198004
610.	All successful public service innovations require learning and just as importantly and often more deeply, unlearning. This research investigates the unlearning of health professionals focusing on the issue of why and how unlearning happens at an individual level for health care professions in the transition from product logic to service-dominant logic at Tampere University Hospital in Finland. We applied a qualitative single case study method, a problem-centred unlearning framework with a narrative approach, which facilitates understanding of how the informants perceived the service transition process. We identified three distinct unlearning narratives, and we recognised barriers and enablers to unlearning in the health care service culture and context and suggest ways in which these might be overcome. Results of the study shows that deep and radical change in public health care services is possible, by applying distributed leadership and allowing individual actors time for reflections, mind-wandering, listening and learning from users and discourse between professionals.	187.96887014308086
611.	The condition monitoring of bogies plays an important role in the safe operation of rail transit systems. In practice, it is difficult to diagnose bogies under variable operating conditions for traditional methods. In this paper, deep residual learning is used to deal with this problem by utilizing its powerful feature self-learning characteristics and fast kurtogram is used to further enhance the robustness of the method to variable operating conditions and noises. Besides, considering the performance of data-driven deep learning method is easily to be affected by data imbalance which often occurs in practical data collection, a novel loss function called imbalance-weighted cross-entropy (IWCE) is proposed in this paper for networks training to solve the data imbalance problem. Finally, the robustness to variable operating conditions, noises and data imbalance of the proposed method is verified by two case studies. (C) 2020 Elsevier Ltd. All rights reserved.	187.9688390903575
612.	The timed up-and-go (TUG) test has been widely accepted as a standard assessment for measuring the basic functional mobility of patients with Parkinson's disease. Several basic mobility sub-tasks "Sit," "Sit-to-Stand," "Walk," "Turn," "Walk-Back," and "Sit-Back" are included in a TUG test. It has been shown that the time costs of these sub-tasks are useful clinical parameters for the assessment of Parkinson's disease. Several automatic methods have been proposed to segment and time these sub-tasks in a TUG test. However, these methods usually require either well-controlled environments for the TUG video recording or information from special devices, such as wearable inertial sensors, ambient sensors, or depth cameras. In this paper, an automatic TUG sub-task segmentation method using video-based activity classification is proposed and validated in a study with 24 Parkinson's disease patients. Videos used in this paper are recorded in semi-controlled environments with various backgrounds. The state-of-the-art deep learning-base 2-D human pose estimation technologies are used for feature extraction. A support vector machine and a long short-term memory network are then used for the activity classification and the subtask segmentation. Our method can be used to automatically acquire clinical parameters for the assessment of Parkinson's disease using TUG videos-only, leading to the possibility of remote monitoring of the patients' condition.	187.96876540458732
613.	Water covers 71% of the Earth's surface and is vital for all known forms of life. Quality of drinking water is very important. The concentration of major chemical elements under the desirable limit is good for health but an increase in the concentration of the element above the desirable limit may cause adverse effects on human health. Major problems being faced by the world population are due to the presence of excess fluoride, sulfate, chloride, nitrate, and sodium in water. In this paper, we address the problem of changes in the drinking water quality and the crucial task for public water companies to monitor the quality of water. Requirements for drinking water quality monitoring change frequently, e.g., due to contamination by civilization itself or in the supply and distribution network. The proposed methods are K-Nearest Neighbour Algorithm (KNN) and Classification Neural Network based on Logistic Regression for obtaining an appropriate solution in an adequate period of time. Also, the paper compares of the result between the proposed methods and other methods applied in previous work. All experiments are carried out using data gathered from Thuringer Fernwasserversorgung (TFW) water company.	187.9687520998969
614.	COVID-19 is a novel virus that causes infection in both the upper respiratory tract and the lungs. The numbers of cases and deaths have increased on a daily basis on the scale of a global pandemic. Chest X-ray images have proven useful for monitoring various lung diseases and have recently been used to monitor the COVID-19 disease. In this paper, deep-learning-based approaches, namely deep feature extraction, fine-tuning of pretrained convolutional neural networks (CNN), and end-to-end training of a developed CNN model, have been used in order to classify COVID-19 and normal (healthy) chest X-ray images. For deep feature extraction, pretrained deep CNN models (ResNet18, ResNet50, ResNet101, VGG16, and VGG19) were used. For classification of the deep features, the Support Vector Machines (SVM) classifier was used with various kernel functions, namely Linear, Quadratic, Cubic, and Gaussian. The aforementioned pretrained deep CNN models were also used for the fine-tuning procedure. A new CNN model is proposed in this study with end-to-end training. A dataset containing 180 COVID-19 and 200 normal (healthy) chest X-ray images was used in the study's experimentation. Classification accuracy was used as the performance measurement of the study. The experimental works reveal that deep learning shows potential in the detection of COVID-19 based on chest X-ray images. The deep features extracted from the ResNet50 model and SVM classifier with the Linear kernel function produced a 94.7% accuracy score, which was the highest among all the obtained results. The achievement of the fine-tuned ResNet50 model was found to be 92.6%, whilst end-to-end training of the developed CNN model produced a 91.6% result. Various local texture descriptors and SVM classifications were also used for performance comparison with alternative deep approaches; the results of which showed the deep approaches to be quite efficient when compared to the local texture descriptors in the detection of COVID-19 based on chest X-ray images.	187.96865401092361
615.	With the rapid development of deep learning techniques, speech-based communication is getting more practically to be embedded into smart devices such as Alexa echo, TV, Fridge, etc. In this work, we have developed an efficient yet accurate Speech Command Recognition (SCR), that is particularly appropriate for low-resource devices. To this aim, a novel neural network, called Light Interior Search Network (LIS-Net), is presented that works with raw speech signal. LIS-Net is structurally composed of a sequence of parameterized LIS-Blocks, each of which is a stack of LIS-Cores, exploring the feature-map inheritance to learn highly distinctive and lightweight footprint of speech patterns. The proposed network is validated on Google Speech Commands benchmark speech datasets, demonstrating a significant improvement of accuracy and processing time in comparison with other state-of-the-art techniques. (C) 2020 Elsevier Ltd. All rights reserved.	187.9686361029181
616.	Deep learning (DL) is one of the key technologies in the artificial intelligence (AI) domain Deep learning neural networks (DLNN) profit a lot from the overall exponential data growth while on the other hand the computational effort for training and inference strongly increase. Most of the computational time in DLNN is consumed by the convolution step, which is based on a general matrix multiplication (GEMM). In order to accelerate the computational time for DLNN different highly optimized GEMM implementations for Graphic Processing Units (GPUs) have been presented in the last years [1] most of these approaches are GPU hardware specific implementations of the GEMM software kernel and do not incorporate the performance dependency of the training data layout. In order to achieve a maximum performance the parameters of the GEMM algorithm have to be tuned for the different GPU hardware and specific data layout of the training task. In this paper we present a two step autotuning approach for GPU based GEMM algorithms. In the first step the kernel parameter search space is pruned by several performance criteria and afterwards further processed by a modified Simulated Annealing in order to find the best kernel parameter combinations with respect to the GPU hardware and the task specific data layout. Our results were carried out on 160 different input problems with the proposed approach an average speedup against the state of the art implementation from NVIDIA (cuBLAS) from around 12 on a NVIDIA GTX 1080 Ti accelerator card can be achieved.	187.96861707650802
617.	The generalization error bound of the support vector machine (SVM) depends on the ratio of the radius and margin. However, conventional SVM only considers the maximization of the margin but ignores the minimization of the radius, which restricts its performance when applied to joint learning of feature transformation and the SVM classifier. Although several approaches have been proposed to integrate the radius and margin information, most of them either require the form of the transformation matrix to be diagonal, or are nonconvex and computationally expensive. In this paper, we suggest a novel approximation for the radius of the minimum enclosing ball in feature space, and then propose a convex radius-margin-based SVM model for joint learning of feature transformation and the SVM classifier, i.e., F-SVM. A generalized block coordinate descent method is adopted to solve the F-SVM model, where the feature transformation is updated via the gradient descent and the classifier is updated by employing the existing SVM solver. By incorporating with kernel principal component analysis, F-SVM is further extended for joint learning of nonlinear transformation and the classifier. F-SVM can also be incorporated with deep convolutional networks to improve image classification performance. Experiments on the UCI, LFW, MNIST, CIFAR-10, CIFAR-100, and Caltech101 data sets demonstrate the effectiveness of F-SVM.	187.96859294184017
618.	Forecasting the copper price volatility is an important yet challenging task. Given the nonlinear and time-varying characteristics of numerous factors affecting the copper price, we propose a novel hybrid method to forecast copper price volatility. Two important techniques are synthesized in this method. One is the classic GARCH model which encodes useful statistical information about the time-varying copper price volatility in a compact form via the GARCH forecasts. The other is the powerful deep neural network which combines the GARCH forecasts with both domestic and international market factors to search for better nonlinear features; it also combines the long short-term memory (LSTM) network with traditional artificial neural network (ANN) to generate better volatility forecasts. Our method synthesizes the merits of these two techniques and is especially suitable for the task of copper price volatility prediction. The empirical results show that the GARCH forecasts can serve as informative features to significantly increase the predictive power of the neural network model, and the integration of the LSTM and ANN networks is an effective approach to construct useful deep neural network structures to boost the prediction performance. Further, we conducted a series of sensitivity analyses of the neural network architecture to optimize the prediction results. The results suggest that the choice between LSTM and BLSTM networks for the hybrid model should consider the forecast horizon, while the ANN configurations should be fine-tuned depending on the choice of the measure of prediction errors. (C) 2020 Elsevier B.V. All rights reserved.	187.9684906053688
619.	Recognizing the widespread existence of intrinsically disordered regions in proteins spurred the development of computational techniques for their detection. All existing techniques can be classified into methods relying on single-sequence information and those relying on evolutionary sequence profiles generated from multiple-sequence alignments. The methods based on sequence profiles are, general, more accurate because the presence or absence of conserved amino acid residues in a protein sequence provides important information on the structural and functional roles of the residues. However, the wide applicability of profile-based techniques is limited by time-consuming calculation of sequence profiles. Here we demonstrate that the performance gap between profile-based techniques and single-sequence methods can be reduced by using an ensemble of deep recurrent and convolutional neural networks that allow whole-sequence learning. In particular, the single-sequence method (called SPOT Disorder-Single) is more accurate than SPOT-Disorder (a profile-based method) for proteins with few homologous sequences and comparable for proteins in predicting long-disordered regions. The method performance is robust across four independent test sets with different amounts of short-and long-disordered regions. SPOT-Disorder-Single is available	187.9684782308351
620.	The increase of network users has led to a large number of commentary languages on various network platforms. Traditional manual processing is time-consuming and labor-intensive. We need a mechanized way to process these commentary corpora and quickly uncover the emotional tendencies. A method of sentimental orientation analysis of comment text based on deep learning is proposed. First, we used GloVe model to train the word vector. Then, Give the different weight on word vector by using TF-IDF. Finally, the processed word vectors would be classificated by TextCNN. Experiments were carried out on the six categories of commodity review data crawled by Jingdong. This method can effectively identify the emotional tendency of the review text, which is more accurate than the traditional deep learning method.	187.96847144324772
621.	The article is devoted to the trends and transformations of philological education in the context of modern technologies development. The purpose of the research is to study the preparation specifics of philology students and to develop a new approach to their training, based on an effective educational methodology of literary and linguistic analysis of the text. To achieve this goal, exercises and methods are defined. Such methods were used as: comparison, contextual-interpretative, comparative-historical method and other general scientific methods. The study found that in a globalized world it is necessary to form new core competencies in students-philologists, namely the capacity for independent learning throughout life and motivation. It is possible to achieve this through rethinking pedagogical methods. The authors proved that the text is an important means of modern communication which is dynamically transformed which determines the need for its deep philological research. For this, the authors improved the method of preparing students of philology which is based on the introduction of modern information technologies into the system of literary and linguistic analysis of the text. Software products such as Compleat Lexical Tutor and ABBYY Compreno, in particular Compleat Lexical Tutor, make the process of text analysis easy.	187.96845125224584
622.	The rapid development of deep learning raises a new research area for condition monitoring and fault diagnosis of mechanical equipment recently. However, the amount of labeled fault samples is limited in industrial field, also the samples are filled with complex environmental noise. Thus, a model with strong generalization and robustness is required. To tackle these challenges, an adversarial denoising convo-lutional neural network (ADCNN) is proposed in this paper. Moving maximum is firstly applied to the frequency spectrum of the vibration signal to enhance the anti-noise performance of the training sam-ples. Then the enhanced training samples are erased with dynamic probability to simulate noise inter-ference. Meanwhile, adversarial training is utilized to expand the labeled samples until Nash equilibrium is reached. These processes improve the robustness and generalization of ADCNN, and avoid over-fitting with limited amount of labeled samples. In our two experiments, when signal to noise ratio(SNR) is -12dB, the ADCNN achieves a diagnosis accuracy of 94.05% and 94.47%, respectively. Besides, ADCNN can maintain a high diagnosis accuracy under limited sample size case, and has the best adaptation perfor-mance across different load domains. The comparison studies with respect to other models demonstrate the applicability and superiority of ADCNN. (C) 2020 Elsevier B.V. All rights reserved.	187.96839717502843
623.	Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest that deep learning approaches could be the vehicle for translating big biomedical data into improved human health. However, we also note limitations and needs for improved methods development and applications, especially in terms of ease-of-understanding for domain experts and citizen scientists. We discuss such challenges and suggest developing holistic and meaningful interpretable architectures to bridge deep learning models and human interpretability.	187.96838936209903
624.	A deep Q-network (DQN) was applied for model-free optimal control balancing between different HVAC systems. The DQN was coupled to a reference office building: an EnergyPlus simulation model provided by the U.S. Department of Energy. The building was air-conditioned with four air-handling units (AHUs), two electric chillers, a cooling tower, and two pumps. EnergyPlus simulation results for eleven days (July 1-11) and three subsequent days (July 12-14) were used to improve the DQN policy and test the optimal control. The optimization goal was to minimize the building's energy use while maintaining the indoor CO2 concentration below 1,000 ppm. It was revealed that the DQN-a reinforcement learning method-can improve its control policy based on prior actions, states, and rewards. The DQN lowered the total energy usage by 15.7% in comparison with the baseline operation while maintaining the indoor CO2 concentration below 1,000 ppm. Compared to model predictive control, the DQN does not require a simulation model, or a predetermined prediction horizon, thus delivering model-free optimal control. Furthermore, it was demonstrated that the DQN can find balanced control actions between different energy consumers in the building, such as chillers, pumps, and AHUs.	187.96834637582626
625.	An increasing number of the renowned company's investors are turning attention to stock prediction in the search for new efficient ways of hypothesizing about markets through the application of behavioral finance. Accordingly, research on stock prediction is becoming a popular direction in academia and industry. In this study, the goal is to establish a model for predicting stock price movement through knowledge graph from the financial news of the renowned companies. In contrast to traditional methods of stock prediction, our approach considers the effects of event tuple characteristics on stocks on the basis of knowledge graph and deep learning. The proposed model and other feature selection models were used to perform feature extraction on the websites of Thomson Reuters and Cable News Network. Numerous experiments were conducted to derive evidence of the effectiveness of knowledge graph embedding for classification tasks in stock prediction. A comparison of the average accuracy with which the same feature combinations were extracted over six stocks indicated that the proposed method achieves better performance than that exhibited by an approach that uses only stock data, a bag-of-words method, and convolutional neural network. Our work highlights the usefulness of knowledge graph in implementing business activities and helping practitioners and managers make business decisions.	187.9683420954951
626.	Deep learning has contributed to solving complex problems in science and engineering. This article provides the fundamental background required to understand and develop deep learning models for medical imaging applications. The authors review the main deep learning architectures such as multilayer perceptron, convolutional neural networks, autoencoders, recurrent neural networks, and generative adversarial neural networks. They also discuss the strategies for training deep learning models when the available datasets are imbalanced or of limited size and conclude with a discussion of the obstacles and challenges hindering the deployment of deep learning solutions in clinical settings.	187.96823741578618
627.	Modern information technology services largely depend on cloud infrastructures to provide their services. These cloud infrastructures are built on top of Datacenter Networks (DCNs) constructed with high-speed links, fast switching gear, and redundancy to offer better flexibility and resiliency. In this environment, network traffic includes long-lived (elephant) and short-lived (mice) flows with partitioned/aggregated traffic patterns. Although SDN-based approaches can efficiently allocate networking resources for such flows, the overhead due to network reconfiguration can be significant. With limited capacity of Ternary Content-Addressable Memory (TCAM) deployed in an OpenFlow enabled switch, it is crucial to determine which forwarding rules should remain in the flow table and which rules should be processed by the SDN controller in case of a table-miss on the SDN switch. This is needed in order to obtain the flow entries that satisfy the goal of reducing the long-term control plane overhead introduced between the controller and the switches. To achieve this goal, we propose a machine learning technique that utilizes two variations of Reinforcement Learning (RL) algorithms-the first of which is a traditional RL-based algorithm, while the other is deep reinforcement learning-based. Emulation results using the RL algorithm show around 60% improvement in reducing the long-term control plane overhead and around 14% improvement in the table-hit ratio compared to the Multiple Bloom Filters (MBF) method, given a fixed size flow table of 4KB.	187.96821081910693
628.	In recent years, big data became a hard challenge. Analyzing big data needs a lot of speed precision combination. In this article, we describe a deep learning-based method to deal with big data with a focus on precision and speed. In our case, the data are images that are the hardest type of data to manipulate because of their complex structure that needs a lot of computation power. Besides, we will solve a hard task on images, which is object detection and identification. Thus, every object in the image will be localized and classified according to the range of classes provided by the training data set. To solve this challenge, we propose an approach based on a deep convolutional neural network (CNN). Moreover, CNN is the most used deep learning model in computer vision tasks such as image classification and object recognition because of its power in self-features extraction and provides useful techniques in the prediction of decision-making. Our approach outperforms state-of-the-art models such as R-CNN, Fast R-CNN, Faster R-CNN, and YOLO (you only look once), with 77% of mean average precision on the Pascal_voc 2007 testing data set and a speed of 16.54 FPS using an Nvidia Geforce GTX 960 GPGPU.	187.96820914527333
629.	Existing stereoscopic 3D (S3D) salient object detection (SOD) networks typically employ a two-branch architecture, in which the RGB and depth channels are learned independently. Conventional methods based on conventional neural networks generally fuse the two branches by combining their deep representations at a later stage with only one path, which can be inefficient and insufficient for retaining a large amount of cross-modal data. In this study, we combine the RGB branch and depth branch to generate a third branch. The first branch is the embedded attention branch containing the attention mechanism, and we introduce the embedded attention module in this branch to give the allocation of available processing resources to the most informative components of an input signal. The second branch is the boundary refinement branch combined with the low-level information of RGB and depth images. Additionally, we propose a new module, called the detail correlation module, to ensure clear object boundaries and salient object refinement. The third branch is the global deep-view branch containing the global view module, which fuses high-level information and expands the sensor field. We also use three different loss functions to match our special SOD network. Extensive experiments demonstrate the effectiveness and robustness of the proposed architecture and show that it represents a significant improvement over other state-of-the-art SOD approaches. (C) 2020 Elsevier Inc. All rights reserved.	187.9682009894449
630.	The continuous increase in extraordinary textual sources on the web has facilitated the act of paraphrase. Its detection has become a challenge in different natural language processing applications (e.g., plagiarism detection, information retrieval and extraction, question answering, etc.). Different from western languages like English, few works have been addressed the problem of extrinsic paraphrase detection in Arabic language. In this context, we proposed a deep learning-based approach to indicate how original and suspect documents expressed the same meaning. Indeed, word2vec algorithm extracted the relevant features by predicting each word to its neighbors. Subsequently, averaging the obtained vectors was efficient for generating sentence vectors representations. Then, convolutional neural network was useful to capture more contextual information and compute the degree of semantic relatedness. Faced to the lack of resources publicly available, paraphrased corpus was developed using skip gram model. It had better performance in replacing an original word by its most similar one that had the same grammatical class from a vocabulary. Finally, the proposed system achieved good results enhancing an efficient contextual relationship detection between Arabic documents in terms of precision (85%) and recall (86.8%) than previous studies.	187.96819017314593
631.	Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio-temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.	187.96818875413538
632.	Recent years have witnessed a clear trend to develop deeper and longer tunnels to meet the growing needs of mining. Micro-seismic events location is vital for predicting and avoiding the traditional mine disasters induced by high stress concentration, such as rock burst, roof caving, water inrush and slope landslide. Deep learning has become a research hotspot within the field of artificial intelligence in recent years, which has achieved significant progresses and applications in the areas of image recognition, speech recognition, language processing and computer vision. The biggest difference between the deep learning and the traditional back propagation training method is that the deep learning can automatically and independently learn the characteristics of a large amount of data without human intervention. This paper uses Convolutional Neural Network (CNN) and deep learning techniques to develop a method for identifying the Time Delay of Arrival (TDOA) and subsequently the source location of micro-seismic events in underground mines. The power spectrum and phase spectrum of cross wavelet transform calculated from the recorded seismic waves due to micro-seismic events are used as inputs to CNN. The amplitude and phase information of the cross wavelet transform power spectrum are parameters that are used without manual manipulation to build the complex mapping to predict TDOA by deep learning network. Experimental data from the in-field blast tests and simulation tests show that the proposed approach can well identify TDOA and hence detect the event source locations of the field blasting tests. It is demonstrated that the proposed approach with the CNN and deep learning techniques gives more accurate micro seismic source identifications with the recorded noisy waveforms from in-situ blast tests, as compared to several typical existing methods.	187.9681787872049
633.	Convolutional neural networks (CNNs) have recently emerged as a popular topic for machine learning in various academic and industrial fields. It is often an important problem to obtain a dataset with an appropriate size for CNN training. However, the lack of training data in the case of remote image research leads to poor performance due to the overfitting problem. In addition, the back-propagation algorithm used in CNN training is usually very slow and thus requires tuning different hyper-parameters. In order to overcome these drawbacks, a new approach fully based on machine learning algorithm to learn useful CNN features from Alexnet, VGG16, VGG19, GoogleNet, ResNet and SqueezeNet CNN architectures is proposed in the present study. This method performs a fast and accurate classification suitable for recognition systems. Alexnet, VGG16, VGG19, GoogleNet, ResNet and SqueezeNet pretrained architectures were used as feature extractors. The proposed method obtains features from the last fully connected layers of each architecture and applies the ReliefF feature selection algorithm to obtain efficient features. Then, selected features are given to the support vector machine classifier with the CNN-learned features instead of the FC layers of CNN to obtain excellent results. The effectiveness of the proposed method was tested on the UC-Merced dataset. Experimental results demonstrate that the proposed classification method achieved an accuracy rate of 98.76% and 99.29% in 50% and 80% training experiment, respectively.	187.96814038873427
634.	Convolutional neural networks applied to video streams often suffer from short-lived misclassifications or false alarms from clutter and noise. We introduce a novel network training method based on the Siamese Networks technique that mitigates false alarms in an Hourglass CNN that segments out quadcopters in a live video stream. To demonstrate this method in a real-world application in real-time, we implement it as part of a quadcopter tracker for vision-based formation control. Quadcopter drone formation control is an important capability for fields like area surveillance, search and rescue, agriculture, and reconnaissance. Of particular interest is formation control in environments where wireless communications and/or GPS may be either denied or not sufficiently accurate for the desired application. Using vision to guide the quadcopters addresses these situations, but computer vision algorithms are often computationally expensive and suffer from high false detection rates. Our novel Siamese networks-based clutter mitigation technique is a good way to mitigate this clutter without added computational complexity at run-time. We run our real-time implementation on an ODROID XU4 with a standard webcam mounted to a quadcopter drone. Flight tests in a motion capture volume demonstrate successful formation control with two quadcopters in a leader-follower setup.	187.9680358887396
635.	Mobile edge computing (MEC) emerges recently as a promising solution to relieve resource-limited mobile devices from computation-intensive tasks, which enables devices to offload workloads to nearby MEC servers and improve the quality of computation experience. In this paper, an MEC enabled multi-user multi-input multi-output (MIMO) system with stochastic wireless channels and task arrivals is considered. In order to minimize long-term average computation cost in terms of power consumption and buffering delay at each user, a deep reinforcement learning (DRL)-based dynamic computation offloading strategy is investigated to build a scalable system with limited feedback. Specifically, a continuous action space-based DRL approach named deep deterministic policy gradient (DDPG) is adopted to learn decentralized computation offloading policies at all users respectively, where local execution and task offloading powers will be adaptively allocated according to each user's local observation. Numerical results demonstrate that the proposed DDPG-based strategy can help each user learn an efficient dynamic offloading policy and also verify the superiority of its continuous power allocation capability to policies learned by conventional discrete action space-based reinforcement learning approaches like deep Q-network (DQN) as well as some other greedy strategies with reduced computation cost. Besides, power-delay tradeoff for computation offloading is also analyzed for both the DDPG-based and DQN-based strategies.	187.96802820038278
636.	As object recognition technology has developed recently, various technologies have been applied to autonomous vehicles, robots, and industrial facilities. However, the benefits of these technologies are not reaching the visually impaired, who need it the most. In this paper, we proposed an object detection system for the blind using deep learning technologies. We use voice recognition technology in order to know what objects a blind person wants, and then to find the objects via object recognition. Furthermore, a voice guidance technique is used to inform sight-impaired persons as to the location of objects. The object recognition deep learning model utilizes the Single Shot Multibox Detector (SSD) neural network architecture, and voice recognition is designed through speech-to-text (STT) technology. In addition, a voice announcement is synthesized using text-to-speech (TTS) to make it easier for the blind to get information about objects. The control system is based on the Arduino microprocessor. As a result, we implement an efficient object-detection system that helps the blind find objects in a specific space without help from others, and the system is analyzed through experiments to verify performance.	187.9679670136763
637.	Screening lung cancer by computed tomography (CT) has shown great benefit for early cancer detection, but requires a great effort to eliminate the associated false detection, where the biopsy option costs most among other eliminating options. Therefore it is significant to study lung cancer through image analysis to decrease biopsy tests. However, it is extremely difficult to get enough data with biopsy reports from hospital for machine learning study in a short period. So this study aims to explore machine transfer learning innovations to predict unnecessary biopsies from a very small dataset of pathologically proven nodule CT images. To overcome the problem of big data requirement of the CNN architecture (such as VGG used in this study), we used the parameters trained by ImageNet as the initial features. Then we put part of the labeled pulmonary nodule dataset with the ground truth into the training dataset to fine-tune the parameters of different architectures. Fifty repetitions of the cross validation method of two-thirds training and one-third testing are used to measure the efficiency of different deep transfer learning architectures. Through the classification results shown in ROC curves and AUC values, we find that deep features transferred from natural images can enhance 0.1663 more than the traditional machine learning method based on texture features extracted from gray images directly. And our improved VGG architecture with 8 layers for achieving less-abstractive features can obtain 0.1081 better performance than the more-abstractive ones on the recognition of malignant nodules.	187.967949339465
638.	Sentiment analysis, a hot research topic, presents new challenges for understanding users' opinions and judgments expressed online. They aim to classify the subjective texts by assigning them a polarity label. In this paper, we introduce a novel machine learning framework using auto-encoders network to predict the sentiment polarity label at the word level and the sentence level. Inspired by the dimensionality reduction and the feature extraction capabilities of the auto-encoders, we propose a new model for distributed word vector representation PMI-SA using as input pointwise-mutual-information PMI word vectors. The resulted continuous word vectors are combined to represent a sentence. An unsupervised sentence embedding method, called Contextual Recursive Auto-Encoders CoRAE, is also developed for learning sentence representation. Indeed, CoRAE follows the basic idea of the recursive auto-encoders to deeply compose the vectors of words constituting the sentence, but without relying on any syntactic parse tree. The CoRAE model consists in combining recursively each word with its context words (neighbors' words: previous and next) by considering the word order. A support vector machine classifier with fine-tuning technique is also used to show that our deep compositional representation model CoRAE improves significantly the accuracy of sentiment analysis task. Experimental results demonstrate that CoRAE remarkably outperforms several competitive baseline methods on two databases, namely, Sanders twitter corpus and Facebook comments corpus. The CoRAE model achieves an efficiency of 83.28% with the Facebook dataset and 97.57% with the Sanders dataset.	187.96793961593605
639.	We present a novel method to explicitly incorporate topological prior knowledge into deep learning based segmentation, which is, to our knowledge, the first work to do so. Our method uses the concept of persistent homology, a tool from topological data analysis, to capture high-level topological characteristics of segmentation results in a way which is differentiable with respect to the pixelwise probability of being assigned to a given class. The topological prior knowledge consists of the sequence of desired Betti numbers of the segmentation. As a proof-of-concept we demonstrate our approach by applying it to the problem of left-ventricle segmentation of cardiac MR images of subjects from the UK Biobank dataset, where we show that it improves segmentation performance in terms of topological correctness without sacrificing pixelwise accuracy.	187.9678507116031
640.	Pneumonia is a global disease that causes high children mortality. The situation has even been worsening by the outbreak of the new coronavirus named COVID-19, which has killed more than 983,907 so far. People infected by the virus would show symptoms like fever and coughing as well as pneumonia as the infection progresses. Timely detection is a public consensus achieved that would benefit possible treatments and therefore contain the spread of COVID-19. X-ray, an expedient imaging technique, has been widely used for the detection of pneumonia caused by COVID-19 and some other virus. To facilitate the process of diagnosis of pneumonia, we developed a deep learning framework for a binary classification task that classifies chest X-ray images into normal and pneumonia based on our proposed CGNet. In our CGNet, there are three components including feature extraction, graph-based feature reconstruction and classification. We first use the transfer learning technique to train the state-of-the-art convolutional neural networks (CNNs) for binary classification while the trained CNNs are used to produce features for the following two components. Then, by deploying graph-based feature reconstruction, we, therefore, combine features through the graph to reconstruct features. Finally, a shallow neural network named GNet, a one layer graph neural network, which takes the combined features as the input, classifies chest X-ray images into normal and pneumonia. Our model achieved the best accuracy at 0.9872, sensitivity at 1 and specificity at 0.9795 on a public pneumonia dataset that includes 5,856 chest X-ray images. To evaluate the performance of our proposed method on detection of pneumonia caused by COVID-19, we also tested the proposed method on a public COVID-19 CT dataset, where we achieved the highest performance at the accuracy of 0.99, specificity at 1 and sensitivity at 0.98, respectively.	187.9677953820173
641.	Speech recognition is one of the key topics in artificial intelligence, as it is one of the most common forms of communication in humans. Researchers have developed many speech-controlled prosthetic hands in the past decades, utilizing conventional speech recognition systems that use a combination of neural network and hidden Markov model. Recent advancements in general-purpose graphics processing units (GPGPUs) enable intelligent devices to run deep neural networks in real-time. Thus, state-of-the-art speech recognition systems have rapidly shifted from the paradigm of composite subsystems optimization to the paradigm of end-to-end optimization. However, a low-power embedded GPGPU cannot run these speech recognition systems in real-time. In this paper, we show the development of deep convolutional neural networks (CNN) for speech control of prosthetic hands that run in real-time on a NVIDIA Jetson TX2 developer kit. First, the device captures and converts speech into 2D features (like spectrogram). The CNN receives the 2D features and classifies the hand gestures. Finally, the hand gesture classes are sent to the prosthetic hand motion control system. The whole system is written in Python with Keras, a deep learning library that has a TensorFlow backend. Our experiments on the CNN demonstrate the 91% accuracy and 2ms running time of hand gestures (text output) from speech commands, which can be used to control the prosthetic hands in real-time.	187.96765314512794
642.	Measuring the productivity of an agent in a call center domain is a challenging task. Subjective measures are commonly used for evaluation in the current systems. In this paper, we propose an objective framework for modeling agent productivity for real estate call centers based on speech signal processing. The problem is formulated as a binary classification task using deep learning methods. We explore several designs for the classifier based on convolutional neural networks (CNNs), long-short-term memory networks (LSTMs), and an attention layer. The corpus consists of seven hours collected and annotated from three different call centers. The result shows that the speech-based approach can lead to significant improvements (1.57% absolute improvements) over a robust text baseline system.	187.96747701023065
643.	Image steganalysis is a technique for detecting data hidden in images. Recent research has shown the powerful capabilities of using convolutional neural networks (CNN) for image steganalysis. However, due to the particularity of steganographic signals, there are still few reliable CNN-based methods for applying steganalysis to images of arbitrary size. In this paper, we address this issue by exploring the possibility of exploiting a network for steganalyzing images of varying sizes without retraining its parameters. On the assumption that natural image noise is similar between different image sub-regions, we propose an end-to-end, deep learning, novel solution for distinguishing steganography images from normal images that provides satisfying performance. The proposed network first takes the image as the input, then identifies the relationships between the noise of different image sub-regions, and, finally, outputs the resulting classification based upon them. Our algorithm adopts a Siamese, CNN-based architecture, which consists of two symmetrical subnets with shared parameters, and contains three phases: preprocessing, feature extraction, and fusion/classification. To validate the network, we generated datasets composed of steganography images with multiple sizes and their corresponding normal images sourced from BOSSbase 1.01 and ALASKA #2. Experimental results produced by the data generated by various methods show that our proposed network is well-generalized and robust.	187.96719003541142
644.	Educational Data Mining (EDM) aims to produce new knowledge from educational settings to support educators, learners and other stakeholders. EDM aims to facilitate the understanding of the educational context by utilizing different methods of statistics and machine learning. Like wise to the current trends in data mining, also EDM approaches have shifted from black box tools and algorithms to more open-ended tools and algorithms where the EDM end-users can adjust multiple parameters, view visualizations, and even adjust the predictive models. Multiple studies have shown that the EDM end-users benefit from the white box approaches and tools. We introduce the concept of Augmented Intelligence (AUI) method in EDM. AUI method is applied in an iterative process where a white box machine learning algorithm generates a predictive model, which is adjustable by the EDM end-user. The adjustable predictive model affects to the perception of the end-user and the adjusting affects to the output of the predictive model. When applied in cycles, the AUI method generates new knowledge from the educational context. To study AUI method, a potential EDM end-user generated multiple adjustable decision tree models and we observed the evolution of the models. The study indicates that, over time, the models generalize better and the AUI method helps to avoid the issue of overfitting. Moreover, the study indicates that the cyclic nature of the AUI method facilitates deeper knowledge generation from the dataset, if the context is known by the end-user.	187.9671588500484
645.	Trajectory prediction plays an important role in supporting many advanced applications such as location-based services and advanced intelligent traffic managements. Most existing trajectory prediction methods employed fixed spatial division and focused on human closeness movement patterns. However, these methods could lead to a sharp boundary limitation and ignore the periodic characteristics of human mobility. This paper proposes a novel trajectory prediction method based on long short-term memory network (LSTM) called the trajectory predictor with fuzzy-long short-term memory network (TrjPre-FLSTM). First, we introduce a new fuzzy trajectory concept and extend the LSTM to a fuzzy-LSTM to overcome the sharp boundary limitation. Second, we explicitly incorporate the periodic movement patterns of moving objects in the trajectory prediction. Using a real-world mobile phone dataset, we evaluate the performance of TrjPre-FLSTM with two latest competitors. The case study results indicate that the proposed method outperforms the comparative methods in terms of the prediction accuracy.	187.9671510648431
646.	COVID-19 is a disease that causes symptoms in the lungs and causes deaths around the world. Studies are ongoing for the diagnosis and treatment of this disease, which is defined as a pandemic. Early diagnosis of this disease is important for human life. This process is progressing rapidly with diagnostic studies based on deep learning. Therefore, to contribute to this field, a deep learning-based approach that can be used for early diagnosis of the disease is proposed in our study. In this approach, a data set consisting of 3 classes of COVID19, normal and pneumonia lung X-ray images was created, with each class containing 364 images. Pre-processing was performed using the image contrast enhancement algorithm on the prepared data set and a new data set was obtained. Feature extraction was completed from this data set with deep learning models such as AlexNet, VGG19, GoogleNet, and ResNet. For the selection of the best potential features, two metaheuristic algorithms of binary particle swarm optimization and binary gray wolf optimization were used. After combining the features obtained in the feature selection of the enhancement data set, they were classified using SVM. The overall accuracy of the proposed approach was obtained as 99.38%. The results obtained by verification with two different metaheuristic algorithms proved that the approach we propose can help experts during COVID-19 diagnostic studies.	187.96713557108106
647.	Manually re-drawing an image in a certain artistic style takes a professional artist a long time. Doing this for a video sequence single-handedly is beyond imagination. We present two computational approaches that transfer the style from one image (for example, a painting) to a whole video sequence. In our first approach, we adapt to videos the original image style transfer technique by Gatys et al. based on energy minimization. We introduce new ways of initialization and new loss functions to generate consistent and stable stylized video sequences even in cases with large motion and strong occlusion. Our second approach formulates video stylization as a learning problem. We propose a deep network architecture and training procedures that allow us to stylize arbitrary-length videos in a consistent and stable way, and nearly in real time. We show that the proposed methods clearly outperform simpler baselines both qualitatively and quantitatively. Finally, we propose a way to adapt these approaches also to 360 images and videos as they emerge with recent virtual reality hardware.	187.96710033843013
648.	Object detection and recognition is one of the important problems in many remote sensing applications such as monitoring, security, rescue mission and other data analysis tasks. So a large number of approaches and techniques have been developed to improve the quality of object detection. Recently, deep learning methods have made significant progress in detecting objects. But when dealing with objects having small size in the image (which are the often case in monitoring or rescue mission), the quality of detection noticeably decreases. To study the performance and the limits of deep learning abilities for object detection in remote sensing imagery with degrading object resolution in the image, a special dataset of aerial images containing objects of interest (human, car) at different resolution has been collected. The dataset consists of images acquired at different distances to the objects of interest, providing representative subsets of object images of various scale. Two state-of-the-art object detection convolutional neural networks (Faster-RCNN and SSD) was evaluated on the collected dataset. The aim of the study was to find out how the object size in the image influences on the detection performance and to estimate the value of object image size at which the performance drops significantly. Also the approaches for improving the small size object recognition were developed and evaluated. First approach uses multimodal image fusion, the second one applies deep learning to increase the resolution of small objects in the image. The performed tests have proved that the developed approaches allow to improve the quality of object recognition when dealing with low resolution object images.	187.96704376733015
649.	Existing deep trackers can be roughly divided into either matching-based or classification-based methods. The formers are fast but not very robust; while the latter ones introduce more discriminative information but often very slow. In this work, we present a novel real-time robust tracking method to take full use of the benefits from both kinds of networks. First, we propose a matching-classification network switching (MCS) framework to integrate the matching, classification, verification networks and conduct dynamic switching among them. Second, to speed up online update, we devlop a meta learning method as a critical component in our classification network. The meta classifier is trained offline to obtain general discriminative ability and updated online to the current frame just through one iteration. Extensive experiments are conducted on two popular benchmark datasets. Both qualitative and quantitative evaluations show that our tracker performs favorably against other state-of-the-art trackers with real-time performance. (C) 2020 Published by Elsevier Ltd.	187.96703872002308
650.	This paper presents the combination of deep and shallow features (multi-view features) using the proposed metric learning (SILD+WCCN/LR) approach for kinship verification. Our approach based on an automatic and more efficient two-step learning into deep/shallow information. First, five layers for deep features and five shallow features (i.e. texture and shape), representing more precisely facial features involved in kinship relations (Father-Son, Father-Daughter, Mother-Son, and Mother-Daughter) are used to train the proposed Side-Information based Linear Discriminant Analysis integrating Within Class Covariance Normalization (SILD+WCCN) method. Then, each of the features projected through the discriminative subspace of the proposed SILD+WCCN metric learning method. Finally, a Logistic Regression (LR) method is used to fuse the six scores of the projected features. To show the effectiveness of our SILD+WCNN method, we do some experiments on LFW database. In term of evaluation, the proposed automatic Facial Kinship Verification (FKV) is compared with existing ones to show its effectiveness, using two challenging kinship databases. The experimental results showed the superiority of our FKV against existing ones and reached verification rates of 86.20% and 88.59% for bi-subject matching on the KinFaceW-II and TSKinFace databases, respectively. Verification rates for tri-subject matching of 90.94% and 91.23% on the available TSKinFace database for Father-Mother-Son and Father-Mother-Daughter, respectively.	187.96698444016022
651.	Vision technologies are used in both industrial and smart city applications in order to provide advanced value products due to embedded self-monitoring and assessment services. In addition, for the full utilization of the obtained data, deep learning is now suggested for use. To this end, the current work presents the implementation of image recognition techniques alongside the original the quality assessment of a Parabolic Trough Collector (PTC) reflector surface to locate and identify surface irregularities by classifying images as either acceptable or non-acceptable. The method consists of a three-step solution that promotes an affordable implementation in a relatively small time period. More specifically, a 3D Computer Aided Design (CAD) of the PTC was used for the pre-training of neural networks, while an aluminum reflector surface was used to verify algorithm performance. The results are promising, as this method proved applicable in cases where the actual part was manufactured in small batches or under the concept of customized manufacturing. Consequently, the algorithm is capable of being trained with a limited number of data.	187.9669555387291
652.	Online donation-based crowdfunding has brought new life to charity by soliciting small monetary contributions from crowd donors to help others in trouble or with dreams. However, a crucial issue for crowdfunding platforms as well as traditional charities is the problem of high donor attrition, i.e., many donors donate only once or very few times within a rather short lifecycle and then leave. Thus, it is an urgent task to analyze the factors of and then further predict the donors behaviors. Especially, we focus on two types of behavioral events, e.g., donation recurrence (whether one donor will make donations at some time slices in the future) and donor retention (whether she will remain on the crowdfunding platform until a future time). However, this problem has not been well explored due to many domain and technical challenges, such as the heterogeneous influence, the relevance of the two types of events, and the censoring phenomenon of retention records. In this paper, we present a focused study on donation recurrence and donor retention with the help of large-scale behavioral data collected from crowdfunding. Specifically, we propose a Joint Deep Survival model, i.e., JDS, which can integrate heterogeneous features, e.g., donor motives, projects recently donated to, social contacts, to jointly model the donation recurrence and donor retention since these two types of behavioral events are highly relevant. In addition, we model the censoring phenomenon and dependence relations of different behaviors from the survival analysis view by designing multiple innovative constraints and incorporating them into the objective functions. Finally, we conduct extensive analysis and validation experiments with large-scale data collected from Kiva.org. The experimental results clearly demonstrate the effectiveness of our proposed models for analyzing and predicting the donation recurrence and donor retention in crowdfunding.	187.96695053495733
653.	The meter readingsystem field has been researched from conventional methods centered on image processing technology to techniques based on learning methods such as machine learning or deep learning. The biggest problem for meter reading systems based on computer vision is difficulty in recognizing the various kinds of meters. In fact, there are more than five major manufacturers for the meters installed in Korea. There are different meter reading areas, ID regions, and number formats by version. Because of these problems, most of the meter reading is still done hands-on. In this paper, we present an automatic meterreading system that can work simply and efficiently, compared to existing meter reading systems that need a skilled worker. Our meter reading system consists of three parts: i) detection of meter-reading and ID regions using You Only Look Once (YOLO), ii) digit segmentation for recognition, and iii) convolutional neural network (CNN)-based digit recognition. It is possible to robustly detect and recognize various meter types by using the method presented here. Therefore, it can provide an environment where gas meter checkers can work efficiently without inconvenient procedures.	187.96692890956695
654.	The powerful representation capacity of deep learning has made it inevitable for the underwater image enhancement community to employ its potential. The exploration of deep underwater image enhancement networks is increasing over time; hence, a comprehensive survey is the need of the hour. In this paper, our main aim is two-fold, (1): to provide a comprehensive and in-depth survey of the deep learning-based underwater image enhancement, which covers various perspectives ranging from algorithms to open issues, and (2): to conduct a qualitative and quantitative comparison of the deep algorithms on diverse datasets to serve as a benchmark, which has been barely explored before. We first introduce the underwater image formation models, which are the base of training data synthesis and design of deep networks, and also helpful for understanding the process of underwater image degradation. Then, we review deep underwater image enhancement algorithms, and a glimpse of some of the aspects of the current networks is presented, including architecture, parameters, training data, loss function, and training configurations. We also summarize the evaluation metrics and underwater image datasets. Following that, a systematically experimental comparison is carried out to analyze the robustness and effectiveness of deep algorithms. Meanwhile, we point out the shortcomings of current benchmark datasets and evaluation metrics. Finally, we discuss several unsolved open issues and suggest possible research directions. We hope that all efforts done in this paper might serve as a comprehensive reference for future research and call for the development of deep learning-based underwater image enhancement.	187.96686894679155
655.	Deep learning is currently the mainstream method of object detection. Faster region-based convolutional neural network (Faster R-CNN) has a pivotal position in deep learning. It has impressive detection effects in ordinary scenes. However, under special conditions, there can still be unsatisfactory detection performance, such as the object having problems like occlusion, deformation, or small size. This paper proposes a novel and improved algorithm based on the Faster R-CNN framework combined with the Faster R-CNN algorithm with skip pooling and fusion of contextual information. This algorithm can improve the detection performance under special conditions on the basis of Faster R-CNN. The improvement mainly has three parts: The first part adds a context information feature extraction model after the conv5_3 of the convolutional layer; the second part adds skip pooling so that the former can fully obtain the contextual information of the object, especially for situations where the object is occluded and deformed; and the third part replaces the region proposal network (RPN) with a more efficient guided anchor RPN (GA-RPN), which can maintain the recall rate while improving the detection performance. The latter can obtain more detailed information from different feature layers of the deep neural network algorithm, and is especially aimed at scenes with small objects. Compared with Faster R-CNN, you only look once series (such as: YOLOv3), single shot detector (such as: SSD512), and other object detection algorithms, the algorithm proposed in this paper has an average improvement of 6.857% on the mean average precision (mAP) evaluation index while maintaining a certain recall rate. This strongly proves that the proposed method has higher detection rate and detection efficiency in this case.	187.96683821727282
656.	With the recently explosive growth of deep learning, automatic modulation recognition has undergone rapid development. Most of the newly proposed methods are dependent on large numbers of labeled samples. We are committed to using fewer labeled samples to perform automatic modulation recognition in the cognitive radio domain. Here, a semi-supervised learning method based on adversarial training is proposed which is called signal classifier generative adversarial network. Most of the prior methods based on this technology involve computer vision applications. However, we improve the existing network structure of a generative adversarial network by adding the encoder network and a signal spatial transform module, allowing our framework to address radio signal processing tasks more efficiently. These two technical improvements effectively avoid nonconvergence and mode collapse problems caused by the complexity of the radio signals. The results of simulations show that compared with well-known deep learning methods, our method improves the classification accuracy on a synthetic radio frequency dataset by 0.1% to 12%. In addition, we verify the advantages of our method in a semi-supervised scenario and obtain a significant increase in accuracy compared with traditional semi-supervised learning methods.	187.9667172562357
657.	Automatically generating descriptive captions for images is a well-researched area in computer vision. However, existing evaluation approaches focus on measuring the similarity between two sentences disregarding fine-grained semantics of the captions. In our setting of images depicting persons interacting with branded products, the subject, predicate, object and the name of the branded product are important evaluation criteria of the generated captions. Generating image captions with these constraints is a new challenge, which we tackle in this work. By simultaneously predicting integer-valued ratings that describe attributes of the human-product interaction, we optimize a deep neural network architecture in a multi-task learning setting, which considerably improves the caption quality. Furthermore, we introduce a novel metric that allows us to assess whether the generated captions meet our requirements (i.e., subject, predicate, object, and product name) and describe a series of experiments on caption quality and how to address annotator disagreements for the image ratings with an approach called soft targets. We also show that our novel clause-focused metrics are also applicable to other image captioning datasets, such as the popular MSCOCO dataset.	187.96663184984223
658.	Object detection and semantic segmentation are two main themes in object retrieval from high-resolution remote sensing images, which have recently achieved remarkable performance by surfing the wave of deep learning and, more notably, convolutional neural networks. In this paper, we are interested in a novel, more challenging problem of vehicle instance segmentation, which entails identifying, at a pixel level, where the vehicles appear as well as associating each pixel with a physical instance of a vehicle. In contrast, vehicle detection and semantic segmentation each only concern one of the two. We propose to tackle this problem with a semantic boundary-aware multitask learning network. More specifically, we utilize the philosophy of residual learning to construct a fully convolutional network that is capable of harnessing multilevel contextual feature representations learned from different residual blocks. We theoretically analyze and discuss why residual networks can produce better probability maps for pixelwise segmentation tasks. Then, based on this network architecture, we propose a unified multitask learning network that can simultaneously learn two complementary tasks, namely, segmenting vehicle regions and detecting semantic boundaries. The latter subproblem is helpful for differentiating "touching" vehicles that are usually not correctly separated into instances. Currently, data sets with a pixelwise annotation for vehicle extraction are the ISPRS data set and the IEEE GRSS DFC2015 data set over Zee-brugge, which specializes in a semantic segmentation. Therefore, we built a new, more challenging data set for vehicle instance segmentation, called the Busy Parking Lot Unmanned Aerial Vehicle Video data set, and we make our data set available at http://www.sipeo.bgu.tum.de/downloads so that it can be used to benchmark future vehicle instance segmentation algorithms.	187.96657169719174
659.	In general, the features of fake news are almost the same as those of real news, so it is not easy to identify them. In this paper, we propose a fake news detection system using a deep learning model. First, news articles are preprocessed and analyzed based on different training models. Then, an ensemble learning model combining four different models called embedding LSTM, depth LSTM, LIWC CNN, and N-gram CNN is proposed for fake news detection. Besides, to achieve higher accuracy in fake news detection, the optimized weights of the ensemble learning model are determined using the Self-Adaptive Harmony Search (SAHS) algorithm. In the experiments, we verify that the proposed model is superior to the state-of-the-art methods, with the highest accuracy of 99.4%. Furthermore, we also investigate the cross-domain intractability issue and achieve the highest accuracy of 72.3%. Finally, we believe there is still room for improving the ensemble learning model in addressing the cross-domain intractability issue. (C) 2020 Elsevier Ltd. All rights reserved.	187.9665423615258
660.	OBJECTIVE: The utilization of hyperspectral imaging (HSI) in real-time tumor segmentation during a surgery have recently received much attention, but it remains a very challenging task. METHODS: In this work, we propose semantic segmentation methods and compare them with other relevant deep learning algorithms for tongue tumor segmentation. To the best of our knowledge, this is the first work using deep learning semantic segmentation for tumor detection in HSI data using channel selection and accounting for more spatial tissue context and global comparison between the prediction map and the annotation per sample. RESULTS AND CONCLUSION: On a clinical data set with tongue squamous cell carcinoma, our best method obtains very strong results of average dice coefficient and area under the ROC-curve of 0.891 +/- 0.053 and 0.924 +/- 0.036, respectively on the original spatial image size. The results show that a very good performance can be achieved even with a limited amount of data. We demonstrate that important information regarding tumor decision is encoded in various channels, but some channel selection and filtering is beneficial over the full spectra. Moreover, we use both visual (VIS) and near-infrared (NIR) spectrum, rather than commonly used only VIS spectrum; although VIS spectrum is generally of higher significance, we demonstrate NIR spectrum is crucial for tumor capturing in some cases. SIGNIFICANCE: The HSI technology augmented with accurate deep learning algorithms has a huge potential to be a promising alternative to digital pathology or a doctors' supportive tool in real-time surgeries.	187.96643608550082
661.	Face attribute estimation has many potential applications in video surveillance, face retrieval, and social media. While a number of methods have been proposed for face attribute estimation, most of them did not explicitly consider the attribute correlation and heterogeneity (e.g., ordinal versus nominal and holistic versus local) during feature representation learning. In this paper, we present a Deep Multi-Task Learning (DMTL) approach to jointly estimate multiple heterogeneous attributes from a single face image. In DMTL, we tackle attribute correlation and heterogeneity with convolutional neural networks (CNNs) consisting of shared feature learning for all the attributes, and category-specific feature learning for heterogeneous attributes. We also introduce an unconstrained face database (LFW+), an extension of public-domain LFW, with heterogeneous demographic attributes (age, gender, and race) obtained via crowdsourcing. Experimental results on benchmarks with multiple face attributes (MORPH II, LFW+, CelebA, LFWA, and FotW) show that the proposed approach has superior performance compared to state of the art. Finally, evaluations on a public-domain face database (LAP) with a single attribute show that the proposed approach has excellent generalization ability.	187.96638291451382
662.	This paper presents an automatic classification segmentation tool for helping screening COVID-19 pneumonia using chest CT imaging. The segmented lesions can help to assess the severity of pneumonia and follow-up the patients. In this work, we propose a new multitask deep learning model to jointly identify COVID-19 patient and segment COVID-19 lesion from chest CT images. Three learning tasks: segmentation, classification and reconstruction are jointly performed with different datasets. Our motivation is on the one hand to leverage useful information contained in multiple related tasks to improve both segmentation and classification performances, and on the other hand to deal with the problems of small data because each task can have a relatively small dataset. Our architecture is composed of a common encoder for disentangled feature representation with three tasks, and two decoders and a multi-layer perceptron for reconstruction, segmentation and classification respectively. The proposed model is evaluated and compared with other image segmentation techniques using a dataset of 1369 patients including 449 patients with COVID-19, 425 normal ones, 98 with lung cancer and 397 of different kinds of pathology. The obtained results show very encouraging performance of our method with a dice coefficient higher than 0.88 for the segmentation and an area under the ROC curve higher than 97% for the classification.	187.96634185598987
663.	Axial Lumbar disc herniation recognition is a difficult task to achieve, due to many challenges such as complex background, noise, blurry image. Lumbar discs are small joints that lie between each two vertebrae (L1-L2, L2-L3, L3-L4, L4-L5 and L5-S1). The segmentation and localization of the different discs are the most important tasks in Computer aided diagnosing of herniation. During the last five years, deep learning based methods have set new standards for many computer vision and pattern recognition research. In this work, our objective is to develop an automatic system based on deep convolutional neural network. This Network processes the input MRI (Magnetic Resonance Imaging) in multiple scales of context and then merges the high-level features to enhance the capability of the network to detect discs from lumbar spine. In this study, we are particularly interested in convolutional neural networks (CNN); it was characterized by a topology similar to a visual cortex of mammals. In fact, these kind of techniques has been applied successfully in many classification problems. In order to recognize herniated lumbar disc in Magnetic Resonance Imaging (MRI), we have chosen to use Convolutional neural networks based on VGG16 architecture. Experiments were carried on our own dataset from Sahloul University Hospital of Sousse. The accuracy achieved of the trained model was 94% which represents a high-performance results by providing state of the art. Our system is very efficient and effective for detecting and diagnosing herniated lumbar disc. Therefore, The contribution of this study includes in: Firstly, the using of the U-net deep neural network architecture to localize and to detail the location of the herniation. Secondly, the using of the axial view MRI in order to locate exactly the pathological and the normal intervertebral discs.The main objective of this paper is to help radiologists in the diagnosing and treating lumbar herniated disc disease.	187.96625532842359
664.	Seismic prediction has been a huge challenge because of the great uncertainties contained in the seismic data. Deep learning (DL) has been successfully applied in many fields and brought revolutionary changes, such as computer vision and natural language processing. The traditional artificial neural networks have been studied to improve the accuracy and resolution of seismic prediction for years, but not DL. In this paper, we develop a new architecture for seismic reservoir characterization based on the DL technique. We apply the convolutional neural network (CNN), which is a DL framework, to predict lithology and have achieved better results compared with traditional methods. We also propose to use continuous wavelet transforms (CWTs) to get a time-frequency spectrum for neural networks. CWTs help to make full use of the frequency content of the post-stack seismic data. According to the difference in the convolution layers and the organization of the input data, we propose four DL architectures for seismic lithology prediction, namely the deep neural networks (DNNs), the CNNs, the CWT-DNNs and the CWT-CNNs. All of these four architectures are applied in the case study. The final results on blind wells, profile and horizontal slice show that CWT-CNN models have the best performance on post-stack seismic lithology prediction. CWT maps contain more information about thinner layers and convolution layers are better at feature extraction from CWT maps. The CWT-CNN model has higher accuracy and resolution, especially on medium and thin layer prediction.	187.9661239763039
665.	Identifying the authenticity and processing history of an image is an important task in multimedia forensics. By analyzing traces left by different image manipulations, researchers have been able to develop several algorithms capable of detecting targeted editing operations. While this approach has led to the development of several successful forensic algorithms, an important problem remains: creating forensic detectors for different image manipulations is a difficult and time consuming process. Furthermore, forensic analysts need general purpose forensic algorithms capable of detecting multiple different image manipulations. In this paper, we address both of these problems by proposing a new general purpose forensic approach using convolutional neural networks (CNNs). While CNNs are capable of learning classification features directly from data, in their existing form they tend to learn features representative of an image's content. To overcome this issue, we have developed a new type of CNN layer, called a constrained convolutional layer, that is able to jointly suppress an image's content and adaptively learn manipulation detection features. Through a series of experiments, we show that our proposed constrained CNN is able to learn manipulation detection features directly from data. Our experimental results demonstrate that our CNN can detect multiple different editing operations with up to 99.97% accuracy and outperform the existing state-of-the-art general purpose manipulation detector. Furthermore, our constrained CNN can still accurately detect image manipulations in realistic scenarios where there is a source camera model mismatch between the training and testing data.	187.96612216835993
666.	In recent years, the application of deep learning based on deep convolutional neural networks has gained great success in face detection. However, one of the remaining open challenges is the detection of small-scaled faces. The depth of the convolutional network can cause the projected feature map for small faces to be quickly shrunk, and most detection approaches with scale invariant can hardly handle less than 15 x 15 pixel faces. To solve this problem, we propose a different scales face detector (DSFD) based on Faster R-CNN. The new network can improve the precision of face detection while performing as real-time a Faster R-CNN. First, an efficient multitask region proposal network (RPN), combined with boosting face detection, is developed to obtain the human face ROI. Setting the ROI as a constraint, an anchor is inhomogeneously produced on the top feature map by the multitask RPN. A human face proposal is extracted through the anchor combined with facial landmarks. Then, a parallel-type Fast R-CNN network is proposed based on the proposal scale. According to the different percentages they cover on the images, the proposals are assigned to three corresponding Fast R-CNN networks. The three networks are separated through the proposal scales and differ from each other in the weight of feature map concatenation. A variety of strategies is introduced in our face detection network, including multitask learning, feature pyramid, and feature concatenation. Compared to state-of-the-art face detection methods such as UnitBox, HyperFace, FastCNN, the proposed DSFD method achieves promising performance on popular benchmarks including FDDB, AFW, PASCAL faces, and WIDER FACE.	187.96608925351137
667.	Human action recognition technology has received increasing interest recently. The technology is very useful in sports video analysis. Most of the action recognition methods in sports mainly focus on recog-nizing which sport is being performed. However, recognizing of the specific action in videos is important for the analysis of some sports video such as tennis matches. Hence, in this paper, we proposed a deep historical long short-term memory network for video-based tennis action recognition and general action recognition. First, the spatial representations are extracted from each frame using a pre-trained convolu-tional neural network (CNN). To describe the temporal information, a stacked multi-layer long short-term memory network (LSTM) was used. The historical information of the past frames is important for model-ing the action. So we propose a historical information layer that is added to the top of the multi-layered LSTM network. A historical feature of each video is generated for classification by hybridizing the hidden state of LSTM at time t and the historical updated feature at time t-1 with an updating scheme and utilized for classification. Experiments on the benchmark datasets demonstrate that our method that using only simple raw RGB video can outperform the state-of-the-art baselines for both general action recognition and tennis action recognition. (C) 2020 Elsevier B.V. All rights reserved.	187.96607744906933
668.	A family of algorithms for time series classification (TSC) involve running a sliding window across each series, discretising the window to form a word, forming a histogram of word counts over the dictionary, then constructing a classifier on the histograms. A recent evaluation of two of this type of algorithm, Bag of Patterns (BOP) and Bag of Symbolic Fourier Approximation Symbols (BOSS) found a significant difference in accuracy between these seemingly similar algorithms. We investigate this phenomenon by deconstructing the classifiers and measuring the relative importance of the four key components between BOP and BOSS. We find that whilst ensembling is a key component for both algorithms, the effect of the other components is mixed and more complex. We conclude that BOSS represents the state of the art for dictionary-based TSC. Both BOP and BOSS can be classed as bag of words approaches. These are particularly popular in Computer Vision for tasks such as image classification. We adapt three techniques used in Computer Vision for TSC: Scale Invariant Feature Transform; Spatial Pyramids; and Histogram Intersection. We find that using Spatial Pyramids in conjunction with BOSS (SP) produces a significantly more accurate classifier. SP is significantly more accurate than standard benchmarks and the original BOSS algorithm. It is not significantly worse than the best shapelet-based or deep learning approaches, and is only outperformed by an ensemble that includes BOSS as a constituent module.	187.96600913196087
669.	The essential human gait parameters are briefly reviewed, followed by a detailed review of the state of the art in deep learning for the human gait analysis. The modalities for capturing the gait data are grouped according to the sensing technology: video sequences, wearable sensors, and floor sensors, as well as the publicly available datasets. The established artificial neural network architectures for deep learning are reviewed for each group, and their performance are compared with particular emphasis on the spatiotemporal character of gait data and the motivation for multi-sensor, multi-modality fusion. It is shown that by most of the essential metrics, deep learning convolutional neural networks typically outperform shallow learning models. In the light of the discussed character of gait data, this is attributed to the possibility to extract the gait features automatically in deep learning as opposed to the shallow learning from the handcrafted gait features.	187.9659649187273
670.	The full behavior of cyber-physical systems (CPS) emerges during operation only, when the systems interact with their environment. Runtime monitoring approaches are used to detect deviations from the expected behavior. While most monitoring approaches assume that engineers define the expected behavior as constraints, the deep domain knowledge required for this task is often not available. We describe an approach that automatically mines constraint candidates for runtime monitoring from event logs recorded from CPS. Our approach extracts different types of constraints on event occurrence, timing, data, and combinations of these. The approach further presents the mined constraint candidates to users and offers filtering and ranking strategies. We demonstrate the usefulness and scalability of our approach by applying it to event logs from two real-world CPS: a plant automation software system and a system controlling unmanned aerial vehicles. In our experiments, domain experts regarded 74% and 63%, respectively, of the constraints mined for these two systems as useful.	187.96583988334885
671.	In order to improve the effectiveness and accuracy of financial status indicators to measure the degree of fiscal tightening, financial market situation and systemic financial risk, the logistic regression method is used to screen the target variables of the indicators. The model improves the objectivity of the selection of target variables. The model chooses 18 alternative indicators such as three-month weighted average interest rate, national real estate prosperity index, money supply M2, declared effective exchange rate and Shenzhen Component Index, and establishes the financial status index. This model validates China' s financial situation from 2013 to 2017. The results indicate that the dynamic weighted financial condition index based on time-varying parameter vector autoregressive model includes five variables: interest rate, real estate price, money supply, exchange rate and stock price, which effectively reflect the actual financial situation of China. It also proves that the degree of fiscal tightening and financial market conditions can be measured and warned in advance by changes in financial indicators. To sum up, it can be concluded that it is necessary to pay attention to the changes of interest rates, real estate prices and stock prices when monitoring the systemic financial risks in China. In order to promote early warning and effectively control financial risks, China should establish an information system and a flexible macro-prudential supervision system. This study is of great significance to the prediction and supervision of systemic financial risks in China. (C) 2020 Elsevier B.V. All rights reserved.	187.96576839240734
672.	Various methods of measuring unit selectivity have been developed with the aim of better understanding how neural networks work. But the different measures provide divergent estimates of selectivity, and this has led to different conclusions regarding the conditions in which selective object representations are learned and the functional relevance of these representations. In an attempt to better characterize object selectivity, we undertake a comparison of various selectivity measures on a large set of units in AlexNet, including localist selectivity, precision, class-conditional mean activity selectivity (CCMAS), the human interpretation of activation maximization (AM) images, and standard signal-detection measures. We find that the different measures provide different estimates of object selectivity, with precision and CCMAS measures providing misleadingly high estimates. Indeed, the most selective units had a poor hit-rate or a high false-alarm rate (or both) in object classification, making them poor object detectors. We fail to find any units that are even remotely as selective as the 'grandmother cell' units reported in recurrent neural networks. In order to generalize these results, we compared selectivity measures on units in VGG-16 and GoogLeNet trained on the ImageNet or Places-365 datasets that have been described as 'object detectors'. Again, we find poor hit-rates and high false-alarm rates for object classification. We conclude that signal-detection measures provide a better assessment of single-unit selectivity compared to common alternative approaches, and that deep convolutional networks of image classification do not learn object detectors in their hidden layers.	187.96568397201085
673.	Pressures build in Middle Eastern and Arabic-speaking societies to diversify economies and democratize social relations. Educators and scholars, contributing to these shifts, have experimented with classroom reforms that aim to advance higher-order thinking skills and the social agility of students. This article reviews 52 empirical studies of such reforms, work that meets methodological standards and gauges effects from an innovative classroom model. Classroom reforms within Arabic-speaking societies focused on various aspects of the technical core, including (1) structured exercises to advance analytic or problem-solving skills, (2) cooperative activities that demand interaction, or (3) projects aiming to advance complex cognition, often drawing on digital technologies. We find consistent evidence that the press for analytic skills or active participation in classrooms yields significant gains in learning. Pedagogical and classroom-reform models typically originate in the West, although local educators and scholars animate them with varying sensitivity to cultural or institutional contexts. Building research capacity in the region, however, would ensure greater rigor in quantitative and qualitative studies, along with deeper theorization of cultural context.	187.96566583002564
674.	Artificial intelligence (AI) has been heralded as the next big wave in the computing revolution and touted as a transformative technology for many industries including health care. In radiology, considerable excitement and anxiety are associated with the promise of AI and its potential to disrupt the practice of the radiologist. Radiology has often served as the gateway for medical technological advancements, and AI will likely be no different. We present a brief overview of AI advancements that have driven recent interest, offer a review of the current literature, and examine the most likely ways that AI will change radiology in the coming years.	187.9656513994656
675.	Radiation exposure and the associated risk of cancer for patients in computed tomography (CT) scans have been major clinical concerns. The radiation exposure can be reduced effectively via lowering the x-ray tube current (mA). However, this strategy may lead to excessive noise and streak artifacts in the conventional filtered back-projection reconstructed images. To address this issue, some deep convolutional neural network (ConvNet) based approaches have been developed for low-dose CT imaging inspired by the recent development of machine learning. Nevertheless, some of the image textures reconstructed by the ConvNet could be corrupted by the severe streaks, especially in ultra-low-dose cases, which could be close to prostheses and hamper diagnosis. Therefore, in this work, we propose an iterative residual-artifact learning ConvNet (IRLNet) approach to improve the reconstruction performance over the ConvNet based approaches. Specifically, the proposed IRLNet estimates the high-frequency details within the noise and then removes them iteratively; after eliminating severe streaks in the low-dose CT images, the residual low-frequency details can be processed through the conventional network. Moreover, the proposed IRLNet scheme can be extended for robust handling of quantitative dual energy CT/cerebral perfusion CT imaging, and statistical iterative reconstruction. Real patient data are used to evaluate the proposed IRLNet, and the experimental results demonstrate that the proposed IRLNet approach outperforms the previous ConvNet based approaches in reducing the image noise and streak artifacts efficiently at the same time as preserving edge details well, suggesting that the proposed IRLNet approach can be used to improve the CT image quality, especially in ultra-low-dose cases.	187.9655728661187
676.	Single-pixel imaging (SPI) can reduce the cost and have the potential of being competent for some challenging tasks. However, for a SPI system, acquiring detailed information from a complex scene for complex vision task is a measurements-consuming process, by which low efficiency resulted is one of the important obstructions of SPI for practical application. Reasonable allocation of resources of measurements and calculations is one of the effective solutions to this problem. As a preprocessing procedure with a role of guidance, salient object detection can help the vision system focus more attention on the area with more important information to improve the efficiency. Therefore, in this letter, we explore the implement of salient object detection based on SPI system and present a scheme via discrete cosine spectrum (DCS) acquisition and deep learning model.	187.96552874316484
677.	In view of the great diversity and complexity of social images, it is of great significance to improve the performance of personalized recommendation by learning a user interest from large-scale social images. Deep learning, as the latest research in the field of artificial intelligence, provides a new personalized recommendation solution of social images for learning a users interest. Moreover, social image sharing websites (such as Flickr) allow users to tag uploaded images with tags. As an important image semantic cue, effective tags not only represent the latent image information but also show personalized user interest. Therefore, a personalized recommendation method of social image is proposed by constructing a user-interest tree with deep features and tag trees in this paper. The main contributions of our paper are as follows: first, to efficiently make use of tags, a tag tree of social images is created by the re-ranked tags; second, for compactly representing the image content, deep features are learned by training the AlexNet network; third, a user-interest tree is constructed with deep features and tag trees that include the user-interest tree of social images and the user-interest tree of tags, respectively, and finally, a personalized recommendation system of social images is built based on a user-interest tree. Experiments on the NUS-WIDE dataset have shown that our method outperforms state-of-the-art methods in terms of both precision and recall of personalized recommendations.	187.96552309786952
678.	The genetic analysis of complex traits does not escape the current excitement around artificial intelligence, including a renewed interest in deep learning (DL) techniques such as Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs). However, the performance of DL for genomic prediction of complex human traits has not been comprehensively tested. To provide an evaluation of MLPs and CNNs, we used data from distantly related white Caucasian individuals (n similar to 100k individuals, m similar to 500k SNPs, and k = 1000) of the interim release of the UK Biobank. We analyzed a total of five phenotypes: height, bone heel mineral density, body mass index, systolic blood pressure, and waist-hip ratio, with genomic heritabilities ranging from similar to 0.20 to 0.70. After hyperparameter optimization using a genetic algorithm, we considered several configurations, from shallow to deep learners, and compared the predictive performance of MLPs and CNNs with that of Bayesian linear regressions across sets of SNPs (from 10k to 50k) that were preselected using single-marker regression analyses. For height, a highly heritable phenotype, all methods performed similarly, although CNNs were slightly but consistently worse. For the rest of the phenotypes, the performance of some CNNs was comparable or slightly better than linear methods. Performance of MLPs was highly dependent on SNP set and phenotype. In all, over the range of traits evaluated in this study, CNN performance was competitive to linear models, but we did not find any case where DL outperformed the linear model by a sizable margin. We suggest that more research is needed to adapt CNN methodology, originally motivated by image analysis, to genetic-based problems in order for CNNs to be competitive with linear models.	187.96548877971605
679.	The large-scale collection of mobile trajectories in mobile social networks makes it possible for us to use artificial intelligence, including deep learning, to explore the hidden attributes of the data and redesign data forwarding algorithms. In this paper, a data forwarding algorithm based on deep learning is proposed to transform data package communication from opportunistic forwarding to fixed path forwarding. First, by compiling statistics on real traces, we find that the number of connected nodes decreases linearly with the decrease of the sampling period, making it possible to use deep learning to process the node meeting data. Next, we design the recurrent neural network with an LSTM (Long Short-Term Memory) structure - a supervised deep learning system - to predict the probability of nodes meeting. We further propose a deep learning data forwarding algorithm which makes full use of fixed paths composed of instantaneous high-probability links. Finally, simulation results show that the algorithm proposed in this paper can effectively improve packet delivery ratio while greatly reducing network overhead.	187.96548867986075
680.	With the increase in the number of electronic devices and developments in the communication system, security becomes one of the challenging issues. Users are interacting with each other through different heterogeneous devices such as smart sensors, actuators, and many other devices to process, monitor, and communicate different scenarios of real life. Such communication needs a secure medium through which users can communicate in a secure and reliable way so that their information may not be lost. The proposed study is an endeavor toward the detection of phishing by using random forest and BLSTM classifiers. The experimental results of the proposed study are promising in phishing detection, and the study reflects the applicability of the proposed algorithms in the information security. The experimental results show that the BLSTM-based phishing detection model is prominent in ensuring the network security by generating a recognition rate of 95.47% compared to the conventional RF-based model that generates a recognition rate of 87.53%. This high recognition rate for the BLSTM-based model reflects the applicability of the proposed model for phishing detection.	187.96542271106244
681.	Prior to failure, most systems exhibit signs of changed characteristics. The early detection of this change is important to remaining useful life estimation. To have the ability to detect the inflection point or "elbow point" of an asset, i.e. the point of the degradation curve that marks the transition from nominal to faulty condition, can enable more sophisticated prognostics because this divide and conquer tactic allows the prediction to focus on the window before failure when significant changes are being expected. In this work, we compare prognostics with and without change point detection. We use different recurrent neural network techniques (standard recurrent neural network, long short-term memory and gated recurrent unit) to find the elbow point location. The actual estimation of the remaining time to failure is based on the echo state network, a state-of-the-art approach in prognostics. Two different experiments are performed on simulated data obtained from NASA Ames prognostics repository. We first compare the performance of the elbow point detectors based on recurrent neural networks against three baseline models: the Z-test, multilayer perceptron and random forests. Results indicate that recurrent neural networks can outperform the baseline approaches. In the second experiment, the best elbow detection model, the gated recurrent unit, is integrated within an echo state network, with a significant increase in overall performance in terms of remaining useful life estimation. (C) 2020 Elsevier Ltd. All rights reserved.	187.96538911816037
682.	Conventional reconstruction algorithms (e.g., delay-and-sum) used in photoacoustic imaging (PAI) provide a fast solution while many artifacts remain, especially for limited-view with ill-posed problem. In this paper, we propose a new convolutional neural network (CNN) framework Y-Net: a CNN architecture to reconstruct the initial PA pressure distribution by optimizing both raw data and beamformed images once. The network combines two encoders with one decoder path, which optimally utilizes more information from raw data and beamformed image. We compared our result with some ablation studies, and the results of the test set show better performance compared with conventional reconstruction algorithms and other deep learning method (U-Net). Both in-vitro and in-vivo experiments are used to validated our method, which still performs better than other existing methods. The proposed Y-Net architecture also has high potential in medical image reconstruction for other imaging modalities beyond PAI.	187.96531202034828
683.	This study explores machine learning methods for the detection of unexpected findings in Spanish radiology reports. Regarding radiological reports, unexpected findings are the set of radiological signs identified at a certain imaging modality exam which meet two characteristics: they are not apparently related with the a priori expected results of the radiological exam and involve a clinical emergency or urgency situation that must be reported shortly to the prescribing physician or another medical specialist as well as to the patient in order to preserve life and/or prevent dangerous occurrences. Several traditional machine learning and deep learning classification algorithms are evaluated and compared. To carry out the task we use 5947 anonymous radiology reports from HT medica. Experimental results suggest that the performance of the Convolutional Neural Networks models are better than traditional machine learning. The best F1 score for the identification of an unexpected finding was 90%. Finally, we also perform an error analysis which will guide us to achieve better results in the future. (c) 2020 Elsevier Ltd. All rights reserved.	187.96530570936625
684.	The graph edit distance (GED) is a flexible graph dissimilarity measure widely used within the structural pattern recognition field. In this paper, we present GEDLIB, a C++ library for exactly or approximately computing GED. Many existing algorithms for GED are already implemented in GEDLIB. Moreover, GEDLIB is designed to be easily extensible: for implementing new edit cost functions and GED algorithms, it suffices to implement abstract classes contained in the library. For implementing these extensions, the user has access to a wide range of utilities, such as deep neural networks, support vector machines, mixed integer linear programming solvers, a blackbox optimizer, and solvers for the linear sum assignment problem with and without error-correction.	187.9651690863373
685.	Pancreas segmentation is a challenging task in medical image analysis because of its large variations in texture, location, shape and size and the high similarity to the surrounding tissues especially around the boundary regions, which leads to the high segmentation uncertainty and makes the results inaccurate. Existing fully automatic segmentation methods rarely achieve sufficiently accurate and robust results. To tackle this problem, we propose a deep learning based interactive uncertain segmentation method which can involve the domain knowledge in the process of segmentation in an interactive and iterative way. Specially, the proposed method describes the uncertain regions of pancreatic CT images based on shadowed sets theory which are further corrected through interaction. The proposed method is evaluated on a challenging 3D pancreatic CT images dataset collected from the Changhai Hospital. The experimental results demonstrate that our proposed method outperforms the existing methods in terms of both the Dice similarity coefficient of 78% and the pixel-wise accuracy of 96%, which reveals the effectiveness and the potential of our method in clinical settings.	187.9650828913576
686.	Many researchers in the field of machine learning have addressed the problem of detecting anomalies within Computed Tomography (CT) scans. Training these machine learning algorithms requires a dataset of CT scans with identified anomalies (labels), usually, in specific organs. This represents a problem, since it requires experts to review thousands of images in order to create labels for these data. We aim to decrease human burden at labeling CT scans by developing a model that identifies anomalies within plain-text-based reports that then could be further used as a method to create labels for models based on CT scans. This study contains more than 4800 CT reports from Duke Health System, for which we aim to identify organ specific abnormalities. We propose an iterative active learning approach that consists of building a machine learning model to classify CT reports by abnormalities in different organs and then improving it by actively adding reports sequentially. At each iteration, clinical experts review the report that provides the model with highest expected information gain. This process is done in real time by using a web interface. Then, this datum is used by the model to improve its performance. We evaluated the performance of our method for abnormalities in kidneys and lungs. When starting with a model trained on 99 reports, the results show the model achieves an Area Under the Curve (AUC) score of 0.93 on the test set after adding 130 actively labeled reports to the model from an unlabeled pool of 4,000. This suggests that a set of labeled CT scans can be obtained with significantly reduced human work by combining machine learning techniques and clinical experts' knowledge.	187.96494708871234
687.	One of the main destinations of image classification methods is to screen out the images belonging to the target class (positive) and identify the images of other classes (negative). Although most classifiers are trained on both positive samples and negative samples, in reality, negative samples are often unavailable. One-class classifiers trained only on positive samples, are proposed to solve this problem. However, how to train effectively a classifier remains a daunting challenge. Considering the success of deep learning in the field of computer vision in recent years, we propose a one-class classification model for images based on convolutional neural network (CNN). The model consists of two parts of networks with different responsibilities. The network of the first part works as the discriminator, used to identify whether the images are positive. The networks of the second part, each of which consists of an encoder-decoder pair work as the guiders of the discriminator. They guide the discriminator to learn what images it should identify to be negative. Different encoder-decoder pairs can restore images to different degrees. Images restored to different degrees can be used to train the discriminator. The discriminator learns that images under a specific restored degree don't belong to the target class. The experiment results on CIFAR-10 show that our method can achieve good performance, with less difficulty in training than the GAN-based counterparts'.	187.96493259746438
688.	In this paper, we introduce a novel deep neural network, coined DeepFPC, and investigate its application to tackling the problem of direction-of-arrival (DOA) estimation. DeepFPC is designed by unfolding the iterations of the fixed-point continuation algorithm with one-sided l(1)-norm (FPC-l(1)), which has been proposed for solving the 1-bit compressed sensing problem. The network architecture resembles that of deep residual learning and incorporates prior knowledge about the signal structure (i.e., sparsity), thereby offering interpretability by design. Once DeepFPC is properly trained, a sparse signal can be recovered fast and accurately from quantized measurements. The proposed model is then applied in DOA estimation and is shown to outperform state-of-the-art solutions; namely, the iterative FPC-l(1) algorithm and the deep convolution network (DCN) model. (C) 2020 Elsevier B.V. All rights reserved.	187.96475918715856
689.	In the current state of the field of machine learning, often, real-world phenomena are learned through studies of isolated modalities; such as modeling language exclusively from verbal modality, which is a common theme in natural language processing. This is widely adopted since downstream tasksin different disciplines of machine learning are also often similarly isolated and unimodal. In sharp contrast to this, human learning from real-world experiences is rarely unimodal, and often exhibits a multisensory nature, regardless of any assumptions about downstream tasks. The cognitive constructs in human brain are consistently developed through multisensory reinforcement, and the same constructs generalize to unimodal scenarios. The difference between the trend of unimodal learning and human cognitive development raises the following question: "Even if downstream tasks are unimodal during test time, is it better to learn from the isolated modality or from multimodal information?". In this paper we focus on an in-depth study of this research question. We study the differences between unimodal learning and Multimodal Co-learning (MCl), both from empirical and theoretical standpoints. Through the lens of information entropy and characteristics of deep neural networks, we demonstrate strong theoretical justifications in favor of MCl.	187.9647469615238
690.	Semantic labeling for very high resolution (VHR) images in urban areas, is of significant importance in a wide range of remote sensing applications. However, many confusing manmade objects and intricate fine-structured objects make it very difficult to obtain both coherent and accurate labeling results. For this challenging task, we propose a novel deep model with convolutional neural networks (CNNs), i.e., an end-to-end self-cascaded network (ScasNet). Specifically, for confusing manmade objects, ScasNet improves the labeling coherence with sequential global-to-local contexts aggregation. Technically, multi-scale contexts are captured on the output of a CNN encoder, and then they are successively aggregated in a self-cascaded manner. Meanwhile, for fine-structured objects, ScasNet boosts the labeling accuracy with a coarse-to-fine refinement strategy. It progressively refines the target objects using the low-level features learned by CNN's shallow layers. In addition, to correct the latent fitting residual caused by multi-feature fusion inside ScasNet, a dedicated residual correction scheme is proposed. It greatly improves the effectiveness of ScasNet. Extensive experimental results on three public datasets, including two challenging benchmarks, show that ScasNet achieves the state-of-the-art performance. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	187.96472658123184
691.	Internet of things (IoT) devices are becoming increasingly popular thanks to many new services and applications they offer. However, in addition to their many benefits, they raise privacy concerns since they share fine-grained time-series user data with untrusted third parties. In this work, we study the privacy-utility trade-off (PUT) in time-series data sharing. Existing approaches to PUT mainly focus on a single data point; however, temporal correlations in time-series data introduce new challenges. Methods that preserve the privacy for the current time may leak significant amount of information at the trace level as the adversary can exploit temporal correlations in a trace. We consider sharing the distorted version of a user's true data sequence with an untrusted third party. We measure the privacy leakage by the mutual information between the user's true data sequence and shared version. We consider both the instantaneous and average distortion between the two sequences, under a given distortion measure, as the utility loss metric. To tackle the history-dependent mutual information minimization, we reformulate the problem as a Markov decision process (MDP), and solve it using asynchronous actor-critic deep reinforcement learning (RL). We evaluate the performance of the proposed solution in location trace privacy on both synthetic and GeoLife GPS trajectory datasets. For the latter, we show the validity of our solution by testing the privacy of the released location trajectory against an adversary network.	187.96470018687302
692.	Lifelong Machine Learning (LML) is a continuous learning process, in which the knowledge learned from previous tasks is accumulated in the knowledge base, then the knowledge will be used to support future learning tasks, for which it may be only a few of samples exists. However, there is a little of studies on LML based on deep neural networks for Named Entity Recognition (NER), especial in Vietnamese. We propose DeepLML-NER model, a lifelong learning model based on using deep learning methods with a CRFs layer, for NER in Vietnamese text. DeepLML-NER includes an algorithm to extract the knowledge of "prefix-features" of Named Entities in previous domains. Then the model uses the knowledge stored in the knowledge base to solve a new NER task. The effect of the model was demonstrated by in-domain and cross-domain experiments, achieving promising results.	187.96462463864697
693.	Digitalization shifts human communication to online platforms, which has many benefits but also builds up a space for antisocial online behavior (AOB) such as harassment, insult and other forms of hateful textual content. Online platforms have good reasons to monitor and moderate such content. The paper examines the viability of automatic content monitoring using deep machine learning and natural language processing (NLP). More specifically, we consolidate prior work in the field of antisocial online behavior detection and compare relevant approaches to recent NLP models in an empirical study. Covering important methodological advancements in NLP including bidirectional encoding, attention, hierarchical text representations, and pre-trained transformer-based language models, and extending previous approaches by introducing a pseudo-sentence hierarchical attention network, the paper provides a comprehensive summary of the state-of-affairs in NLP-based AOB detection, clarifies the detection accuracy that is attainable with today's technology, discusses whether this degree is sufficient for deploying deep learning-based text screening systems, and approaches the interpretability topic.	187.96460425178606
694.	Hashing methods have been intensively studied and widely used in image retrieval. Hashing methods aim to learn a group of hash functions to map original data into compact binary codes and simultaneously preserve some notion of similarity in the Hamming space. The generated binary codes are effective for image retrieval and highly efficient for large-scale data storage. The decision tree is a fast and interpretable model, but the current decision tree based hashing methods have insufficient learning ability due to the use of shallow decision trees. Most current deep hashing methods are based on deep neural networks. However, considering the deficiencies of deep neural network-based hashing, such as the presence of too many hyperparameters, poor interpretability, and requirement for expensive and powerful computational facilities during the training process, a non-deep neural network-based hashing model need to be designed to achieve efficient image retrieval with few hyperparameters, easy theoretical analysis and an efficient training process. The multi-grained cascade forest (gcForest) is a novel deep model that generates a deep forest ensemble classifier to process data layer-by-layer with multi-grained scanning and a cascade forest. To date, gcForest has not been used to generate compact binary codes; therefore, we propose a deep forest-based method for hashing learning that aims to learn shorter binary codes to achieve effective and efficient image retrieval. The experimental results show that the proposed method has better performance with shorter binary codes than other corresponding hashing methods. (C) 2019 Elsevier Ltd. All rights reserved.	187.96458445300627
695.	Migration and the sustainability of the welfare state are irrefutably two essential topics in the political debate throughout Europe. Not only has the dominant pattern within the political discourse been focused on the generosity of benefits attracting migrants as, until recently, researchers tended to concentrate on the supposed "weight" of migration on destination countries. This view contrasts with new perspectives that highlight not only the levels of unawareness regarding benefits or social services in the destination countries as well as transnational practices involving a myriad of formal and informal providers across borders. Drawing on qualitative data gathered through 39 interviews conducted with British migrants in Portugal and Portuguese migrants in the UK, we explore migrants' welfare experiences. Deploying the idea of social protection assemblages, which is the combination of formal and informal elements of protection, the analysis explores the welfare tactics that migrants adopt across transnational space to ensure their social welfare needs are met in the present and future. Local social capital, social networks and the process of welfare learning are key aspects in navigating the welfare system in the destination. Simultaneously, transnational practices are employed to overcome the gaps in formal services, either by piecing two formal social protection systems or informal elements provided by interpersonal networks. We demonstrate the importance of happenstance and "just in case" practices as well as cultural values and other non-economic factors as bearing a deep impact on how migrants 'do' social protection.	187.96456869806076
696.	In this paper, we propose a learning rule based on a back-propagation (BP) algorithm that can be applied to a hardware-based deep neural network using electronic devices that exhibit discrete and limited conductance characteristics. This adaptive learning rule, which enables forward, backward propagation, as well as weight updates in hardware, is helpful during the implementation of power-efficient and high-speed deep neural networks. In simulations using a three-layer perceptron network, we evaluate the learning performance according to various conductance responses of electronic synapse devices and weight-updating methods. It is shown that the learning accuracy is comparable to that obtained when using a software-based BP algorithm when the electronic synapse device has a linear conductance response with a high dynamic range. Furthermore, the proposed unidirectional weight-updating method is suitable for electronic synapse devices which have nonlinear and finite conductance responses. Because this weight-updating method can compensate the demerit of asymmetric weight updates, we can obtain better accuracy compared to other methods. This adaptive learning rule, which can be applied to full hardware implementation, can also compensate the degradation of learning accuracy due to the probable device-to-device variation in an actual electronic synapse device.	187.96454695313497
697.	Deep-learner hyper-parameters, such as kernel sizes, batch sizes, and learning rates, can significantly influence the quality of trained models. The state of the art for finding optimal hyper-parameters generally uses a brute force, grid search approach, random search, or Bayesian-based optimization among other techniques. We applied an evolutionary algorithm to optimize kernel sizes for a convolutional neural network used to detect settlements in satellite imagery. Usually convolutional layer kernel sizes are small - typically one, three, or five - but we found that the system converged at, or near, kernel sizes of nine for the last convolutional layer, and that this occurred formultiple runs using two different datasets. Moreover, the larger kernel sizes had fewer false positives than the 3x3 kernel sizes found as optimal via a brute force uniform grid search. This suggests that this large kernel size may be leveraging patterns found in larger areal features in the source imagery, and that this may be generalized as possible guidance for similar remote sensing deep-learning tasks.	187.96454387182388
698.	Melanocytic lesions of acral sites (ALM) are common, with an estimated prevalence of 28 - 36% in the USA. While the majority of these lesions are benign, differentiation from acral melanoma (AM) is often challenging. Much research has been done in segmenting and classifying skin moles located in acral volar areas. However, methods published to date cannot be easily extended to new skin regions because of different appearance and properties. In this paper, we propose a deep learning (U-Net) architecture to segment acral melonacytic lesions which is a necessary initial step for skin lesion pattern recognition, furthermore it is a prerequisite step to provide an accurate classification and diagnosis. The U-Net is one of the most promising deep learning solution for image segmentation and is built upon fully convolutional network. On the independent validation dataset including 210 dermoscopy images our implemented method showed high segmentation accuracy. For the U-Net convolutional neural network, an average DSC of 0.92, accuracy 0.94, sensitivity 0.91, and specificity 0.92 has been achieved. ALM due to small size and similarity to other local structures create enormous difficulties during the segmentation and assessment process. The use of advanced segmentation methods like deep learning models especially convolutional neural networks have the potential to improve the accuracy of advanced medical area segmentation.	187.9644920624644
699.	Our daily lives have been immersed in wide-spread location-based social networks (LBSNs). As an open platform LBSNs typically allow all kinds of users to register accounts. Malicious attackers can easily join and post misleading information often with the intention of influencing users' decisions in urban computing environments. To provide reliable information and improve the experience for legitimate users we design and implement DeepScan a malicious account detection system for LBSNs. Different from existing approaches DeepScan leverages emerging deep learning technologies to learn users' dynamic behavior. In particular we introduce the long short-term memory (LSTM) neural network to conduct time series analysis of user activities. DeepScan combines newly introduced time series features and a set of conventional features extracted from user activities and exploits a supervised machine-learning-based model for detection. Using real traces collected from Dianping a representative LBSN we demonstrate that DeepScan can achieve excellent prediction performance with an F1-score of 0.964. We also find that the time series features play a critical role in the detection system.	187.96444935449802
700.	Convolutional neural networks (CNNs) have been widely used to improve the accuracy of polarimetric synthetic aperture radar (PolSAR) image classification. However, in most studies, the difference between PolSAR images and optical images is rarely considered. Most of the existing CNNs are not tailored for the task of PolSAR image classification, in which complex-valued PolSAR data have been simply equated to real-valued data to fit the optical image processing architectures and avoid complex-valued operations. This is one of the reasons CNNs unable to perform their full capabilities in PolSAR classification. To solve the above problem, the objective of this paper is to develop a tailored CNN framework for PolSAR image classification, which can be implemented from two aspects: Seeking a better form of PolSAR data as the input of CNNs and building matched CNN architectures based on the proposed input form. In this paper, considering the properties of complex-valued numbers, amplitude and phase of complex-valued PolSAR data are extracted as the input for the first time to maintain the integrity of original information while avoiding immature complex-valued operations. Then, a multi-task CNN (MCNN) architecture is proposed to match the improved input form and achieve better classification results. Furthermore, depthwise separable convolution is introduced to the proposed architecture in order to better extract information from the phase information. Experiments on three PolSAR benchmark datasets not only prove that using amplitude and phase as the input do contribute to the improvement of PolSAR classification, but also verify the adaptability between the improved input form and the well-designed architectures.	187.96441758705672
701.	Music generation by neural networks has become a central issue since deep neural networks demonstrated their ability in learning from big data collections. This paper proposes a music score generation model which employs multi-layer RNNs and GAN scheme. First of all, the midi sequences are passed to the model, which is parsed as tone lengths, frequencies, intensities, and timing, and then the music theory law is introduced, while the initial sequences are set as music chords. Consequently, the distribution of music is learned in the process of training. The experimental results show that it is a feasible network structure which can generate multi-category music with good hearing experience.	187.96439117116356
702.	Steganography can hide secret information in an innocent cover medium. Its opponent is steganalysis, which is used to discriminate whether a suspicious carrier contains a hidden message or not. With the rapid development of deep-learning frameworks, deep-learning-based steganalytic models have hold the dominant position in the field of steganalysis. In recent years, some scholars have successfully utilised model compression methods in the field of image classification. However, as far as the authors know, no prior works are devoted to the application of model compression methods in the field of deep-learningbased steganalysis. In this study, the authors explore the effect of two quantisation schemes, namely 8-bit calculation and floating-point calculation, on the performance of XuNet, a state-of-the-art deep-learning steganalytic model. The experimental results show that the two deep-learning model quantisation schemes are applicable to steganalysis. It is even possible to compress the network size while retaining satisfactory performance.	187.96433456665122
703.	For sandwich panels with truss core, the weakest part is the low-density core; therefore, some effective damage identification methods have been previously proposed for sandwich panels. However, these studies have mainly focused on damage location identification and only a few studies have discussed detection of the extent of the damage. In this study, a damage identification method integrating a deep learning technique with dynamic properties is proposed to identify both the location and extent of internal damage in sandwich panels with truss core. An analytical model verified by experiments based on a laser vibrometer is used to obtain raw data, which can generate various levels of damage inside the two face sheets. Instead of using surface photographs or raw data as the deep learning training dataset, the dataset is constructed using damage indices. By combining this with an analytical model, a dataset of specimens with various defects was collected and used as the input for the neural networks. The ability to identify the locations of damage and the extent of damage was used to evaluate the effectiveness of the proposed technique. The results show that the proposed method could be used to identify the location and extent of internal damage accurately.	187.96433254441152
704.	Image ordinal classification has drawn substantial attention from the research community due to the ordering relation between image categories. Recent advancements towards image ordinal classification lie in applying deep neural networks [convolutional neural network (CNN)]. Nevertheless, the lack of ordinal training data prevents deep models from generalising to testing data. In this work, two multi-view learning approaches are proposed to tackle the insufficient data issue. On one hand, a multi-view ordinal classification with multi-view max pooling (MVMP) approach is proposed, in which each image is randomly blocked with some grids thus creating multiple views of the original data. All views are then used to train multi-view CNN for classification. On the other hand, in order to account for the ordinal relation, the authors propose a double-task learning on MVMP for classification and average pooling for regression. The task of regression benefits that of classification, mainly focusing on improving classification's recognition accuracy. The two proposed approaches are validated on Adience dataset, and show very compelling results. The code and models will be available online.	187.96426521674672
705.	Varying types of shots is a fundamental element in the language of film, commonly used by a visual storytelling director. The technique is often used in creating professional recordings of a live concert, but meanwhile may not be appropriately applied in audience recordings of the same event. Such variations could cause the task of classifying shots in concert videos, professional or amateur, very challenging. To achieve more reliable shot classification, we propose a novel probabilistic-based approach, named as coherent classification net (CC-Net), by addressing three crucial issues. First, we focus on learning more effective features by fusing the layer-wise outputs extracted from a deep convolutional neural network (CNN), pretrained on a large-scale data set for object recognition. Second, we introduce a frame-wise classification scheme, the error weighted deep cross-correlation model (EW-Deep-CCM), to boost the classification accuracy. Specifically, the deep neural network-based cross-correlation model (deep-CCM) is constructed to not only model the extracted feature hierarchies of CNN independently, but also relate the statistical dependencies of paired features from different layers. Then, a Bayesian error weighting scheme for a classifier combination is adopted to explore the contributions from individual Deep-CCM classifiers to enhance the accuracy of shot classification in each image frame. Third, we feed the frame-wise classification results to a linear-chain conditional random field module to refine the shot predictions by taking into account the global and temporal regularities. We provide extensive experimental results on a data set of live concert videos to demonstrate the advantage of the proposed CC-Net over existing popular fusion approaches for shot classification.	187.9640702722384
706.	Stereo matching has been solved as a supervised learning task with convolutional neural network (CNN). However, CNN based approaches basically require huge memory use. In addition, it is still challenging to find correct correspondences between images at ill-posed dim and sensor noise regions. To solve these problems, we propose Sparse Cost Volume Net (SCV-Net) achieving high accuracy, low memory cost and fast computation. The idea of the cost volume for stereo matching was initially proposed in GC-Net. In our work, by making the cost volume compact and proposing an efficient similarity evaluation for the volume, we achieved faster stereo matching while improving the accuracy. Moreover, we propose to use weight normalization instead of commonly-used batch normalization for stereo matching tasks. This improves the robustness to not only sensor noises in images but also batch size in the training process. We evaluated our proposed network on the Scene Flow and KITTI 2015 datasets, its performance overall surpasses the GC-Net. Comparing with the GC-Net, our SCV-Net achieved to: (1) reduce 73.08% GPU memory cost; (2) reduce 61.11% processing time; (3) improve the 3PE from 2.87% to 2.61% on the KITTI 2015 dataset.	187.9640182349421
707.	Subspace clustering aims at discovering the intrinsic structure of data in unsupervised fashion. As ever in most of approaches, an affinity matrix is constructed by learning from original data or the corresponding hand-crafted feature with some constraints on the self-expressive matrix (SEM), which is then followed by spectral clustering algorithm. Based on successful applications of deep technologies, it has become popular to simultaneously accomplish deep feature and self-representation learning for subspace clustering. However, deep feature and SEM in previous deep methods are lack of precise constraints, which is sub-optimal to conform with the linear subspace model. To address this, we propose an approach, namely sparse and low-rank regularized deep subspace clustering (SLR-DSC). In the proposed SLR-DSC, an end-to-end framework is proposed by introducing sparse and low-rank constraints on deep feature and SEM respectively. The sparse deep feature and low-rank regularized SEM implemented via fully-connected layers are encouraged to facilitate a more informative affinity matrix. In order to solve the nuclear norm minimization problem, a sub-gradient computation strategy is utilized to cater to the chain rule. Experiments on the data sets demonstrate that our method significantly outperforms the competitive unsupervised subspace clustering approaches. (C) 2020 Elsevier B.V. All rights reserved.	187.96396286789275
708.	Synthesizing realistic multi-view face images from a single-view input is an effective and cheap way for data augmentation. In addition it is promising for more efficiently training deep pose-invariant models for large-scale unconstrained face recognition. It is a challenging generative learning problem due to the large pose discrepancy between the synthetic and real face images, and the need to preserve identity after generation. We propose IP-GAN, a framework based on Generative Adversarial Networks to disentangle the identity and pose of faces, such that we can generate face images of a specific person with a variety of poses, or images of different identities with a particular pose. To rotate a face, our framework requires one input image of that person to produce an identity vector, and any other input face image to extract a pose embedding vector. Then we recombine the identity vector and the pose vector to synthesize a new face of the person with the extracted pose. Two learning pathways are introduced, the generation and the transformation, where the generation path focuses on learning complete representation in the latent embedding space. While the transformation path focuses on synthesis of new face images with target poses. They collaborate and compete in a parameter-sharing manner, and in an unsupervised settings. The experimental results demonstrate the effectiveness of the proposed framework.	187.96395225894386
709.	The microscopic image is important data for recording the microstructure information of materials. Researchers usually use image-processing algorithms to extract material features from that and then characterise the material microstructure. However, the microscopic images obtained by a microscope often have random damaged regions, which will cause the loss of information and thus inevitably influence the accuracy of microstructural characterisation, even lead to a wrong result. To handle this problem, we provide a deep learning-based fully automatic method for detecting and inpainting damaged regions in material microscopic images, which can automatically inpaint damaged regions with different positions and shapes, as well as we also use a data augmentation method to improve the performance of inpainting model. We evaluate our method on Al-La alloy microscopic images, which indicates that our method can achieve promising performance on inpainted and material microstructure characterisation results compared to other image inpainting software for both accuracy and time consumption. Lay Description A basic goal of materials data analysis is to extract useful information from materials datasets that can in turn be used to establish connections along the composition-processing-structure-properties chain. The microscopic images obtained by a microscope is the key carrier of material microstructural information. Researchers usually use image analysis algorithms to extract regions of interest or useful features from microscopic images, aiming to analyse material microstructure, organ tissues or device quality etc. Therefore, the integrity and clarity of the microscopic image are the most important attributes for image feature extraction. Scientists and engineers have been trying to develop various technologies to obtain perfect microscopic images. However, in practice, some extrinsic defects are often introduced during the preparation and/or shooting processes, and the elimination of these defects often requires mass efforts and cost, or even is impossible at present. Take the microstructure image of metallic material for example, samples prepared to microstructure characterisation often need to go through several steps such as cutting, grinding with sandpaper, polishing, etching, and cleaning. During the grinding and polishing process, defects such as scratches could be introduced. During the etching and cleaning process, some defects such as rust caused by substandard etching, stains etc. may arise and be persisted. These defects can be treated as damaged regions with nonfixed positions, different sizes, and random shapes, resulting in the loss of information, which seriously affects subsequent visual observation and microstructural feature extraction. To handle this problem, we provide a deep learning-based fully automatic method for detecting and inpainting damaged regions in material microscopic images, which can automatically inpaint damaged regions with different positions and shapes, as well as we also use a data augmentation method to improve the performance of inpainting model. We evaluate our method on Al-La alloy microscopic images, which indicates that our method can achieve promising performance on inpainted and material microstructure characterisation results compared to other image inpainting software for both accuracy and time consumption.	187.96387583246053
710.	We propose a multi-stage framework to create the stylized map art images. Existing techniques are successful in transferring style in photos. Yet, the noise in results and the harmonization in the generated art images still need to be investigated. We address these issues with a proposed algorithm that defines a good portrait for map art application in the initial round. A refinement strategy is then applied to produce the final map arts that meet the aforementioned expectations. Beside our plausible results, the objective evaluation presented in this paper shows that our proposed method can interactively achieve better and appealing map art results in the comparison with those of other works. In addition, our method can also create ocean or landscape stylized paintings using our map art collage.	187.96385552325842
711.	The Internet of things (IoT) is the extension of Internet connectivity into physical devices and everyday objects. These IoT devices can communicate with others over the Internet and fully integrate into people's daily life. In recent years, IoT devices still suffer from basic security vulnerabilities making them vulnerable to a variety of threats and malware, especially IoT botnets. Unlike common malware on desktop personal computer and Android, heterogeneous processor architecture issue on IoT devices brings various challenges for researchers. Many studies take advantages of well-known dynamic or static analysis for detecting and classifying botnet on IoT devices. However, almost studies yet cannot address the multi-architecture issue and consume vast computing resources for analyzing. In this paper, we propose a lightweight method for detecting IoT botnet, which based on extracting high-level features from function-call graphs, called PSI-Graph, for each executable file. This feature shows the effectiveness when dealing with the multi-architecture problem while avoiding the complexity of control flow graph analysis that is used by most of the existing methods. The experimental results show that the proposed method achieves an accuracy of 98.7%, with the dataset of 11,200 ELF files consisting of 7199 IoT botnet samples and 4001 benign samples. Additionally, a comparative study with other existing methods demonstrates that our approach delivers better outcome. Lastly, we make the source code of this work available to Github.	187.96380924410363
712.	Multiple construction worker tracking is an active research area critical to the planning of the job site. Challenges in multiple construction worker tracking include miss detection and mismatch due to occlusion and identity switches. To the best knowledge of the authors, the mismatch is not reported in the literature of con-struction for image based single camera multiple worker tracking. As a result, the mismatch should be taken into account through a representative performance index such as the Multi-Object Tracking Accuracy (MOTA). This work aims to improve the performance of the current multiple worker tracking through an approach composed of three stages: detection, matching and re-matching. In the detection stage, the deep learning detector, Mask R CNN, is utilized. In the matching stage, we attempt to track workers between consecutive image frames through a gradient based method with feature based comparison. Several cost means and matching methods have been experimented for model selection. Trajectories of tracking objects are derived in this stage. The best cost measurements and matching methods are recommended. Trajectories of tracking objects could be interrupted because of miss detection or mismatch. We call those broken trajectories, without matched detections, orphans. In the re-matching stage, we attempt to recover unmatched detections in the current frame with previous orphans based on extracted features. A competitive MOTA of 56.7% was obtained from the proposed approach over MOTA of 55.9% from the state-of-the-art Detect-And-Track model on a human tracking benchmark dataset. On construction job sites, we have tested the approach with 4 testing videos, resulting in a total MOTA of 81.8%, average MOTA per video of 79.0% and standard deviation of 13.0%, while the maximum and minimum MOTAs are 96.0% and 69.0%, respectively. As a result, the proposed work could potentially provide better multiple worker tracking on the construction job site. Additionally, to have a better representation of the tracking errors, this work suggests to utilize the MOTA for multiple construction worker tracking.	187.96380774274297
713.	Videos are inherently multimodal. This paper studies the problem of exploiting the abundant multimodal clues for improved video classification performance. We introduce a novel hybrid deep learning framework that integrates useful clues from multiple modalities, including static spatial appearance information, motion patterns within a short time window, audio information, as well as long-range temporal dynamics. More specifically, we utilize three Convolutional Neural Networks (CNNs) operating on appearance, motion, and audio signals to extract their corresponding features. We then employ a feature fusion network to derive a unified representation with an aim to capture the relationships among features. Furthermore, to exploit the long-range temporal dynamics in videos, we apply two long short-term memory (LSTM) networks with extracted appearance and motion features as inputs. Finally, we also propose refining the prediction scores by leveraging contextual relationships among video semantics. The hybrid deep learning framework is able to exploit a comprehensive set of multimodal features for video classification. Through an extensive set of experiments, we demonstrate that: 1) LSTM networks that model sequences in an explicitly recurrent manner are highly complementary to the CNN models; 2) the feature fusion network that produces a fused representation through modeling feature relationships outperforms a large set of alternative fusion strategies; and 3) the semantic context of video classes can help further refine the predictions for improved performance. Experimental results on two challenging benchmarks-the UCF-101 and the Columbia Consumer Videos (CCV)-provide strong quantitative evidence that our framework can produce promising results: 93.1% on the UCF-101 and 84.5% on the CCV, outperforming several competing methods with clear margins.	187.96380165668967
714.	Homogenization is a technique commonly used in multiscale computational science and engineering for predicting collective response of heterogeneous materials and extracting effective mechanical properties. In this paper, a three-dimensional deep convolutional neural network (3D-CNN) is proposed to predict the anisotropic effective material properties for representative volume elements (RVEs) with random inclusions. The high-fidelity dataset generated by a computational homogenization approach is used for training the 3D-CNN models. The inference results of the trained networks on unseen data indicate that the network is capable of capturing the microstructural features of RVEs and produces an accurate prediction of effective stiffness and Poisson's ratio. The benefits of the 3D-CNN over conventional finite-element-based homogenization with regard to computational efficiency, uncertainty quantification and model's transferability are discussed in sequence. We find the salient features of the 3D-CNN approach make it a potentially suitable alternative for facilitating material design with fast product design iteration and efficient uncertainty quantification.	187.96379351015486
715.	Learning intervention based on a "Mars and Space" exhibition was designed according to STEAM-education (Science, Technology, Engineering, Art and Mathematics) principles and practices in order to bridge the gap between formal and informal learning. The cognitive learning of 12-year-old students in Finland (N = 306) showed a sustained level for a six months period. The results of this study provided evidence that situational motivation was enhanced by interest in school science in the STEAM science exhibition context. This led to better cognitive learning results in the post-knowledge test. Thus, interest and situational motivation were the first steps, and the superficial situational motivation seemed to successfully change into content-based intrinsic motivation with longer-lasting, deep learning outcomes. STEAM intervention apparently produced long-term learning, and this exhibition learning setting is shown to provide an appropriate platform to reach the deeper layers to successfully retain knowledge. Boys' scores rose even in the delayed test. Using structural equation modelling (SEM) to assess the effects on individual, motivational and situational interest in learning, situation motivation is shown to work as a catalyst and acting as a catalyst and also acted as a stepping stone for intrinsic motivation as part of relative autonomy (RAI) and a deep learning strategy.	187.96374168047367
716.	Automatic detection of casting defects on radiography images is an important technology to automatize digital radiography defect inspection. Traditionally, in an industrial application, conventional methods are inefficient when the detection targets are small, local, and subtle in the complex scenario. Meanwhile, the outperformance of deep learning models, such as the convolutional neural network (CNN), is limited by a huge volume of data with precise annotations. To overcome these challenges, an efficient CNN model, only trained with image-level labels, is first proposed for detection of tiny casting defects in a complicated industrial scene. Then, in this article, we present a novel training strategy which can form a new object-level attention mechanism for the model during the training phase, and bilinear pooling is utilized to improve the model capability of detecting local contrast casting defects. Moreover, to enhance the interpretability, we extend class activation maps (CAM) to bilinear CAM (Bi-CAM) which is adapted to bilinear architectures as a visualization technique to reason about the model output. Experimental results show that the proposed model achieves superior performance in terms of each quantitative metric and is suitable for most actual applications. The real-time defect detection of castings is efficiently implemented in the complex scenario.	187.963688459199
717.	Automatic detection of multi-class objects in remote sensing images is a fundamental but challenging problem faced for remote sensing image analysis. Traditional methods are based on hand-crafted or shallow-learning-based features with limited representation power. Recently, deep learning algorithms, especially Faster region based convolutional neural networks (FRCN), has shown their much stronger detection power in computer vision field. However, several challenges limit the applications of FRCN in multi-class objects detection from remote sensing images: (1) Objects often appear at very different scales in remote sensing images, and FRCN with a fixed receptive field cannot match the scale variability of different objects; (2) Objects in large-scale remote sensing images are relatively small in size and densely peaked, and FRCN has poor localization performance with small objects; (3) Manual annotation is generally expensive and the available manual annotation of objects for training FRCN are not sufficient in number. To address these problems, this paper proposes a unified and effective method for simultaneously detecting multi-class objects in remote sensing images with large scales variability. Firstly, we redesign the feature extractor by adopting Concatenated ReLU and Inception module, which can increases the variety of receptive field size. Then, the detection is preformed by two sub-networks: a multi-scale object proposal network (MS-OPN) for object-like region generation from several intermediate layers, whose receptive fields match different object scales, and an accurate object detection network (AODN) for object detection based on fused feature maps, which combines several feature maps that enables small and densely packed objects to produce stronger response. For large-scale remote sensing images with limited manual annotations, we use cropped image blocks for training and augment them with re-scalings and rotations. The quantitative comparison results on the challenging NWPU VHR-10 data set, aircraft data set, Aerial-Vehicle data set and SAR-Ship data set show that our method is more accurate than existing algorithms and is effective for multi-modal remote sensing images. (C) 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	187.96368037012098
718.	The classification of wood types plays an important role in many fields, especially in construction industry and furniture manufacturing. In order to manufacture rubber wood furniture with highly uniform color and texture, wood boards of different colors and textures should be classified elaborately. Many traditional methods have been applied in wood classification relying on extracting features using handcrafted descriptors designed by experienced experts, but it is not easy to construct robust features in various conditions. In this article, we present a split-shuffle-residual (SSR)-based CNN that can learn features automatically from wood images for real-time classification of rubber wood boards. Specifically, we introduce an SSR module that combines channel split and shuffle operations with residual structure to reduce the computation cost while maintaining high classification accuracy. In each module, the input is split into two low-dimensional branches, and the channel shuffle operation is used to enable the information communication between the input and the two separated branches, which is regarded as the feature reuse that enlarges network capacity without increasing complexity. The comprehensive experiments demonstrate that our algorithm outperforms other traditional classification methods and the state-of-the-art deep learning classification networks, yielding an accuracy of 94.86%. Furthermore, the analysis of running time indicates that the SSR-based CNN can be employed for wood classification in real time, which takes only 26.55 ms to handle a single image.	187.96365093993532
719.	The use of a virtual learning environment is increasingly gaining popularity with universities among students and instructors. VLEs is said to increase flexibility and promote independent learning. However, the pedagogical effects and the contribution of instructors in student's experience of cognitive active learning in these online classrooms is worth investigating. This paper seeks to explore the disparity between students and the instructor's perception of cognitive active learning experience in a VLE. Consequently, this paper utilizes a phenomenological constructivism approach by using interviews and questionnaires as the primary method of data collection. The results show that instructors believe students are often not intrinsically motivated and consequently do not automatically experience deep learning in the VLE without the appropriate instructional support. The instructor must stimulate deep thinking with a well-formed and probing questions or comments which promotes critical thinking and knowledge transference. This highlights the disconnect between the two instructors and learners in the expectations, attitude towards learning, and the learning environment.	187.9635231657171
720.	This paper explains our efforts in regards of hybrid climate services. As one part of our research efforts and exploration in Africa, we have worked with the Marigat District in Baringo County, Kenya, where we first intended to help the farmers to replace the invasive Prosopis juliflora deep-root species by another deep-root species easier to keep under control. Data was collected through questionnaires with open-ended and closed-ended questions to find a baseline of community challenges and technology use. The lessons learned in the project inspired us to analyze the data by using the lens of Heeks' [3] design theories. The main outcome of this study is a hybrid evaluation and its discussion with future implications for future climate services.	187.9635011142193
721.	The recent trend in adapting ultra-energy-efficient (but error-prone) nanomagnetic devices to non-Boolean computing and information processing (e.g. stochastic/probabilistic computing, neuromorphic, belief networks, etc) has resulted in rapid strides in new computing modalities. Of particular interest are Bayesian networks (BN) which may see revolutionary advances when adapted to a specific type of nanomagnetic devices. Here, we develop a novel nanomagnet-based computing substrate for BN that allows high-speed sampling from an arbitrary Bayesian graph. We show that magneto-tunneling junctions (MTJs) can be used for electrically programmable 'sub-nanosecond' probability sample generation by co-optimizing voltage-controlled magnetic anisotropy and spin transfer torque. We also discuss that just by engineering local magnetostriction in the soft layers of MTJs, one can stochastically couple them for programmable conditional sample generation as well. This obviates the need for extensive energy-inefficient hardware like OP-AMPS, gates, shift-registers, etc to generate the correlations. Based on the above findings, we present an architectural design and computation flow of the MTJ network to map an arbitrary Bayesian graph where we develop circuits to program and induce switching and interactions among MTJs. Our discussed framework can lead to a new generation of stochastic computing hardware for various other computing models, such as stochastic programming and Bayesian deep learning. This can spawn a novel genre of ultra-energy-efficient, extremely powerful computing paradigms, which is a transformational advance.	187.9634611728784
722.	Manually selecting appropriate scholarly venues is becoming a tedious and time-consuming task for researchers due to many reasons that include relevance, scientific impact, and research visibility. Sometimes, high-quality papers get rejected due to mismatch between the area of the paper and the scope of the journal. Recommending appropriate academic venues can, therefore, enable researchers to identify and take part in relevant conferences and publish in journals that matter the most. A researcher may certainly know of a few leading venues for her specific field of interest. However, a venue recommendation system becomes particularly helpful when exploring a new domain or when more options are needed. Due to high dimensionality and sparsity of text data, and complex semantics of the natural language, journal identification presents difficult challenges. We propose a novel and unified architecture that contains a Bi-directional LSTM (Bi-LSTM) and a Hierarchical Attention Network (HAN) to address the above problems. We call the proposed architecture modularized Hierarchical Attention-based Scholarly Venue Recommender system (HASVRec), which only requires the abstract, title, keywords, field of study, and author of a new paper along with its past publication record to recommend scholarly venues. Experiments on the DBLP-Citation-Network V11 dataset exhibit that our proposed approach outperforms several state-of-the-art methods in terms of accuracy, F1, nDCG, MRR, average venue quality, and stability. (C) 2020 Elsevier B.V. All rights reserved.	187.963433877682
723.	Condition sensing and understanding for CNC machine tools is an effective means to find hidden faults and to make their diagnosis. In this paper, an intelligent perception system of CNC machine tools is designed and implemented based on human-machine collaboration. With the application of wearable and mobile smart devices, such as Google Glasses and mobile phones, the system makes the information acquisition and data analysis capabilities of site-operator improved further more. A light deep learning model MobileNetV2 is used in this system, which can identify the key parts of the machine tools observed by the site-operator with the Google Glass. The various sensing data of the machine tools can be displayed visually via the screen of the Google Glass, so that site-operator can monitor them more conveniently. Finally, a fault response method for CNC machine tools based on human-machine collaboration is presented. The method improves the sensing capability and responding speed of site-operator by the collaboration of the smart glasses.	187.963412369051
724.	In the last few years, a great attention was paid to the deep learning Techniques used for image analysis because of their ability to use machine learning techniques to transform input data into high level presentation. For the sake of accurate diagnosis, the medical field has a steadily growing interest in such technology especially in the diagnosis of melanoma. These deep learning networks work through making coarse segmentation, conventional filters and pooling layers. However, this segmentation of the skin lesions results in image of lower resolution than the original skin image. In this paper, we present deep learning based approaches to solve the problems in skin lesion analysis using a dermoscopic image containing skin tumor. The proposed models are trained and evaluated on standard benchmark datasets from the International Skin Imaging Collaboration (ISIC) 2018 Challenge. The proposed method achieves an accuracy of 96.67% for the validation set. The experimental tests carried out on a clinical dataset show that the classification performance using deep learning-based features performs better than the state-of-the-art techniques.	187.96338867454665
725.	As radiology is inherently a data-driven specialty, it is especially conducive to utilizing data processing techniques. One such technique, deep learning (DL), has become a remarkably powerful tool for image processing in recent years. In this work, the Association of University Radiologists Radiology Research Alliance Task Force on Deep Learning provides an overview of DL for the radiologist. This article aims to present an overview of DL in a manner that is understandable to radiologists; to examine past, present, and future applications; as well as to evaluate how radiologists may benefit from this remarkable new tool. We describe several areas within radiology in which DL techniques are having the most significant impact: lesion or disease detection, classification, quantification, and segmentation. The legal and ethical hurdles to implementation are also discussed. By taking advantage of this powerful tool, radiologists can become increasingly more accurate in their interpretations with fewer errors and spend more time to focus on patient care.	187.96336132030268
726.	Identification of malignancy and false recalls (women who are recalled in screening for additional workup, but later proven benign) in screening mammography has significant clinical value for accurate diagnosis of breast cancer. Deep learning methods have recently shown success in the area of medical imaging classification. However, there are a multitude of different training strategies that can significantly impact the overall model performance for a specific classification task. In this study, we aimed to investigate the impact of training strategy on classification of digital mammograms by performing a robustness analysis of deep learning models to distinguish malignancy and false-recall from normal (benign) findings. Specifically, we employed several pre-training strategies including transfer learning with medical and non-medical datasets, layer freezing, and varied network structure on both binary and three-class classification tasks of digital mammography images. We found that, overall, deep learning models appear to be robust to some modifications of network structure and pre-training strategy that we tested for mammogram-specific classification tasks. However, for specific classification tasks, some training strategies offer performance gains. The most notable performance gains in our experiments involved residual network models.	187.96333622982792
727.	In this paper, we aim to improve the performance of semantic image segmentation in a semi-supervised setting where training is performed with a reduced set of annotated images and additional non-annotated images. We present a method based on an ensemble of deep segmentation models. Models are trained on subsets of the annotated data and use non-annotated images to exchange information with each other, similar to co-training. Diversity across models is enforced with the use of adversarial samples. We demonstrate the potential of our method on three challenging image segmentation problems, and illustrate its ability to share information between simultaneously trained models, while preserving their diversity. Results indicate clear advantages in terms of performance compared to recently proposed semi-supervised methods for segmentation. (C) 2020 Elsevier Ltd. All rights reserved.	187.963315976402
728.	Deep learning-based speech enhancement approaches like deep neural networks (DNN) and Long Short-Term Memory (LSTM) have already demonstrated superior results to classical methods. However, these methods do not take full advantage of temporal context information. While DNN and LSTM consider temporal context in the noisy source speech, it does not do so for the estimated clean speech. Both DNN and LSTM also have a tendency to over-smooth spectra, which causes the enhanced speech to sound muffled. This paper proposes a novel architecture to address both issues, which we term a conditional generative model (CGM). By adopting an adversarial training scheme applied to a generator of deep dilated convolutional layers, CGM is designed to model the joint and symmetric conditions of both noisy and estimated clean spectra. We evaluate CGM against both DNN and LSTM in terms of Perceptual Evaluation of Speech Quality (PESQ) and Short-Time Objective Intelligibility (STOI) on TIMIT sentences corrupted by ITU-T P.501 and NOISEX-92 noise in a range of matched and mismatched noise conditions. Results show that both the CGM architecture and the adversarial training mechanism lead to better PESQ and STOI in all tested noise conditions. In addition to yielding significant improvements in PESQ and STOI, CGM and adversarial training both mitigate against over-smoothing.	187.9632489797229
729.	Over the past two decades, machine learning has been gaining significant attention for solving complex engineering problems. Genetic programing (GP) is an advanced framework that can be used for a variety of machine learning tasks. GP searches a program space instead of a data space without a need to pre-defined models. This method generates transparent solutions that can be easily deployed for practical civil engineering applications. GP is establishing itself as a robust intelligent technique to solve complicated civil engineering problems. This paper provides a review of the GP technique and its applications in the civil engineering arena over the last decade. We discuss the features of GP and its variants followed by their potential for solving various civil engineering problems. We finally envision the potential research avenues and emerging trends for the application of GP in civil engineering.	187.96318200606504
730.	The fixed-pattern noise (FPN) caused by nonuniform optoelectronic response limits the sensitivity of an infrared imaging system and severely reduces the image quality. Therefore, nonuniform correction of infrared images is very important. In this paper, we propose a deep filter neural network to solve the problems of network underfitting and complex training with convolutional neural network (CNN) applications in nonuniform correction. Our work is mainly based on the idea of deep learning, where the nonuniform image noise features are fully learned from a large number of simulated training images. The network is designed by introducing the filter and the subtraction structure. The background interference of the image is removed by the filter, so the learning model is gathered in the nonuniform noise. The subtraction structure is used to further reduce the input-to-output mapping range, which effectively simplifies the training process. The results from the test on infrared images shows that our algorithm is superior to the state-of-the-art algorithm in visual effects and quantitative measurements, providing a new method for deep learning in nonuniformity correction of single images.	187.9631411816574
731.	Automatic crack detection on pavement surfaces is an important research field in the scope of developing an intelligent transportation infrastructure system. In this paper, a cost effective solution for road crack inspection by mounting the commercial grade sport camera, GoPro, on the rear of the moving vehicle is introduced. Also, a novel method called ConnCrack combining conditional Wasserstein generative adversarial network and connectivity maps is proposed for road crack detection. In this method, a 121-layer densely connected neural network with deconvolution layers for multi-level feature fusion is used as generator, and a 5-layer fully convolutional network is used as discriminator. To overcome the scattered output issue related to deconvolution layers, connectivity maps are introduced to represent the crack information within the proposed ConnCrack. The proposed method is tested on a publicly available dataset as well our collected data. The results show that the proposed method achieves state-of-the-art performance compared with other existing methods in terms of precision, recall and F1 score. (C) 2020 Elsevier Ltd. All rights reserved.	187.96311082715425
732.	Super-resolution is the use of low-resolution images to reconstruct corresponding high-resolution images. This technology is used in many places such as medical fields and monitor systems. The traditional method is to interpolate to fill in the information lost when the image is enlarged. The initial use of deep learning is SRCNN, which is divided into three steps, extracting image block features, feature nonlinear mapping and reconstruction. Both PSNR and SSIM have significant progress compared with traditional methods, but there are still some details in detail restoration. defect. SRGAN will generate anti-network applications to SR problems. The method is to improve the image magnification by more than 4 times, which is easy to produce too smooth. In this study, we hope to improve the EnhanceNet by training with different loss functions and different types of images to achieve better reconstruction results.	187.96309778969436
733.	Wearable computing and context awareness are the focuses of study in the field of artificial intelligence recently. One of the most appealing as well as challenging applications is the Human Activity Recognition (HAR) utilizing smart phones. Conventional HAR based on Support Vector Machine relies on manually extracted features. This approach is time and energy consuming in prediction due to the partial view toward which features to be extracted by human. With the rise of deep learning, artificial intelligence has been making progress toward being a mature technology. This paper proposes a new approach based on deep learning called HAR-Net to address the HAR issue. The study used the data collected by gyroscopes and acceleration sensors in android smart phones. The HAR-Net fusing the hand-crafted features and high-level features extracted from convolutional neural network to make prediction. The performance of the proposed method was proved to be higher than the original MC-SVM approach. The experimental results on the UCI dataset demonstrate that fusing the two kinds of features can make up for the shortage of traditional feature engineering and deep learning techniques.	187.96304140194562
734.	Neurodegenerative diseases, mainly amyotrophic lateral sclerosis, Parkinson, Alzheimer, and rarer diseases, have gained the attention of healthcare service providers due to their impact on the economy of countries where healthcare is a public service. These diseases increase with aging and affect the neuromotor cells and cognitive areas in the brain, causing serious disabilities in people affected by them.Early prediction of these syndromes is the first strategy to be implemented, then the developing of prostheses that rehabilitate motion and the primary cognitive functions. Prostheses could recover some important disabilities such as motion and aphasia, reduce the cost of assistance and increase the life quality of people affected by neurodegenerative diseases.Due to recent advances in the field of artificial intelligence (AI) (deep learning, brain-inspired computational paradigms, nonlinear predictions, neuro-fuzzy modeling), the early prediction of neurodegenerative diseases is possible using state-of-the-art computational technologies. The latest generation of artificial neural networks (ANNs) exploits capabilities such as online learning, fast training, high level knowledge representation, online evolution, learning by data and inferring rules.Wearable electronics is also developing rapidly and represents an important enabling technology to deploy physical and practical (noninvasive) devices using AI-based models for early prediction of neurodegenerative diseases and of intelligent prostheses.Here we describe how to apply advanced brain-inspired methods for inference and prediction, the evolving fuzzy neural network (EFuNN) paradigm and the spiking neural network (SNN) paradigm, and the system requirements to develop a wearable electronic prosthesis for functional rehabilitation.	187.96295991259984
735.	In the era of the Internet of Things (IoT), an immense amount of data is generated from numerous sensors and devices. Data as a service (DaaS) represents a new market whose time has come, and DaaS-based businesses are emerging quickly. Businesses across sectors begin seeing their data not only as fundamentally valuable but economically viable to distribute. Due to the exponential growth of the DaaS market, the current pricing models gradually become less suitable for the selling of data sets. A more sophisticated pricing strategy is needed to unlock the value of that data for the data vendor's (DV's) revenue growth and their customers' benefits such as online service providers (SPs). In this article, we aim to maximize the DV's profits by designing a mixed sales mechanism, which allows the DV to sell data sets separately or bundled. Particularly, we apply a multidimensional adverse selection model from contract theory to model the data set trading between DVs and SPs. The DV's surplus maximization problem is solved in the single-product case first, then extended to the multiproduct case. Furthermore, the analysis of the solution of the pricing strategy in single-product and multiproduct cases is provided. Finally, the simulation results show that the proposed pricing model can improve the DV's profits efficiently.	187.96294116321127
736.	This letter develops a new approach for a class of stochastic control problems under partial observations. The new approach is a deep filtering based method. Algorithms are proposed, and comparisons to the Kalman filter are provided. Both quadratic and non-quadratic costs are considered. Numerical experiments and production planning case studies are presented to demonstrate that training with a constant-gain linear feedback integrated with the DF state estimator can meet the needs of a broad class of optimal control problems under partially observation of the state.	187.96277577821954
737.	By exploiting the total variation (TV) regularization scheme and the contrast transfer function (CTF), a phase map can be retrieved from single-distance coherent diffraction images via the sparsity of the investigated object. However, the CTF-TV phase retrieval algorithm often struggles in the presence of strong noise, since it is based on the traditional compressive sensing optimization problem. Here, convolutional neural networks, a powerful tool from machine learning, are used to regularize the CTF-based phase retrieval problems and improve the recovery performance. This proposed method, the CTF-Deep phase retrieval algorithm, was tested both via simulations and experiments. The results show that it is robust to noise and fast enough for high-resolution applications, such as in optical, x-ray, or terahertz imaging. (C) 2019 Optical Society of America	187.96275363547193
738.	Developments and accessibility of computational methods within machine learning and deep learning have led to the resurgence of methods for computer assisted synthesis planning (CASP). In this paper we introduce our viewpoints on the analysis of reaction data, model building and evaluation. We show how the models' performance is affected by the specificity of the extracted reaction rules (templates) and outline the direction of research within our group.	187.96269444620793
739.	Docking is one of the most important steps in virtual screening pipelines, and it is an established method for examining potential interactions between ligands and receptors. However, this method is computationally expensive, and it is often among the last steps of the process of compound libraries evaluation. In this work, we investigate the feasibility of learning a deep neural network to predict the docking output directly from a two-dimensional compound structure. The developed protocol is orders of magnitude faster than typical docking software, and it returns ligand-receptor complexes encoded in the form of the interaction fingerprint. Its speed and efficiency unlock the application possibilities, such as screening compound libraries of vast size on the basis of contact patterns or docking score (derived on the basis of predicted interaction schemes). We tested our approach on several G protein-coupled receptor targets and 4 CYP enzymes in retrospective virtual screening experiments, and a variant of graph convolutional network appeared to be most effective in emulating docking results. The method can be easily used by the community based on the code available in the Supporting Information.	187.96267481475365
740.	There is increasing demand for efficient ways to process large volumes of data from visual-based remote-technology, such as unmanned aerial vehicles (UAVs) in ecology and conservation, with machine learning methods representing a promising avenue to address varying user demands. Here, we evaluated current trends in how machine learning and UAVs are used to process imagery data for detecting animals and vegetation across habitats, placing emphasis on their utility for endangered species. We reviewed 213 publications that used UAVs at 256 study sites, of which just 89 (42 %) used machine learning to assess the visual data. We evaluated geographical and temporal trends and identified how each technology is used at a global scale. We also identified the most commonly encountered machine-learning methods, including potential reasons for their limited use in ecology and possible solutions. Thirteen out of the 17 habitats defined by the International Union for Conservation of Nature (IUCN) habitat classification scheme were monitored using UAVs, while 12 habitats were monitored using both UAVs and machine learning. Our results show that, while machine learning is already being used across many habitat types, it is primarily restricted to more uniform habitats at present. Out of 173 plant and animal species monitored using UAV surveys, 30 were of conservation concern, with machine learning being used to assess UAV imagery data for 9 of these species. In conclusion, we anticipate that the joint use of UAVs and machine learning for ecological research and conservation will expand as machine learning methods become more accessible.	187.96263623603193
741.	Over the past few years, Convolutional neural networks (ConvNets) is emerging as computer vision discipline within deep learning. ConvNets is a key strategy for addressing computer vision problems, yet the theories behind their effectiveness in the processing are not yet fully understood. ConvNets have attained a state of the art-performances on various datasets for computer vision tasks such as remote sensing images scene classification, face recognition, and object detection. This is attributed to their effectiveness in image feature processing. This work reviews the major advances on ConvNets for effective processing in computer vision from some dimensions which include, convolutional layer design configurations, pooling layer strategies, network activation functions, loss functions, network regularization techniques, and ConvNet optimization methods. Further, this works surveys the application of ConvNets on three computer vision tasks,i.e.remote sensing images scene recognition, face recognition, and object detection to demonstrate the effectiveness of convNets in image feature processing. Additionally, datasets for evaluation and benchmarking purposes with the aforementioned computer vision tasks are briefly discussed.	187.96262764282028
742.	Intravenous (IV) medication administration processes have been considered as high-risk steps, because accidents during IV administration can lead to serious adverse effects, which can deteriorate the therapeutic effect or threaten the patient's life. In this study, we propose a multi-modal infusion pump (IP) monitoring technique, which can detect mismatches between the IP setting and actual infusion state and between the IP setting and doctor's prescription in real time using a thin membrane potentiometer and convolutional-neural-network-based deep learning technique. During performance evaluation, the percentage errors between the reference infusion rate (IR) and average estimated IR were in the range of 0.50-2.55%, while those between the average actual IR and average estimated IR were in the range of 0.22-2.90%. In addition, the training, validation, and test accuracies of the implemented deep learning model after training were 98.3%, 97.7%, and 98.5%, respectively. The training and validation losses were 0.33 and 0.36, respectively. According to these experimental results, the proposed technique could provide improved protection functions to IV-administration patients.	187.9626259422522
743.	Data augmentation (DA) is a key element in the success of Deep Learning (DL) models, as its use can lead to better prediction accuracy values when large size data sets are used. DA was not very much used with earlier neural network models before 2012, and the reason might be related to the type of models and the size of the data sets used. We investigate in this work, applying several state-of-the-art models based on Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), the effect of DA when using small size data sets, analyzing the results in terms of the prediction accuracy obtained according to the different characteristics of the training samples (number of instances and features, and class unbalance degree). We further introduce modifications to the standard methods used to generate the synthetic samples to alter the class balance representation, and the overall results indicate that with some computational effort a significant increase in prediction accuracy can be obtained when small data sets are considered. (C) 2020 Elsevier Ltd. All rights reserved.	187.96260817373215
744.	Deep learning-based methods have attracted the attention of researchers due to their outstanding performance in automatic feature learning, a crucial step for satisfactory fault diagnosis. However, faults in rotating machinery may occur occasionally, and fault-related signals are difficult to collect, resulting in imbalanced data. This problem is a major concern in fault diagnosis research. In this study, an enhanced generative adversarial network (EGAN) is proposed to establish a fault diagnosis model for rotating machinery. The model, based on a 2D convolutional network, consists of a generator and a discriminator. The generator produces specified samples to automatically enrich small samples for balancing datasets. The discriminator validates the distribution similarity between the generated and original samples. Fault types are recognized by a classifier using the generated and original samples. An adaptive training ratio strategy is also proposed to improve the convergence rapidity and stability of the EGAN training process. In case studies, two datasets are applied to verify the generalization performance of the EGAN. Results confirm the superior performance of the EGAN in fault diagnosis, particularly in the analyses of datasets with imbalanced data. Moreover, visualization results demonstrate that the proposed EGAN exhibits satisfactory ability and great potential for fault diagnosis applications of rotating machinery.	187.96241845971426
745.	Lateral logging sounding (LLS) is currently the only widely used Russian method of resistivity measurements, sensitive to vertical electrical resistivity in vertical wells. However, interpreting data measured by this method in thin-layered sections is difficult and requires the utilization of resource-intensive numerical simulation algorithms. Today, the development of computational methods and an increase in computer performance allow us to invert LLS data in the class of two-dimensional axisymmetric models. However, in virtue of the large number of difficulties associated with the nonlocal responses of the probes and their asymmetry, this process requires the active participation of a log analyst. One of the first issues is the creation of an initial approximation of the geoelectric model. It consists in splitting the target interval into layers within which the properties of the medium can be considered constant in the vertical direction, since LLS signals have a very complex shape in the intervals of alternation of beds with different resistivities. We propose applying a fully connected convolutional artificial neural network to automatically create sectional layering suitable for constructing the initial approximation of the geoelectric model for two-dimensional LLS data inversion, including vertical resistivity estimation. The neural network was trained and tested on the synthetic and field data measured in West Siberia. Based on the results of the testing, we established the workability of the proposed approach.	187.9623591599007
746.	Glioma grading is critical to clinical prognosis and survival prediction. In this paper, we propose a noninvasive method which combines radiomics and deep learning features to conduct glioma grading. By integrating radiomics features with high-level deep learning features, a more comprehensive representation of the images was constructed. First, different types of radiomics features were extracted from region of interest (ROI) of the image. A VGG-16 model pretrained on ImageNet was finetuned for the extraction of the deep learning features. Subsequent feature selection was performed to obtain three kinds of optimal feature subsets: radiomics features only, deep learning features only, and combined features. Finally, these feature subsets were used to train three classifiers including logistic regression (LR), support vector machine (SVM) and linear discriminant analysis (LDA) to predict the glioma grade. Our method was evaluated on an open dataset, BraTS 2018, which contains 285 subjects from multiple institutions. The proposed combination method exhibits the best AUC value of 94.4% when compared with that use only radiomics or deep learning features.	187.9622624145012
747.	In this paper, we propose to use the deep learning technique to estimate and predict the torso direction from the head movements alone. The prediction allows to implement the walk-in-place navigation interface without additional sensing of the torso direction, and thereby improves the convenience and usability. We created a small dataset and tested our idea by training an LSTM model and obtained a 3-class prediction rate of about 90%, a figure higher than using other conventional machine learning techniques. While preliminary, the results show the possible inter-dependence between the viewing and torso directions, and with richer dataset and more parameters, a more accurate level of prediction seems possible.	187.96216476372467
748.	With the continuous development of information technology, the demand for security and safety is gradually improving. For the consideration of security, face recognition has been studied for many decades. With the development of information technology, face recognition is widely used in our daily life, especially in security systems, information security, human-computer interaction. Researches are committed to improving the recognition accuracy and response speed of the face recognition system. The state-of-art of face recognition has been significantly improved by the appearance of deep learning. Although these systems perform well on large amounts of web collected facial data, the performance and accuracy are still limited when they are applied in actual scenarios. There is still a long way to go to improve the recognition accuracy of face recognition system in real scenarios. This paper gives a comprehensive description of a series of face recognition methods. In this paper, we introduce the definition and development of face recognition, and also indicate main challenges in this domain. Furthermore, some classical popular methods in the development of face recognition technology are described in detail. Finally, the application of face recognition technology will be introduced.	187.9621135909218
749.	As the new cases of COVID-19 are growing every daysince January 2020, the major way to control the spread wasthrough early diagnosis. Prevention and early diagnosis are the key strategies followed by most countries. This study presents the perspective of different modes of transmission of coronavirus,especially during clinical practices and among the pediatrics. Further, the diagnostic methods and the advancement of the computerized tomography have been discussed. Droplets, aerosol, and close contact are thesignificantfactors to transfer the infection to the suspect. This study predicts the possible transmission of the virus through medical practices such as ophthalmology, dental, and endoscopy procedures. With regard to pediatric transmission, as of now, only afew child fatalities had been reported. Childrenusually respond to the respiratory virus; however, COVID-19 response ison the contrary. The possibility of getting infected is minimal for the newborn. There has been no asymptomatic spread in children until now. Moreover, breastfeedingwould not transmit COVID-19, which is encouraging hygiene news for the pediatric. In addition, the current diagnostic methods for COVID-19 including Immunoglobulin M (IgM) and Immunoglobulin G (IgG)and chest computed topography(CT) scan, reverse transcription-polymerase chain reaction (RT-PCR) andimmunochromatographic fluorescence assay, are also discussed in detail. The introduction of artificial intelligence and deep learning algorithmhas the ability to diagnose COVID-19 in precise. However, the developments of a potential technology for the identification of the infection, such as a drone with thermal screening without human intervention, need to be encouraged.	187.9620579824027
750.	Feature selection is an important data preprocessing strategy, has been proven empirically that it contributes to reducing the dimensionality of feature and enhancing the performance of learning algorithms in practice. Typical sparse learning-based models select the features by removing ones that the feature scores are zero. However, linear models puzzle to build the non-linear relations between features and responses. The Deep Neural Network (DNN) has a strong capability to mode the non-linear relations and has been employed to select features. In this paper, we introduce a novel deep Neural network-based Feature Selection (NeuralFS) method to identify features. The new model comprises of a fully-connection network, a decision network, and connect them through a pairwise connected structure. In NeuralFS, the fully-connected network is the crucial structure in NeuralFS that transforms the features into their corresponding scores, and the decision network is the final structure that performs classification or regression. The pairwise connected can be regarded as a "bridge" to connect the two networks, and its weights are fixed as the normalized input as well as it is un-trainable during model training. After optimizing, the feature scores can be obtained by calculating the output of the fully-connected network. NeuralFS takes advantage of the deep network to model the non-linearity, and also make features scores sparse without the sparse regularization technology. We apply the proposed method to both synthetic datasets and benchmark datasets to prove its effectiveness. (C) 2020 Elsevier B.V. All rights reserved.	187.96200550001493
751.	Several works have studied clustering strategies that combine classical clustering algorithms and deep learning methods. These strategies generally improve clustering performance, however deep autoencoder setting issues impede the robustness of these approaches. To alleviate the impact of hyperparameters setting, we propose a model which combines spectral clustering and deep autoencoder strengths in an ensemble framework. Our proposal does not require any pretraining and includes the three following steps: generating various deep embeddings from the original data, constructing a sparse and low-dimensional ensemble affinity matrix based on anchors strategy and applying spectral clustering to obtain the common space shared by multiple deep representations. While the anchors strategy ensures an efficient merging of the encodings, the fusion of various deep representations enables to mitigate the deep networks setting issues. Experiments on various benchmark datasets demonstrate the potential and robustness of our approach compared to state-of-the-art deep clustering methods. (C) 2020 Elsevier Ltd. All rights reserved.	187.9619598112523
752.	This article provides a universal and tractable methodology based on deep reinforcement learning to implement the equal risk pricing framework for financial derivatives pricing under very general conditions. The equal risk pricing framework entails solving for a derivative price which equates the optimally hedged residual risk exposure associated, respectively, with the long and short positions in the contingent claim. The solution to the hedging optimization problem considered, which is inspired from the [Marzban, S., Delage, E. and Li, J.Y., Equal risk pricing and hedging of financial derivatives with convex risk measures. arXiv preprint arXiv:2002.02876, 2020.] framework relying on convex risk measures, is obtained through the use of the deep hedging algorithm of [Buehler, H., Gonon, L., Teichmann, J. and Wood, B., Deep hedging.Q. Finance, 2019,19, 1271-1291]. Consequently, the current paper's approach allows for the pricing and the hedging of a very large number of contingent claims (e.g. vanilla options, exotic options, options with multiple underlying assets) with multiple liquid hedging instruments under a wide variety of market dynamics (e.g. regime-switching, stochastic volatility, jumps). A novel epsilon-completeness measure allowing for the quantification of the residual hedging risk associated with a derivative is also proposed. The latter measure generalizes the one presented in [Bertsimas, D., Kogan, L. and Lo, A.W., Hedging derivative securities and incomplete markets: an epsilon-arbitrage approach.Oper. Res., 2001,49, 372-397.] based on the quadratic penalty. Monte Carlo simulations are performed under a large variety of market dynamics to demonstrate the practicability of our approach, to perform benchmarking with respect to traditional methods and to conduct sensitivity analyses. Numerical results show, among others, that equal risk prices of out-of-the-money options are significantly higher than risk-neutral prices stemming from conventional changes of measure across all dynamics considered. This finding is shown to be shared by different option categories which include vanilla and exotic options.	187.96195255991424
753.	Enterprises increasingly rely on cognitive capabilities to enhance their core business processes by adopting systems that utilize machine learning and deep learning approaches to support cognitive decisions to aid humans responsible for business process execution. Unlike conventional information systems, for which the design and implementation is a much-studied area, the design of cognitive systems and their integration into existing enterprise business processes is less well understood. This results in long drawn-out implementation and adoption cycles, and requires individuals with highly specialized skills. As cognitively-assisted business processes involve human and machine collaboration, non-functional requirements, such as reusability and configurability that are prominent for software system design, must also be addressed at the enterprise level. Supporting processes may emerge and evolve over time to monitor, evaluate, adjust, or modify these cognitively-enhanced business processes. In this paper, we utilize a goal-oriented approach to analyze the requirements for designing cognitive systems for simplified adoption in enterprises, which are then used to guide and inform the design of a process architecture for cognitive business operations.	187.96186924566462
754.	Recently, convolution neural network (CNN) has been widely used in single image super-resolution (SR). However, the traditional network structure has the problems of fewer convolution layers and slow convergence speed. In this paper, an image super-resolution method based on deep residual network is proposed. Through the deepening of the network structure, more receptive fields are obtained. Thus, more pixel information is utilized to improve the reconstruction accuracy of the model. The feature extraction process is carried out directly in low resolution space, and the images are sampled by shuffling the pixels at the end of the network. The learning method combining global residual and local residual is used to improve the convergence speed of the network while recovering the high-frequency details of the images. In order to make full use of image feature information, feature maps extracted from different residual blocks are fused. In addition, parametric rectified linear unit (PReLU) is used as the activation function, and the Adam optimization method is used to further improve the reconstruction effect. The experimental results of benchmark datasets show that the proposed method is superior to other methods in subjective visual effects and objective evaluation indicators.	187.9618532795103
755.	As technology continues to scale aggressively, Sub-Resolution Assist Features (SRAF) are becoming an increasingly key resolution enhancement technique (RET) to maximize the process window enhancement. For the past few technology generations, lithographers have chosen to use a rules-based (RB-SRAF) or a model-based (MB-SRAF) approach to place assist features on the design. The inverse lithography solution, which provides the maximum process window entitlement, has always been out of reach for full-chip applications due to its very high computational cost. ASML has developed and demonstrated a deep learning SRAF placement methodology, Newron (TM) SRAF, which can provide the performance benefit of an inverse lithography solution while meeting the cycle time requirements for full-chip applications [1]. One of the biggest challenges for a deep learning approach is pattern selection for neural network training. To ensure pattern coverage for maximum accuracy while maintaining turn-around time (TAT,) a deep-learning-based Auto Pattern Selection (APS) tool is evaluated. APS works in conjunction with Newron SRAF to provide the optimal lithography solution. In this paper, Newron SRAF is used on a DRAM layer. A Deep Convolutional Neural Network (DCNN) is trained using the target images and Continuous Transmission Mask (CTM) images. CTM images are gray tone images that are fully optimized by the Tachyon inverse mask optimization engine. Representative patterns selected by APS are used to train the neural network. The trained neural network generates SRAFs on the full-chip and then Tachyon OPC+ is performed to correct main and SRAF simultaneously. The neural network trained by APS patterns is compared with those trained by patterns from manual selection and multiple random selections to demonstrate its robustness on pattern coverage. Tachyon Hierarchical OPC+ (HScan+) is used to apply Newron SRAF at full-chip level in order to keep consistency and increase speed. Full-chip simulation results from Newron SRAF are compared with the baseline OPC flow using RB-SRAF and MB-SRAF. The Newron SRAF flow shows significant improvements in NILS and PV band over the baseline flows. This whole flow including APS, Newron SRAF and full-chip HScan+ OPC enables the inverse mask optimization on full-chip level to achieve superior mask performance with production-affordable TAT.	187.9618007740507
756.	Just like many other topics in computer vision, image classification has achieved significant progress recently by using deep learning neural networks, especially the Convolutional Neural Networks (CNNs). Most of the existing works focused on classifying very clear natural images, evidenced by the widely used image databases such as Caltech-256, PASCAL VOCs and ImageNet. However, in many real applications, the acquired images may contain certain degradations that lead to various kinds of blurring, noise, and distortions. One important and interesting problem is the effect of such degradations to the performance of CNN-based image classification and whether degradation removal helps CNN-based image classification. More specifically, we wonder whether image classification performance drops with each kind of degradation, whether this drop can be avoided by including degraded images into training, and whether existing computer vision algorithms that attempt to remove such degradations can help improve the image classification performance. In this paper, we empirically study those problems for nine kinds of degraded images - hazy images, motion-blurred images, fish-eye images, underwater images, low resolution images, salt-and-peppered images, images with white Gaussian noise, Gaussian-blurred images and out-of-focus images. We expect this work can draw more interests from the community to study the classification of degraded images.	187.96180045796746
757.	Compressed sensing (CS) aims to precisely reconstruct the original signal from under-sampled measurements, which is a typical ill-posed problem. Solving such a problem is challenging and generally needs to incorporate suitable priors about the underlying signals. Traditionally, these priors are hand-crafted and the corresponding approaches generally have limitations in expressive capacity. In this paper, a nonconvex optimization inspired multi-scale reconstruction network is developed for block-based CS, abbreviated as iPiano-Net, by unfolding the classic iPiano algorithm. In iPiano-Net, a block-wise inertial gradient descent interleaves with an image-level network-inducing proximal mapping to exploit the local block and global content information alternately. Therein, network-inducing proximal operators can be adaptively learned in each module, which can efficiently characterize image priors and improve the modeling capacity of iPiano-Net. Such learned image-level priors can suppress blocky artifacts and noises/corruptions while preserving the global information. Different from existing discriminative CS reconstruction models trained with specific measurement ratios, an effective single model is learned to handle CS reconstruction with several measurement ratios even the unseen ones. Experimental results demonstrate that the proposed approach is substantially superior to previous CS methods in terms of Peak Signal to Noise Ratio (PSNR) and visual quality, especially at low measurement ratios. Meanwhile, it is robust to noise while maintaining comparable execution speed.	187.9617601639627
758.	Simulations of biological macromolecules play an important role in understanding the physical basis of a number of complex processes such as protein folding. However, even with increasing computational power and evolution of specialized architectures, the ability to simulate protein folding at atomistic scales still remains challenging. This stems from the dual aspects of high dimensionality of protein conformational landscapes, and the inability of atomistic molecular dynamics (MD) simulations to sufficiently sample these landscapes to observe folding events. Machine learning/deep learning (ML/DL) techniques, when combined with atomistic MD simulations offer the opportunity to potentially overcome these limitations by: (1) effectively reducing the dimensionality of MD simulations to automatically build latent representations that correspond to biophysically relevant reaction coordinates (RCs), and (2) driving MD simulations to automatically sample potentially novel conformational states based on these RCs. We examine how coupling DL approaches with MD simulations can fold small proteins effectively on supercomputers. In particular, we study the computational costs and effectiveness of scaling DL-coupled MD workflows by folding two prototypical systems, viz., Fs-peptide and the fast-folding variant of the villin head piece protein. We demonstrate that a DL driven MD workflow is able to effectively learn latent representations and drive adaptive simulations. Compared to traditional MD-based approaches, our approach achieves an effective performance gain in sampling the folded states by at least 2x. Together, our study provides quantitative basis to understand how DL driven MD simulations, can lead to effective performance gains and reduced times to solution on supercomputing resources.	187.9617505533596
759.	Photoplethysmography (PPG) has shown its great potential for noninvasive health monitoring, but its application in wearable devices is largely impeded due to its extreme vulnerability to motion artifacts. In this article, we proposed a new stochastic modeling based nonlinear Bayesian filtering framework for the recovery of corrupted PPG waveform under strenuous physical exercise in wearable health-monitoring devices. A deep recurrent neural network was first recruited for accurate cardiac-period segmentation of corrupted PPG signals. Then, a stochastic model was applied to extract waveform details from clean PPG pulses, and was further derived into a system-state space. Following this was an extended Kalman filter using the state-space structured by modeling. The covariance of measurement noise was estimated by motion-related information to adjust it into the real physical environment adaptively. Comparison results with state-of-the-art methods on a wearable-device-based 48-subject data set showed the outstanding performance of the proposed denoising framework, with period-segmentation sensitivity and precision higher than 99.1%, instantaneous heart rate (HR) error lower than 2 beats/min, average HR error down to 1.14 beats/min, and recovery accuracy of waveform details significantly improved (p < 0.05). This framework is the first PPG denoising strategy that introduces waveform-modeling methods to ensure detail recovery, and a great example of algorithm fusion between stochastic signal processing and emerging deep learning methods for time-sequential biomedical signal processing.	187.9617428456201
760.	Reliability and stability have been treated as the major requirements for the Business Support System (BSS) in telecommunications networks. It is crucial and essential for service providers to maintain good operating state of the BSS. In this article, we aim at system error prediction for a BSS, i.e., we predict occurrences of the abnormal state or behavior of the BSS. Because the occurrences of system errors are rare events in the BSS (i.e., the dataset of system status is highly imbalanced), it is highly challenging to use machine learning or deep learning algorithms to predict system error for the BSS. To address this challenge, we propose a machine learning-based framework for the system error prediction and a Frequency-based Feature Creation (FFC) algorithm to create new features to improve prediction. By adding the time-series information created by the existing features, the proposed FFC can amplify the effects of important features. Our experimental results show that the FFC significantly improves the prediction performance for the Random Forest algorithm.	187.96172584723587
761.	In many applications of tomography, the acquired data are limited in one or more ways due to unavoidable experimental constraints. In such cases, popular direct reconstruction algorithms tend to produce inaccurate images, and more accurate iterative algorithms often have prohibitively high computational costs. Using machine learning to improve the image quality of direct algorithms is a recently proposed alternative, for which promising results have been shown. However, previous attempts have focused on using encoder-decoder networks, which have several disadvantages when applied to large tomographic images, preventing wide application in practice. Here, we propose the use of the Mixed-Scale Dense convolutional neural network architecture, which was specifically designed to avoid these disadvantages, to improve tomographic reconstruction from limited data. Results are shown for various types of data limitations and object types, for both simulated data and large-scale real-world experimental data. The results are compared with popular tomographic reconstruction algorithms and machine learning algorithms, showing that Mixed-Scale Dense networks are able to significantly improve reconstruction quality even with severely limited data, and produce more accurate results than existing algorithms.	187.96165164811754
762.	Deep reinforcement learning (RL) has achieved outstanding results in recent years. This has led to a dramatic increase in the number of applications and methods. Recent works have explored learning beyond single-agent scenarios and have considered multiagent learning (MAL) scenarios. Initial results report successes in complex multiagent domains, although there are several challenges to be addressed. The primary goal of this article is to provide a clear overview of current multiagent deep reinforcement learning (MDRL) literature. Additionally, we complement the overview with a broader analysis: (i) we revisit previous key components, originally presented in MAL and RL, and highlight how they have been adapted to multiagent deep reinforcement learning settings. (ii) We provide general guidelines to new practitioners in the area: describing lessons learned from MDRL works, pointing to recent benchmarks, and outlining open avenues of research. (iii) We take a more critical tone raising practical challenges of MDRL (e.g., implementation and computational demands). We expect this article will help unify and motivate future research to take advantage of the abundant literature that exists (e.g., RL and MAL) in a joint effort to promote fruitful research in the multiagent community.	187.96136177305084
763.	PURPOSE: Epidemiological evidence suggests an increased risk of cancer related to computed tomography (CT) scans, with children exposed to greater risk. The purpose of this work is to test the reliability of a linear Boltzmann transport equation (LBTE) solver for rapid and patient-specific CT dose estimation. This includes building a flexible LBTE framework for modeling modern clinical CT scanners and to validate the resulting dose maps across a range of realistic scanner configurations and patient models. METHODS: In this study, computational tools were developed for modeling CT scanners, including a bowtie filter, overrange collimation, and tube current modulation. The LBTE solver requires discretization in the spatial, angular, and spectral dimensions, which may affect the accuracy of scanner modeling. To investigate these effects, this study evaluated the LBTE dose accuracy for different discretization parameters, scanner configurations, and patient models (male, female, adults, pediatric). The method used to validate the LBTE dose maps was the Monte Carlo code Geant4, which provided ground truth dose maps. LBTE simulations were implemented on a GeForce GTX 1080 graphic unit, while Geant4 was implemented on a distributed cluster of CPUs. RESULTS: The agreement between Geant4 and the LBTE solver quantifies the accuracy of the LBTE, which was similar across the different protocols and phantoms. The results suggest that 18 views per rotation provides sufficient accuracy, as no significant improvement in the accuracy was observed by increasing the number of projection views. Considering this discretization, the LBTE solver average simulation time was approximately 30s. However, in the LBTE solver the phantom model was implemented with a lower voxel resolution with respect to Geant4, as it is limited by the memory of the GPU. Despite this discretization, the results showed a good agreement between the LBTE and Geant4, with root mean square error of the dose in organs of approximately 3.5% for most of the studied configurations. CONCLUSIONS: The LBTE solver is proposed as an alternative to Monte Carlo for patient-specific organ dose estimation. This study demonstrated accurate organ dose estimates for the rapid LBTE solver when considering realistic aspects of CT scanners and a range of phantom models. Future plans will combine the LBTE framework with deep learning autosegmentation algorithms to provide near real-time patient-specific organ dose estimation.	187.9612570514736
764.	Tuberculosis (TB) is determined as a major health threat resulting in approximately 1.8 million people died in 2015 in most of the low and middle income countries. Many of those deaths could have been prevented if TB had been diagnosed and treated at an earlier stage. Nevertheless, recent advanced diagnosis techniques such as the methods of frontal thoracic radiographs have been still cost prohibitive for mass adoption due to the need of individual analysis of each radiograph by properly experienced radiologists. In addition, current outperformances of deep learning accomplish significant results for classification tasks on diverse domains, but its capability remains limited for tuberculosis detection. Therefore, in this study, we examine the efficiency of deep convolutional neural networks (DCNNs) for detecting TB on chest radiographs using public ChestXray14 as training dataset and Montgomery and Shenzhen as two external testing datasets. Multiple preprocessing techniques, tSNE visualization and data augmentation are first performed. Three different pre-trained DCNNs, namely ResNet152, Inception-ResNet and DenseNet121 models are then used to classify X-ray images as having manifestations of pulmonary TB or as healthy. We observe that appropriate data augmentation techniques are able to further increase accuracies of DCNNs. We achieve the best classifier having an average AUC of 0.95 with DenseNet121 while 0.91 and 0.77 with Inception-ResNet and ResNet121, respectively.	187.96115138139442
765.	This paper studies the performance of a convolutional neural network (CNN) trained to learn the behavior of a vehicle using data from a simulator that allows real-time information gathering from vehicle chassis, machine position and speed. The network uses information from the front-facing, right and right cameras, the car's position on the lane and its speed. This approach proves to be quite effective: with a minimum of driving time taken directly from proper driving simulations in the form of a game, the system learns to drive on a marked strip road. The network automatically learns the internal representations of the necessary processing steps, such as the detection of useful road features, required speed, and track position. Different types of activation functions are used, and it is noticed that the exponential linear unit (ELU) activation function leads to improved learning compared to other activation functions.	187.96110431359585
766.	This paper introduces the idea of using deep fully convolutional neural networks for pixel-level defect detection in concrete infrastructure systems. Although coarse patch-level deep learning crack detection models abound in the literature and have shown promise, the coarse level of detail provided, together with the requirement for fixed-size input images, significantly detract from their applicability and usefulness for refined damage analysis. The deep fully convolutional model for crack detection introduced in this paper (CrackPix) leverages well-known image classification architectures for dense predictions by transforming their fully connected layers into convolutional filters. A transposed convolution layer is then used to upsample and resize the resulting prediction heatmap to the size of the input images, thus providing pixel-level predictions. To develop and train these models, a concrete crack image data set was collected and carefully annotated at the pixel level and was then used to train the model. Sensitivity analysis showed that CrackPix was capable of correctly detecting over 92% of crack pixels and 99.9% of noncrack pixels in the validation set. The model performance was then compared against a state-of-the-art patchwise model, as well as traditional edge detection and adaptive thresholding alternatives, and its advantages were illustrated. The success of CrackPix, which enables the quantification of crack characteristics (e.g., width and length) in concrete structures, provides a key step toward automated inspection and quality assurance for infrastructure in future smart cities.	187.96104262146204
767.	In recent years, fully convolutional neural network (FCN) has broken all records in various vision task. It also achieves great performance in salient object detection. However, most of the state-of-the-art methods have suffered from the challenge of precisely segmenting the entire salient object with uniform region and explicit boundary and effectively suppressing the backgrounds on complex images. There is still a large room for improvement over the FCN-based saliency detection approaches. In this paper, we propose an attention and boundary guided deep neural network for salient object detection to better locate and segment the salient objects with uniform interior and explicit boundary. A channel-wise attention module is utilized to emphasize the important regions, which selects the important feature channels and assigns large weights to them. A boundary information localization module is proposed for suppressing the irrelevant boundary information to better locate and explore the useful structure of objects. The proposed approach achieves state-of-the-art performance on four well-known benchmark datasets. (C) 2020 Elsevier Ltd. All rights reserved.	187.96099726619502
768.	Counting humans is an essential part of many people-centric applications. In this paper, we propose CrossCount: an accurate deep-learning-based human count estimator that uses a single WiFi link to estimate the human count in an area of interest. The main idea is to depend on the temporal link-blockage pattern as a discriminant feature that is more robust to wireless channel noise than the signal strength, hence delivering a ubiquitous and accurate human counting system. As part of its design, CrossCount addresses a number of deep learning challenges such as class imbalance and training data augmentation for enhancing the model generalizability. Implementation and evaluation of CrossCount in multiple testbeds show that it can achieve a human counting accuracy to within a maximum of 2 persons 100% of the time. This highlights the promise of CrossCount as a ubiquitous crowd estimator with nonlabor-intensive data collection from off-the-shelf devices.	187.960994183445
769.	Different ages are closely related especially among the adjacent ages because aging is a slow and extremely non-stationary process with much randomness. To explore the relationship between the real age and its adjacent ages, an age group-n encoding (AGEn) method is proposed in this paper. In our model, adjacent ages are grouped into the same group and each age corresponds to n groups. The ages grouped into the same group would be regarded as an independent class in the training stage. On this basis, the original age estimation problem can be transformed into a series of binary classification sub-problems. And a deep Convolutional Neural Networks (CNN) with multiple classifiers is designed to cope with such sub-problems. Later, a Local Age Decoding (LAD) strategy is further presented to accelerate the prediction process, which locally decodes the estimated age value from ordinal classifiers. Besides, to alleviate the imbalance data learning problem of each classifier, a penalty factor is inserted into the unified objective function to favor the minority class. To compare with state-of-the-art methods, we evaluate the proposed method on FG-NET. MORPH II, CACD and Chalearn LAP 2015 databases and it achieves the best performance.	187.96099247058265
770.	The use of IoT (Internet of Things) technology for the management of pet dogs left alone at home is increasing. This includes tasks such as automatic feeding, operation of play equipment, and location detection. Classification of the vocalizations of pet dogs using information from a sound sensor is an important method to analyze the behavior or emotions of dogs that are left alone. These sounds should be acquired by attaching the IoT sound sensor to the dog, and then classifying the sound events (e.g., barking, growling, howling, and whining). However, sound sensors tend to transmit large amounts of data and consume considerable amounts of power, which presents issues in the case of resource-constrained IoT sensor devices. In this paper, we propose a way to classify pet dog sound events and improve resource efficiency without significant degradation of accuracy. To achieve this, we only acquire the intensity data of sounds by using a relatively resource-efficient noise sensor. This presents issues as well, since it is difficult to achieve sufficient classification accuracy using only intensity data due to the loss of information from the sound events. To address this problem and avoid significant degradation of classification accuracy, we apply long short-term memory-fully convolutional network (LSTM-FCN), which is a deep learning method, to analyze time-series data, and exploit bicubic interpolation. Based on experimental results, the proposed method based on noise sensors (i.e., Shapelet and LSTM-FCN for time-series) was found to improve energy efficiency by 10 times without significant degradation of accuracy compared to typical methods based on sound sensors (i.e., mel-frequency cepstrum coefficient (MFCC), spectrogram, and mel-spectrum for feature extraction, and support vector machine (SVM) and k-nearest neighbor (K-NN) for classification).	187.9609826744169
771.	To solve the problem of fuzziness and uncertainty of traffic states in signalized intersection, a method was proposed for estimating traffic condition based on stacked de-noising auto-encoder model. The simulation data and empirical data were used to train the model, and the K-means clustering method was used to determine the traffic state thresholds and the data were divided into three categories based on the threshold values. Relevant features based on the reconstruction theory of de-noising auto-encoder were automatically extracted, and unsupervised greedy layer-wise pre-training and supervised fine-tuning were utilized to train the deep auto-encoder network, so that it had good robust performance on obtaining the traffic state characters with low quality in the complex environment. From the experimental results, the proposed method obtains an accuracy of 91.5% in simulation data and 88% in empirical data, which is better by 7.1% than using decision tree model.	187.96089880116543
772.	Monitoring student knowledge states or skill acquisition levels known as knowledge tracing, is a fundamental part of intelligent tutoring systems. Despite its inherent challenges, recent deep neural networks based knowledge tracing models have achieved great success, which is largely from models' ability to learn sequential dependencies of questions in student exercise data. However, in addition to sequential information, questions inherently exhibit side relations, which can enrich our understandings about student knowledge states and has great potentials to advance knowledge tracing. Thus, in this paper, we exploit side relations to improve knowledge tracing and design a novel framework DTKS. The experimental results on real education data validate the effectiveness of the proposed framework and demonstrate the importance of side information in knowledge tracing.	187.96087151879334
773.	Stock market prediction is of great importance for financial analysis. Traditionally, many studies only use the news or numerical data for the stock market prediction. In the recent years, in order to explore their complementary, some studies have been conducted to equally treat dual sources of information. However, numerical data often play a much more important role compared with the news. In addition, the existing simple combination cannot exploit their complementarity. In this paper, we propose a numerical-based attention (NBA) method for dual sources stock market prediction. Our major contributions are summarized as follows. First, we propose an attention-based method to effectively exploit the complementarity between news and numerical data in predicting the stock prices. The stock trend information hidden in the news is transformed into the importance distribution of numerical data. Consequently, the news is encoded to guide the selection of numerical data. Our method can effectively filter the noise and make full use of the trend information in news. Then, in order to evaluate our NBA model, we collect news corpus and numerical data to build three datasets from two sources: the China Security Index 300 (CSI300) and the Standard & Poor's 500 (S&P500). Extensive experiments are conducted, showing that our NBA is superior to previous models in dual sources stock price prediction.	187.9608223033827
774.	We introduce deep neural networks for scanpath and saliency prediction trained on 360-degree images. The scanpath prediction model called SaltiNet is based on a temporal-aware novel representation of saliency information named the saliency volume. The first part of the network consists of a model trained to generate saliency volumes, whose parameters are fit by back-propagation using a binary cross entropy (BCE) loss over downsampled versions of the saliency volumes. Sampling strategies over these volumes are used to generate scanpaths over the 360-degree images. Our experiments show the advantages of using saliency volumes, and how they can be used for related tasks. We also show how a similar architecture achieves state-of-the-art performance for the related task of saliency map prediction. Our source code and trained models available at https://github.com/massens/saliency-360salient-2017.	187.96069273922066
775.	In this paper, we introduce a 3D convolutional neural network (CNN)-based method to segment point clouds obtained by mobile laser scanning (MLS) sensors into nine different semantic classes, which can be used for high definition city map generation. The main purpose of semantic point labeling is to provide a detailed and reliable background map for self-driving vehicles (SDV), which indicates the roads and various landmark objects for navigation and decision support of SDVs. Our approach considers several practical aspects of raw MLS sensor data processing, including the presence of diverse urban objects, varying point density, and strong measurement noise of phantom effects caused by objects moving concurrently with the scanning platform. We also provide a new manually annotated MLS benchmark set called SZTAKI CityMLS, which is used to evaluate the proposed approach, and to compare our solution to various reference techniques proposed for semantic point cloud segmentation. Apart from point level validation we also present a case study on Lidar-based accurate self-localization of SDVs in the segmented MLS map.	187.96064685580646
776.	It is a crucial problem to process abbreviation in the field of natural language processing. The most commonly used way to cope with this problem is to construct the reference database by predicting the abbreviation through its fully expanded form. Previous work on abbreviation prediction mostly rely on traditional machine learning algorithms, which inevitably requires a large number of manual annotations or expert knowledge to establish a feature system. In this paper, a neural network model based on CNN-BLSTM-CRF is proposed, which can predict Chinese abbreviations better without relying too much on the feature system: Firstly, convolutional neural network extracts phrase and Chinese character information from the fully expanded form, and then BLSTM-CRF deep network is constructed to annotate the fully expanded form, so as to extract its corresponding abbreviation form. The experimental results show that the method in this paper can perform better than the state-of-art method in traditional machine learning, and the results provide a reference for abbreviation research and the construction of resource repository.	187.96060057173972
777.	Biometric systems have the goal of measuring and analyzing the unique physical or behavioral characteristics of an individual. The main feature of biometric systems is the use of bodily structures with distinctive characteristics. In the literature, there are biometric systems that use physiological features (fingerprint, iris, palm print, face, etc.) as well as systems that use behavioral characteristics (signature, walking, speech patterns, facial dynamics, etc.) Recently, facial biometrics has been one of the most preferred biometric data since it generally does not require the cooperation of the user and can be obtained without violating the personal private space. In this paper, the methods used to obtain and classify facial biometric data in the literature have been summarized. We give a taxonomy of image-based and video-based face recognition methods, outline the major historical developments, and the main processing steps. Popular data sets that have been used for face recognition by researchers are also reviewed. We also cover the recent deep-learning based methods for face recognition and point out possible directions for future research. (C) 2020 Elsevier Inc. All rights reserved.	187.96056496638857
778.	With the continuous development of financial markets and the gradual improvement of the financial system, people participate in financial market investment. The interest in capital is also growing, and it is accompanied by a strong demand for accurate and effective financial information services. So how to accurately predict the trend of stocks has become a focus of attention. In this paper, based on the traditional method ARIMA, the corresponding RNN (LSTM) model is proposed for the stock time series prediction problem, and its application situation is further analyzed and optimized, so that it can better explore the change law of stock data. And by setting the corresponding experimental test model method on the stock forecasting task performance. The research and evaluation of the model method demonstrates the good performance of the deep learning model and the ARIMA model in the stock time series forecasting task. The error between the stock forecasting result and the real value of each model method is at a low level. In comparison with the prediction effects of model methods such as Prophet, the RNN model proposed in this paper is closer to the real market performance, and has achieved a significantly better prediction effect than the comparison method.	187.9604927654445
779.	Recently a lot of work has been done on applying deep learning to medical problems. In this paper, we use Brain MRI images to predict parameters like memory scores, body mass index (BMI) and age of a person with simple 3D neural network architectures. We model the problem as both single and multi task. We compare the performance of the two approaches. We also use visualizations to find potential biomarkers for these parameters.	187.96042361842916
780.	The deep space-exploration spacecraft or robot need to perform missions in complex and harsh environments and far away from the earth. Restricted by large communication delay and low-bandwidth, the operator on the earth can't interact frequently with spacecraft or robot. For the reasons, the system design of spacecraft is required to powerfully autonomous and reliable. This paper is based on the application of the sampling robot for extraterrestrial planets, described the design of interactive framework for task-level Command control of robotic systems, establish a standard planning operators(POs) sets that can cover the operating space basically, and shows how to improve system autonomy through interactive planning and learning. Under this framework designation, with a small amount of task-level command and state feedback telemetering between the operator on the earth and the spacecraft, it can meet the mission.	187.9603652948049
781.	Deep learning-based tracking methods have shown favorable performance on multiple benchmarks. However, most of these methods are not designed for real-time video surveillance systems due to the complex online optimization process. In this article, we propose a single-shot adversarial tracker (SAT) to efficiently locate objects of interest in surveillance videos. Specifically, we propose a lightweight convolutional neural network-based generator, which fuses multilayer feature maps to accurately generate the target probability map (TPM) for tracking. To more effectively train the generator, an adversarial learning framework is presented. During the online tracking stage, the learned TPM generator can be directly employed to generate the target probability map corresponding to the searching region in a single shot. The proposed SAT can lead to the average tracking speed of 212 FPS on a single GPU, while still achieving the favorable performance on several popular benchmarks. Furthermore, we also present a variant of SAT by considering both scale estimation and online updating in SAT, which achieves better accuracy than SAT while still maintaining very fast tracking speed (i.e., exceeding 100 FPS).	187.96031869856984
782.	Physical mechanisms of emulsion are generally observed by microscopy images and subjectively identified or judged by experimenters. However, results are not scientific or convincing due to the lack of specific qualitative or quantitative indicators. To overcome this drawback, AlexNet with transfer learning was employed to automatically identify, classify, and quantify three different physical mechanisms of emulsions. The proposed network achieved good performance with high classification accuracy, and fast training and testing time. Feature visualization of the last fully connected layer represents the common and high-level features of each mechanism, especially the feature image of coalescence, which clearly shows a large droplet is consisting of two or more merged small droplets. Moreover, information entropy calculated the disorder level in feature images of each mechanism, and strongest activations demonstrated the proposed network learns correct features. Therefore, these results contribute to a better understanding of emulsion science from the perspective of deep learning.	187.96028309264466
783.	In recent years Convolutional Neural Networks (CNN) have come to dominate many machine learning tasks, specially those related to image analysis, such as object recognition. Herein we explore the possibility of developing image denoising filters by stacking multiple Genetic Programming (GP) syntax trees, in a similar fashion to how CNNs are designed. We test the evolved filters performance in removing additive Gaussian noise. Results show that GP is able to generate a diverse set of feature maps at the 'hidden' layers of the proposed architecture. Although more research is required to validate the suitability of GP for image denoising, our work set the basis for bridging the gap between deep learning and evolutionary computation.	187.9602157379747
784.	In the field of target-based sentiment analysis, the deep neural model combining attention mechanism is a remarkable success. In current research, it is commonly seen that attention mechanism is combined with Long Short-Term Memory (LSTM) networks. However, such neural network-based architectures generally rely on complex computation and only focus on single target. In this paper, we propose a gated hierarchical LSTM (GH-LSTMs) model which combines regional LSTM and sentence-level LSTM via a gated operation for the task of target based sentiment analysis. This approach can distinguish different polarities of sentiment of different targets in the same sentence through a regional LSTM. Furthermore, it is able to concentrate on the long-distance dependency of target in the whole sentence via a sentence-level LSTM. The final results of our experiments on multi-domain datasets of two languages from SemEval 2016 indicate that our approach yields better performance than Support Vector Machine (SVM) and several typical neural network models. A case study of some typical examples also makes a supplement to this conclusion.	187.96016012708685
785.	Image understanding heavily relies on accurate multi-label classification. In recent years, deep learning algorithms have become very successful for such tasks, and various commercial and open-source APIs have been released for public use. However, these APIs are often trained on different datasets, which, besides affecting their performance, might pose a challenge to their performance evaluation. This challenge concerns the different object-class dictionaries of the APIs' training dataset and the benchmark dataset, in which the predicted labels are semantically similar to the benchmark labels but considered different simply because they have different wording in the dictionaries. To face this challenge, we propose semantic similarity metrics to obtain richer understating of the APIs predicted labels and thus their performance. In this study, we evaluate and compare the performance of 13 of the most prominent commercial and open-source APIs in a best-of-breed challenge on the Visual Genome and Open Images benchmark datasets. Our findings demonstrate that, while using traditional metrics, the Microsoft Computer Vision, Imagga, and IBM APIs performed better than others. However, applying semantic metrics also unveil the InceptionResNet-v2, Inception-v3, and ResNet50 APIs, which are trained only with the simple ImageNet dataset, as challengers for top semantic performers. (c) 2020 Elsevier Ltd. All rights reserved.	187.9600417818407
786.	The science and technology is more and more developed. Digital media such as articles, commentary, videos, animations and others on the Internet is becoming more and more important. English semantic analysis has many basic technologies, many applications are also gradually budding in this basic technology. On the other hand, there is no uniform or complete reorganization of the basic technologies in Chinese semantic analysis. Chinese semantic analysis is difficult than English semantic analysis because it is difficult to judge the true meaning of Chinese words and sentences. This study collects articles about common news sites in Taiwan and related to individual stocks. After the data is preprocessed and Skip-gram, each word is converted to word features using Word2Vec. The Lexicon stores the most relevant words around the keyword. In the prediction stage, this study calculates the impact of new articles on the stock price according to the full training lexicon. Finally, this study uses the deep learning approach - LSTM (Long Short-Term Memory) to evaluate the final results. The aim of this study is to adopt anticipatory computing to explore the public mood and emotion from news articles. Then this study can predict the future stock market trend and can be the reference model to the related industries.	187.9599748376226
787.	In this paper, we proposed a 3D fully convolutional network (FCN) incorporating Savitzky-Golay (SG) filtering for prostate segmentation using magnetic resonance images (MRIs). Deep learning methods have achieved promising results in the field of segmentation, especially in semantic segmentation. However, it is not fully applicable to 3D medical images. To better extract the spatial information encoded in the 3D volumetric data, we designed a 3D FCN with long skip connection and the Parametric Rectified Linear Unit (PReLU) being the activation function. To further polish the deep learning based segmentation results, we employed SG filtering as a post-processing step. The SG filter was applied for smoothing and denoising, wherein second-order partial derivatives were taken to extract the edge information and achieve hole filling. In comparison with the 3D FCN without SG filtering, the post-processed results were more smooth, accurate and robust. The proposed method performed superiorly for prostate segmentation over several other state-of-the-art methods.	187.95997104928927
788.	Matching, i.e. determining the exact 2D pose (e.g., position and orientation) of objects, is still one of the key tasks in machine vision applications like robot navigation, measuring, or grasping an object. There are many classic approaches for matching, based on edges or on the pure gray values of the template. In recent years, deep learning has been utilized mainly for more difficult tasks where the objects of interest are from many different categories with high intra-class variations and classic algorithms are failing. In this work, we compare one of the latest deep-learning-based object detectors with classic shape-based matching. We evaluate the methods both on a matching dataset as well as an object detection dataset that contains rigid objects and is thus also suitable for shape-based matching. We show that for datasets of this type, where rigid objects appear with rigid transformations, shape-based matching still outperforms recent object detectors regarding runtime, robustness, and precision if only a single template image per object is used. On the other hand, we show that for the application of object detection, the deep-learning-based approach outperforms the classic approach if annotated data is used for training. Ultimately, the choice of the best suited approach depends on the conditions and requirements of the application.	187.9599268585771
789.	Spiking neural network (SNN) system that uses rank order coding (ROC) as input spike encoding, gener-ally suffers from low recognition accuracy and unnecessary computations that increase complexities. In this paper, we present a Spiking convolutional neural network (Spiking CNN) architecture that signifi-cantly improves recognition accuracy as well as computation efficiencies based on a novel ROC and mod-ified kernel sizes. The proposed ROC generates spike trains based on maximum input value without sorting operations. In addition, as the recognition accuracy is affected by the reduced number of spikes as layers become deeper, the proposed ROC is inserted just before the final layer to increase the number of input spikes. The 2 x 2 pooling kernels are also replaced with 4 x 4 to reduce the network size. The hardware architecture of the proposed Spiking CNN has been implemented using 65 nm CMOS process. Neuron-centric membrane voltage update approach is also efficiently exploited in convolutional and fully connected layers to improve the hardware energy efficiencies. The Spiking CNN processor is seamlessly processing 2.85 K classifications per second with 6.79 uJ/classification. It also achieves 90.2% of recogni-tion accuracy for MNIST dataset using unsupervised learning with STDP. (C) 2020 Elsevier B.V. All rights reserved.	187.9599117999232
790.	There is a biological evidence to prove information is coded through precise timing of spikes in the brain. However, training a population of spiking neurons in a multilayer network to fire at multiple precise times remains a challenging task. Delay learning and the effect of a delay on weight learning in a spiking neural network (SNN) have not been investigated thoroughly. This paper proposes a novel biologically plausible supervised learning algorithm for learning precisely timed multiple spikes in a multilayer SNNs. Based on the spike-timing-dependent plasticity learning rule, the proposed learning method trains an SNN through the synergy between weight and delay learning. The weights of the hidden and output neurons are adjusted in parallel. The proposed learning method captures the contribution of synaptic delays to the learning of synaptic weights. Interaction between different layers of the network is realized through biofeedback signals sent by the output neurons. The trained SNN is used for the classification of spatiotemporal input patterns. The proposed learning method also trains the spiking network not to fire spikes at undesired times which contribute to misclassification. Experimental evaluation on benchmark data sets from the UCI machine learning repository shows that the proposed method has comparable results with classical rate-based methods such as deep belief network and the autoencoder models. Moreover, the proposed method can achieve higher classification accuracies than single layer and a similar multilayer SNN.	187.9598988773132
791.	Businesses are naturally interested in detecting anomalies in their internal processes, because these can be indicators for fraud and inefficiencies. Within the domain of business intelligence, classic anomaly detection is not very frequently researched. In this paper, we propose a method, using autoencoders, for detecting and analyzing anomalies occurring in the execution of a business process. Our method does not rely on any prior knowledge about the process and can be trained on a noisy dataset already containing the anomalies. We demonstrate its effectiveness by evaluating it on 700 different datasets and testing its performance against three state-of-the-art anomaly detection methods. This paper is an extension of our previous work from 2016 (Nolle et al. in Unsupervised anomaly detection in noisy business process event logs using denoising autoencoders. In: International conference on discovery science, Springer, pp 442-456, 2016). Compared to the original publication we have further refined the approach in terms of performance and conducted an elaborate evaluation on more sophisticated datasets including real-life event logs from the Business Process Intelligence Challenges of 2012 and 2017. In our experiments our approach reached an score of 0.72. Furthermore, our approach can be used to analyze the detected anomalies in terms of which event within one execution of the process causes the anomaly.	187.95989493295826
792.	Chromosome classification is critical for karyotyping in abnormality diagnosis. To expedite the diagnosis, we present a novel method named Varifocal-Net for simultaneous classification of chromosome's type and polarity using deep convolutional networks. The approach consists of one global-scale network (G-Net) and one local-scale network (L-Net). It follows three stages. The first stage is to learn both global and local features. We extract global features and detect finer local regions via the G-Net. By proposing a varifocal mechanism, we zoom into local parts and extract local features via the L-Net. Residual learning and multi-task learning strategies are utilized to promote high-level feature extraction. The detection of discriminative local parts is fulfilled by a localization subnet of the G-Net, whose training process involves both supervised and weakly supervised learning. The second stage is to build two multi-layer perceptron classifiers that exploit features of both two scales to boost classification performance. The third stage is to introduce a dispatch strategy of assigning each chromosome to a type within each patient case, by utilizing the domain knowledge of karyotyping. The evaluation results from 1909 karyotyping cases showed that the proposed Varifocal-Net achieved the highest accuracy per patient case () of 99.2 for both type and polarity tasks. It outperformed state-of-the-art methods, demonstrating the effectiveness of our varifocal mechanism, multi-scale feature ensemble, and dispatch strategy. The proposed method has been applied to assist practical karyotype diagnosis.	187.9598810055126
793.	OBJECTIVE: To develop an effective and scalable individual-level patient cost prediction method by automatically learning hidden temporal patterns from multivariate time series data in patient insurance claims using a convolutional neural network (CNN) architecture. METHODS: We used three years of medical and pharmacy claims data from 2013 to 2016 from a healthcare insurer, where data from the first two years were used to build the model to predict costs in the third year. The data consisted of the multivariate time series of cost, visit and medical features that were shaped as images of patients' health status (i.e., matrices with time windows on one dimension and the medical, visit and cost features on the other dimension). Patients' multivariate time series images were given to a CNN method with a proposed architecture. After hyper-parameter tuning, the proposed architecture consisted of three building blocks of convolution and pooling layers with an LReLU activation function and a customized kernel size at each layer for healthcare data. The proposed CNN learned temporal patterns became inputs to a fully connected layer. We benchmarked the proposed method against three other methods: (1) a spike temporal pattern detection method, as the most accurate method for healthcare cost prediction described to date in the literature; (2) a symbolic temporal pattern detection method, as the most common approach for leveraging healthcare temporal data; and (3) the most commonly used CNN architectures for image pattern detection (i.e., AlexNet, VGGNet and ResNet) (via transfer learning). Moreover, we assessed the contribution of each type of data (i.e., cost, visit and medical). Finally, we externally validated the proposed method against a separate cohort of patients. All prediction performances were measured in terms of mean absolute percentage error (MAPE). RESULTS: The proposed CNN configuration outperformed the spike temporal pattern detection and symbolic temporal pattern detection methods with a MAPE of 1.67 versus 2.02 and 3.66, respectively (p<0.01). The proposed CNN outperformed ResNet, AlexNet and VGGNet with MAPEs of 4.59, 4.85 and 5.06, respectively (p<0.01). Removing medical, visit and cost features resulted in MAPEs of 1.98, 1.91 and 2.04, respectively (p<0.01). CONCLUSIONS: Feature learning through the proposed CNN configuration significantly improved individual-level healthcare cost prediction. The proposed CNN was able to outperform temporal pattern detection methods that look for a pre-defined set of pattern shapes, since it is capable of extracting a variable number of patterns with various shapes. Temporal patterns learned from medical, visit and cost data made significant contributions to the prediction performance. Hyper-parameter tuning showed that considering three-month data patterns has the highest prediction accuracy. Our results showed that patients' images extracted from multivariate time series data are different from regular images, and hence require unique designs of CNN architectures. The proposed method for converting multivariate time series data of patients into images and tuning them for convolutional learning could be applied in many other healthcare applications with multivariate time series data.	187.95980086123262
794.	Image synthesis is currently one of the most addressed image processing topic in computer vision and deep learning fields of study. Researchers have tackled this problem focusing their efforts on its several challenging problems, e.g. image quality and size, domain and pose changing, architecture of the networks, and so on. Above all, producing images belonging to different domains by using a single architecture is a very relevant goal for image generation. In fact, a single multi-domain network would allow greater flexibility and robustness in the image synthesis task than other approaches. This paper proposes a novel architecture and a training algorithm, which are able to produce multi-domain outputs using a single network. A small portion of a dataset is intentionally used, and there are no hard-coded labels (or classes). This is achieved by combining a conditional Generative Adversarial Network (cGAN) for image generation and a Meta-Learning algorithm for domain switch, and we called our approach MetalGAN. The approach has proved to be appropriate for solving the multi-domain label-less problem and it is validated on facial attribute transfer, using CelebA dataset.	187.9597624651227
795.	Among many improved convolutional neural network (CNN) architectures in the optical image classification, only a few were applied in synthetic aperture radar (SAR) automatic target recognition (ATR). One main reason is that direct transfer of these advanced architectures for the optical images to the SAR images easily yields overfitting due to its limited data set and less features relative to the optical images. Thus, based on the characteristics of the SAR image, we proposed a novel deep convolutional neural network architecture named umbrella. Its framework consists of two alternate CNN-layer blocks. One block is a fusion of six 3-layer paths, which is used to extract diverse level features from different convolution layers. The other block is composed of convolution layers and pooling layers are mainly utilized to reduce dimensions and extract hierarchical feature information. The combination of the two blocks could extract rich features from different spatial scale and simultaneously alleviate overfitting. The performance of the umbrella model was validated by the Moving and Stationary Target Acquisition and Recognition (MSTAR) benchmark data set. This architecture could achieve higher than 99% accuracy for the classification of 10-class targets and higher than 96% accuracy for the classification of 8 variants of the T72 tank, even in the case of diverse positions located by targets. The accuracy of our umbrella is superior to the current networks applied in the classification of MSTAR. The result shows that the umbrella architecture possesses a very robust generalization capability and will be potential for SAR-ART.	187.9597171059771
796.	Recognition and classification of Figurative Language (FL) is an open problem of Sentiment Analysis in the broader field of Natural Language Processing (NLP) due to the contradictory meaning contained in phrases with metaphorical content. The problem itself contains three interrelated FL recognition tasks: sarcasm, irony and metaphor which, in the present paper, are dealt with advanced Deep Learning (DL) techniques. First, we introduce a data prepossessing framework towards efficient data representation formats so that to optimize the respective inputs to the DL models. In addition, special features are extracted in order to characterize the syntactic, expressive, emotional and temper content reflected in the respective social media text references. These features aim to capture aspects of the social network user's writing method. Finally, features are fed to a robust, Deep Ensemble Soft Classifier (DESC) which is based on the combination of different DL techniques. Using three different benchmark datasets (one of them containing various FL forms) we conclude that the DESC model achieves a very good performance, worthy of comparison with relevant methodologies and state-of-the-art technologies in the challenging field of FL recognition.	187.9597108462939
797.	Learning on machine vision and image processing generally require high-level knowledge on techniques, algorithms and programming skills. The educational process is frequently supported by formal lecture approaches assisted by object lessons or lab activities, and project-based learning methodologies where students engage complex questions, challenges, and problems over a longer period of time. These educational approaches are not effective when applying to learners in robotics study programs or without a programming background where time and motivation are different. To address this concern, this paper presents an educational tool developed to teach the basic principles of machine vision and image processing through the design of short case studies. As the main contribution, the proposed tool allows to shorten the training time required by students-mainly beginners-without the skills in programming and deep understanding of math hidden behind each image operation. This lets to fit theoretical and practical works into short development times. To this end, we conducted an educational experience in robotics subjects with third year students of the computer science and industrial engineering degrees. As a result of this scenario, we statistically compared the teaching and learning issues, the user preferences about the tool and the student academic performance.	187.9596955939498
798.	Background Readmission after discharge from a hospital is disruptive and costly, regardless of the reason. However, it can be particularly problematic for psychiatric patients, so predicting which patients may be readmitted is critically important but also very difficult. Clinical narratives in psychiatric electronic health records (EHRs) span a wide range of topics and vocabulary; therefore, a psychiatric readmission prediction model must begin with a robust and interpretable topic extraction component. Results We designed and evaluated multiple multilayer perceptron and radial basis function neural networks to predict the sentences in a patient's EHR that are associated with one or more of seven readmission risk factor domains that we identified. In contrast to our baseline cosine similarity model that is based on the methodologies of prior works, our deep learning approaches achieved considerably better F1 scores (0.83 vs 0.66) while also being more scalable and computationally efficient with large volumes of data. Additionally, we found that integrating clinically relevant multiword expressions during preprocessing improves the accuracy of our models and allows for identifying a wider scope of training data in a semi-supervised setting. Conclusion We created a data pipeline for using document vector similarity metrics to perform topic extraction on psychiatric EHR data in service of our long-term goal of creating a readmission risk classifier. We show results for our topic extraction model and identify additional features we will be incorporating in the future.	187.95968409895988
799.	The most significant barrier to success in human activity recognition is extracting and selecting the right features. In traditional methods, the features are chosen by humans, which requires the user to have expert knowledge or to do a large amount of empirical study. Newly developed deep learning technology can automatically extract and select features. Among the various deep learning methods, convolutional neural networks (CNNs) have the advantages of local dependency and scale invariance and are suitable for temporal data such as accelerometer (ACC) signals. In this paper, we propose an efficient human activity recognition method, namely Iss2Image (Inertial sensor signal to Image), a novel encoding technique for transforming an inertial sensor signal into an image with minimum distortion and a CNN model for image-based activity classification. Iss2Image converts real number values from the X, Y, and Z axes into three color channels to precisely infer correlations among successive sensor signal values in three different dimensions. We experimentally evaluated our method using several well-known datasets and our own dataset collected from a smartphone and smartwatch. The proposed method shows higher accuracy than other state-of-the-art approaches on the tested datasets.	187.95966538989765
800.	Multi-view representation learning plays a fundamental role in multimedia data analysis. Some specific inter-view alignment principles are adopted in conventional models, where there is an assumption that different views share a common latent subspace. However, when dealing views on diverse semantic levels, the view-specific characteristics are neglected, and the divergent inconsistency of similarity measurements hinders sufficient information sharing. This paper proposes a hybrid deep network by introducing tensor factorization into the multi-view deep auto-encoder. The network adopts skeleton-embedding process for unsupervised multi-view subspace learning. It takes full consideration of view-specific characteristics, and leverages the strength of both shallow and deep architectures for modeling low- and high-level views, respectively. We first formulate the high-level-view semantic distribution as the underlying skeleton structure of the learned subspace, and then infer the local tangent structures according to the affinity propagation of low-level-view geometric correlations. As a consequence, more discriminative subspace representation can be learned from global semantic pivots to local geometric details. Experimental comparisons on three benchmark image datasets show the promising performance and flexibility of our model.	187.95960447315957
801.	Main conclusion Deep learning is a promising technology to accurately select individuals with high phenotypic values based on genotypic data. Genomic selection (GS) is a promising breeding strategy by which the phenotypes of plant individuals are usually predicted based on genome-wide markers of genotypes. In this study, we present a deep learning method, named DeepGS, to predict phenotypes from genotypes. Using a deep convolutional neural network, DeepGS uses hidden variables that jointly represent features in genotypes when making predictions; it also employs convolution, sampling and dropout strategies to reduce the complexity of high-dimensional genotypic data. We used a large GS dataset to train DeepGS and compared its performance with other methods. The experimental results indicate that DeepGS can be used as a complement to the commonly used RR-BLUP in the prediction of phenotypes from genotypes. The complementarity between DeepGS and RR-BLUP can be utilized using an ensemble learning approach for more accurately selecting individuals with high phenotypic values, even for the absence of outlier individuals and subsets of genotypic markers. The source codes of DeepGS and the ensemble learning approach have been packaged into Docker images for facilitating their applications in different GS programs.	187.95956596498223
802.	Face hallucination is a domain-specific super-resolution problem that aims to generate a high-resolution (HR) face image from a low-resolution (LR) input. In contrast to the existing patch-wise super-resolution models that divide a face image into regular patches and independently apply LR to HR mapping to each patch, we implement deep reinforcement learning and develop a novel attention-aware face hallucination (Attention-FH) framework, which recurrently learns to attend a sequence of patches and performs facial part enhancement by fully exploiting the global interdependency of the image. Specifically, our proposed framework incorporates two components: a recurrent policy network for dynamically specifying a new attended region at each time step based on the status of the super-resolved image and the past attended region sequence, and a local enhancement network for selected patch hallucination and global state updating. The Attention-FH model jointly learns the recurrent policy network and local enhancement network through maximizing a long-term reward that reflects the hallucination result with respect to the whole HR image. Extensive experiments demonstrate that our Attention-FH significantly outperforms the state-of-the-art methods on in-the-wild face images with large pose and illumination variations.	187.95947594233252
803.	The modern design of advanced functional materials or surfaces has increasingly undergone miniaturization and integration, so as to implement multiple functions using the same aperture. Metasurfaces, as an emerging kind of artificial functional surface, have provided unprecedented freedom in manipulating electomagnetic (EM) waves upon two-dimensional surfaces. It is desirable that the aperture of metasurfaces can be multiplexed with a number of functions for EM waves. Based on previous research, an artificial neural network-forward design can achieve an inverse design. In this paper, we propose an inverse design method of multiplexing metasurface apertures. A deep learning network (DLN) is trained to serve as a forward model for a genetic algorithm (GA), that is, a deep-leaning-forward genetic algorithm (DLF-GA). With the DLF-GA model, the phase of meta-atoms can be predicted for orthogonally linearly polarized waves simultaneously. The DLN was trained by a data set consisting of 70 000 samples with an accuracy of 95% on the test data. To demonstrate the competency of this method, we demonstrate the design of a multiplexed metasurface that can achieve focusing and diffuse scattering for polarization. The metasurface, which consists of 24 x 24 meta-atoms, can be generated monolithically with the input phase profile. A prototype was fabricated and measured. The predicted, simulated, and measured results are well consistent and underscore the validity of this inverse design method. This method provides an efficient and accurate method for the fast design of multiplexed metasurfaces and will find applications in microwave engineering such as in satellite communications.	187.95944806539413
804.	Due to the aging of electric infrastructures, conventional power grid is being modernized toward smart grid that enables two-way communications between consumer and utility, and thus more vulnerable to cyber-attacks. However, due to the attacking cost, the attack strategy may vary a lot from one operation scenario to another from the perspective of adversary, which is not considered in previous studies. Therefore, in this paper, scenario-based two-stage sparse cyber-attack models for smart grid with complete and incomplete network information are proposed. Then, in order to effectively detect the established cyber-attacks, an interval state estimation-based defense mechanism is developed innovatively. In this mechanism, the lower and upper bounds of each state variable are modeled as a dual optimization problem that aims to maximize the variation intervals of the system variable. At last, a typical deep learning, i.e., stacked auto-encoder, is designed to properly extract the nonlinear and nonstationary features in electric load data. These features are then applied to improve the accuracy for electric load forecasting, resulting in a more narrow width of state variables. The uncertainty with respect to forecasting errors is modeled as a parametric Gaussian distribution. The validation of the proposed cyber-attack models and defense mechanism have been demonstrated via comprehensive tests on various IEEE benchmarks.	187.9593733543627
805.	Image hash codes are produced by binarizing the embeddings of convolutional neural networks (CNN) trained for either classification or retrieval. While proxy embeddings achieve good performance on both tasks, they are non-trivial to binarize, due to a rotational ambiguity that encourages non-binary embeddings. The use of a fixed set of proxies (weights of the CNN classification layer) is proposed to eliminate this ambiguity, and a procedure to design proxy sets that are nearly optimal for both classification and hashing is introduced. The resultinghash-consistent large margin(HCLM) proxies are shown to encourage saturation of hashing units, thus guaranteeing a small binarization error, while producing highly discriminative hash-codes. A semantic extension (sHCLM), aimed to improve hashing performance in a transfer scenario, is also proposed. Extensive experiments show that sHCLM embeddings achieve significant improvements over state-of-the-art hashing procedures on several small and large datasets, both within and beyond the set of training classes.	187.95933661670065
806.	Automatic delineation and measurement of main organs such as liver is one of the critical steps for assessment of hepatic diseases, planning and postoperative or treatment follow-up. However, addressing this problem typically requires performing computed tomography (CT) scanning and complicated post-processing of the resulting scans using slice-by-slice techniques. In this paper, we show that 3D organ shape can be automatically predicted directly from topogram images, which are easier to acquire and have limited exposure to radiation during acquisition, compared to CT scans. We evaluate our approach on the challenging task of predicting liver shape using a generative model. We also demonstrate that our method can be combined with user annotations, such as a 2D mask, for improved prediction accuracy. We show compelling results on 3D liver shape reconstruction and volume estimation on 2129 CT scans (This feature is based on research, and is not commercially available. Due to regulatory reasons its future availability cannot be guaranteed).	187.95932743591615
807.	Introduction: Saliency detection is a fundamental task of computer vision. Its ultimate aim is to localize the objects of interest that grab human visual attention with respect to the rest of the image. A great variety of saliency models based on different approaches was developed since 1990s. In recent years, the saliency detection has become one of actively studied topic in the theory of Convolutional Neural Network (CNN). Many original decisions using CNNs were proposed for salient object detection and, even, event detection. Purpose: A detailed survey of saliency detection methods in deep learning era allows to understand the current possibilities of CNN approach for visual analysis conducted by the human eyes' tracking and digital image processing. Results: A survey reflects the recent advances in saliency detection using CNNs. Different models available in literature, such as static and dynamic 2D CNNs for salient object detection and 3D CNNs for salient event detection are discussed in the chronological order. It is worth noting that automatic salient event detection in durable videos became possible using the recently appeared 3D CNN combining with 2D CNN for salient audio detection. Also in this article, we have presented a short description of public image and video datasets with annotated salient objects or events, as well as the often used metrics for the results' evaluation. Practical relevance: This survey is considered as a contribution in the study of rapidly developed deep learning methods with respect to the saliency detection in the images and videos.	187.9591171886405
808.	In this paper, we present the Metamorphic Testing of an in-use deep learning based forecasting application. The application looks at the past data of system characteristics (e.g. `memory allocation') to predict outages in the future. We focus on two statistical / machine learning based components - a) detection of co-relation between system characteristics and b) estimating the future value of a system characteristic using an LSTM (a deep learning architecture). In total, 19 Metamorphic Relations have been developed and we provide proofs & algorithms where applicable. We evaluated our method through two settings. In the first, we executed the relations on the actual application and uncovered 8 issues not known before. Second, we generated hypothetical bugs, through Mutation Testing, on a reference implementation of the LSTM based forecaster and found that 65.9% of the bugs were caught through the relations.	187.9590580727115
809.	Volatility plays crucial roles in financial markets, such as in derivative pricing, portfolio risk management, and hedging strategies. Therefore, accurate prediction of volatility is critical. We propose a new hybrid long short-term memory (LSTM) model to forecast stock price volatility that combines the LSTM model with various generalized autoregressive conditional heteroscedasticity (GARCH)-type models. We use KOSPI 200 index data to discover proposed hybrid models that combine an LSTM with one to three GARCH-type models. In addition, we compare their performance with existing methodologies by analyzing single models, such as the GARCH, exponential GARCH, exponentially weighted moving average, a deep feedforward neural network (DFN), and the LSTM, as well as the hybrid DFN models combining a DFN with one GARCH-type model. Their performance is compared with that of the proposed hybrid LSTM models. We discover that GEW-LSTM, a proposed hybrid model combining the LSTM model with three GARCH-type models, has the lowest prediction errors in terms of mean absolute error (MAE), mean squared error (MSE), heteroscedasticity adjusted MAE (HMAE), and heteroscedasticity adjusted MSE (HMSE). The MAE of GEW-ISTM is 0.0107, which is 37.2% less than that of the E-DFN (0.017), the model combining EGARCH and DFN and the best model among those existing. In addition, the GEW-LSTM has 57.3%, 24.7%, and 48% smaller MSE, HMAE, and HMSE, respectively. The first contribution of this study is its hybrid LSTM model that combines excellent sequential pattern learning with improved prediction performance In stock market volatility. Second, our proposed model markedly enhances prediction performance of the existing literature by combining a neural network model with multiple econometric models rather than only a single econometric model. Finally, the proposed methodology can be extended to various fields as an integrated model combining time-series and neural network models as well as forecasting stock market volatility. (C) 2018 Elsevier Ltd. All rights reserved.	187.9590021767149
810.	in this work we propose an adaptive and scalable hardware implementation of convolutional Neural Networks. The adaptive hardware model is the result of a design loop that starts with a software implementation relying on standard scanning window and MAC operations. This design is developed into a deterministic, hardware-friendly model which introduces timing, fixed-point representation and a pixel streaming interface. Then finally HDL code is generated and an RTL of the system is created. Each step is analyzed and validated against pre-set objectives using a golden reference from the last step. The proposed system is capable of selective output execution of different data-paths. It allows for real time trade-offs between accuracy for execution time and power. This is achieved by implementing a CNN network through a number of sequential layer blocks. Layer-blocks can effectively be considered standalone networks with differing complexities. Each layer blocks branches off into an output that is independent of the block that follows it. This allows the system to execute partially or fully according to performance requirements. This reconfigurable model trades off accuracy for speed and power, results show a tradeoff in accuracy for a 50% and 70% gain in both speed and power respectfully.	187.95897845097167
811.	Purpose Data augmentation is a common technique to overcome the lack of large annotated databases, a usual situation when applying deep learning to medical imaging problems. Nevertheless, there is no consensus on which transformations to apply for a particular field. This work aims at identifying the effect of different transformations on polyp segmentation using deep learning. Methods A set of transformations and ranges have been selected, considering image-based (width and height shift, rotation, shear, zooming, horizontal and vertical flip and elastic deformation), pixel-based (changes in brightness and contrast) and application-based (specular lights and blurry frames) transformations. A model has been trained under the same conditions without data augmentation transformations (baseline) and for each of the transformation and ranges, using CVC-EndoSceneStill and Kvasir-SEG, independently. Statistical analysis is performed to compare the baseline performance against results of each range of each transformation on the same test set for each dataset. Results This basic method identifies the most adequate transformations for each dataset. For CVC-EndoSceneStill, changes in brightness and contrast significantly improve the model performance. On the contrary, Kvasir-SEG benefits to a greater extent from the image-based transformations, especially rotation and shear. Augmentation with synthetic specular lights also improves the performance. Conclusion Despite being infrequently used, pixel-based transformations show a great potential to improve polyp segmentation in CVC-EndoSceneStill. On the other hand, image-based transformations are more suitable for Kvasir-SEG. Problem-based transformations behave similarly in both datasets. Polyp area, brightness and contrast of the dataset have an influence on these differences.	187.95883470608976
812.	Face re-identification (Re-ID) aims to track the same individuals over space and time with subtle identity class information in automatically detected face images captured by unconstrained surveillance camera views. Despite significant advances of face recognition systems for constrained social media facial images, face Re-ID is more challenging due to poor-quality surveillance face imagery data and remains under-studied. However, solving this problem enables a wide range of practical applications, ranging from law enforcement and information security to business, entertainment and e-commerce. To facilitate more studies on face Re-ID towards practical and robust solutions, a true large scale Surveillance Face Re-ID benchmark (SurvFace) is introduced, characterised by natively low-resolution, motion blur, uncontrolled poses, varying occlusion, poor illumination, and background clutters. This new benchmark is the largest and more importantly the only true surveillance face Re-ID dataset to our best knowledge, where facial images are captured and detected under realistic surveillance scenarios. We show that the current state-of-the-art FR methods are surprisingly poor for face Re-ID. Besides, face Re-ID is generally more difficult in an open-set setting as naturally required in surveillance scenarios, owing to a large number of non-target people (distractors) appearing in open ended scenes. Moreover, the low-resolution problem inherent to surveillance facial imagery is investigated. Finally, we discuss open research problems that need to be solved in order to overcome the under-studied face Re-ID problem. (C) 2020 Elsevier Ltd. All rights reserved.	187.95882243233996
813.	With the ever-increasing demand for location-based services in the indoor environments, Wi-Fi-based positioning technology has attracted much attention in decades of years because of its ubiquitous deployment and low cost. There is the fact that Wi-Fi signal not only changes with the distance away from the target, but also changes with time. To improve positioning accuracy and robustness, we consider both the spatial relation and temporal sequential relation simultaneously, and propose a spatial-temporal positioning algorithm that combines residual network and long short-term memory (LSTM) network. In this algorithm, to avoid the degradation problem, we adopt the residual-based network to extract the spatial features of the Wi-Fi signal at the same time slice. Furthermore, the LSTM is used to extract temporal features of the Wi-Fi signal among successive time slices. Finally, a fully connected layer is used to obtain the final location estimation. Extensive experiments on the IPIN2016 data sets demonstrate that our proposed algorithm can obtain 4.93-, 5.40-, 3.20-, and 4.98-m average positioning error on the UAH, CAR, UJIUB, and UJITI subdata set, respectively. The experimental results show that our proposed algorithm outperforms other state-of-the-art positioning algorithms with better accuracy and robustness.	187.9587785282672
814.	Developing deep neural networks (DNNs) for manifold-valued data sets has gained significant interest of late in the deep learning research community. Examples of manifold-valued data in the medical imaging domain include (but are not limited to) diffusion magnetic resonance imaging, tensor-based morphometry, shape analysis and more. In this paper we present a novel theoretical framework for DNNs to cope with manifold-valued data inputs, taking inspiration from the convolutional neural network (CNN) architecture. We call our network the ManifoldNet. Analogous to vector spaces where convolutions are equivalent to computing weighted means, manifold-valued data convolutions can be defined using the weighted Fr ' echet Mean (wFM). To this end, we present a provably convergent recursive algorithm for computation of the wFM of the given data, where the weights are to be learned. Further, we prove that the proposed wFM layer achieves a contraction mapping and hence the ManifoldNet need not have additional non-linear ReLU units used in standard CNNs to achieve a contraction mapping. Analogous to the equivariance of convolution in Euclidean space to translations, we prove that the wFM is equivariant to the action of the group of isometries admitted by the Riemannian manifold on which the data reside. This equivariance property facilitates weight sharing within the network. We present experiments using the ManifoldNet framework to achieve regression between diffusion MRI scans of Parkinson Disease (PD) patients and clinical information such as their Movement Disorder Society's Unified Parkinson's Disease Rating Scale (MDS-UPDRS) scores. In another experiment, we present results of finding group differences based on brain connectivity at the fiber bundle level between PD and controls.	187.95875905998685
815.	A large amount of digital image material is routinely captured during esophagogastroduodenoscopies but, for the most part, is not used for confirming the diagnosis process of celiac disease which is primarily based on histological examination of biopsies. Recently, considerable effort has been undertaken to make use of image material by developing semi- or fully-automated systems to improve the diagnostic workup. Recently, focus was especially laid on developing state-of-the-art deep learning architectures, exploiting the endoscopist's expert knowledge and on making systems fully automated and thereby completely observer independent. In this work, we summarize recent trends in the field of computer-aided celiac disease diagnosis based on upper endoscopy and discuss about recent progress, remaining challenges, limitations currently prohibiting a deployment in clinical practice and future efforts to tackle them.	187.95874542534614
816.	Multipose face recognition system is one of the recent challenges faced by the researchers interested in security applications. Different researches have been introduced discussing the accuracy improvement of multipose face recognition through enhancing the face detector as Viola-Jones, Real Adaboost, and Cascade Object Detector while others concentrated on the recognition systems as support vector machine and deep convolution neural networks. In this paper, a combined adaptive deep learning vector quantization (CADLVQ) classifier is proposed. The proposed classifier has boosted the weakness of the adaptive deep learning vector quantization classifiers through using the majority voting algorithm with the speeded up robust feature extractor. Experimental results indicate that, the proposed classifier provided promising results in terms of sensitivity, specificity, precision, and accuracy compared to recent approaches in deep learning, statistical, and classical neural networks. Finally, the comparison is empirically performed using confusion matrix to ensure the reliability and robustness of the proposed system compared to the state-of art.	187.95873456199513
817.	This paper presents Vesta, a digital health platform composed of a smart home in a box for data collection and a machine learning based analytic system for deriving health indicators using activity recognition, sleep analysis and indoor localization. This system has been deployed in the homes of 40 patients undergoing a heart valve intervention in the United Kingdom (UK) as part of the EurValve project, measuring patients health and well-being before and after their operation. In this work a cohort of 20 patients are analyzed, and 2 patients are analyzed in detail as example case studies. A quantitative evaluation of the platform is provided using patient collected data, as well as a comparison using standardized Patient Reported Outcome Measures (PROMS) which are commonly used in hospitals, and a custom survey. It is shown how the ubiquitous in-home Vesta platform can increase clinical confidence in self-reported patient feedback. Demonstrating its suitability for digital health studies, Vesta provides deeper insight into the health, well-being and recovery of patients within their home. (C) 2020 The Authors. Published by Elsevier B.V.	187.95872281726787
818.	With the increasing demand for information security and security regulations all over the world, biometric recognition technology has been widely used in our everyday life. In this regard, multimodal biometrics technology has gained interest and became popular due to its ability to overcome a number of significant limitations of unimodal biometric systems. In this paper, a new multimodal biometric human identification system is proposed, which is based on a deep learning algorithm for recognizing humans using biometric modalities of iris, face, and finger vein. The structure of the system is based on convolutional neural networks (CNNs) which extract features and classify images by softmax classifier. To develop the system, three CNN models were combined; one for iris, one for face, and one for finger vein. In order to build the CNN model, the famous pertained model VGG-16 was used, the Adam optimization method was applied and categorical cross-entropy was used as a loss function. Some techniques to avoid overfitting were applied, such as image augmentation and dropout techniques. For fusing the CNN models, different fusion approaches were employed to explore the influence of fusion approaches on recognition performance, therefore, feature and score level fusion approaches were applied. The performance of the proposed system was empirically evaluated by conducting several experiments on the SDUMLA-HMT dataset, which is a multimodal biometrics dataset. The obtained results demonstrated that using three biometric traits in biometric identification systems obtained better results than using two or one biometric traits. The results also showed that our approach comfortably outperformed other state-of-the-art methods by achieving an accuracy of 99.39%, with a feature level fusion approach and an accuracy of 100% with different methods of score level fusion.	187.95844595176473
819.	In this paper, a novel impact load identification method of nonlinear structures by using deep Recurrent Neural Network (RNN) is proposed. The deep RNN model, mainly consisting of two Long Short-Term Memory (LSTM) layers and one bidirectional LSTM (BLSTM) layer, is trained through a large number of dynamic responses and impact loads to learn the complex inverse mapping between structural inputs and outputs. The effectiveness and practicability of the proposed method are verified by three nonlinear cases: damped Duffing oscillator, nonlinear three-degree-of-freedom system and nonlinear composite plate. The results show that the proposed method has the capability for identifying the complex impact load even when the impact location is unknown. Meanwhile, hyperparameters of the deep RNN model and placement scheme of sensors are not highly sensitive to the identification accuracy. (C) 2019 Elsevier Ltd. All rights reserved.	187.95841380073173
820.	To solve the common problem of classification performance restriction caused by big intra-class variations and inter-class similarities in video classification domain, this paper proposes a deep metric learning based video classification method. The proposed method designs a deep network which contains three parts: feature learning, deep metric learning based similarity measure as well as classification. The principle of similarity measure is: Firstly, the Euclidean distance between features is calculated as the semantic distance between samples. Secondly, a margin distributing function is designed to dynamically allocate margin in the basis of the semantic distances. Finally, the difference of the sample semantic distance can be learned by calculating the loss and propagating it backwards so as to the network can automatically focus on the hard negative samples and more fully learn the characteristic of them. With a multi-task learning training method in the training stage, the similarity measure and classification can be learned jointly. Experimental results on UCF101 and HMDB51 show that the proposed method can effectively improve the classification precision.	187.95841303089682
821.	Texture, highlights, and shading are some of many visual cues that allow humans to perceive material appearance in pictures. Designing algorithms able to leverage these cues to recover spatially-varying bi-directional reflectance distribution functions (SVBRDFs) from a few images has challenged computer graphics researchers for decades. I explore the use of deep learning to tackle lightweight appearance capture and make sense of these visual cues. Our networks are capable of recovering per-pixel normals, diffuse albedo, specular albedo and specular roughness from as little as one picture of a flat surface lit by a hand-held flash. We propose a method which improves its prediction with the number of input pictures, and reaches high quality reconstructions with up to 10 images - a sweet spot between existing single-image and complex multi-image approaches. We introduce several innovations on training data acquisition and network design, bringing clear improvement over the state of the art for lightweight material capture.	187.95838794307363
822.	Educators show great interest in participating in social-media communities, such as Twitter, to support their professional development and learning. The majority of the research into Twitter based professional learning communities has investigated why educators choose to use Twitter for professional development and learning and what they actually do in these communities. However, few studies have examined why certain community members remain committed and others gradually drop out. To fill this gap in the research, this study investigated how some key features of online discourse influenced the continued participation of the members of a Twitter based professional learning community. More than 600,000 tweets generated over six years under the hashtag #edchat were gathered. Online discourse was deconstructed to the cognitive dimension, the interactive dimension, and the social dimension. Text-mining methods were then used to automatically identify these dimensions in the tweets. Finally, survival analysis was used to quantify the influences of these dimensions on users' commitment time to the Twitter community. The implications of the results and findings are then discussed. Wanli Xing is an Assistant Professor in Instructional Technology at Texas Tech University, USA with background in learning sciences, statistics, computer science and mathematical modeling. His research interests are educational data mining, learning analytics, and CSCL. Gao Fei is an Associate Professor at Bowling Green State University. Her current research involves examining the types of interaction and learning enabled by online social technologies, designing technology-mediated environments that encourage meaningful social interaction, and exploring pedagogical methods that promote deep learning in such environments.	187.9583869563283
823.	Online Multi-Object Tracking (MOT) has wide applications in time-critical video analysis scenarios, such as robot navigation' and autonomous driving'. In tracking by-detection, a major challenge of online MOT is how to robustly associate noisy object detections on a new video frame with previously tracked objects. This paper aims to build technology that can track a movement of people via surveillance cameras that are located in stores, but not only (theoretically, the algorithm may be applicable to the location of the camera at any premises). The algorithm works with a variety of camera angles that allows. The main innovation of the paper is that algorithm SORT has been updated to consider the difference between datasets used on competitions and the real ones. The difference is that recognition is not perfect in data created by the program. People's contours may be of different size (rectangles corresponding to the same man may differ twice) and some of them may be not recognized The new metric of proximity called "soft-iou" has been introduced in SORT. We have achieved the accuracy of 95% for the daily number of visitors for one of jewelry retail chains This level of accuracy allows applying the algorithm in different areas: not only retail stores, but also shopping centers, sports events, performances, traffic in public transport, etc.	187.95824219737872
824.	Chest x-rays are the most common radiology studies for diagnosing lung and heart disease. Hence, a system for automated pre-reporting of pathologic findings on chest x-rays would greatly enhance radiologists' productivity. To this end, we investigate a deep-learning framework with novel training schemes for classification of different thoracic pathology labels from chest x-rays. We use the currently largest publicly available annotated dataset ChestX-ray14 of 112,120 chest radiographs of 30,805 patients. Each image was annotated with either a 'NoFinding' class, or one or more of 14 thoracic pathology labels. Subjects can have multiple pathologies, resulting in a multi-class, multi-label problem. We encoded labels as binary vectors using k-hot encoding. We study the ResNet34 architecture, pre-trained on ImageNet, where two key modifications were incorporated into the training framework: (1) Stochastic gradient descent with momentum and with restarts using cosine annealing, (2) Variable image sizes for fine-tuning to prevent overfitting. Additionally, we use a heuristic algorithm to select a good learning rate. Learning with restarts was used to avoid local minima. Area Under receiver operating characteristics Curve (AUC) was used to quantitatively evaluate diagnostic quality. Our results are comparable to, or outperform the best results of current state-of-the-art methods with AUCs as follows: Atelectasis:0.81, Cardiomegaly:0.91, Consolidation:0.81, Edema:0.92, Effusion:0.89, Emphysema: 0.92, Fibrosis:0.81, Hernia:0.84, Infiltration:0.73, Mass:0.85, Nodule:0.76, Pleural Thickening:0.81, Pneumonia:0.77, Pneumothorax:0.89 and NoFinding:0.79. Our results suggest that, in addition to using sophisticated network architectures, a good learning rate, scheduler and a robust optimizer can boost performance.	187.95819942496342
825.	Organic synthesis methodology enables the synthesis of complex molecules and materials used in all fields of science and technology and represents a vast body of accumulated knowledge optimally suited for deep learning. While most organic reactions involve distinct functional groups and can readily be learned by deep learning models and chemists alike, regio- and stereoselective transformations are more challenging because their outcome also depends on functional group surroundings. Here, we challenge the Molecular Transformer model to predict reactions on carbohydrates where regio- and stereoselectivity are notoriously difficult to predict. We show that transfer learning of the general patent reaction model with a small set of carbohydrate reactions produces a specialized model returning predictions for carbohydrate reactions with remarkable accuracy. We validate these predictions experimentally with the synthesis of a lipid-linked oligosaccharide involving regioselective protections and stereoselective glycosylations. The transfer learning approach should be applicable to any reaction class of interest. Organic reactions can readily be learned by deep learning models, however, stereochemistry is still a challenge. Here, the authors fine tune a general model using a small dataset, then predict and validate experimentally regio- and stereo-selectivity for various carbohydrates transformations.	187.95812627156295
826.	Weeds in agricultural farms are aggressive growers which compete for nutrition and other resources with the crop and reduce production. The increasing use of chemicals to control them has inadvertent consequences to the human health and the environment. In this work, a novel neural network training method combining semantic graphics for data annotation and an advanced encoder-decoder network for (a) automatic crop line detection and (b) weed (wild millet) detection in paddy fields is proposed. The detected crop lines act as a guiding line for an autonomous weeding robot for inter-row weeding, whereas the detection of weeds enables autonomous intra-row weeding. The proposed data annotation method, semantic graphics, is intuitive, and the desired targets can be annotated easily with minimal labor. Also, the proposed "extended skip network" is an improved deep convolutional encoder-decoder neural network for efficient learning of semantic graphics. Quantitative evaluations of the proposed method demonstrated an increment of 6.29% and 6.14% in mean intersection over union (mIoU), over the baseline network on the task of paddy line detection and wild millet detection, respectively. The proposed method also leads to a 3.56% increment in mIoU and a significantly higher recall compared to a popular bounding box-based object detection approach on the task of wild-millet detection.	187.95810526985454
827.	Unconstrained text recognition is an important computer vision task, featuring a wide variety of different sub-tasks, each with its own set of challenges. One of the biggest promises of deep neural networks has been the convergence and automation of feature extractors from input raw signals, allowing for the highest possible performance with minimum required domain knowledge. To this end, we propose a data-efficient, end-to-end neural network model for generic, unconstrained text recognition. In our proposed architecture we strive for simplicity and efficiency without sacrificing recognition accuracy. Our proposed architecture is a fully convolutional network without any recurrent connections trained with the CTC loss function. Thus it operates on arbitrary input sizes and produces strings of arbitrary length in a very efficient and parallelizable manner. We show the generality and superiority of our proposed text recognition architecture by achieving state-of-the-art results on seven public benchmark datasets, covering a wide spectrum of text recognition tasks, namely: Handwriting Recognition, CAPTCHA recognition, OCR, License Plate Recognition, and Scene Text Recognition. Our proposed architecture has won the ICFHR2018 Competition on Automated Text Recognition on a READ Dataset. (C) 2020 Published by Elsevier Ltd.	187.95810173345248
828.	The development of single cell transcriptome sequencing has allowed researchers the possibility to dig inside the role of the individual cell types in a plethora of disease scenarios. It also expands to the whole transcriptome what before was only possible for a few tenths of antibodies in cell population analysis. More importantly, it allows resolving the permanent question of whether the changes observed in a particular bulk experiment are a consequence of changes in cell type proportions or an aberrant behavior of a particular cell type. However, single cell experiments are still complex to perform and expensive to sequence making bulk RNA-Seq experiments yet more common. scRNA-Seq data is proving highly relevant information for the characterization of the immune cell repertoire in different diseases ranging from cancer to atherosclerosis. In particular, as scRNA-Seq becomes more widely used, new types of immune cell populations emerge and their role in the genesis and evolution of the disease opens new avenues for personalized immune therapies. Immunotherapy have already proven successful in a variety of tumors such as breast, colon and melanoma and its value in other types of disease is being currently explored. From a statistical perspective, single-cell data are particularly interesting due to its high dimensionality, overcoming the limitations of the "skinny matrix" that traditional bulk RNA-Seq experiments yield. With the technological advances that enable sequencing hundreds of thousands of cells, scRNA-Seq data have become especially suitable for the application of Machine Learning algorithms such as Deep Learning (DL). We present here a DL based method to enumerate and quantify the immune infiltration in colorectal and breast cancer bulk RNA-Seq samples starting from scRNA-Seq. Our method makes use of a Deep Neural Network (DNN) model that allows quantification not only of lymphocytes as a general population but also of specific CD8+, CD4Tmem, CD4Th and CD4Tregs subpopulations, as well as B-cells and Stromal content. Moreover, the signatures are built from scRNA-Seq data from the tumor, preserving the specific characteristics of the tumor microenvironment as opposite to other approaches in which cells were isolated from blood. Our method was applied to synthetic bulk RNA-Seq and to samples from the TCGA project yielding very accurate results in terms of quantification and survival prediction.	187.95798292717953
829.	Spoken language understanding(SLU) is an important function module of the dialogue system. Slot filling and intent detection are two key sub-tasks of task-oriented spoken language understanding. In recent years, the methods of joint recognition have become the mainstream methods of spoken language understanding to solve slot filling and intent detection. Since deep neural network has advantages such as strong generalization and autonomous learning characteristics compared with traditional methods. So far, slot filling and intent detection have been developed from traditional methods to deep neural network methods, and the performance has also been significantly improved. This paper introduces the methods of two tasks from the independent model to the joint model. It focuses on the joint modeling methods based on deep neural network, analyzes current problems and future development trend of two sub-tasks.	187.95798113866775
830.	Deep convolutional neural network (DCNN) object detection is a powerful solution in visual perception, but it requires huge computation and communication costs. We proposed a fast and low-power always-on object detection processor that allows visually impaired people to understand their surroundings. We designed an automatic DCNN quantization algorithm that successfully quantizes the data to 8-bit fix-points with 32 values and uses 5-bit indexes to represent them, reducing hardware cost by over 68 & x0025; compared to the 16-bit DCNN, with negligible accuracy loss. A specific hardware accelerator is designed, which uses reconfigurable process engines to realize multi-layer pipelines to significantly reduce or eliminate the off-chip temporary data transfer. A lookup table is used to implement all multiplications in convolutions to reduce the power significantly. The design is fabricated in SMIC 55-nm technology, and the post-layout simulation shows only 68-mw power at 1.1-v voltage with 155 Go/s performance, achieving 2.2 Top/w energy efficiency.	187.95787678003347
831.	Recent head pose estimation techniques are advanced by performing bin classification, where the pre-dicted result is compared against a one-hot classification vector. We argue that the head poses may better be modelled by discrete distribution sampled from a smooth continuous curve rather than one-hot cod-ing or some other kinds of binned classification vector, since pose angles in practice are arbitrary. In this paper, we propose a deep head pose estimation scheme by regressing between predicted probabilistic labels and discrete Gaussian distribution. Such Gaussian distribution aims at modelling the arbitrary state of true head poses and supervises the deep network through maximum mean discrepancy loss. Besides, we also propose a spatial channel-aware residual attention structure for enhancing intrinsic pose features to further improve the prediction accuracy and speed up training convergence. Experiments on two pub-lic datasets AFLW2000 and BIWI show the proposed method outperforms all previous methods, and its individual components yield substantial improvements. (C) 2020 Elsevier B.V. All rights reserved.	187.95785728477816
832.	Metasurfaces is an emerging field that enables the manipulation of light by an ultra-thin structure composed of sub-wavelength antennae and fulfills an important requirement for miniaturized optical elements. Finding a new design for a metasurface or optimizing an existing design for a desired functionality is a computationally expensive and time consuming process as it is based on an iterative process of trial and error. We propose a deep learning (DL) architecture dubbed bidirectional autoencoder for nanophotonic metasurface design via a template search methodology. In contrast with the earlier approaches based on DL, our methodology addresses optimization in the space of multiple metasurface topologies instead of just one, in order to tackle the one to many mapping problem of inverse design. We demonstrate the creation of a Geometry and Parameter Space Library (GPSL) of metasurface designs with their corresponding optical response using our DL model. This GPSL acts as a universal design and response space for the optimization. As an example application, we use our methodology to design a multi-band gap-plasmon based half-wave plate metasurface. Through this example, we demonstrate the power of our technique in addressing the non-uniqueness problem of common inverse design. Our network converges aptly to multiple metasurface topologies for the desired optical response with a low mean absolute error between desired optical response and the optical response of topologies searched. Our proposed technique would enable fast and accurate design and optimization of various kinds of metasurfaces with different functionalities.	187.9577904267041
833.	Human anatomy and physiology classes for pre-nursing students at Gordon State College are taught using the body systems approach, focusing on one organ system in each learning unit. The body systems approach does not always generate a deeper understanding of the interdependence of organ systems. To address this issue we developed an analogy-based lab activity consisting of four modules (Module 1, cranial bone markings; Module 2, cranial nerves; Module 3, facial and neck muscles; and Module 4, inter-relationships that produce common activities, such as smiling, frowning, chewing, olfaction, vision, eyeball movements, gustation, etc.). Unlike traditional lab exercises that follow the body systems approach, this set of lab activities can emphasize the specific interactions between body systems for common body functions, such as smiling. This linking method utilizes a number of the hands-on lab activities featuring text, diagrams, and models. Assessment of these activities demonstrates that students can effectively learn the relationships between different organ systems by using a series of lab activities that emphasize creativity and fun.	187.95771016261824
834.	This research work aims to develop a deep learning-based crop classification framework for remotely sensed time series data.Tobaccois a major revenue generating crop of Khyber Pakhtunkhwa (KP) province of Pakistan, with over 90% of the country'sTobaccoproduction. In order to analyze the performance of the developed classification framework, a pilot sub-region named Yar Hussain is selected for experimentation work. Yar Hussain is a tehsil of district Swabi, within KP province of Pakistan, having highest contribution to the gross production of the KPTobaccocrop. KP generally consists of a diverse crop land with different varieties of vegetation, having similar phenology which makes crop classification a challenging task. In this study, a temporal convolutional neural network (TempCNNs) model is implemented for crop classification, while considering remotely sensed imagery of the selected pilot region with specific focus on theTobaccocrop. In order to improve the performance of the proposed classification framework, instead of using the prevailing concept of utilizing a single satellite imagery, both Sentinel-2 and Planet-Scope imageries are stacked together to assist in providing more diverse features to the proposed classification framework. Furthermore, instead of using a single date satellite imagery, multiple satellite imageries with respect to the phenological cycle ofTobaccocrop are temporally stacked together which resulted in a higher temporal resolution of the employed satellite imagery. The developed framework is trained using the ground truth data. The final output is obtained as an outcome of the SoftMax function of the developed model in the form of probabilistic values, for the classification of the selected classes. The proposed deep learning-based crop classification framework, while utilizing multi-satellite temporally stacked imagery resulted in an overall classification accuracy of 98.15%. Furthermore, as the developed classification framework evolved with specific focus onTobaccocrop, it resulted in bestTobaccocrop classification accuracy of 99%.	187.95765920026795
835.	Gait authentication, especially sensor-based patterns, has been studied by researchers for decades. Nowadays, gait authentication has become an important facet of biometric systems due to the so-called unique characteristics of each user. With the development of various technologies (i.e., hardware, data processing, features extraction, and learning algorithms), the performance of sensor-based authentication methods is gradually improving. But we have found that the vulnerability of most existing methods can be compromised easily. In this paper, we propose a novel attack model, called one cycle attack, to bypass existing gait authentication methods. Firstly, the gait sequence is divided into multiple gait cycles. By adopting the K-mean algorithm, we get the average distance of each feature sample (extracted from the gait cycle) to its closest cluster center, and its result confirms that independent individuals may have similar gait cycles. Secondly, using six state-of-the-art models it was found that the adversarial gait cycle found with the clustering method can bypass the victim's model rapidly. Furthermore, to improve the accuracy of sensor-based gait authentication methods to fight against attacks, we present a WPD-LSTM (Wavelet Packet Decomposition and Long Short-Term Memory) multi-cycle defense model which considers the contextual contents of the neighboring gait cycles in the gait sequence. Experimental results on two datasets (the largest public sensor-based gait database OU-ISIR and new dataset from our laboratory) show that our attack model can bypass most of the victims' models within a limited number of attempts. Specifically, we can compromise 20%-80% of users within 5 attempts by utilizing imitation. On the contrary, the success rate of attackers has been greatly mitigated by deploying our multi-cycle defense model.	187.95762769708858
836.	Computed Tomography (CT) is commonly used in clinical procedures and limited angle tomography reconstruction has important applications in diagnostic CT, breast tomography, dental tomography, etc. However, CT images reconstructed from limited angle acquisitions suffer from severe artifacts due to incomplete sinogram data. Although existing iterative reconstruction methods improve image quality relative to filtered back projection, these methods require extensive computation and still often provide unsatisfactory images. Supervised deep learning methods have been proposed to further improve the image quality of limited angle reconstructions. However, a key limitation in supervised deep learning for this application is the lack of large-scale real sinogram-reconstruction pairs for training. Given the large number of CT images available in the wild, we can create a large number of simulated sinogram-reconstruction pairs. Thus the requirement for real paired sinogram-reconstruction data can be alleviated if simulated sinograms (e.g. monochromatic) are able to train a reconstruction network for real sinograms (e.g. polychromatic source, scattering, beam hardening). In this paper, we propose an end-to-end limited angle tomography reconstruction adversarial network (Tomo-GAN) via unsupervised sinogram adaptation without having real sinogram-reconstruction pairs. Tomo-GAN is trained by using (1) unpaired sinograms from the simulation and real domains, and (2) large-scale reconstruction images from only the simulation domain. Tomo-GAN is built based upon a cycle consistent network with similarity constrained for sinogram adaptation and a multi-scale conditional reconstruction network. Experimental results on a public dataset with a limited angle setting demonstrated a consistent improvement over previous methods while significantly reducing the reconstruction computation time.	187.95756239103366
837.	Diabetic Retinopathy (DR) is an outcome of prolonged diabetes which directly or indirectly affect the human vision. DR is asymptomatic in its early stages and the late diagnosis lead to undeviating loss of vision. The computer aided diagnosis with the assistance of medical images helps in timely and accurate treatment. Microaneurysms (MA) mark the onset of DR, thus a vital point in screening of this disease. This review discuses various state of the art methods available till date for automated computer aided analysis of microaneurysms and haemorrhages. The paper also highlights qualitative and quantitative comparison of the existing literature with limitations for analysis of microaneurysms and haemorrhages. It is an attempt to systematize the available algorithms for an easy gathering and guidance to researchers working in this domain for future research.	187.95741891441574
838.	PurposeWe propose an approach of 3D convolutional neural network to segment the prostate in MR images.MethodsA 3D deep dense multi-path convolutional neural network that follows the framework of the encoder-decoder design is proposed. The encoder is built based upon densely connected layers that learn the high-level feature representation of the prostate. The decoder interprets the features and predicts the whole prostate volume by utilizing a residual layout and grouped convolution. A set of sub-volumes of MR images, centered at the prostate, is generated and fed into the proposed network for training purpose. The performance of the proposed network is compared to previously reported approaches.ResultsTwo independent datasets were employed to assess the proposed network. In quantitative evaluations, the proposed network achieved 95.11 and 89.01 Dice coefficients for the two datasets. The segmentation results were robust to variations in MR images. In comparison experiments, the segmentation performance of the proposed network was comparable to the previously reported approaches. In qualitative evaluations, the segmentation results by the proposed network were well matched to the ground truth provided by human experts.ConclusionsThe proposed network is capable of segmenting the prostate in an accurate and robust manner. This approach can be applied to other types of medical images.	187.95740313069996
839.	Given the recent advances in computer vision, image processing and control systems, self-driving vehicles has been one of the most promising and challenging research topics nowadays. The design of vision -based robust controllers to keep an autonomous car in the center of the lane, despite uncertainties and disturbances, is still an ongoing challenge. This paper presents a hybrid control architecture that combines Deep Reinforcement Learning (DRL) and Robust Linear Quadratic Regulator (RLQR) for vision-based lateral control of an autonomous vehicle. Evolutionary estimation is used to model the vehicle uncertainties. For performance comparison, a DRL method and three other hybrid controllers are also evaluated. The inputs for each controller are real-time semantically segmented RGB camera images which serve as the basis to calculate continuous steering actions to keep the vehicle on the center of the lane with a constant velocity. Simulation results show that the proposed hybrid RLQR with evolutionary estimation of uncertainties architecture outperforms the other algorithms implemented. It presents lower tracking errors, smoother steering inputs, total collision avoidance and better generalization in new urban environments. Furthermore, it significantly decreases the required training time.	187.95739258002936
840.	With the goal to screen high-risk populations for oral cancer in low- and middle-income countries (LMICs), we have developed a low-cost. portable. easy to use smartphone-based immoral dual-modality imaging platform. In this paper we present an image classification approach based on autofluorescence and white light images using deep learning methods. The information from the autofluorescence and white light image pair is extracted. calculated, and fused to feed the deep learning neural networks. We have investigated and compared the performance of different convolutional neural networks, transfer learning. and several regularization techniques for oral cancer classification. Our experimental results demonstrate the effectiveness of deep learning methods in classifying dual-modal images for oral cancer detection. (C) 2018 Optical Society of America under the terms of the OSA Open Access Publishing Agreement	187.9571626179698
841.	Deep learning has shown promise in the field of computer vision for image recognition. We evaluated two deep transfer learning techniques (feature extraction and fine-tuning) in the diagnosis of breast cancer compared to a lesion-based radiomics computer-aided diagnosis (CAD) method. The dataset included a total of 2006 breast lesions (1506 malignant and 500 benign) that were imaged with dynamic contrast-enhanced MRI. Pre-contrast, first post-contrast, and second post-contrast timepoint images for each lesion were combined to form an RGB image, which subsequently served as input to a VGG19 convolutional neural network (CNN) pre-trained on the ImageNet database. The first transfer learning technique was feature extraction conducted by extracting feature output from each of the five max-pooling layers in the trained CNN, average-pooling the features, performing feature reduction, and merging the CNN-features with a support vector machine in the classification of malignant and benign lesions. The second transfer learning method used a 64% training, 16% validation, and 20% testing dataset split in the fine-tuning of the final fully connected layers of the pre-trained VGG19 to classify the images as malignant or benign. The performance of each of the three CAD methods were evaluated using receiver operating characteristic (ROC) analysis with area under the ROC curve (AUC) as the performance metric in the task of distinguishing between malignant and benign lesions. The performance of the radiomics CAD (AUC = 0.90) was significantly better than that of the CNN-feature-extraction (AUC = 0.84; p<0.0001), however, we failed to show a significant difference with the fine-tuning method (AUC = 0.86; p=0.1251), and thus, we conclude that transfer learning shows potential as a comparable computer-aided diagnosis technique.	187.9571300675339
842.	Recently, deep learning has emerged as a state-of-the-art machine learning technique with promising potential to drive significant breakthroughs in a wide range of research areas. The application of deep learning for network traffic control, however, remains immature due to the difficulty in uniquely characterizing the network traffic features as an appropriate input and output dataset to the learning structures. The network traffic features are anticipated to be even more dynamic and complex in the UDNs of the emerging 5G networks with high traffic demands coupled with beamforming and massive MIMO technologies. Therefore, it is critical for 5G network operators to carry out radio resource control in an efficient manner instead of adopting the simple conventional F/TDD. This is because the conventional uplink-downlink configuration change in the existing dynamic TDD method, typically used for resource assignment in beamforming and massive-MIMO-based UDNs, is prone to repeated congestion. In this article, we address this issue and discuss how to leverage the deep LSTM learning technique to make localized prediction of the traffic load at the UDN base station (i.e., the eNB). Based on localized prediction, our proposed algorithm executes the appropriate action policy a priori to avoid/alleviate the congestion in an intelligent fashion. Simulation results demonstrate that our proposal outperforms the conventional method in terms of packet loss rate, throughput, and MOS.	187.95691747282467
843.	We are developing a U-Net based deep learning (U-DL) model for bladder segmentation in CT urography (CTU) as a part of a computer-assisted bladder cancer detection and treatment response assessment pipeline. We previously developed a bladder segmentation method that used a deep-learning convolution neural network and level sets (DCNN-LS) within a user-input bounding box. The new method does not require a user-input box nor the level sets for post-processing. To identify the best model for this task, we compared a number of U-DL models: 1) 2D CTU slices or 3D volume as input, 2) different image resolutions, and 3) preprocessing with and without automated cropping on each slice. We evaluated the segmentation performance of the different U-DL models using 3D hand-segmented contours as reference standard. The segmentation accuracy was quantified by the average volume intersection ratio (AVI), average percent volume error (AVE), average absolute volume error (AAVE), average minimum distance (AMD), and the Jaccard index (JI) for a data set of 81 training/validation and 92 independent test cases. For the test set, the best 2D U-DL model achieved AVI, AVE, AAVE, AMD, and JI values of 93.4 +/- 9.5%, -4.2 +/- 14.2%, 9.2 +/- 11.5%, 2.7 +/- 2.5 mm, 85.0 +/- 11.3%, respectively, while the best 3D U-DL achieved 90.6 +/- 11.9%, -2.3 +/- 21.7%, 11.5 +/- 18.5%, 3.1 +/- 3.2 mm, and 82.6 +/- 14.2%, respectively. For comparison, the corresponding values obtained with our previous DCNN-LS method were 81.9 +/- 12.1%, 10.2 +/- 16.2%, 14.0 +/- 13.0%, 3.6 +/- 2.0 mm, and 76.2 +/- 11.8%, respectively, for the same test set. The U-DL model provided highly accurate bladder segmentation and was more automated than the previous approach.	187.9569151455931
844.	Failure detection is employed in the industry to improve system performance and reduce costs due to unexpected malfunction events. So, a good dataset of the system is desirable for designing an automated failure detection system. However, industrial process datasets are unbalanced and contain little information about failure behavior due to the uniqueness of these events and the high cost for running the system just to get information about the undesired behaviors. For this reason, performing correct training and validation of automated failure detection methods is challenging. This paper proposes a methodology called FaultFace for failure detection on Ball-Bearing joints for rotational shafts using deep learning techniques to create balanced datasets. The FaultFace methodology uses 2D representations of vibration signals denominated faceportraits obtained by time-frequency transformation techniques. From the obtained faceportraits, a Deep Convolutional Generative Adversarial Network is employed to produce new faceportraits of the nominal and failure behaviors to get a balanced dataset. A Convolutional Neural Network is trained for fault detection employing the balanced dataset. The FaultFace methodology is compared with other deep learning techniques to evaluate its performance in for fault detection with unbalanced datasets. Obtained results show that FaultFace methodology has a good performance for failure detection for unbalanced datasets. (C) 2020 Elsevier Inc. All rights reserved.	187.95684037983105
845.	Surgical tool presence detection is one of the key problems in automatic surgical video content analysis. Solving this problem benefits many applications such as the evaluation of surgical instrument usage and automatic surgical report generation. Given the fact that each video is only sparsely labeled at the frame level, meaning that only a small portion of video frames will be properly labeled, existing approaches only model this problem as an image (frame) classification problem without considering temporal information in surgical videos. In this paper, we propose a deep neural network model utilizing both spatial and temporal information from surgical videos for surgical tool presence detection. The proposed model uses Graph Convolutional Networks (GCNs) along the temporal dimension to learn better features by considering the relationship between continuous video frames. To the best of our knowledge, this is the first work taking videos as input to solve the surgical tool presence detection problem. Our experiments demonstrate the employment of temporal information offers a significant improvement to this problem, and the proposed approach achieves better performance than all state-of-the-art methods.	187.9566867503886
846.	Background: A poster presentation is an experiential learning activity that stimulates curiosity and interest among students. Moreover, it encourages exploration and integration of concepts and provides students with a novel way to demonstrate their understanding of scientific principles. This pilot projects aimed to analyse views of participants on the academic benefits and learning of medical sciences via poster presentations. Methods: This cross-sectional study used the sequential exploratory type of mixed methods design in which quantitative data analysis was performed via survey-based questionnaires and qualitative study. For this purpose, we performed a thematic analysis of semi-structured interview questions that were administered to all participants using the self-interview technique. Results: A majority of students were of the opinion that the process of making poster preparation acted as an opportunity to promote deep learning. Moreover, a majority expressed that making these presentations required teamwork, which gave them an insight into collaborative learning. Conclusion: Our study revealed that poster presentations, when used effectively as an assignment, can facilitate a learner's critical and reflective thinking and promoting active learning. Previous generic guidelines for making posters were found to be an important step that led to a systematic scientific approach amongst learners as well as for integrating basic science and medical knowledge.	187.95667783383044
847.	In this paper, we propose a scheme which aims at determining and forecasting sampling rate of active biosensors in Wireless Body Area Networks (WBANs). In this regard, from the first round until a certain round, the sampling rate of biosensors would be determined. Accordingly, we introduce our modified Fisher test, develop Spline interpolation method, introduce three main parameters namely information of patient's activity, patient's risk and pivot biosensor's value. Then, by employing these parameters plus introduced statistical and mathematical based strategies, the sampling rate of the active biosensors in the next round would be determined at the end of each entire round. After reaching a pre-denoted round the sampling rate of biosensors would be predicted through forecasting methods. In this regard, we develop two machine learning based techniques namely Adaptive Neuro Fuzzy Inference System (ANFIS) and Long Short Term Memory (LSTM) and compare them with four famous similar techniques. In addition to using forecasted sampling frequencies of the biosensors for controlling their energy expenditure, these forecasted values would also be used to forecast patient's status in the future. This is the first work in this domain that uses current information of the patient to determine adaptive sampling frequency and then employs the time series of determined sampling frequencies to forecast the patient's status and biosensors energy expenditure in the future. For estimating our schemes, we simulated them in MATLAB R2018b software and compared the results with a number of similar schemes. Based on the simulation results, the proposed schemes are capable to reduce data traffic by 81%, decrease energy consumption of the network by 73% while having the capability of predicting sampling rate of biosensors with 97% accuracy.	187.95662466620732
848.	Document classification is a challenging task with important applications. The deep learning approaches to the problem have gained much attention recently. Despite the progress, the proposed models do not incorporate the knowledge of the document structure in the architecture efficiently and not take into account the contexting importance of words and sentences. In this paper, we propose a new approach based on a combination of convolutional neural networks, gated recurrent units, and attention mechanisms for document classification tasks. We use of convolution layers varying window sizes to extract more meaningful, generalizable and abstract features by the hierarchical representation. The proposed method in improves the results of the current attention-based approaches for document classification.	187.9564706843915
849.	This paper investigates the issue of real-world identification to fulfill better species protection. We focus on plant species identification as it is a classic and hot issue. In tradition plant species identification the samples are scanned specimen and the background is simple. However, real-world species recognition is more challenging. We first systematically investigate what is realistic species recognition and the difference from tradition plant species recognition. To deal with the challenging task, an interdisciplinary collaboration is presented based on the latest advances in computer science and technology. We propose a novel framework and an effective data augmentation method for deep learning in this paper. We first crop the image in terms of visual attention before general recognition. Besides, we apply it as a data augmentation method. We call the novel data augmentation approach attention cropping (AC). Deep convolutional neural networks are trained to predict species from a large amount of data. Extensive experiments on traditional dataset and specific dataset for real-world recognition are conducted to evaluate the performance of our approach. Experiments first demonstrate that our approach achieves state-of-the-art results on different types of datasets. Besides, we also evaluate the performance of data augmentation method AC. Results show that AC provides superior performance. Compared with the precision of methods without AC, the results with AC achieve substantial improvement.	187.95646613260993
850.	The free energy plays a fundamental role in theories of phase transformations and microstructure evolution. It encodes the thermodynamic coupling between different fields, such as mechanics and chemistry, within continuum descriptions of non-equilibrium materials phenomena. In mechano-chemically interacting materials systems, even consideration of only compositions, order parameters and strains results in a free energy description that occupies a high-dimensional space. Scale bridging between the electronic structure of a solid and continuum descriptions of its non-equilibrium behavior can be realized with integrable deep neural networks (IDNN) that are trained to free energy derivative data generated by first-principles statistical mechanics simulations and then analytically integrating to recover a free energy density function. Here we combine the IDNN with an active learning workflow to ensure well-distributed sampling of the free energy derivative data in high-dimensional input spaces, thereby enabling true scale bridging between first-principles statistical mechanics and continuum phase field models. As a prototypical material system we focus on Ni-Al. Cahn-Hilliard and Allen-Cahn phase field simulations using the resulting IDNN representation for the free energy density of Ni-Al demonstrate that the appropriate physics of the material have been learned. This work advances the treatment of scale bridging, starting with electronic structure calculations and proceeding through statistical mechanics to continuum physics. Its coupling of Cahn-Hilliard and Allen-Cahn phase field descriptions with nonlinear elasticity through the free energy density ensures a rigorous treatment of phase transformation phenomena. (C) 2020 Elsevier B.V. All rights reserved.	187.95638517095196
851.	.Splenomegaly segmentation on computed tomography (CT) abdomen anatomical scans is essential for identifying spleen biomarkers and has applications for quantitative assessment in patients with liver and spleen disease. Deep convolutional neural network automated segmentation has shown promising performance for splenomegaly segmentation. However, manual labeling of abdominal structures is resource intensive, so the labeled abdominal imaging data are rare resources despite their essential role in algorithm training. Hence, the number of annotated labels (e.g., spleen only) are typically limited with a single study. However, with the development of data sharing techniques, more and more publicly available labeled cohorts are available from different resources. A key new challenging is to co-learn from the multi-source data, even with different numbers of labeled abdominal organs in each study. Thus, it is appealing to design a co-learning strategy to train a deep network from heterogeneously labeled scans. In this paper, we propose a new deep convolutional neural network (DCNN) based method that integrates heterogeneous multi-resource labeled cohorts for splenomegaly segmentation. To enable the proposed approach, a novel loss function is introduced based on the Dice similarity coefficient to adaptively learn multi-organ information from different resources. Three cohorts were employed in our experiments, the first cohort (98 CT scans) has only splenomegaly labels, while the second training cohort (100 CT scans) has 15 distinct anatomical labels with normal spleens. A separate, independent cohort consisting of 19 splenomegaly CT scans with labeled spleen was used as testing cohort. The proposed method achieved the highest median Dice similarity coefficient value (0.94), which is superior (p-value<0.01 against each other method) to the baselines of multi-atlas segmentation (0.86), SS-Net segmentation with only spleen labels (0.90) and U-Net segmentation with multi-organ training (0.91). Our approach for adapting the loss function and training structure is not specific to the abdominal context and may be beneficial in other situations where datasets with varied label sets are available.	187.95630743241603
852.	This work presents a novel deep learning architecture called BNU-Net for the purpose of cardiac segmentation based on short-axis MRI images. Its name is derived from the Batch Normalized (BN) U-Net architecture for medical image segmentation. New generations of deep neural networks (NN) are called convolutional NN (CNN). CNNs like U-Net have been widely used for image classification tasks. CNNs are supervised training models which are trained to learn hierarchies of features automatically and robustly perform classification. Our architecture consists of an encoding path for feature extraction and a decoding path that enables precise localization. We compare this approach with a parallel approach named U-Net. Both BNU-Net and U-Net are cardiac segmentation approaches: while BNU-Net employs batch normalization to the results of each convolutional layer and applies an exponential linear unit (ELU) approach that operates as activation function, U-Net does not apply batch normalization and is based on Rectified Linear Units (ReLU). The presented work (i) facilitates various image preprocessing techniques, which includes affine transformations and elastic deformations, and (ii) segments the preprocessed images using the new deep learning architecture. We evaluate our approach on a dataset containing 805 MRI images from 45 patients. The experimental results reveal that our approach accomplishes comparable or better performance than other state-of-the-art approaches in terms of the Dice coefficient and the average perpendicular distance.	187.9562928535398
853.	This article describes a study undertaken in New Zealand, England and Sweden and is based on the use of a tool developed by the researcher as a professional development and teaching tool in technology education for teachers of students between four and six years of age. The aim of the research was to investigate teachers' views of the effectiveness of the tool designed to deepening their understandings of technology content and pedagogical content knowledge. The tool, technology observations and conversation framework (TOCF) was designed to guide teachers' interactions with and observations of young children when learning technology with the aim of developing teacher insight into their own understanding of technology and how students learn technology. The tool was developed using the building of learning power theory to facilitate the identification of key dispositions and attitudes within four aspects of learning and across five pre-determined behaviours relevant to technology education. Qualitative research methods were used to investigate teachers' interaction with the TOCF by observing their use of it, and interviewing them about their perceived developed understanding of technology content knowledge and pedagogical content knowledge (PCK). The initial purpose of the framework, presented to the teachers prior to teaching, was to guide interactions with students to assist this development and subsequently assist their ability to teach technology effectively and give specific feedback to students in technology education. The study found that teachers felt that they gained a deeper understanding of technology education and their understanding of students' learning in technology also developed. This article presents the final framework and teachers' views on how they were assisted by the framework. The study offers an international perspective on ways to broaden and deepen students' understanding in technological literacy through the development of teacher content knowledge and PCK and contributes significantly to the field of formative assessment in technology education.	187.9561733898176
854.	Person re-identification (Re-ID) aims to match person images captured from two non-overlapping cameras. In this paper, a deep hybrid similarity learning (DHSL) method for person Re-ID based on a convolution neural network (CNN) is proposed. In our approach, a light CNN learning feature pair for the input image pair is simultaneously extracted. Then, both the elementwise absolute difference and multiplication of the CNN learning feature pair are calculated. Finally, a hybrid similarity function is designed to measure the similarity between the feature pair, which is realized by learning a group of weight coefficients to project the elementwise absolute difference and multiplication into a similarity score. Consequently, the proposed DHSL method is able to reasonably assign complexities of feature learning and metric learning in a CNN, so that the performance of person Re-ID is improved. Experiments on three challenging person Re-ID databases, QMUL GRID, VIPeR, and CUHK03, illustrate that the proposed DHSL method is superior to multiple state-of-the-art person Re-ID methods.	187.95609205594
855.	The smart metering infrastructure has changed how electricity is measured in both residential and industrial application. The large amount of data collected by smart meter per day provides a huge potential for analytics to support the operation of a smart grid, an example of which is energy demand forecasting. Short term energy forecasting can be used by utilities to assess if any forecasted peak energy demand would have an adverse effect on the power system transmission and distribution infrastructure. It can also help in load scheduling and demand side management. Many techniques have been proposed to forecast time series including Support Vector Machine, Artificial Neural Network and Deep Learning. In this work we use Long Short Term Memory architecture to forecast 3-day ahead energy demand across each month in the year. The results show that 3-day ahead demand can be accurately forecasted with a Mean Absolute Percentage Error of 3.15%. In addition to that, the paper proposes way to quantify the time as a feature to be used in the training phase which is shown to affect the network performance.	187.95602765288095
856.	Breast radiologists inspect mammograms with the utmost consideration to capture true cancer cases. Yet, machine learning models are typically designed to perform a binary classification, by joining several severities into one positive class. In such scenarios with mixed gradings, a reliable classifier would make less mistakes between distant severities such as missing a true cancer case and calling it as normal or vise versa. To this end, we suggest a simple yet elegant formulation for training a deep learning model with ordered loss, by increasingly weighting the loss of more severe cases, to enforce importance of certain errors over others. Training with the ordered loss yields fewer severe errors and can decrease the chances of missing true cancers. We evaluated our method on mammogram classification, using a weakly supervised deep learning method. Our data set included over 16K mammograms, with a large set of nearly 2,500 biopsy proven cancer cases. Evaluation of our proposed loss function showed a reduction in severe errors of missing true cancers, while preserving overall classification performance in the original task.	187.95600899320488
857.	The execution time prediction for query tasks in graph database has become difficult and challenging due to the complexity of query plan and system. It is difficult for Database Administrators (DBA) or Database Management System (DBMS) to catch the accurate execution time during and before the execution of a query task. Before executing a query task, predicting its execution time can help the DBA or DBMS to efficiently management in the fields of load management, task scheduling, permission control, progress monitoring, system scale customization, etc. Therefore, accurately and efficiently predicting the execution time for query tasks is a key technology in these fields. In this paper, motivated by the combination of artificial intelligence technologies and graph database theories, we first propose a novel deep learning method to predict the execution time for query tasks in graph database. First, each query plan tree of tasks is encoded into an operation sequence. Second, top-20 features are selected from 68 candidate system features using random forest (RF), and the selected top-20 features are reduced to five principal components using principal component analysis (PCA). Finally, an accurate and efficient model based on the long short-term memory (LSTM) is designed and implemented to predict the execution time. The model can predict the execution time in advance before executing a query task in graph database. The experimental results from six kinds of benchmarks with the public data set Yelp show that the average accuracy of the proposed model can reach 81.34% with a high prediction efficiency rate, which proves the feasibility of the deep learning method. In particular, the proposed model can achieve the state-of-the-art prediction performance for query task execution time. (c) 2020 Published by Elsevier B.V.	187.95598857479365
858.	Imbalance of residential environments in cities (e.g., slums and wealthy districts) causes serious social in-equality, negatively impacting livable city development and attracting worldwide attentions. Previous studies on residential environmental quality (REQ) mainly focused on general evaluations at city level, while ignored the spatial heterogeneity of REQ inside cities and failed to survey REQ at local scales. This study recognizes the heterogeneity of REQ strongly related to land-use patterns, and aims to explore how local land-use patterns influence REQ. Firstly, a multimodal semantic segmentation method is presented to classify land uses by using satellite images, building data and points of interests. Secondly, a feature system is defined to characterize land-use patterns, which can be extracted at multiple scales based on land-use classification results. Thirdly, these features are fitted with REQ survey data by random forest regressions, which can predict REQ scores across Beijing and give deep insights into how land-use patterns influence REQ. Experimental results indicate that 1) REQ of Beijing is strongly heterogeneous, and our method can generate a REQ map revealing REQ's imbalance across the city; 2) land-use patterns within 700 m have significant impacts on the local REQ; 3) spatial allocations of land uses are more important than proportions for influencing REQ; and 4) our method visualizes the rules that land-use patterns influence REQ, thus can assist urban land-use planning to balance and improve REQ.	187.9559216462464
859.	Deep learning (DL), a new generation of artificial neural network research, has transformed industries, daily lives, and various scientific disciplines in recent years. DL represents significant progress in the ability of neural networks to automatically engineer problem-relevant features and capture highly complex data distributions. I argue that DL can help address several major new and old challenges facing research in water sciences such as interdisciplinarity, data discoverability, hydrologic scaling, equifinality, and needs for parameter regionalization. This review paper is intended to provide water resources scientists and hydrologists in particular with a simple technical overview, transdisciplinary progress update, and a source of inspiration about the relevance of DL to water. The review reveals that various physical and geoscientific disciplines have utilized DL to address data challenges, improve efficiency, and gain scientific insights. DL is especially suited for information extraction from image-like data and sequential data. Techniques and experiences presented in other disciplines are of high relevance to water research. Meanwhile, less noticed is that DL may also serve as a scientific exploratory tool. A new area termed AI neuroscience, where scientists interpret the decision process of deep networks and derive insights, has been born. This budding subdiscipline has demonstrated methods including correlation-based analysis, inversion of network-extracted features, reduced-order approximations by interpretable models, and attribution of network decisions to inputs. Moreover, DL can also use data to condition neurons that mimic problem-specific fundamental organizing units, thus revealing emergent behaviors of these units. Vast opportunities exist for DL to propel advances in water sciences.	187.9557725516839
860.	Integrated modular avionics is one of the most advanced systems. Its performance deeply impacts on the working condition of aircraft. In order to enhance the safety and reliability of aircraft, the health state of the integrated modular avionics should be evaluated accurately. In this paper, a novel deep learning method is developed to evaluate the health state. Firstly, as one of the deep learning methods, stacked denoising autoencoders is used to extract the features from the raw data immediately to retain original information. Secondly, the extracted features are fed into the quantum neural network to classify the data set. The loss function of the quantum neural network is evolved to improve the classification performance. Experiments conducted on standard datasets show that the proposed method is more effective and robust than other four conventional algorithms. Finally, this paper builds an integrated modular avionics degradation model by the changing probability of the occurrence of soft faults in the whole life serves and the proposed method is applied to the health state evaluation.	187.9557421876156
861.	A depth estimation has been widely studied with the emergence of a Lytro camera. However, skin depth estimation using a Lytro camera is too sensitive to the influence of illumination due to its low image quality, and thus, when three-dimensional reconstruction is attempted, there are limitations in that either the skin texture information is not properly expressed or considerable numbers of errors occur in the reconstructed shape. To address these issues, we propose a method that enhances the texture information and generates robust images unsusceptible to illumination using a deep learning method, conditional generative adversarial networks (CGANs), in order to estimate the depth of the skin surface more accurately. Because it is difficult to estimate the depth of wrinkles with very few characteristics, we have built two cost volumes using the difference of the pixel intensity and gradient, in two ways. Furthermore, we demonstrated that our method could generate a skin depth map more precisely by preserving the skin texture effectively, as well as by reducing the noise of the final depth map through the final depth-refinement step (CGAN guidance image filtering) to converge into a haptic interface that is sensitive to the small surface noise.	187.95574200508986
862.	Back projection filtering (BPF) and filtered back projection (FBP) are classic CT reconstruction analytic methods. However, when dealing with the reconstruction of incomplete datasets, analytic methods may suffer from artifacts due to the global nature of filtering. The iterative algorithm is another CT reconstruction method. Although the iterative algorithm can get excellent results, it requires high computation cost. In this work, inspired by the idea of BPF, we propose a CT image reconstruction strategy based on a new convolutional neural network that can capture features with different levels. The proposed method can learn the mapping between the direct back projection and the ideal CT images and then realize accurate image reconstruction. It is suitable for not only complete projection data but also transverse truncated projection data with different regions of interest (ROIs) sizes. The experiment results show that the proposed method outperforms the conventional FBP and other state-of-the-art deep learning methods in the truncated reconstruction. At the same time, the proposed method requires a lower computation cost which is helpful for fast reconstruction in the clinical research.	187.95572694159938
863.	For the generation of representative volume elements a statistical description of the relevant parameters is necessary. These parameters usually describe the geometric structure of a single grain. Commonly, parameters like area, aspect ratio, and slope of the grain axis relative to the rolling direction are applied. However, usually simple distribution functions like log normal or gamma distribution are used. Yet, these do not take the interdependencies between the microstructural parameters into account. To fully describe any metallic microstructure though, these interdependencies between the singular parameters need to be accounted for. To accomplish this representation, a machine learning approach was applied in this study. By implementing a Wasserstein generative adversarial network, the distribution, as well as the interdependencies could accurately be described. A validation scheme was applied to verify the excellent match between microstructure input data and synthetically generated output data.	187.95570854695353
864.	In this paper we propose a novel augmentation technique that improves not only the performance of deep neural networks on clean test data, but also significantly increases their robustness to random transformations, both affine and projective. Inspired by ManiFool, the augmentation is performed by a line-search manifold-exploration method that learns affine geometric transformations that lead to the misclassification on an image, while ensuring that it remains on the same manifold as the training data. This augmentation method populates any training dataset with images that lie on the border of the manifolds between two-classes and maximizes the variance the network is exposed to during training. Our method was thoroughly evaluated on the challenging tasks of fine-grained skin lesion classification from limited data, and breast tumor classification of mammograms. Compared with traditional augmentation methods, and with images synthesized by Generative Adversarial Networks our method not only achieves state-of-the-art performance but also significantly improves the network's robustness.	187.95568150945712
865.	Intelligent agents that can interact with users using natural language are becoming increasingly common. Sometimes an intelligent agent may not correctly understand a user command or may not perform it properly. In such cases, the user might try a second time by giving the agent another, slightly different command. Giving an agent the ability to detect such user corrections might help it fix its own mistakes and avoid making them in the future. In this work, we consider the problem of automatically detecting user corrections using deep learning. We develop a multimodal architecture called SAIF, which detects such user corrections, taking as inputs the user's voice commands as well as their transcripts. Voice inputs allow SAIF to take advantage of sound cues, such as tone, speed, and word emphasis. In addition to sound cues, our model uses transcripts to determine whether a command is a correction to the previous command. Our model also obtains internal input from the agent, indicating whether the previous command was executed successfully or not. Finally, we release a unique dataset in which users interacted with an intelligent agent assistant, by giving it commands. This dataset includes labels on pairs of consecutive commands, which indicate whether the latter command is in fact a correction of the former command. We show that SAIF outperforms current state-of-the-art methods on this dataset.	187.95563687596524
866.	Financial time-series modeling is a challenging problem as it retains various complex statistical properties and the mechanism behind the process is unrevealed to a large extent. In this paper, a deep neural networks based approach, generative adversarial net works (GANs) for financial time-series modeling is presented. GANs learn the properties of data and generate realistic data in a data-driven manner. The GAN model produce a time-series that recovers the statistical properties of financial time-series such as the linear unpredictability, the heavy-tailed price return distribution, volatility clustering leverage effects, the coarse-fine volatility correlation, and the gain/loss asymmetry. (C) 2019 Elsevier B.V. All rights reserved	187.95562465547363
867.	Built environment attributes have been demonstrated to be associated with various health outcomes. However, most empirical studies have typically focused on objective built environmental measures. Still, perceptions of the built environment also play an important role in health and may complement studies with objective measures. Some built environment attributes, such as liveliness or beauty, are difficult to measure objectively. Traditional methods to assess perceptions of the built environment, such as questionnaires and focus groups, are time-consuming and prone to recall bias. The recent development in machine deep learning techniques and big data of street view images, makes it possible to assess perceptions of the built environment with street view images for a large-scale study area. By using online free Tencent Street View (TSV) images, this study assessed six perceptual attributes of the built environment: wealth, safety, liveliness, depression, bore and beauty. These attributes were associated with both the physical and the mental health outcomes of 1231 older adults in 48 neighborhoods in the Haidian District, Beijing, China. Results show that perceived safety was significantly associated with both the physical and mental health outcomes. Perceived depression and beauty were significant related to older adults' mental health, while perceived wealth, bore and liveliness were significantly related to their physical health. The findings carry important policy implications and hence contribute to the development of healthy cities. It is urgent to improve residents' positive perceptions and decrease their negative perceptions of the built environment, especially in neighborhoods that are highly populated by older adults.	187.95560677677855
868.	The fifth generation (5G) technology is expected to support a rapid increase in infrastructure and mobile user subscriptions with an increase in the number of remote radio heads (RRHs) per unit area using cloud radio access networks (C-RANs). From the economic point of view, minimizing the amount of energy consumption of the RRHs is a challenging issue. From the environmental point of view, achieving "greenness" in wireless networks is one of the many goals of telecommunication operators. This paper proposes a framework to balance the energy consumption of RRHs and quality of service (QoS) satisfaction of users in cellular networks using a convolutional neural network (CNN)-based relational dueling deep Q-Network (DQN) scheme. Firstly, we formulate the cell activation/deactivation problem as a Markov decision process (MDP) and set up a two-layer CNN which takes raw captured images in the environment as its input. Then, we develop a dueling DQN-based autonomous cell activation scheme to dynamically turn RRHs on or off based on the energy consumption and QoS requirements of users in the network. Finally, we decouple a customized physical resource allocation for rate-constrained users and delay-constrained users from the cell activation scheme and formulate the problem as a convex optimization problem to ensure the QoS requirements of users are achieved with the minimum number of active RRHs under varying traffic conditions. Extensive simulations reveal that the proposed algorithm achieves faster rate of convergence than nature DQN, Q-learning and dueling DQN schemes. Our algorithm also achieves stability in mobility scenarios compared with DQN and dueling DQN without CNN. We also observe a slight improvement in balancing energy consumption and QoS satisfaction compared with DQN and dueling DQN schemes.	187.95555314605465
869.	Opinion summarization is based on aspect analyses of products, events or topics, which is a very interesting topic in natural language processing. Opinions are often expressed in various different ways in regards to objects. Therefore, it is important to express the characteristics of a product, event or topic in a final summary compiled by an automatic summarizing system. This paper proposes a method for conducting data preprocessing on the sentence level of a text using Convolutional Neural Networks. The corpus includes Vietnamese opinions on cars collected from social networking sites, forums, online newspapers and the websites of automobile dealers. The data processing phase will standardize terms for aspects that occur in opinion expressing aspects of the product. These aspects are used by manufacturers. Similarly, the standardization will be performed for both positive and negative terms used in opinions. The sentiment terms in the opinions will be replaced by standardized sentiment terms expressing the same sentiment polarities as those being replaced. This standardization is performed with the support of a semantic and sentiment ontology which has a tree hierarchy in the case of cars. This ontology ensures that the semantics and sentiment of the original opinion are not changed. The experimental results of the paper show that the proposed method gives better results than using no data preprocessing method for deep learning.	187.95550589178453
870.	Speckle noise in optical coherence tomography (OCT) impairs both the visual quality and the performance of automatic analysis. Edge preservation is an important issue for speckle reduction. In this paper, we propose an end-to-end framework for simultaneous speckle reduction and contrast enhancement for retinal OCT images based on the conditional generative adversarial network (cGAN). The edge loss function is added to the final objective so that the model is sensitive to the edge-related details. We also propose a novel method for obtaining clean images for training from outputs of commercial OCT scanners. The results show that the overall denoising performance of the proposed method is better than other traditional methods and deep learning methods. The proposed model also has good generalization ability and is capable of despeckling different types of retinal OCT images. (C) 2018 Optical Society of America under the terms of the OSA Open Access Publishing Agreement	187.95540223805423
871.	Electric power consumption short-term forecasting for individual households is an important and challenging topic in the fields of AI-enhanced energy saving, smart grid planning, sustainable energy usage and electricity market bidding system design. Due to the variability of each household's personalized activity, difficulties exist for traditional methods, such as auto-regressive moving average models, machine learning methods and non-deep neural networks, to provide accurate prediction for single household electric power consumption. Recent works show that the long short term memory (LSTM) neural network outperforms most of those traditional methods for power consumption forecasting problems. Nevertheless, two research gaps remain as unsolved problems in the literature. First, the prediction accuracy is still not reaching the practical level for real-world industrial applications. Second, most existing works only work on the one-step forecasting problem; the forecasting time is too short for practical usage. In this study, a hybrid deep learning neural network framework that combines convolutional neural network (CNN) with LSTM is proposed to further improve the prediction accuracy. The original short-term forecasting strategy is extended to a multi-step forecasting strategy to introduce more response time for electricity market bidding. Five real-world household power consumption datasets are studied, the proposed hybrid deep learning neural network outperforms most of the existing approaches, including auto-regressive integrated moving average (ARIMA) model, persistent model, support vector regression (SVR) and LSTM alone. In addition, we show a k-step power consumption forecasting strategy to promote the proposed framework for real-world application usage.	187.95521134337505
872.	This article presents a theory for constructing hierarchical networks in such a way that the networks are guaranteed to be provably scale covariant. We first present a general sufficiency argument for obtaining scale covariance, which holds for a wide class of networks defined from linear and nonlinear differential expressions expressed in terms of scale-normalized scale-space derivatives. Then, we present a more detailed development of one example of such a network constructed from a combination of mathematically derived models of receptive fields and biologically inspired computations. Based on a functional model of complex cells in terms of an oriented quasi quadrature combination of first- and second-order directional Gaussian derivatives, we couple such primitive computations in cascade over combinatorial expansions over image orientations. Scale-space properties of the computational primitives are analysed, and we give explicit proofs of how the resulting representation allows for scale and rotation covariance. A prototype application to texture analysis is developed, and it is demonstrated that a simplified mean-reduced representation of the resulting QuasiQuadNet leads to promising experimental results on three texture datasets.	187.95518772595446
873.	The transport of intensity equation (TIE) is an ideal candidate for phase imaging with partially coherent illuminations. TIE has the advantages of simplicity in phase calculation due to its closed-form solution and no requirement for a reference beam and phase unwrapping due to its non-interferometric nature. However, TIE requires multiple through-focus intensity images, and is very sensitive to image boundaries and noise. Thus, in this paper, we combine deep learning with TIE, abbreviated as dTIE. After being trained by TIE phase results, the dTIE retains the advantages of TIE, and overcomes the shortcomings of TIE as follows: (i) only one de-focus intensity image is required for phase imaging while the result is very close to the TIE result with SSIM index reaches 0.95, enabling more efficient phase imaging; (H) the boundary problem automatically disappears due to the translation invariance of the convolutional networks; (Hi) it is insensitive to noise even with very heavy noise. All these enhancements are verified in the application of dTIE for phase imaging of real cells.	187.95512213016718
874.	This paper presents a method to automatically segment tympanic membranes (TMs) from video-otoscopic images based on the deep learning approach. The paper introduces a hybrid loss function combining the Dice loss and active contour loss to the fully convolutional network. By this way, the proposed model takes into account the Dice similarity and the desired boundary contour information including the contour length as well as regions inside and outside the contour during learning. The proposed loss function is then applied to the fully convolutional network for tympanic membrane segmentation. We evaluate the proposed approach on TMs data set which includes 1139 otoscopic images from patients diagnosed with and without otitis media. Experimental results show that the proposed deep learning model achieves an average Dice similarity coefficient of 0.895, a mean Hausdorff distance of 19.189, and average perpendicular distance of 6.429, that outperforms other state-of-the-art methods.	187.95508308399366
875.	Crop yields are critically dependent on weather. A growing empirical literature models this relationship in order to project climate change impacts on the sector. We describe an approach to yield modeling that uses a semiparametric variant of a deep neural network, which can simultaneously account for complex nonlinear relationships in high-dimensional datasets, as well as known parametric structure and unobserved cross-sectional heterogeneity. Using data on corn yield from the US Midwest, we show that this approach outperforms both classical statistical methods and fully-nonparametric neural networks in predicting yields of years withheld during model training. Using scenarios from a suite of climate models, we show large negative impacts of climate change on corn yield, but less severe than impacts projected using classical statistical methods. In particular, our approach is less pessimistic in the warmest regions and the warmest scenarios.	187.95500561316135
876.	In this study, we attempt to estimate the effects of various transportation policies on the perceived safety of the built environment. We train a convolutional neural network on a dataset of safety perception scores for Google Street View images taken in Boston, MA . We then apply the trained neural network to a large set of Google Street View images of coordinates in Montreal and Toronto to generate their respective safety perception scores. We estimate probit, logit, and ordinary least squares regression models using our cross-sectional dataset consisting of safety perception scores, as well as transportation policy variables and a set of control variables, by regressing the safety perception scores on the remaining set of variables. We answer our research question by observing the direction, magnitude, and statistical significance of the coefficient estimates associated with the policy variables across all regression models. We studied and cataloged transportation policies planned for over the past 10 years in both cities. We found that those census tracts with the poorest safety scores were the same places where planners focused their transportation investments. The study makes an important contribution to transportation planning methodologies by drawing on the novel data source of Google Street View images, to understand the safety of an area.	187.955003400318
877.	The head and neck (HN) consists of a large number of vital anatomic structures within a compact area. Imaging plays a central role in the diagnosis and management of major disorders affecting the HN. This article reviews the recent applications of machine learning (ML) in HN imaging with a focus on deep learning approaches. It categorizes ML applications in HN imaging into deep learning and traditional ML applications and provides examples of each category. It also discusses the main challenges facing the successful deployment of ML-based applications in the clinical setting and provides suggestions for addressing these challenges.	187.9549797884899
878.	Magnetic resonance (MR) imaging offers a wide variety of imaging techniques. A large amount of data is created per examination which needs to be checked for sufficient quality in order to derive a meaningful diagnosis. This is a manual process and therefore time- and cost-intensive. Any imaging artifacts originating from scanner hardware, signal processing or induced by the patient may reduce the image quality and complicate the diagnosis or any image post-processing. Therefore, the assessment or the ensurance of sufficient image quality in an automated manner is of high interest. Usually no reference image is available or difficult to define. Therefore, classical reference-based approaches are not applicable. Model observers mimicking the human observers (HO) can assist in this task. Thus, we propose a new machine-learning-based reference-free MR image quality assessment framework which is trained on HO-derived labels to assess MR image quality immediately after each acquisition. We include the concept of active learning and present an efficient blinded reading platform to reduce the effort in the HO labeling procedure. Derived image features and the applied classifiers (support-vector-machine, deep neural network) are investigated for a cohort of 250 patients. The MR image quality assessment framework can achieve a high test accuracy of 93.7% for estimating quality classes on a 5-point Likert-scale. The proposed MR image quality assessment framework is able to provide an accurate and efficient quality estimation which can be used as a prospective quality assurance including automatic acquisition adaptation or guided MR scanner operation, and/or as a retrospective quality assessment including support of diagnostic decisions or quality control in cohort studies.	187.95482454915833
879.	Proactive process adaptation can prevent and mitigate upcoming problems during process execution. Proactive adaptation decisions are based on predictions about how an ongoing process instance will unfold up to its completion. On the one hand, these predictions must have high accuracy, as, for instance, false negative predictions mean that necessary adaptations are missed. On the other hand, these predictions should be produced early during process execution, as this leaves more time for adaptations, which typically have non-negligible latencies. However, there is an important tradeoff between prediction accuracy and earliness. Later predictions typically have a higher accuracy, because more information about the ongoing process instance is available. To address this tradeoff, we use an ensemble of deep learning models that can produce predictions at arbitrary points during process execution and that provides reliability estimates for each prediction. We use these reliability estimates to dynamically determine the earliest prediction with sufficient accuracy, which is used as basis for proactive adaptation. Experimental results indicate that our dynamic approach may offer cost savings of 27% on average when compared to using a static prediction point.	187.95481509275155
880.	As an object passes through strongly scattering slab, it cannot be imaged, due to scattering slab scrambling the object information. In this paper, we employ convolutional neural network (CNN) to realize the imaging reconstruction in such a specific optical system where an object is located between two strongly scattering slabs. The influence of the thickness of the scattering slabs on the imaging reconstruction is investigated, in which we can obtain the imaging reconstruction from the object-speckle pairs of the object passing through the certain thickness of scattering slab, by using the trained CNN with the certain object-speckle pairs. It is shown that good reconstructed images are achieved for three different thickness of the scattering slab. Moreover the so-called hybrid trained network is employed, in which we train the network by using totally 9000 object-speckle pairs from three sets of data, each set of data we selecting equal 3,000 pairs of object-speckle patterns, corresponding to the three different thickness of the rear scattering slabs. We find that hybrid trained network is capable of reconstructing the image from speckles taken from the three different scattering conditions Our approach may have applications in biomedical imaging.	187.9547953613386
881.	Automated Gleason grading is an important preliminary step for quantitative histopathological feature extraction. Different from the traditional task of classifying small pre-selected homogeneous regions, semantic segmentation provides pixel-wise Gleason predictions across an entire slide. Deep learning based segmentation models can automatically learn visual semantics from data, which alleviates the need for feature engineering. However, performance of deep learning models is limited by the scarcity of large-scale fully annotated datasets, which can be both expensive and time-consuming to create. One way to address this problem is to leverage external weakly labeled datasets to augment models trained on the limited data. In this paper, we developed an expectation maximization-based approach constrained by an approximated prior distribution in order to extract useful representations from a large number of weakly labeled images generated from low-magnification annotations. This method was utilized to improve the performance of a model trained on a limited fully annotated dataset. Our semi-supervised approach trained with 135 fully annotated and 1800 weakly annotated tiles achieved a mean Jaccard Index of 49.5% on an independent test set, which was 14% higher than the initial model trained only on the fully annotated dataset. (C) 2018 Elsevier Ltd. All rights reserved.	187.95472305449988
882.	MOTIVATION: With the rapid increase of biomedical articles, large-scale automatic Medical Subject Headings (MeSH) indexing has become increasingly important. FullMeSH, the only method for large-scale MeSH indexing with full text, suffers from three major drawbacks: FullMeSH 1) uses Learning To Rank (LTR), which is time-consuming, 2) can capture some pre-defined sections only in full text, and 3) ignores the whole MEDLINE database. RESULTS: We propose a computationally lighter, full-text and deep learning based MeSH indexing method, BERTMeSH, which is flexible for section organization in full text. BERTMeSH has two technologies: 1) the state-of-the-art pre-trained deep contextual representation, BERT (Bidirectional Encoder Representations from Transformers), which makes BERTMeSH capture deep semantics of full text. 2) a transfer learning strategy for using both full text in PubMed Central (PMC) and title and abstract (only and no full text) in MEDLINE, to take advantages of both. In our experiments, BERTMeSH was pre-trained with 3 million MEDLINE citations and trained on approximately 1.5 million full text in PMC. BERTMeSH outperformed various cutting edge baselines. For example, for 20K test articles of PMC, BERTMeSH achieved a Micro F-measure of 69.2%, which was 6.3% higher than FullMeSH with the difference being statistically significant. Also prediction of 20K test articles needed 5minutes by BERTMeSH, while it took more than 10hours by FullMeSH, proving the computational efficiency of BERTMeSH. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.	187.954715711651
883.	A Recurrent Neural Network (RNN) trained with a set of molecules represented as SMILES strings can generate millions of different valid and meaningful chemical structures. In most of the reported architectures the models have been trained using a canonical (unique for each molecule) representation of SMILES. Instead, this research shows that when using randomized SMILES as a data amplification technique, a model can generate more molecules and those are going to accurately represent the training set properties. To show that, an extensive benchmark study has been conducted using research from a recently published article which shows that models trained with molecules from the GDB13 database (975 million molecules) achieve better overall chemical space coverage when the posterior probability distribution is as uniform as possible. Specifically, we created models that generate nearly all the GDB-13 chemical space using only 1 million molecules as training set. Lastly, models were also trained with smaller training set sizes and show substantial improvement when using randomized SMILES compared to canonical.	187.9545032964129
884.	Projection-based model reduction has become a popular approach to reduce the cost associated with integrating large-scale dynamical systems so they can be used in many-query settings such as optimization and uncertainty quantification. For nonlinear systems, significant cost reduction is only possible with an additional layer of approximation to reduce the computational bottleneck of evaluating the projected nonlinear terms. Prevailing methods to approximate the nonlinear terms are code intrusive, potentially requiring years of development time to integrate into an existing codebase, and have been known to lack parametric robustness. This work develops a non-intrusive method to efficiently and accurately approximate the expensive nonlinear terms that arise in reduced nonlinear dynamical system using deep neural networks. The neural network is trained using only the simulation data used to construct the reduced basis and evaluations of the nonlinear terms at these snapshots. Once trained, the neural network-based reduced-order model only requires forward and backward propagation through the network to evaluate the nonlinear term and its derivative, which are used to integrate the reduced dynamical system at a new parameter configuration. We provide two numerical experiments - the dynamical systems result from the semi-discretization of parametrized, nonlinear, hyperbolic partial differential equations that show, in addition to non-intrusivity, the proposed approach provides more stable and accurate approximations to each dynamical system across a large number of training and testing points than the popular empirical interpolation method. (C) 2020 Elsevier B.V. All rights reserved.	187.95449901046112
885.	Deep learning based on structured deep neural networks has provided powerful applications in various fields. The structures imposed on the deep neural networks are crucial, which makes deep learning essentially different from classical schemes based on fully connected neural networks. One of the commonly used deep neural network structures is generated by convolutions. The produced deep learning algorithms form the family of deep convolutional neural networks. Despite of their power in some practical domains, little is known about the mathematical foundation of deep convolutional neural networks such as universality of approximation. In this paper, we propose a family of new structured deep neural networks: deep distributed convolutional neural networks. We show that these deep neural networks have the same order of computational complexity as the deep convolutional neural networks, and we prove their universality of approximation. Some ideas of our analysis are from ridge approximation, wavelets, and learning theory.	187.95436353036604
886.	Conventional intelligent diagnostic models are built on the foundation that the training data and testing data are recorded under the same operating conditions, which neglects the fact that the operating condition of the rotating machinery usually varies. The feature distribution of the recorded data under one set of operating conditions may be inconsistent with the feature distribution of the data recorded under different operating conditions. It is therefore easy to create a significant distribution discrepancy between training data and testing data. To address this issue, an unsupervised domain adaptation approach, based on a symmetric co-training framework, is proposed in this study. In the proposed symmetric co-training framework, a universal feature extractor and two individual classifiers are built as the main elements. The structures of the two classifiers are symmetric, and its parameters are updated in a co-training style. The parameters of the feature extractor and the two classifiers are continuously updated via an adversarial training process. The cosine similarity of the predictions from the two classifiers is introduced in order to guide the adversarial training process, which not only minimizes the distribution discrepancies between source domain data and the target domain data, but also pushes the feature subspaces for different healthy conditions away from the class boundaries. The application of the proposed method to two sets of experimental bearing fault data validates that the proposed method can successfully address the domain shift phenomenon between the recorded data under different operating conditions.	187.95435971044247
887.	Due to the rapid development of printed circuit board (PCB) design technology, inspection of PCB surface defects has become an increasingly critical issue. The classification of PCB defects facilitates the root causes of detect's identification. As PCB defects may be intensive, the actual PCB classification should not be considered as a binary or multi-category problem. This type of problem is called multi-label classification problem. Recently, as one of the deep learning frameworks, a convolutional neural network (CNN) has a major breakthrough in many areas of image processing, especially in the image classification. This study proposes a multi-task CNN model to handle the multi-label learning problem by defining each label learning as a binary classification task. In this study, the multi-label learning is transformed into multiple binary classification tasks by customising the loss function. Extensive experiments demonstrate that the proposed method achieves great performance on the dataset of defects.	187.95435925281242
888.	This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing.	187.9543525423909
889.	Radio air interface identification provides necessary information for dynamically and efficiently exploiting the wireless radio frequency spectrum. In this study, a general machine learning framework is proposed for Global System for Mobile communications (GSM), Wideband Code Division Multiple Access (WCDMA), and Long Term Evolution (LTE) signal identification by utilizing the outputs of the spectral correlation function (SCF), fast Fourier Transform (FFT), auto-correlation function (ACF), and power spectral density (PSD) as the training inputs for the support vector machines (SVMs). In order to show the robustness and practicality of the proposed method, the performance of the classifier is investigated with respect to different fading channels by using simulation data. Various over-the-air real-world measurements are taken to show that wireless signals can be successfully distinguished from each other without any prior information while accounting for a comprehensive set of parameters such as different kernel types, number of in-phase/quadrature (I/Q) samples, training set size, or signal-to-noise ratio (SNR) values. Furthermore, the performance of the proposed classifier is compared to the existing well-known deep learning (DL) networks. The comparative performance of the proposed method is also quantified by classification confusion matrices and Precision/Recall/F-1-scores. It is shown that the investigated system can be also utilized for spectrum sensing and its performance is also compared with that of cyclostationary feature detection spectrum sensing.	187.95431574037434
890.	Automatic short answer grading (ASAG), which autonomously score student answers according to reference answers, provides a cost-effective and consistent approach to teaching professionals and can reduce their monotonous and tedious grading workloads. However, ASAG is a very challenging task due to two reasons: (1) student answers are made up of free text which requires a deep semantic understanding; and (2) the questions are usually open-ended and across many domains in K-12 scenarios. In this paper, we propose a generalized end-to-end ASAG learning framework which aims to (1) autonomously extract linguistic information from both student and reference answers; and (2) accurately model the semantic relations between free-text student and reference answers in open-ended domain. The proposed ASAG model is evaluated on a large real-world K-12 dataset and can outperform the state-of-the-art baselines in terms of various evaluation metrics.	187.9543035340779
891.	This work attempts to meet the challenges associated with the classification of LIDAR point clouds by means of deep learning. In addition to achieving high accuracy, the designed system should allow the classification of point clouds covering an area of several dozen square kilometers within a reasonable time interval. Therefore, it must be characterized by fast processing and efficient use of memory. Thus, the most popular approaches to the point cloud classification using neural networks are discussed. At the same time, their shortcomings are indicated. A developed model based on the PointNet architecture is presented and the way of preparing data for classification is shown. The model is tested on a cloud coming from the 3D Semantic Labeling competition, achieving a good result, confirmed by the high quality of the system, i.e. a high rate of categorization of objects. (C) 2019, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.	187.95421770698965
892.	Data efficiency has always been a significant key topic for deep reinforcement learning. The main progress has been on sufficient exploration and effective exploitation. However, the two are often discussed separately. Profit from distributed systems, we propose an asynchronous approach to deep reinforcement learning by combining exploration and exploitation. We apply our framework to off-the-shelf deep reinforcement learning algorithms, and experimental results show that our algorithm is superior in final performance and efficiency.	187.9541974803081
893.	Under the background of high incidence and mortality of cardiovascular diseases, the accurate and automatic left ventricle (LV) segmentation method is of essential importance for the diagnosis of the cardiovascular system. However, fully automatic LV segmentation remains challenging due to the complex structure of cardiac magnetic resonance image (MRI) and the morphological changes of LV caused by various cardiovascular diseases. In this paper, we propose a novel parallel end-to-end convolutional neural network (CNN) for LV segmentation. Our network consists of two interactive subnetworks which utilize essentially identical but formally different labels in the hope that they can learn segmentation from different perspectives. The two subnetworks take the same cardiac MRI as input and output a pair of segmentation maps in different forms. After averaging the two segmentation maps obtained from the two subnetworks, we get the final contours of the endocardium (endo) and epicardium (epi) simultaneously. The proposed method is evaluated on the dataset provided by the Left Ventricle Full Quantification Challenge of MICCAI 2019. The average Dice scores on epi, endo, and myocardium (myo) reach 0.961, 0.949, and 0.867 respectively which outperform the other methods. The experimental results show that our method has the potential for clinical application. (C) 2020 Elsevier B.V. All rights reserved.	187.95418633691543
894.	Race recognition (RR), which has many applications such as in surveillance systems, image/video understanding, analysis, etc., is a difficult problem to solve completely. To contribute towards solving that problem, this article investigates using a deep learning model. An efficient Race Recognition Framework (RRF) is proposed that includes information collector (IC), face detection and preprocessing (FD&P), and RR modules. For the RR module, this study proposes two independent models. The first model is RR using a deep convolutional neural network (CNN) (the RR-CNN model). The second model (the RR-VGG model) is a fine-tuning model for RR based on VGG, the famous trained model for object recognition. In order to examine the performance of our proposed framework, we perform an experiment on our dataset named VNFaces, composed specifically of images collected from Facebook pages of Vietnamese people, to compare the accuracy between RR-CNN and RR-VGG. The experimental results show that for the VNFaces dataset, the RR-VGG model with augmented input images yields the best accuracy at 88.87% while RR-CNN, an independent and lightweight model, yields 88.64% accuracy. The extension experiments conducted prove that our proposed models could be applied to other race dataset problems such as Japanese, Chinese, or Brazilian with over 90% accuracy; the fine-tuning RR-VGG model achieved the best accuracy and is recommended for most scenarios.	187.95405926784002
895.	Targeting protein-protein interactions is a challenge and crucial task of the drug discovery process. A good starting point for rational drug design is the identification of hot spots (HS) at protein-protein interfaces, typically conserved residues that contribute most significantly to the binding. In this chapter, we depict point-by-point an in-house pipeline used for HS prediction using only sequence-based features from the well-known SpotOn dataset of soluble proteins (Moreira et al., Sci Rep 7:8007, 2017), through the implementation of a deep neural network. The presented pipeline is divided into three steps: (1) feature extraction, (2) deep learning classification, and (3) model evaluation. We present all the available resources, including code snippets, the main dataset, and the free and open-source modules/packages necessary for full replication of the protocol. The users should be able to develop an HS prediction model with accuracy, precision, recall, and AUROC of 0.96, 0.93, 0.91, and 0.86, respectively.	187.95392224685747
896.	Object detection is significant for event analysis in various intelligent multimedia processing systems. Although there have been many studies conducting research in this area, effective and efficient object detection methods for video sequences are still much desired. In this article, we investigate salient object detection in real-time multimedia processing systems. Considering the intrinsic relationship between top-down and bottom-up saliency features, we present a new effective method for video salient object detection based on deep semantic and spatiotemporal cues. After extracting top-down semantic features for object perception by a 2-D convolutional network, we concatenate them with bottom-up spatiotemporal cues for motion perception extracted by a 3-D convolutional network. In order to combine these features effectively, we feed them into a 3-D deconvolutional network for feature-sharing learning between semantic features and spatiotemporal cues for the final saliency prediction. Additionally, we propose a novel Gaussian-like loss function with an L-2-norm regularization term for parameter learning. Experimental results show that the proposed salient object detection approach performs better in terms of both effectiveness and efficiency for video sequences compared with the state-of-the-art models.	187.95391269308007
897.	High-dimensional partial differential equations (PDEs) appear in a number of models from the financial industry, such as in derivative pricing models, credit valuation adjustment models, or portfolio optimization models. The PDEs in such applications are high-dimensional as the dimension corresponds to the number of financial assets in a portfolio. Moreover, such PDEs are often fully nonlinear due to the need to incorporate certain nonlinear phenomena in the model such as default risks, transaction costs, volatility uncertainty (Knightian uncertainty), or trading constraints in the model. Such high-dimensional fully nonlinear PDEs are exceedingly difficult to solve as the computational effort for standard approximation methods grows exponentially with the dimension. In this work, we propose a new method for solving high-dimensional fully nonlinear second-order PDEs. Our method can in particular be used to sample from high-dimensional nonlinear expectations. The method is based on (1) a connection between fully nonlinear second-order PDEs and second-order backward stochastic differential equations (2BSDEs), (2) a merged formulation of the PDE and the 2BSDE problem, (3) a temporal forward discretization of the 2BSDE and a spatial approximation via deep neural nets, and (4) a stochastic gradient descent-type optimization procedure. Numerical results obtained using TensorFlow in Python illustrate the efficiency and the accuracy of the method in the cases of a 100-dimensional Black-Scholes-Barenblatt equation, a 100-dimensional Hamilton-Jacobi-Bellman equation, and a nonlinear expectation of a 100-dimensional G-Brownian motion.	187.95388400091147
898.	Computational intelligence in finance has been a very popular topic for both academia and financial industry in the last few decades. Numerous studies have been published resulting in various models. Meanwhile, within the Machine Learning (ML) field, Deep Learning (DL) started getting a lot of attention recently, mostly due to its outperformance over the classical models. Lots of different implementations of DL exist today, and the broad interest is continuing. Finance is one particular area where DL models started getting traction, however, the playfield is wide open, a lot of research opportunities still exist. In this paper, we tried to provide a state-of-the-art snapshot of the developed DL models for financial applications. We not only categorized the works according to their intended subfield in finance but also analyzed them based on their DL models. In addition, we also aimed at identifying possible future implementations and highlighted the pathway for the ongoing research within the field. (C) 2020 Elsevier B.V. All rights reserved.	187.9538146826167
899.	Globally, over 80% of fisheries are at maximum sustainable levels or overexploited. However, small-scale fisheries (SSFs) in developing countries play a relevant role in coastal communities' development with important impacts on the economy. The SSFs are normally multi-specific and due to the lack of data, studying them by simulation poses an important challenge especially forecasting models. These models are necessary to support management decisions or develop sustainable fisheries; therefore, models based on Deep Learning were proposed to forecast SSFs catch, using data from official catch landing reports (OCLRs), satellite images, and oceanographic data. The finfish fishery in Bahia Magdalena-Almejas (Mexico) was used for the present study. According to an analysis of OCLRs, the target species of major importance in the fishery were identified and selected for the model. The proposed deep learning models used two artificial neural networks structures: non-linear autoregressive neural network and long-short term memory network, which were designed to assess and forecast monthly catch levels of Paralabrax nebulifer and Caulolatilus princeps. Models with a performance efficiency of R>0.8, MSE<300 were found, which indicate that the models are applicable in SSF with poor data and multi-specific fishery contexts, at low cost.	187.9536985325055
900.	In the past decade, advances in precision oncology have resulted in an increased demand for predictive assays that enable the selection and stratification of patients for treatment. The enormous divergence of signalling and transcriptional networks mediating the crosstalk between cancer, stromal and immune cells complicates the development of functionally relevant biomarkers based on a single gene or protein. However, the result of these complex processes can be uniquely captured in the morphometric features of stained tissue specimens. The possibility of digitizing whole-slide images of tissue has led to the advent of artificial intelligence (Al) and machine learning tools in digital pathology, which enable mining of subvisual morphometric phenotypes and might, ultimately, improve patient management. In this Perspective, we critically evaluate various AI-based computational approaches for digital pathology, focusing on deep neural networks and 'hand-crafted' feature-based methodologies. We aim to provide a broad framework for incorporating Al and machine learning tools into clinical oncology, with an emphasis on biomarker development. We discuss some of the challenges relating to the use of Al, including the need for well-curated validation datasets, regulatory approval and fair reimbursement strategies. Finally, we present potential future opportunities for precision oncology.	187.95364384344214
901.	We propose a deep-learning based annotation-efficient framework for vessel detection in ultra-widefield (UWF) fundus photography (FP) that does not require de novo labeled UWF FP vessel maps. Our approach utilizes concurrently captured UWF fluorescein angiography (FA) images, for which effective deep learning approaches have recently become available, and iterates between a multi-modal registration step and a weakly-supervised learning step. In the registration step, the UWF FA vessel maps detected with a pre-trained deep neural network (DNN) are registered with the UWF FP via parametric chamfer alignment. The warped vessel maps can be used as the tentative training data but inevitably contain incorrect (noisy) labels due to the differences between FA and FP modalities and the errors in the registration. In the learning step, a robust learning method is proposed to train DNNs with noisy labels. The detected FP vessel maps are used for the registration in the following iteration. The registration and the vessel detection benefit from each other and are progressively improved. Once trained, the UWF FP vessel detection DNN from the proposed approach allows FP vessel detection without requiring concurrently captured UWF FA images. We validate the proposed framework on a new UWF FP dataset, PRIME-FP20, and on existing narrow-field FP datasets. Experimental evaluation, using both pixel-wise metrics and the CAL metrics designed to provide better agreement with human assessment, shows that the proposed approach provides accurate vessel detection, without requiring manually labeled UWF FP training data.	187.9535928291824
902.	Deep learning has made remarkable progress in the field of image anomaly detection. An explanation of the validity of the detection is required for practical application. Conventional methods for localizing abnormal regions are mainly based on image reconstruction errors. However, they cannot directly extract specific features from abnormal regions, which limits localization performance. To address this issue, we developed a method for explainable anomaly detection in an unsupervised manner. We trained a feature extractor to extract features that had both the compactness of the normal state and the descriptiveness of the abnormal state for the input images and their reconstructed images. For explainability, our method localized and visualized abnormal regions by accumulating intermediate layers, which led to a significant difference in features extracted from the input image and the reconstructed image. The quantitative results of the defect segmentation and the qualitative results of anomaly localization from experiments on two datasets showed that our method outperformed conventional methods when it came to localizing abnormal regions.	187.95351980654198
903.	Objective and efficient diagnosis of Alzheimer's disease (AD) has been a major topic with extensive researches in recent years, and some promising results have been shown for imaging markers using magnetic resonance imaging (MRI) data. Beside conventional machine learning methods, deep learning based methods have been developed in several studies, where layer-by-layer neural network settings were purposed to extract features for disease classification from the patches or whole images. However, as the disease develops from subcortical nuclei to cortical regions, specific brain regions with morphological changes might contribute to the diagnosis of disease progress. Therefore, we propose a novel spatial and depth weighted neural network structure to extract effective features, and further improve the performance of AD diagnosis. Specifically, we first use group comparison to detect the most distinctive AD-related landmarks, and then sample landmark-based image patches as our training data. In the model structure, with a 15-layer DenseNet as backbone, we introduce a attention bypass to estimate the spatial weights in the image space to guide the network to focus on specific regions. A squeeze-and-excitation (SE) mechanism is also adopted to further weight the feature map channels. We used 2335 subjects from public datasets (i.e., ADNI-1, ADNI-2 and ADNI-GO) for experiment and results show that our framework achieves 90.02% accuracy, 81.25% sensitivity, and 96.33% specificity in diagnosis AD patients from normal controls.	187.95348058633402
904.	Financial analysis of the stock market using the historical data is the exigent demand in business and academia. This work explores the efficiency of three deep learning (Dl) techniques, namely Bayesian regularization (BE), Levenberg-Marquardt (lM), and scaled conjugate gradient (SCG), for training nonlinear autoregressive artificial neural networks (NARX) for predicting specifically the closing price of the Egyptian Stock Exchange indices (EGX-30, EGX-30-Capped, EGX-50-EWI, EGX-70, EGX-100, and NIlE). An empirical comparison is established among the experimented prediction models considering all techniques for the time horizon of 1 day, 3 days, 5 days, 7 days, 5 days and 30 days in advance, applying on all the datasets used in this study. For performance evaluation, statistical measures such as mean squared error (MSE) and correlationRare used. From the simulation result, it can be clearly suggested that BR outperforms other models for short-term prediction especially for 3 days ahead. On the other hand, lM generates better prediction accuracy than BR- and SCG-based models for long-term prediction, especially for 7-day prediction.	187.9533903511924
905.	Recently, deep learning methodologies have become popular to analyse physiological signals in multiple modalities via hierarchical architectures for human emotion recognition. In most of the state-of-the-arts of human emotion recognition, deep learning for emotion classification was used. However, deep learning is mostly effective for deep feature extraction. Therefore, in this research, we applied unsupervised deep belief network (DBN) for depth level feature extraction from fused observations of Electro-Dermal Activity (EDA), Photoplethysmogram (PPG) and Zygomaticus Electromyography (zEMG) sensors signals. Afterwards, the DBN produced features are combined with statistical features of EDA, PPG and zEMG to prepare a feature-fusion vector. The prepared feature vector is then used to classify five basic emotions namely Happy, Relaxed, Disgust, Sad and Neutral. As the emotion classes are not linearly separable from the feature-fusion vector, the Fine Gaussian Support Vector Machine (FGSVM) is used with radial basis function kernel for non-linear classification of human emotions. Our experiments on a public multimodal physiological signal dataset show that the DBN, and FGSVM based model significantly increases the accuracy of emotion recognition rate as compared to the existing state-of-the-art emotion classification techniques.	187.95336000597626
906.	Atrial Fibrillation (AF), either permanent or intermittent (paroxysnal AF), increases the risk of cardioembolic stroke. Accurate diagnosis of AF is obligatory for initiation of effective treatment to prevent stroke. Long term cardiac monitoring improves the likelihood of diagnosing paroxysmal AF. We used a deep learning system to detect AF beats in Heart Rate (HR) signals. The data was partitioned with a sliding window of 100 beats. The resulting signal blocks were directly fed into a deep Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM). The system was validated and tested with data from the MIT-BIH Atrial Fibrillation Database. It achieved 98.51% accuracy with 10-fold cross-validation (20 subjects) and 99.77% with blindfold validation (3 subjects). The proposed system structure is straight forward, because there is no need for information reduction through feature extraction. All the complexity resides in the deep learning system, which gets the entire information from a signal block. This setup leads to the robust performance for unknown data, as measured with the blind fold validation. The proposed Computer-Aided Diagnosis (CAD) system can be used for long-term monitoring of the human heart. To the best of our knowledge, the proposed system is the first to incorporate deep learning for AF beat detection.	187.95333996682712
907.	The advancements in computer vision-related technologies attract many researchers for surveillance applications, particularly involving the automated crowded scenes analysis such as crowd counting in a very congested scene. In crowd counting, the main goal is to count or estimate the number of people in a particular scene. Understanding overcrowded scenes in real-time is important for instant responsive actions. However, it is a very difficult task due to some of the key challenges including clutter background, occlusion, variations in human pose and scale, and limited surveillance training data, that are inadequately covered in the employed literature. To tackle these challenges, we introduce "SD-Net" an end-to-end CNN architecture, which produces real-time high quality density maps and effectively counts people in extremely overcrowded scenes. The proposed architecture consists of depthwise separable, standard, and dilated 2D convolutional layers. Depthwise separable and standard 2D convolutional layers are used to extract 2D features. Instead of using pooling layers, dilated 2D convolutional layers are employed that results in huge receptive fields and reduces the number of parameters. Our CNN architecture is evaluated using four publicly available crowd analysis datasets, demonstrating superiority over state-of-the-art in terms of accuracy and model size.	187.953258000578
908.	Automatic question generation, which aims at converting sentences in an article to high-quality questions, is an important task for educational practices. Recent work mainly focuses on designing effective generation architectures based on deep neural networks. However, the first and possibly the foremost step of automatic question generation has largely been ignored, i.e., identifying sentences carrying important information or knowledge that is worth asking questions about. In this work, we (i) propose a total of 9 strategies, which are grounded on heuristic question-asking assumptions, to determine sentences that are question-worthy, and (ii) compare their performance on 4 datasets by using the identified sentences as input for a well-trained question generator. Through extensive experiments, we show that (i) LexRank, a stochastic graph-based method for selecting important sentences from articles, gives robust performance across all datasets, (ii) questions collected in educational settings feature a more diverse set of source sentences than those obtained in non-educational settings, and (iii) more research efforts are needed to further improve the design of educational question generation architectures.	187.95315852046465
909.	The role of the stock market across the overall financial market is indispensable. The way to acquire practical trading signals in the transaction process to maximize the benefits is a problem that has been studied for a long time. This paper put forward a theory of deep reinforcement learning in the stock trading decisions and stock price prediction, the reliability and availability of the model are proved by experimental data, and the model is compared with the traditional model to prove its advantages. From the point of view of stock market forecasting and intelligent decision-making mechanism, this paper proves the feasibility of deep reinforcement learning in financial markets and the credibility and advantages of strategic decision-making.	187.95296509518062
910.	The accurate and stable identification of the traffic load distribution on the bridge deck is of great significance to bridge health monitoring and safety early warning. To accomplish this task, we have combined the weigh-in-motion system (WIMs) with machine vision and developed a traffic load monitoring (TLM) technology for the whole bridge deck. For bridge health monitoring, the TLM should be available for online structural analysis, have high accuracy, and be able to adapt to changes in lighting conditions. However, existing TLM methods are difficult to meet the requirements of real-time, accuracy, and lighting robustness simultaneously. In this regard, this paper proposes an improved full-bridge TLM method based on YOLO-v3 convolutional neural network. The core of this method includes training a dual-target detection model and correcting vehicle locations. The detection model can identify profiles of the entire vehicle and its tail and can mark them with compact rectangular boxes. Based on the corner points of these rectangular boxes, an optical geometry model is proposed to measure vehicle dimensions and correct vehicle centroids, thereby the vehicle locations can be estimated more accurately. By applying the time synchronization of cameras and the WIMs, each measured load is paired with the vehicle "pixel cluster" detected in the video; further, the traffic load distribution on the whole bridge deck is identified accurately in real-time. Verified by the field data of a ramp bridge, the proposed method is proved more accurately on the identification of vehicle locations, more robust lighting adaptability, and faster calculation speed, which can meet the requirements of field monitoring of traffic load distribution.	187.9529242396826
911.	This paper proposed a new gene selection method based on modified Minimum Redundancy Maximum Relevancy (MRMR) as a filtering approach and hybrid bat algorithm with beta-hill climbing as an efficient wrapper approach. The gene selection is a process of selecting the discriminative genes that aid in the development of efficient cancer diagnosis and classification. In general, the current filter-based approaches produced gene subset according to its discriminative power. However, one of the deficiencies of single filter approaches is that it has high variability of the classification results. Accordingly, this study aim to improve MRMR through incorporating its with ensemble of filters to increase the robustness and the stability of MRMR. The result of filtering-based approach is a set of discriminative genes. The wrapper-based approach considers the results from the filtering-based approach to formulate the gene selection search space. In wrapper approach, bat algorithm is tailored for gene selection problem and hybridized with a powerful local search method called beta hill climbing to further stress the deep learning side in the search space navigation and thus find a very robust and stable discriminative genes. Bat-inspired algorithm (BA) is a recent swarm-based optimization method while beta-hill climbing is an exploratory local search. The proposed method is called Robust MRMR and Hybrid Bat-inspired Algorithm (rMRMR-HBA). To evaluate the proposed method, ten well-known microarray datasets are experimented with. These datasets are varies in terms of number of genes, samples, and classes. For performance evaluation, the proposed filtering-based approach (i.e., rMRMR) is initially tested against the standard MRMR and other well-regard filtering approaches. Thereafter, the wrapper-based approach (i.e., HBA) is evaluated by studying the convergence behavior of BA with and without beta-hill climbing. For comparative evaluation, the results of the proposed rMRMR-HBA were compared with state-of-art methods using the same microarray datasets. The comparative results show that our proposed approach achieved outstanding results in two out of ten datasets in terms of clarification accuracy and minimum number of genes.	187.95290066237314
912.	We propose an intensity-based technique to homogenize dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) data acquired at six institutions. A total of 234 T1-weighted MRI volumes acquired at the peak kinetic curve were obtained for study of the homogenization and unsupervised deep-learning feature extraction techniques. The homogenization uses reference regions of adipose breast tissue since they are less susceptible to variations due to cancer and contrast medium. For the homogenization, the moments of the distribution of reference pixel intensities across the cases were matched and the remaining intensity distributions were matched accordingly. A deep stacked autoencoder with six convolutional layers was trained to reconstruct a 128x128 MRI slice and to extract a latent space of 1024 dimensions. We used the latent space from the stacked autoencoder to extract deep embedding features that represented the global and local structures of the imaging data. An analysis using spectral embedding of the latent space shows that, before homogenization the dominating factor was the dependency on the imaging center; after homogenization the histograms of the cases between different centers were matched and the center dependency was reduced. The results of feature analysis indicate that the proposed homogenization approach may lessen the effects of different imaging protocols and scanners in MRI, which may then allow more consistent quantitative analysis of radiomic information across patients and improve the generalizability of machine learning methods across different clinical sites. Further study is underway to evaluate the performance of machine learning models with and without image homogenization.	187.95284509987096
913.	We describe a machine-learning system for supporting teachers through the selection of homework assignments. Our system uses behavioural cloning of teacher activity to generate personalised homework assignments for students. Classroom use is then supported through additional mechanisms to combine these predictions into group assignments. We train and evaluate our system against 50,065 homework assignments collected over two years by the Isaac Physics platform. We use baseline policies incorporating expert curriculum knowledge for evaluation and find that our technique improves on the strongest baseline policy by 18.5% in Year 1 and by 13.3% in Year 2.	187.95283598521934
914.	We describe a Transformer model for a retrosynthetic reaction prediction task. The model is trained on 45 033 experimental reaction examples extracted from USA patents. It can successfully predict the reactants set for 42.7% of cases on the external test set. During the training procedure, we applied different learning rate schedules and snapshot learning. These techniques can prevent overfitting and thus can be a reason to get rid of internal validation dataset that is advantageous for deep models with millions of parameters. We thoroughly investigated different approaches to train Transformer models and found that snapshot learning with averaging weights on learning rates minima works best. While decoding the model output probabilities there is a strong influence of the temperature that improves at T = 1.3 the accuracy of models up to 1-2%.	187.9528271151118
915.	Early action recognition seeks to recognize human actions in a video, while the video has been only partially observed. In this paper, we introduce an approach to this kind of recognition task. In some offline (non-early) recognition works, it has been proposed to sample frames of the video uniformly and use them in training of the model. However, there is no reason that uniform sampling should be optimal, so we propose a non-uniform sampling to make it more tailored to early recognition. The proposed method samples the frames in such a way that earlier frames are more likely to be chosen. These frames are then used in training a deep network architecture. We compare our sampling approach with a uniform sampling process, using HMDB51 dataset as a benchmark. We further compare our method with other state-of-the-art early recognition works. The experimental results suggest that our sampling process leads to better recognition accuracy than uniform sampling, at the early stages of the video, and that our proposed algorithm outperforms the state-of-the-art.	187.9527911825671
916.	With increasing global demand for learning English as a second language, there has been considerable interest in methods of automatic assessment of spoken language proficiency for use in interactive electronic learning tools as well as for grading candidates for formal qualifications. This paper presents an automatic system to address the assessment of spontaneous spoken language. Prompts or questions requiring spontaneous speech responses elicit more natural speech which better reflects a learner's proficiency level than read speech. In addition to the challenges of highly variable non-native, learner, speech and noisy real-world recording conditions, this requires any automatic system to handle disfluent, non-grammatical, spontaneous speech with the underlying text unknown. To handle these, a strong deep learning based speech recognition system is applied in combination with a Gaussian Process (GP) grader. A range of features derived from the audio using the recognition hypothesis are investigated for their efficacy in the automatic grader. The proposed system is shown to predict grades at a similar level to the original examiner graders on real candidate entries. Interpolation with the examiner grades further boosts performance. The ability to reject poorly estimated grades is also important and measures are proposed to evaluate the performance of rejection schemes. The GP variance is used to decide which automatic grades should be rejected. Back-off to an expert grader for the least confident grades gives gains.	187.9527667849909
917.	For emotion classification in facial expression recognition (FER), the performance of both traditional statistical methods and state-of-the-art deep learning methods are highly dependent on the quality of data. Traditional methods use image preprocessing (such as smoothing and segmentation) to improve image quality. However, the results still fail to meet the quality requirements of the emotion classifiers in FER. To address the above issues, this paper proposed a novel framework based on reinforcement learning for pre-selecting useful images(RLPS) for emotion classification in FER, which is made up of two modules: image selector and rough emotion classifier. Image selector is used to select useful images for emotion classification through reinforcement strategy and rough emotion classifier acts as a teacher to train image selector. Our framework improves classification performance by improving the quality of the dataset and can be applied to any classifier. Experiment results on RAF-DB, ExpW, and FER2013 datasets show that the proposed strategy achieves consistent improvements compared with the state-of-the-art emotion classification methods in FER.(1) (C) 2020 Elsevier B.V. All rights reserved.	187.9527656080709
918.	Fingerprint classification helps in reducing the number of comparisons during the matching stage in automatic fingerprint identification system. In this study, a convolutional neural network model is proposed for classification of plain, rolled and latent fingerprints. We first propose a new convolutional neural network model initialised with random weights and train the model on fingerprint images. Then we fine-tune two pre-trained convolutional neural network models on fingerprint images. Finally, we compare these three models: two pre-trained models and a custom convolutional neural network model initialised with random weights. We show that pre-trained models can achieve the state-of-the-art results on other similar tasks with no or little fine-tuning. We also show that training data size and depth of the network have a serious impact on the overall performance of deep networks. Dropout is used to enhance the performance of deep networks where the labelled training data is not of sufficient size. All the three models trained on NIST DB4 fingerprint and IIIT-D latent fingerprint databases report good accuracy. By only fine-tuning the pre-trained convolutional neural network model, we get the accuracy of 99%, easily out-performing the state-of-the-art.	187.9527375996064
919.	Convolutional neural networks have been shown to demonstrate high diagnostic performance in radiologic image interpretation tasks ranging from recognition of acute stroke on computed tomography to identification of tuberculosis on plain radiographs. To a radiologist not immersed in computer science jargon, it may seem that this inscrutable black box is best treated warily, at arm's length. In this work, we illustrate how a radiologist without a deep background in computer science may be able to set up a state-of-the-art convolutional neural network for image interpretation tasks through transfer learning. This technique is relatively simple to implement, has been shown to demonstrate equivalent performance to neural networks specifically trained on medical image data, and offers a chance for the interested-but-intimidated radiologist to deep her toe in the water without becoming overwhelmed. (C) 2019 Elsevier Inc. All rights reserved.	187.95268493010062
920.	The agriculture sector faces crop losses every year due to diseases around the globe, which adversely affect food productivity and quality. Detecting and identifying plant diseases at an early stage is still a challenge for farmers, particularly in developing countries. Widespread use of mobile computing devices and the advancements in artificial intelligence have created opportunities for developing technologies to assist farmers in plant disease detection and treatment. To this end, deep learning has been widely used for disease detection in plants with highly favorable outcomes. In this paper, we propose an efficient convolutional neural network-based disease detection framework in plum under true field conditions for resource-constrained devices. As opposed to the publicly available datasets, images used in this study were collected in the field by considering important parameters of image-capturing devices such as angle, scale, orientation, and environmental conditions. Furthermore, extensive data augmentation was used to expand the dataset and make it more challenging to enable robust training. Investigations of recent architectures revealed that transfer learning of scale-sensitive models like Inception yield results much better with such challenging datasets with extensive data augmentation. Through parameter quantization, we optimized the Inception-v3 model for deployment on resource-constrained devices. The optimized model successfully classified healthy and diseased fruits and leaves with more than 92% accuracy on mobile devices.	187.95263371228367
921.	An automatic bird identification system is required for offshore wind farms in Finland. Indubitably, a radar is the obvious choice to detect flying birds, but external information is required for actual identification. We applied visual camera images as external data. The proposed system for automatic bird identification consists of a radar, a motorized video head and a single-lens reflex camera with a telephoto lens. A convolutional neural network trained with a deep learning algorithm is applied to the image classification. We also propose a data augmentation method in which images are rotated and converted in accordance with the desired color temperatures. The final identification is based on a fusion of parameters provided by the radar and the predictions of the image classifier. The sensitivity of this proposed system, on a dataset containing 9312 manually taken original images resulting in 2.44 x 10(6) augmented data set, is 0.9463 as an image classifier. The area under receiver operating characteristic curve for two key bird species is 0.9993 (the White-tailed Eagle) and 0.9496 (The Lesser Black-backed Gull), respectively. We proposed a novel system for automatic bird identification as a real world application. We demonstrated that our data augmentation method is suitable for image classification problem and it significantly increases the performance of the classifier.	187.95262497346738
922.	Gaussian and Laplacian pyramids have long been important for image analysis and compression. More recently, Gaussian and Laplacian pyramids have become an important component of machine learning and deep learning for image analysis and image recognition. Constructing these pyramids consists of a series of filtering, decimation, and differencing operations, and the quality indicator is usually mean squared reconstruction error in comparison to the original image. We present a new characterization of the information loss in a Gaussian pyramid in terms of the change in mutual information. More specifically, we show that one half the log ratio of entropy powers between two stages in a Gaussian pyramid is equal to the difference in mutual information between these two stages. We show that this relationship holds for a wide variety of probability distributions and present several examples of analyzing Gaussian and Laplacian pyramids for different images.	187.95249866973586
923.	Despite the approaching Internet of Things (IoT) era, most smart devices cannot directly execute complicated deep neural networks (DNNs) due to their limited memory sizes and computing power. Even with model compression, compressing and executing a non-binarized DNN model often needs a codebook for weight calculation, which typically requires acceleration from a Graphics Processing Unit (GPU). Parameter binarization is one commonly used method to reduce computing time and space, but it often seriously compromises the accuracy of the binarized DNN (BNN), which tends to adopt single-stage non-modularized design. To address these issues, we propose a modularized multi-stage BNN model compression with flexible combination of parameter and structure compression to minimize model size while maintaining maximum accuracy possible. The compressed BNNs do not need any codebooks so they better fit into embedded platforms without any GPU acceleration. From our evaluations, the size of a BNN model can be reduced to 1/57 size at the cost of only about a 5% decrease in accuracy, which outperforms the state-of-the-art single-stage compression on BNN models. Furthermore, the proposed method can recover the accuracy of a BNN by 5% even after its size has been further compressed to approximately half its size, demonstrating its potentials in leveraging edge intelligence.	187.95245593525516
924.	Ensemble weather predictions require statistical postprocessing of systematic errors to obtain reliable and accurate probabilistic forecasts. Traditionally, this is accomplished with distributional regression models in which the parameters of a predictive distribution are estimated from a training period. We propose a flexible alternative based on neural networks that can incorporate nonlinear relationships between arbitrary predictor variables and forecast distribution parameters that are automatically learned in a data-driven way rather than requiring prespecified link functions. In a case study of 2-m temperature forecasts at surface stations in Germany, the neural network approach significantly outperforms benchmark postprocessing methods while being computationally more affordable. Key components to this improvement are the use of auxiliary predictor variables and station-specific information with the help of embeddings. Furthermore, the trained neural network can be used to gain insight into the importance of meteorological variables, thereby challenging the notion of neural networks as uninterpretable black boxes. Our approach can easily be extended to other statistical postprocessing and forecasting problems. We anticipate that recent advances in deep learning combined with the ever-increasing amounts of model and observation data will transform the postprocessing of numerical weather forecasts in the coming decade.	187.95244958200203
925.	Parkinson's Disease (PD) is one of the most prevalent neurological disorders characterized by impairment of motor function. Early diagnosis of PD is important for initial treatment. This paper presents a newly developed method for application in remote tracking of PD progression. The method is based on deep learning and clustering approaches. Specifically, we use the Deep Belief Network (DBN) and Support Vector Regression (SVR) to predict Unified Parkinson's Disease Rating Scale (UPDRS). The DBN prediction models were developed by different epoch numbers. We use a clustering approach, namely, Self Organizing Map (SOM), to improve the accuracy and scalability of prediction. We evaluate our method on a real-world PD dataset. In all, nine clusters were detected from the data with the best SOM map quality for clustering, and for each cluster, a DBN was developed with a specific number of epochs. The results of the DBN prediction models were integrated by the SVR technique. Further, we compare our work with other supervised learning techniques, SVR and Neuro-Fuzzy techniques. The results revealed that the hybrid of clustering and DBN with the aid of SVR for an ensemble of the DBN outputs can make relatively better predictions of Total-UPDRS and Motor-UPDRS than other learning techniques. (c) 2020 Elsevier Ltd. All rights reserved.	187.95244178433717
926.	Detection and segmentation of motorways, railroads and other roads with similar features are significant for comprehension of both low and high resolution synthetic aperture radar (SAR) imagery. Separation of transportation network from other fields or features is important to understand area contained in SAR image (i.e. the road density can inform about characteristic of that area). Standard image processing methods are inadequate to detect multiple linear targets correctly where computer vision, especially deep learning, provides more insight about features for different type of roads which help better discrimination of multiple linear features like roads and railroads. State-of-art deep learning algorithms are proposed as solutions for understanding road characteristics and extraction of multiple roads. In this paper, a method which uses deep convolutional neural network (DeepLabv3+) backbone architecture is proposed to detect road and railways concurrently. Semantic segmentation of roads using SAR imagery is challenging since these images differ as ground sample distance changes with sensor types which creates a setback for establishing dataset for all sensors. Training set contains 3 classes (road, railway, other) with collected signatures from TerraSAR-X Spotlight images for classification. Proposed method shows robust performance when applied to other sensor and results are presented.	187.95237883303355
927.	This paper introduces a system capable of real-time video surveillance in low-end edge computing environment by combining object detection tracking algorithm. Recently, the accuracy of object detection has been improved due to the performance of approaches based on deep learning algorithm such as region-based convolutional network, which has two stages for inferencing. One-stage detection algorithms such as single shot detector and you only look once (YOLO) have been developed at the expense of some accuracy and can be used for real-time systems. However, high-performance hardware such as general-purpose graphics processing unit is required to achieve excellent object detection performance and speed. In this study, we propose an approach called N-YOLO which is instead of resizing image step in YOLO algorithm, it divides into fixed size images used in YOLO and merges detection results of each divided sub-image with inference results at different times using correlation-based tracking algorithm the amount of computation for object detection and tracking can be significantly reduced. In addition, we propose a system that can guarantee real-time performance in various edge computing environments by adaptively controlling the cycle of object detection and tracking.	187.95227382494224
928.	It has still been difficult to solve nonlinear evolution equations analytically. In this paper, we present a deep learning method for recovering the intrinsic nonlinear dynamics from spatiotemporal data directly. Specifically, the model uses a deep neural network constrained with given governing equations to try to learn all optimal parameters. In particular, numerical experiments on several third-order nonlinear evolution equations, including the Korteweg-de Vries (KdV) equation, modified KdV equation, KdV-Burgers equation and Sharma-Tasso-Olver equation, demonstrate that the presented method is able to uncover the solitons and their interaction behaviors fairly well.	187.95225803972255
929.	Background: Digital services have been found promising in managing different aspects of health, also stress. We developed a web service for cultivating the positive side of stress based on the stress experiences of entrepreneurs. In this paper, we present a field study conducted to evaluate the user acceptance and the user experience of the developed service. Methods: Twenty-two participants, working as entrepreneurs or having an entrepreneurial-type job description, used the web service for 6 weeks. User experiences were collected from all participants with electronic questionnaires, and 10 participants were interviewed to gain deeper understanding and to formulate design implications. In addition, usage logs of the web service were analysed to assess how actively the participants used the service and a pre and post questionnaires on stress and work engagement were conducted to evaluate the preliminary effectiveness of the service. Results: The usage activity of the service was relatively low, on average, the service was used on 3 days and a total of 101 min. During the usage period, the participants' negative stress measured by the perceived stress scale decreased and their self-reported positive stress experiences had increased. The participants considered the positive perspective to stress useful. In the Eustress Toolbox service, the users appreciated especially the off-line and reflection exercises, as well as the quotations from peers, but the design should have supported more active triggering to use the service. Conclusions: Based on user experience, we propose four design implications: Integrate the service into the daily hassle of entrepreneurs, Provide personal guidance while maintaining a possibility to explore, Recognise the user's progress and accomplishments in a meaningful way and Support implicit learning from peer entrepreneurs.	187.95220725572278
930.	Deep Echo State Networks (DeepESNs) recently extended the applicability of Reservoir Computing (RC) methods towards the field of deep learning. In this paper we study the impact of constrained reservoir topologies in the architectural design of deep reservoirs, through numerical experiments on several RC benchmarks. The major outcome of our investigation is to show the remarkable effect, in terms of predictive performance gain, achieved by the synergy between a deep reservoir construction and a structured organization of the recurrent units in each layer. Our results also indicate that a particularly advantageous architectural setting is obtained in correspondence of DeepESNs where reservoir units are structured according to a permutation recurrent matrix.	187.95213036997268
931.	The link between spatial design, the social construction of gender and gendered spatial education becomes evident in school playgrounds, where social and cultural roles are reproduced, hi many cases we can observe the segregation of boys and girls in games and hierarchies between different zones, especially between center and periphery. Taking in account the importance of the school playground as a space for learning, play and coexistence, a methodology is proposed that, based on a collective process, seeks to generate proposals that incorporate gender equality, cooperation and social inclusion. This methodology combines different techniques, from the most traditional observations and interviews to resources from the dynamics used for citizen participation. The case that is presented demonstrates how to reflect and experiment with the reorganization of space can be a starting point to achieve deeper changes, both at the educational and community level.	187.9520689141553
932.	Previous efforts on analyzing the sorting level of rock particles rely on particle segmentation, which is time-consuming and inaccurate due to lighting and infra-particle statistical variations. With high-level features learned from a deep neural network, we directly conduct the classification of sorting in rocks. Our approach avoids the need for laborious segmentation and is entirely automatic. We use an off-the-shelf convolutional neural network (CNN) model that has been pre-trained on a large scale image dataset to extract feature representations for our rock images. Then we trained a support vector machine (SVM) classifier with the feature representations as input. The experiments show that the off-the-shelf CNN features lead to significantly improved results for the classification compared with handcrafted features and low-level K-means features.	187.95204745183787
933.	Using deep convolutional neural networks (CNN) to predict the depth from a single image has received considerable attention in recent years due to its impressive performance. However, existing methods process each single image independently without leveraging the multiview information of video sequences in practical scenarios. Properly taking into account multiview information in video sequences beyond individual frames could offer considerable benefits in terms of depth prediction accuracy and robustness. In addition, a meaningful measure of prediction uncertainty is essential for decision making, which is not provided in existing methods. This paper presents a novel video-based depth prediction system based on a monocular camera, named Bayesian DeNet. Specifically, Bayesian DeNet consists of a 59-layer CNN that can concurrently output a depth map and an uncertainty map for each video frame. Each pixel in an uncertainty map indicates the error variance of the corresponding depth estimate. Depth estimates and uncertainties of previous frames are propagated to the current frame based on the tracked camera pose, yielding multiple depth/uncertainty hypotheses for the current frame which are then fused in a Bayesian inference framework for greater accuracy and robustness. Extensive exper-iments on three public datasets demonstrate that our Bayesian DeNet outperforms the state-of-the-art methods for monocular depth prediction. A demo video and code are publicly available.(1)	187.95202063550295
934.	Deep learning has recently been successfully applied to lithography hotspot detection. However, automatic correction of the detected hotspots into non-hotspots has not been explored. This problem is challenging because the standard supervised learning requires a training dataset with pairs of hotspots and non-hotspots, which is impractical to collect because lithography hotspots involve diverse and complicated lithographic pattern properties. In this paper, we propose a new framework for lithography hotspot correction with a deep generative network combined with a learning strategy optimized for lithography patterns. Our key idea is to learn to translate hotspots to non-hotspots and vice versa, simultaneously. In this way, the training dataset does not have to be paired, and hotspot patterns in variety of background can be learned. Our method does not require the understanding of the cause of hotspots and can correct hotspots that are difficult to recognize by conventional approaches. For evaluation, we propose to synthesize a training dataset that reflects a variety of real-world lithography patterns. Experimental results show that our framework can correct hotspot images with comparable quality as a conventional complicated process, while significantly reducing the overall processing time.	187.95188222615144
935.	Nuclei segmentation is a fundamental task in histopathology image analysis. Typically, such segmentation tasks require significant effort to manually generate accurate pixel-wise annotations for fully supervised training. To alleviate such tedious and manual effort, in this paper we propose a novel weakly supervised segmentation framework based on partial points annotation, i.e., only a small portion of nuclei locations in each image are labeled. The framework consists of two learning stages. In the first stage, we design a semi-supervised strategy to learn a detection model from partially labeled nuclei locations. Specifically, an extended Gaussian mask is designed to train an initial model with partially labeled data. Then, self-training with background propagation is proposed to make use of the unlabeled regions to boost nuclei detection and suppress false positives. In the second stage, a segmentation model is trained from the detected nuclei locations in a weakly-supervised fashion. Two types of coarse labels with complementary information are derived from the detected points and are then utilized to train a deep neural network. The fully-connected conditional random field loss is utilized in training to further refine the model without introducing extra computational complexity during inference. The proposed method is extensively evaluated on two nuclei segmentation datasets. The experimental results demonstrate that our method can achieve competitive performance compared to the fully supervised counterpart and the state-of-the-art methods while requiring significantly less annotation effort.	187.9518502277572
936.	The purpose of researches on multi-focus image fusion is to obtain a composed image where the objects are all captured in focus. Compared with the source images, the new one is of richer information and much better visual performance. Deep convolutional neural network (DCNN) and extreme learning machine (ELM) are combined to be a novel model (DCELM) to deal with the issue of multi-focus image fusion. First, the source images are input into DCELM. Then, ELM is responsible for generating random weights between adjacent layers. Moreover, a convolution layer followed by a pooling one forms the basic unit of DCELM, which is used to get the feature maps of the source images from different perspectives. Finally, the above features are classified via ELM, and the information in focus from the source images can be fused into the final fused image. Experimental results demonstrate that the proposed fusion method well combines the better feature extraction ability of DCNN and much faster training speed of ELM, and its performance is superior to current state-of-the-art typical ones.	187.95178548809153
937.	The past 10 years have witnessed the rapid growth of global mobile cellular traffic demands due to the popularity of mobile devices. While accurate traffic prediction becomes extremely important for stable and high-quality Internet service, the performance of existing methods is still poor due to three challenges: complicated temporal variations including burstiness and long periods, multi-variant impact factors such as the point of interest and day of the week, and potential spatial dependencies introduced by the movement of population. While existing traditional methods fail in characterizing these features, especially the latter two, deep learning models with powerful representation ability give us a chance to consider these from a new perspective. In this article, we propose Deep Traffic Predictor (DeepTP), a deep-learning-based end-to-end model, which forecasts traffic demands from spatial-dependent and long-period cellular traffic. DeepTP consists of two components: a general feature extractor for modeling spatial dependencies and encoding the external information, and a sequential module for modeling complicated temporal variations. In the general feature extractor, we introduce a correlation selection mechanism for a spatial modeling and embedding mechanism to encode external information. Moreover, we apply a seq2seq model with attention mechanism to build the sequential model. Extensive experiments based on large-scale mobile cellular traffic data demonstrate that our model outperforms the state-of-the-art traffic prediction models by more than 12.31 percent.	187.95175466866732
938.	Different artifacts will manifest, whenever an image is compressed by a lossy compression algorithm. Higher frequency details present in the image may tend to be eliminated by compression. In certain cases, compression may introduce small image structures and noise. This phenomenon will limit the image quality thereby making images to appear much less pleasant to the human eye. Furthermore, other machine learning tasks like object detectors performance will be reduced due to compression. In this paper, we introduce a novel deep neural network with densely connected parallel convolutions to remove such artifacts and to recover the original image from its perturbed version. The proposed algorithm is named as densely connected parallel convolutional neural network in short DPCNN. Parallel convolution provides model parallelism and reduce the training burden. Furthermore, the dense skip connections provide short paths for gradient back-propagation and alleviates the gradient vanishing problem. Moreover, skip connections reduce the feature redundancy by combining features from different levels and increases the learning efficiency. However, these skip connections increase the model complexity. A bottleneck layer is used to keep the model compactness and to reduce the model complexity. The proposed approach can be used as a preprocessing step in different computer vision tasks where images are degraded by compression. Different from other methods, the proposed method is able to remove compression artifacts generated at any quality factor (QF). The experiments on benchmark datasets show the superiority of the proposed method over other methods quantitatively and qualitatively.	187.95167029982443
939.	In recent years, we have seen a large growth in the number of applications which use deep learning-based object detectors. Autonomous driving assistance systems (ADAS) are one of the areas where they have the most impact. This work presents a novel study evaluating a state-of-the-art technique for urban object detection and localization. In particular, we investigated the performance of the Faster R-CNN method to detect and localize urban objects in a variety of outdoor urban videos involving pedestrians, cars, bicycles and other objects moving in the scene (urban driving). We propose a new dataset that is used for benchmarking the accuracy of a real-time object detector (Faster R-CNN). Part of the data was collected using an HD camera mounted on a vehicle. Furthermore, some of the data is weakly annotated so it can be used for testing weakly supervised learning techniques. There already exist urban object datasets, but none of them include all the essential urban objects. We carried out extensive experiments demonstrating the effectiveness of the baseline approach. Additionally, we propose an R-CNN plus tracking technique to accelerate the process of real-time urban object detection.	187.95161512941573
940.	This study examined how reflective assessment supported by principles facilitated metadiscourse for knowledge advances mediated by Knowledge Forum(center dot) (KF). Participants were 60 tertiary students in two classes engaging in knowledge building and reflecting on their collaborative knowledge building using e-portfolios; one class was a principle-based knowledge-building environment (KBP, n = 30), and the other a regular knowledge-building environment (KBR, n = 30). The KF embedded assessment tools, the Analytical Toolkit and Applet, showed increased KF participation and connectedness during the year. Regression analysis showed that KF participation predicted conceptual understanding for both classes. Analyses of e-portfolios revealed that the students adopted nine reflective strategies in knowledge building, and that reflective metadiscourse strategies involving metacognitive and collective processes were related with deeper conceptual understanding. Analyses of online discourse threads further showed that metadiscourse involving collective processes was associated with higher levels of knowledge advances. Both classes showed improvement and the KBP class outperformed the KBR class on KF participation, metadiscourse processes and conceptual understanding. This study has theoretical implications advancing the idea of metadiscourse, discourse about discourse, for enriching research on knowledge building and computer-supported collaborative learning (CSCL). There are also design implications for using principle-based e-portfolios to facilitate collective reflection and metadiscourse to address issues of fragmented online discussion, and for promoting sustained inquiry.	187.95152151934408
941.	Despite rapid advances in deep learning applications for radiological diagnosis and prognosis, the clinical adoption of such models is limited by their inability to explain or justify their predictions. This work developed a probabilistic approach for interpreting the predictions of a convolutional neural network (CNN) trained to classify liver lesions from multiphase magnetic resonance imaging (MRI). It determined the presence of 14 radiological features, where each lesion image contained one to four features and only ten examples of each feature were provided. Using stochastic forward passes of these example images through a trained CNN, samples were obtained from each feature's conditional probability distribution over the network's intermediate outputs. The marginal distribution was sampled with stochastic forward passes of images from the entire training dataset, and sparse kernel density estimation (KDE) was used to infer which features were present in a test set of 60 lesion images. This approach was tested on a CNN that reached 89.7% accuracy in classifying six types of liver lesions. It identified radiological features with 72.2 +/- 2.2% precision and 82.6 +/- 2.0% recall. In contrast with previous interpretability approaches, this method used sparsely labeled data, did not change the CNN architecture, and directly outputted radiological descriptors of each image. This approach can identify and explain potential failure modes in a CNN, as well as make a CNN's predictions more transparent to radiologists. Such contributions could facilitate the clinical translation of deep learning in a wide range of diagnostic and prognostic applications.	187.9514951366575
942.	In quantum mechanics, a norm-squared wave function can be interpreted as the probability density that describes the likelihood of a particle to be measured in a given position or momentum. This statistical property is at the core of the fuzzy structure of microcosmos. Recently, hybrid neural structures raised intense attention, resulting in various intelligent systems with far-reaching influence. Here, we propose a probability-density-based deep learning paradigm for the fuzzy design of functional metastructures. In contrast to other inverse design methods, our probability-density-based neural network can efficiently evaluate and accurately capture all plausible metastructures in a high-dimensional parameter space. Local maxima in probability density distribution correspond to the most likely candidates to meet the desired performances. We verify this universally adaptive approach in but not limited to acoustics by designing multiple metastructures for each targeted transmission spectrum, with experiments unequivocally demonstrating the effectiveness and generalization of the inverse design.	187.95148821103186
943.	The rapid development of computational methods and the increasing volume of chemical and biological data have contributed to an immense growth in chemical research. This field of study is known as "chemoinformatics," which is a discipline that uses machine-learning techniques to extract, process, and extrapolate data from chemical structures. One of the significant lines of research in chemoinformatics is the study of blood-brain barrier (BBB) permeability, which aims to identify drug penetration into the central nervous system (CNS). In this research, we attempt to solve the problem of BBB permeability by predicting compounds penetration to the CNS. To accomplish this goal: (i) First, an overview is provided to the field of chemoinformatics, its definition, applications, and challenges, (ii) Second, a broad view is taken to investigate previous machine-learning and deep-learning computational models to solve BBB permeability. Based on the analysis of previous models, three main challenges that collectively affect the classifier performance are identified, which we define as "the triple constraints"; subsequently, we map each constraint to a proposed solution, (iii) Finally, we conclude this endeavor by proposing a deep learning based Recurrent Neural Network model, to predict BBB permeability (RNN-BBB model). Our model outperformed other studies from the literature by scoring an overall accuracy of 96.53%, and a specificity score of 98.08%. The obtained results confirm that addressing the triple constraints substantially improves the classification model capability specifically when predicting compounds with low penetration.	187.95147928119962
944.	The paper presents the results of the original research on the application of a neural network using deep learning techniques in the task of identity recognition on the basis of facial images acquired in both visual and thermal radiation ranges. In the research, the database containing images acquired in various but controlled conditions was used. On the basis of the obtained results it can be established that both investigated spectral ranges provide distinctive and complementary details about the identity of an examined person.	187.95145243887885
945.	Deep learning has been widely applied in computer vision, natural language processing, and audio-visual recognition. The overwhelming success of deep learning as a data processing technique has sparked the interest of the research community. Given the proliferation of Fintech in recent years, the use of deep learning in finance and banking services has become prevalent. However, a detailed survey of the applications of deep learning in finance and banking is lacking in the existing literature. This study surveys and analyzes the literature on the application of deep learning models in the key finance and banking domains to provide a systematic evaluation of the model preprocessing, input data, and model evaluation. Finally, we discuss three aspects that could affect the outcomes of financial deep learning models. This study provides academics and practitioners with insight and direction on the state-of-the-art of the application of deep learning models in finance and banking.	187.95143037934935
946.	As more and more deep learning tasks are pushed to mobile devices, accelerators for running these networks efficiently gain in importance. We show a that an existing class of general purpose accelerators, modulo-scheduled coarse-grained reconfigurable array (CGRA) processors typically used to accelerate multimedia workloads, can be a viable alternative to dedicated deep neural network processing hardware. To this end, an auto-tuning compiler is presented that maps convolutional neural networks (CNNs) efficiently on such architectures. The auto-tuner analyzes the structure of the CNN and the features of the CGRA, then explores the large optimization space to generate code that allows for an efficient mapping of the network. Evaluated with various CNNs, the auto-tuned code achieves an 11-fold speedup over the initial mapping. Comparing the energy per interference, the CGRA outperforms other general-purpose accelerators and an ARMv8 processor by a significant margin.	187.95136670971522
947.	Objectives To evaluate the performance of a novel three-dimensional (3D) joint convolutional and recurrent neural network (CNN-RNN) for the detection of intracranial hemorrhage (ICH) and its five subtypes (cerebral parenchymal, intraventricular, subdural, epidural, and subarachnoid) in non-contrast head CT. Methods A total of 2836 subjects (ICH/normal, 1836/1000) from three institutions were included in this ethically approved retrospective study, with a total of 76,621 slices from non-contrast head CT scans. ICH and its five subtypes were annotated by three independent experienced radiologists, with majority voting as reference standard for both the subject level and the slice level. Ninety percent of data was used for training and validation, and the rest 10% for final evaluation. A joint CNN-RNN classification framework was proposed, with the flexibility to train when subject-level or slice-level labels are available. The predictions were compared with the interpretations from three junior radiology trainees and an additional senior radiologist. Results It took our algorithm less than 30 s on average to process a 3D CT scan. For the two-type classification task (predicting bleeding or not), our algorithm achieved excellent values (>= 0.98) across all reporting metrics on the subject level. For the five-type classification task (predicting five subtypes), our algorithm achieved > 0.8 AUC across all subtypes. The performance of our algorithm was generally superior to the average performance of the junior radiology trainees for both two-type and five-type classification tasks. Conclusions The proposed method was able to accurately detect ICH and its subtypes with fast speed, suggesting its potential for assisting radiologists and physicians in their clinical diagnosis workflow.	187.95131053548485
948.	Drug discovery is time- and resource-consuming. To this end, computational approaches that are applied in de novo drug design play an important role to improve the efficiency and decrease costs to develop novel drugs. Over several decades, a variety of methods have been proposed and applied in practice. Traditionally, drug design problems are always taken as combinational optimization in discrete chemical space. Hence optimization methods were exploited to search for new drug molecules to meet multiple objectives. With the accumulation of data and the development of machine learning methods, computational drug design methods have gradually shifted to a new paradigm. There has been particular interest in the potential application of deep learning methods to drug design. In this chapter, we will give a brief description of these two different de novo methods, compare their application scopes and discuss their possible development in the future.	187.95128229799147
949.	Investment in a financial market is aimed at getting higher benefits; this complex market is influenced by a large number of events wherein the prediction of future market dynamics is challenging. The investors' etiquettes towards stock market may demand the need of studying various associated factors and extract the useful information for reliable forecasting. Fusion can be considered as an approach to integrate data or characteristics, in general, and enhance the prediction based on the combinational approach that can aid each other. We conduct a systematic approach to present a survey for the years 2011-2020 by considering articles that have used fusion techniques for various stock market applications and broadly categorize them into information fusion, feature fusion, and model fusion. The major applications of stock market include stock price and trend prediction, risk analysis and return forecasting, index prediction, as well as portfolio management. We also provide an infographic overview of fusion in stock market prediction and extend our survey for other finely addressed financial prediction problems. Based on our surveyed articles, we provide potential future directions and concluding remarks on the significance of applying fusion in stock market.	187.95127624331695
950.	With the popularization of health concept, the demand of fitness trainer system has increased. However, the existent trainer systems only provide motion demonstration but lack users' motion feedback. This paper designs and implements intelligent fitness trainer system based on human pose estimation, which not only shows fitness training courses but also provides motion correction. The system obtains users' motion data by optical camera, and then applies human pose estimation, finally providing motion correction advice. In this paper, we present the system design on hardware and software, and introduce the applied human pose estimation algorithm in detail. The field trail results show that the system exerts a good influence on fitness training.	187.9512453661815
951.	Shear wave velocity (Vs) is an important parameter for reservoir description and fluid identification and is extensively applied in study of oil and gas reservoir geomechanics and rock physics. However, due to high cost of Vs log, actual well log data generally lacks information about Vs, which doesn't meet the requirements of practical work. Therefore, it is very important to estimate the Vs by using conventional logs. In this study, according to the new achievements in deep learning, a novel hybrid Vs prediction model is established based on long short term memory (LSTM) recurrent neutral network optimized by particle swarm optimization (PSO) algorithm with adaptive learning strategy. For this purpose, firstly, the grey relational analysis method was employed to reduce data dimensions, the sensitive logs were chosen among the inputs to predict Vs. Next, LSTM network is applied to model the nonlinear relationship between the selected sensitive logs and Vs, and through finding the key hyper-parameters in LSTM model by the PSO algorithm with adaptive learning strategy, the log data feature matches the network topology structure, and the model's prediction ccuracy of Vs is improved. Finally, the superiority is verified through real petrophysical log data, and compared with other prediction methods. By this method, Vs can be predicted from series of input log data with consideration of variation trend and context information with depth. It is more suitable for the problem with multiple series data such as Vs prediction. Results of processing real petrophysical log data indicate that compare with conventional methods, the PSO algorithm with adaptive learning strategy based LSTM network model may not only provide higher predictive accuracy and robustness, but also has a promising application prospect in Vs prediction study.	187.9511905244212
952.	The attack surface of a modern vehicle increases with its connectivity. A strategy to prevent attacks or at least to identify such attacks and to mitigate their effects is therefore imperative. The detection of indications for intrusive behavior in an in-vehicle network is an important aspect of a holistic security concept. The structure of the payload of in-vehicle messages with respect to the encoded sensor values is in general confidential. Therefore, most researchers consider the structure of the in-vehicle messages to be bitor byte-fields. However, this may hide anomalies which are characterized by correlations between sensor values transferred by the in-vehicle messages. In this work, we evaluate the influence of accuracy of the model of the payload structure with respect to the actual sensor values on the results of different intrusion detection methods. In particular, we analyze if an improved alignment is helpful to detect anomalies introduced by stealthy intrusions. In order to cover conceptually different modeling and reasoning techniques, we adapted a deep learning approach as well as a characteristic functions based intrusion detection approach to utilize such message streams. An important aspect is that the explainability of the results is better compared to deep learning systems. We further developed a set of test vectors based on log files of a vehicle enriched by different intrusions. In particular, we included simulations of stealthy intrusions which mask certain sensor values within the respective messages. The effectiveness of the developed methods is demonstrated by various experiments.	187.95118332274558
953.	Speech separation aims to separate individual voices from an audio mixture of multiple simultaneous talkers. Audio-only approaches show unsatisfactory performance when the speakers are of the same gender or share similar voice characteristics. This is due to challenges on learning appropriate feature representations for separating voices in single frames and streaming voices across time. Visual signals of speech (e.g., lip movements), if available, can be leveraged to learn better feature representations for separation. In this paper, we propose a novel audio-visual deep clustering model (AVDC) to integrate visual information into the process of learning better feature representations (embeddings) for Time-Frequency (T-F) bin clustering. It employs a two-stage audio-visual fusion strategy where speaker-wise audio-visual T-F embeddings are first computed after the first-stage fusion to model the audio-visual correspondence for each speaker. In the second-stage fusion, audio-visual embeddings of all speakers and audio embeddings calculated by deep clustering from the audio mixture are concatenated to form the final T-F embedding for clustering. Through a series of experiments, the proposed AVDC model is shown to outperform the audio-only deep clustering and utterance-level permutation invariant training baselines and three other state-of-the-art audio-visual approaches. Further analyses show that the AVDC model learns a better T-F embedding for alleviating the source permutation problem across frames. Other experiments show that the AVDC model is able to generalize across different numbers of speakers between training and testing and shows some robustness when visual information is partially missing.	187.95106893797094
954.	The world is suffering from an existential global health crisis known as the COVID-19 pandemic. Countries like India, Bangladesh, and other developing countries are still having a slow pace in the detection of COVID-19 cases. Therefore, there is an urgent need for fast detection with clear visualization of infection is required using which a suspected patient of COVID-19 could be saved. In the recent technological advancements, the fusion of deep learning classifiers and medical images provides more promising results corresponding to traditional RT-PCR testing while making detection and predictions about COVID-19 cases with increased accuracy. In this paper, we have proposed a deep transfer learning algorithm that accelerates the detection of COVID-19 cases by using X-ray and CT-Scan images of the chest. It is because, in COVID-19, initial screening of chest X-ray (CXR) may provide significant information in the detection of suspected COVID-19 cases. We have considered three datasets known as 1) COVID-chest X-ray, 2) SARS-COV-2 CT-scan, and 3) Chest X-Ray Images (Pneumonia). In the obtained results, the proposed deep learning model can detect the COVID-19 positive cases in  2 seconds which is faster than RT-PCR tests currently being used for detection of COVID-19 cases. We have also established a relationship between COVID-19 patients along with the Pneumonia patients which explores the pattern between Pneumonia and COVID-19 radiology images. In all the experiments, we have used the Grad-CAM based color visualization approach in order to clearly interpretate the detection of radiology images and taking further course of action.	187.95101980390382
955.	Objectives Most research investigating children's experiences of stress and coping has utilized a quantitative approach. This study aimed to examine children's experiences of stress by conducting interviews with children and their parents. Design Dyadic child-parent interviews, embedded within a multiphase design. Methods Thirty-eight children (22 boys) aged 7-11 years and 38 parents (34 mothers) completed in-depth dyadic interviews about stressful life events, adversity, and coping, analysed using inductive thematic analysis with a phenomenological lens. Results Four themes emerged: (1) navigating the social minefield; (2) pressure to thrive in the modern world; (3) fear of the unknown; and (4) learning life's lessons. The first suggested that social relationships are a major feature of children's stress experiences; however, social support was also found to be a beneficial coping mechanism. The second theme highlighted multiple sources of pressure on young children (including school, extracurricular activities, pressure from self and others); the impact of such pressure was dependent upon children's coping resources. The third theme emphasized the difficulty of coping with novel stressors, and how awareness can help reduce this fear. The final theme highlighted important lessons that children can learn from stressful experiences and how to cope with stress. Conclusions This study addresses the importance of the person and context-dependent nature of stress and coping in order for children to survive and thrive following stressful experiences. These findings contribute to existing knowledge that could be used to develop a toolkit for coping with stress, designed specifically for children, parents, schools, and services. Statement of contribution What is already known on this subject? Stress experienced in childhood can have a significant impact on psychological and physiological outcomes across the life course. It is known that individual differences are vital for understanding the effects of stress on health, for children as well as adults. Qualitative methods enable deeper understanding of children's experiences of stress and coping. What does the study add? Depth and breadth to understanding children's experiences of stressful events. An individual differences focus on the early stress experience that is frequently overlooked. Support for the use of a dyadic interview approach for assessing children's stress experiences.	187.9510089095376
956.	One of the major challenges in the current drug discovery is the improvement of the docking-based virtual screening performance. It is especially important in the rational design of compounds with desired polypharmacology or selectivity profiles. To address this problem, we present a methodology for the development of target-specific scoring functions possessing high screening power. These scoring functions were built using the machine learning methods for the dual target inhibitors of PI3K alpha and tankyrase, promising targets for colorectal cancer therapy. The Deep Neural Network models achieve the external test AUC ROC values of 0.96 and 0.93 for the random split and 0.90 and 0.84 for the time-based split of the PI3K alpha and tankyrase inhibitors, respectively. In addition, the impact of the training set size and the actives/decoys ratio on the model quality was assessed. The study demonstrates that the optimized scoring functions could significantly improve the docking screening power for each individual target. This is very useful in the design of multitarget or selective drugs wherein the screening filters are applied in sequence.	187.95097571989726
957.	Urban land cover and land use mapping plays an important role in urban planning and management. In this paper, novel multi-scale deep learning models, namely ASPP-Unet and ResASPP-Unet are proposed for urban land cover classification based on very high resolution (VHR) satellite imagery. The proposed ASPP-Unet model consists of a contracting path which extracts the high-level features, and an expansive path, which up-samples the features to create a high-resolution output. The atrous spatial pyramid pooling (ASPP) technique is utilized in the bottom layer in order to incorporate multi-scale deep features into a discriminative feature. The ResASPP-Unet model further improves the architecture by replacing each layer with residual unit. The models were trained and tested based on WorldView-2 (WV2) and WorldView-3 (WV3) imageries over the city of Beijing. Model parameters including layer depth and the number of initial feature maps (IFMs) as well as the input image bands were evaluated in terms of their impact on the model performances. It is shown that the ResASPP-Unet model with 11 layers and 64 IFMs based on 8-band WV2 imagery produced the highest classification accuracy (87.1% for WV2 imagery and 84.0% for WV3 imagery). The ASPP-Unet model with the same parameter setting produced slightly lower accuracy, with overall accuracy of 85.2% for WV2 imagery and 83.2% for WV3 imagery. Overall, the proposed models outperformed the state-of-the-art models, e.g., U-Net, convolutional neural network (CNN) and Support Vector Machine (SVM) model over both WV2 and WV3 images, and yielded robust and efficient urban land cover classification results.	187.95094199582323
958.	The linear inverse problem is fundamental to the development of various scientific areas. Innumerable attempts have been carried out to solve different variants of the linear inverse problem in different applications. Nowadays, the rapid development of deep learning provides a fresh perspective for solving the linear inverse problem, which has various well-designed network architectures results in state-of-the-art performance in many applications. In this paper, we present a comprehensive survey of the recent progress in the development of deep learning for solving various linear inverse problems. We review how deep learning methods are used in solving different linear inverse problems, and explore the structured neural network architectures that incorporate knowledge used in traditional methods. Furthermore, we identify open challenges and potential future directions along this research line. (C) 2020 Published by Elsevier B.V.	187.95093328446796
959.	We present a novel deep learning architecture for obtaining a latent image from a single blurry image, which contains dynamic motion blurs through object/camera movements. The proposed architecture consists of two sub-modules: blur image restoration and optical flow estimation. The tasks are highly related in that object/camera movements make cause blurry artifacts, whereas they are estimated through optical flow. The ablation study demonstrates that training multi-task architecture simultaneously improves both tasks compared to handling them separately. Objective and subjective evaluations show that our method outperforms the state-of-the-arts deep learning based techniques.	187.95088212029165
960.	With the advent of Industry 4.0, localization of materials and factory items will play important roles in factory automation. Since GPS signals are not available in indoor environments, a lot of indoor localization technologies have been proposed based on inertial sensors, audio signals, visible light, wireless signals, etc. In this research, we consider using magnetic fields, which usually exhibit high uniqueness at different locations especially in factories where a lot of stacks, machineries, materials, and metal partitions may coexist. These factors allow us to incorporate deep learning neural networks to learn location-related features. Existing works try to collect magnetic field data by human and leverage interpolation to augment dataset. However, our experiments show that the data generated by interpolation is usually different from the ground truth because magnetic fields may not be linear. Therefore, to collect a large enough dataset without human intervention, we dispatch a robot carrying a smartphone to collect dataset at a fine resolution. We use these collected data to train two localization models: deep neural network (DNN) and recurrent neural network (RNN). Besides, we augment our RNN training dataset by combining multiple single-point magnetic values to synthesize fake magnetic trajectories. We conduct field trials, which validate that our approach outperforms previous work.	187.9508691572023
961.	With the decreasing noise level of underwater vehicle, the infrared imaging characteristics of underwater vehicle wake become one of its main detectable sources. Using the infrared characteristics of underwater vehicle wake to remote sensing detect the traces of underwater vehicle has gradually developed into a new detection method. Because of the high contingency and large error in judging underwater vehicle wake artificially, it can be overcome by using deep transfer learning to identify and locate the wake. This paper focuses on the infrared feature recognition of underwater vehicle wake with deep transfer learning, and wake sample sets of different classes are produced by image classification. The training effect of different pre-training networks is compared by using deep transfer learning. The influence of internal parameters of pre-training networks on the training effect of wake is discussed. Finally, combined with Faster-RCNN algorithm, the identification effect of wake is tested. The final recognition accuracy is ideal. It has certain application potential for future research on wake remote sensing detection combined with convolution neural network identification.	187.95071132914552
962.	Transfer learning has shown promising results for transferring knowledge of source tasks to target tasks in natural language processing (NLP). In this paper, we investigate a multi-task and multi-view learning (MTMVL) framework for end-to-end neural relation extraction, using large noisy data as one auxiliary task for improving manually labeled data, and a dependency parsing objective as a second auxiliary task for leveraging syntax. Two views are taken for relation extraction, consisting of a joint tagging view and a novel context relation view. To capture sentence multi-level information, we explore a weighted average approach to represent shared deep bi-directional recurrent neural networks and encourage auxiliary tasks to accommodate relation extraction task via a time-related scheduled sampling strategy. We evaluate MTMVL framework on manual-labeled ACE2005 dataset, and experimental results show that our model outperforms the state-of-the-art methods, which indicates the effectiveness of multi-auxiliary information for knowledge transferring. (C) 2019 Elsevier B.V. All rights reserved.	187.9506678120506
963.	The new billing approaches are manly to apply the integrated concept of data warehouse with relevant billing data; in addition, use the methods of mining association rule to sort out the Billing Quantities Pattern and then figure out the billing quantities. Moreover, employ the Decision Tree algorithm of data mining to find out the unit billing price. As a result, the new billing approach is made of the methods of data warehouse and date mining. This study is mainly focused on improving the operation of current billing system to establish the new functionality of the Billing quantities and Billing price. As for the benefit of these two new functions, it is not only able to lead into clients' billing systems, but it is also capable of upgrading the efficiency in rapid setup; especially for the enterprises that already possessed billing system internally but not yet implemented. In addition, it can also reduce the difference in revenue, shorten the process of issuing invoice, speed up the export operation, increase the export efficiency and provide the revenue data for integrating into the Executive Data System (EIS), Decision Support System (DSS) and Business Intelligent System (BIS) to allow enterprises making the right decisions promptly.	187.9506345686554
964.	Point set is a major type of 3D structure representation format characterized by its data availability and compactness. Most former deep learning-based point set models pay equal attention to different point set regions and channels, thus having limited ability in focusing on small regions and specific channels that are important for characterizing the object of interest. In this paper, we introduce a novel model named Attention-based Point Network (AttPNet). It uses attention mechanism for both global feature masking and channel weighting to focus on characteristic regions and channels. There are two branches in our model. The first branch calculates an attention mask for every point. The second branch uses convolution layers to abstract global features from point sets, where channel attention block is adapted to focus on important channels. Evaluations on the ModelNet40 benchmark dataset show that our model outperforms the existing best model in classification tasks by 0.7% without voting. In addition, experiments on augmented data demonstrate that our model is robust to rotational perturbations and missing points. We also design a Electron Cryo-Tomography (ECT) point cloud dataset and further demonstrate our model's ability in dealing with fine-grained structures on the ECT dataset.	187.95049973864766
965.	In hyperspectral image processing, classification is one of the most popular research topics. In recent years, research progress made in deep-learning-based hierarchical feature extraction and classification has shown a great power in many applications. In this paper, we propose a novel local spatial sequential (LSS) method, which is used in a recurrent neural network (RNN). Using this model, we can extract local and semantic information for hyperspectral image classification. First, we extract low-level features from hyperspectral images, including texture and differential morphological profiles. Second, we combine the low-level features together and propose a method to construct the LSS features. Afterwards, we build anRNNand use the LSS features as the input to train the network for optimizing the system parameters. Finally, the high-level semantic features generated by the RNN is fed into a softmax layer for the final classification. In addition, a nonlocal spatial sequential method is presented for the recurrent neural networkmodel (NLSS-RNN) to further enhance the classification performance. NLSS-RNN finds nonlocal similar structures to a given pixel and extracts corresponding LSS features, which not only preserve the local spatial information, but also integrate the information of nonlocal similar samples. The experimental results on three publicly accessible datasets show that our proposed method can obtain competitive performance compared with several state-of-the-art classifiers.	187.9504601076622
966.	Security indices are the main tools for evaluation of the status of financial markets. Moreover, a main part of the economy of any country is constituted of investment in stock markets. Therefore, investors could maximize the return of investment if it becomes possible to predict the future trend of stock market with appropriate methods. The nonlinearity and nonstationarity of financial series make their prediction complicated. This study seeks to evaluate the prediction power of machine-learning models in a stock market. The data used in this study include the daily close price data of iShares MSCI United Kingdom exchange-traded fund from January 2015 to June 2018. The prediction process is done through four models of machine-learning algorithms. The results indicate that the deep learning method is better in prediction than the other methods, and the support vector regression method is in the next rank with respect to neural network and random forest methods with less error.	187.95033124594846
967.	The accurate classification of the histopathological images of breast cancer diagnosis may face a huge challenge due to the complexity of the pathologist images. Currently, computer-aided diagnosis is implemented to get sound and error-less diagnosis of this lethal disease. However, the classification accuracy and processing time can be further improved. This study was designed to control diagnosis error via enhancing image accuracy and reducing processing time by applying several algorithms such as deep learning,K-means, autoencoder in clustering and enhanced loss function (ELF) in classification. Histopathological images were obtained from five datasets and pre-processed by using stain normalisation and linear transformation filter. These images were patched in sizes of 512 x 512 and 128 x 128 and extracted to preserve the tissue and cell levels to have important information of these images. The patches were further pre-trained by ResNet50-128 and ResNet512. Meanwhile, the 128 x 128 were clustered and autoencoder was employed withK-means which used latent feature of image to obtain better clustering result. Classification algorithm is used in current proposed system to ELF. This was achieved by combining SVM loss function and optimisation problem. The current study has shown that the deep learning algorithm has increased the accuracy of breast cancer classification up to 97% compared to state-of-the-art model which gave a percentage of 95%, and the time was decreased to vary from 30 to 40 s. Also, this work has enhanced system performance via improving clustering by employingK-means with autoencoder for the nonlinear transformation of histopathological image.	187.9502812670181
968.	Segmentation of the left atrium and proximal pulmonary veins is an important clinical step for diagnosis of atrial fibrillation. However, the automatic segmentation of the left atrium from late gadolinium-enhanced magnetic resonance (LGE-MRI) images remains a challenging task due to differences in acquisition and large variability between individuals. Deep learning has shown to outperform traditional methodologies for segmentation in numerous tasks. A popular deep learning architecture for segmentation is the U-Net, which has shown promising results biomedical segmentation problems. Many newer network architectures have been proposed that leverage the base U-Net architecture such as attention U-Net, dense U-Net and residual U-Net. These models incorporate updated encoder blocks into the U-Net architecture to incrementally improve performance over the base U-Net. Currently, there is no comprehensive evaluation of performance between these models. In this study we (1) explore approaches for the segmentation of the left atrium based on different-Net architectures. (2) We compare and evaluate these on the STACOM 2018 Atrial Segmentation Challenge dataset and (3) ensemble these models to improve overall segmentation by reducing the internal variance between models and architectures. (4) Lastly, we define and build upon a U-Net framework to simplify development of novel U-Net inspired architectures. Our ensemble achieves a mean Dice similarity coefficient (DSC) of 92.1 +/- 2.0% on a test set of twenty 3D LGE-MRI images, outperforming other fully automatic segmentation methodologies.	187.95026594927975
969.	During an epidemic crisis, medical image analysis namely microscopic analyses are made to confirm or not the existence of the epidemic pathogen in suspected cases. Pathogen are all infectious agents such as a virus, bacterium, protozoa, prion etc. However, there is often a lack of specialists in the handling of microscopes, hence allowing the need to make the microscopic analysis abroad. This results in a considerable loss of time and in the meantime, the epidemic continues to spread. To save time in the analysis of samples, we propose to make the future microscopes more intelligent so that they will be able to indicate by themselves the existence or not of the pathogen of an epidemic in a sample. To have a smart microscope, we propose a methodology based on efficient Convolution Neural Network (CNN) architecture in order to classify epidemic pathogen with five deep learning phases: (1) Training dataset of provided images (2) CNN Training (3) Testing data preparation (4) CNN generated model on testing data and finally (5) Evaluation of images classified. The resulted classification process can be integrated in a mobile computing solution on future microscopes. CNN can improve the accuracy in pathogens diagnosis that are focused on hand-tuned feature extraction implying some human mistakes. For our study, we consider cholera and malaria epidemics for microscopic images classification with a relevant CNN, respectively Vibrio cholerae images and Plasmodium falciparum images. Image classification is the task of taking an input image and outputting a class or a probability of classes that best describes the image. Interesting results have been obtained from the CNN model generated achieving the classification accuracy of 94%, with 200 Vibrio cholera images and 200 Plasmodium falciparum images for training dataset and 80 images for testing data. Although this document addresses the classification of epidemic pathogen images using a CNN model, the underlying principles apply to the other fields of science and technology, because of its performance and its capability to handle more layers than the previous traditional neural networks.	187.9502401229688
970.	Plant identification is a critical step in protecting plant diversity. However, many existing identification systems prohibitively rely on hand-crafted features for plant species identification. In this paper, a deep learning method is employed to extract discriminative features from plant images along with a linear SVM for plant identification. To offer a self-learning feature representation for different plant organs, we choose a very deep convolutional neural networks (CNNs), which consists of sixteen convolutional layers followed by three Fully-Connected (FC) layers and a final soft-max layer. Five max-pooling layers are performed over a 2x2 pixel window with stride 2. Extensive experiments on several plant datasets demonstrate the remarkable performance of the very deep neural network compared to the hand-crafted features.	187.95023827150442
971.	Frame interpolation has recently witnessed success by convolutional neural networks, that are learned from end to end to minimizing the reconstruction loss of dropped frames. This paper introduces a novel self-reproducing mechanism, that the real (given) frames could in turn be interpolated from the interpolated ones, to further substantially improve the consistency and performance of video frame interpolation. Such a consistency constraint accounts for the inherent symmetry between existing and interpolated frames in a video sequence, providing a strong form of self-supervision. We then build a pyramid-like architecture, under which existing interpolation models can plug-and-play as building blocks. Extensive experiments validate its state-of-the-art performance, on both high resolution videos in the wild and public benchmarks.	187.95022493821358
972.	To explore an effective non-invasion medical imaging diagnostics approach for hepatocellular carcinoma (HCC), we propose a method based on adopting the multiple technologies with the multi-parametric data fusion, transfer learning, and multi-scale deep feature extraction. Firstly, to make full use of complementary and enhancing the contribution of different modalities viz. multi-parametric MRI images in the lesion diagnosis, we propose a data-level fusion strategy. Secondly, based on the fusion data as the input, the multi-scale residual neural network with SPP (Spatial Pyramid Pooling) is utilized for the discriminative feature representation learning. Thirdly, to mitigate the impact of the lack of training samples, we do the pre-training of the proposed multi-scale residual neural network model on the natural image dataset and the fine-tuning with the chosen multi-parametric MRI images as complementary data. The comparative experiment results on the dataset from the clinical cases show that our proposed approach by employing the multiple strategies achieves the highest accuracy of 0.847 +/- 0.023 in the classification problem on the HCC differentiation. In the problem of discriminating the HCC lesion from the non-tumor area, we achieve a good performance with accuracy, sensitivity, specificity and AUC (area under the ROC curve) being 0.981 +/- 0.002, 0.981 +/- 0.002, 0.991 +/- 0.007 and 0.999 +/- 0.0008, respectively.	187.9501778941805
973.	Non Intrusive Load Monitoring is the field that encompasses energy disaggregation and appliance detection. In recent years, Deep Neural Networks have improved the classification performance, using the standard data representation that most datasets provide; that being low-frequency or high-frequency data. In this paper, we explore the NILM problem from the scope of transfer learning. We propose a way of changing the feature space with the use of an image representation of the low-frequency data from UK-Dale and REDD datasets and the pretrained Convolutional Neural Network VGG16. We then train some basic classifiers and use the metric F1 score to test the performance of this representation. Multiple tests are performed to test the adaptability of the models to unseen houses and different datasets. We find that the performance is on par and in some cases outperforms that of popular deep NN algorithms.	187.95012753880556
974.	The classification methods based on fusion techniques of multisource multispectral (MS) images have been studied for a long time. However, it may he difficult to classify these data based on a feature level while avoiding the inconsistency of data caused by multisource and multiple regions or cities. In this letter, we propose a deep learning structure called 2-branch SPL-ResNet which combines the self-paced learning with deep residual network to classify multisource MS data based on the feature-level fusion. First, a 2-D discrete wavelet is used to obtain the multiscale features and sparse representation of MS data. Then, a 2-branch SPL-ResNet is established to extract respective characteristics of the two satellites. Finally, we implement the feature-level fusion by cascading the two feature vectors and then classify the integrated feature vector. We conduct the experiments on Landsat_8 and Sentinel_2 MS images. Compared with the commonly used classification methods such as support vector machine and convolutional neural networks, our proposed 2-branch SPL-ResNet framework has higher accuracy and more robustness.	187.95007382742273
975.	With the increased population in urban areas, it has become a challenge to a service provider to manage big data coming from various users and devices. One of the fastest growing devices used by the citizens of urban areas is the smart-phone. Today we can find almost nobody with-out at least one smartphone in their possession. While talking through a smartphone, surrounding environmental noises are added to the speech of the talker. Sometimes these noises are very annoying to the listeners. In this article, we propose a communication framework for urban mobile big data integrating an urban environment classification system. The proposed system utilizes a deep learning approach to classify environmental noises so that an appropriate noise cancellation algorithm can be used to reduce the effect of noise while having a conversation through smartphones. The proposed framework uses mobile edge computing technology to provide low-latency and efficient transmission. Experimental results demonstrate that the proposed system is very efficient in classifying environmental noises.	187.9500283373389
976.	We developed a deep learning neural network, the Shape Variation Analyzer (SVA), that allows disease staging of bony changes in temporomandibular joint (TMJ) osteoarthritis (OA). The sample was composed of 259 TMJ CBCT scans for the training set and 34 for the testing dataset. The 3D meshes had been previously classified in 6 groups by 2 expert clinicians. We improved the robustness of the training data using data augmentation, SMOTE, to alleviate over-fitting and to balance classes. We combined geometrical features and a shape descriptor, heat kernel signature, to describe every shape. The results were compared to nine different supervised machine learning algorithms. The deep learning neural network was the most accurate for classification of TMJ OA. In conclusion, SVA is a 3D Slicer extension that classifies pathology of the temporomandibular joint osteoarthritis cases based on 3D morphology.	187.9499930973926
977.	During the past few decades, content-based image retrieval (CBIR) has been a prominent research area in medical image analysis. It enables retrieving images from an image database that are similar to a given query image. Numerous types of medical image retrieval approaches have been proposed by different research groups. In particular, supervised, deep neural network-based methods have achieved higher accuracy than others. However, they are computationally very expensive and an effective and comprehensive deep neural network-based retinal image retrieval model for diabetic retinopathy (DR) is not available in the literature. The principal objective of CBIR for DR is to efficiently retrieve retinal images that are semantically similar to a given query for effective treatment based on the severity stage of the disease. We propose to use a deep, supervised hashing approach in order to perform efficient retinal image retrieval, where we implicitly learn a good image representation along with a similarity-preserving compact binary hash code for each image by extracting features using an ensemble of deep convolutional neural networks through transfer learning and then feed these extracted features to an ANN classifier. This approach maps the image pixels to a lower-dimensional space and then generates compact binary codes to speedup the retrieval process. Moreover, our approach requires less memory and computational time, which can constructively accelerate the training process. Our experimental results show a considerable improvement compare to the other several state-of-the-art hashing techniques on the retinal dataset. We further analyze the effectiveness and efficiency of our approach using another medical dataset, KVASIR, which includes Gastrointestinal tract endoscopic imagery.	187.9499710938461
978.	Facial expression recognition (FER) is important in vision-related applications. Deep neural networks demonstrate impressive performance for face recognition; however, it should be noted that this method relies heavily on a great deal of manually labeled training data, which is not available for facial expressions in real-world applications. Hence, we propose a powerful facial feature called deep peak-neutral difference (DPND) for FER. DPND is defined as the difference between two deep representations of the fully expressive (peak) and neutral facial expression frames. The difference tends to emphasize the facial parts that are changed in the transition from the neutral to the expressive face and to eliminate the face identity information retained in the fine-tuned deep neural network for facial expression, the network has been trained on large-scale face recognition dataset. Furthermore, unsupervised clustering and semi-supervised classification methods are presented to automatically acquire the neutral and peak frames from the expression sequence. The proposed facial expression feature achieved encouraging results on public databases, which suggests that it has strong potential to recognize facial expressions in real-world applications.	187.9498909514403
979.	We propose a learning-based method to automatically segment arteriovenous malformations (AVM) target volume from computed tomography (CT) in stereotactic radiosurgery (SRS). A deeply supervised 3D V-Net is introduced to enable end-to-end segmentation. Deep supervision mechanism is integrated into the hidden layers to overcome the optimization difficulties when training such a network with limited training data. The probability map of new AVM contour is generated by the well-trained network. To evaluate the proposed method, we retrospectively investigate 30 AVM patients treated by SRS. For each patient, both digital subtraction angiography (DSA) and CT with contrast had been acquired. Using our proposed method, the AVM contours are generated solely based on contrast CT images, and are compared with the AVM contours delineated from DSA by physicians as ground truth. The average centroid distance, volume difference and DSC value among all 30 patients are 0.83 +/- 0.91mm, -0.01 +/- 0.79 and 0.84 +/- 0.09, which indicates that the proposed method is able to generate AVM target contour with around 1mm error in displacement, 1cc error in volume size and 84% overlapping compared with ground truth. The proposed method has great potential in eliminating DSA acquisition and developing a solely CT-based treatment planning workflow for AVM SRS treatment.	187.94989024243864
980.	In this work we employ data-driven homogenization approaches to predict the particular mechanical evolution of polycrystalline aggregates with tens of individual crystals. In these oligocrystals the differences in stress response due to microstructural variation is pronounced. Shell-like structures produced by metal-based additive manufacturing and the like make the prediction of the behavior of oligocrystals technologically relevant. The predictions of traditional homogenization theories based on grain volumes are not sensitive to variations in local grain neighborhoods. Direct simulation of the local response with crystal plasticity finite element methods is more detailed, but the computations are expensive. To represent the stress-strain response of a polycrystalline sample given its initial grain texture and morphology we have designed a novel neural network that incorporates a convolution component to observe and reduce the information in the crystal texture field and a recursive component to represent the causal nature of the history information. This model exhibits accuracy on par with crystal plasticity simulations at minimal computational cost per prediction.	187.9498882412525
981.	ALEKS ("Assessment and LEarning in Knowledge Spaces") is an adaptive learning and assessment system based on knowledge space theory. In this work, our goal is to improve the overall efficiency of the ALEKS assessment by developing an algorithm that can accurately predict when the assessment should be stopped. Using data from more than 1.4 million assessments, we first build recurrent neural network classifiers that attempt to predict the final result of each assessment. We then use these classifiers to develop our stopping algorithm, with the test results indicating that the length of the assessment can potentially be reduced by a large amount while maintaining a high level of accuracy.	187.9497860609369
982.	Early detection of cancer is important to improve survival and reduce associated morbility. Nowadays, there is no automatic classification process with enough accuracy to be recommended to its use in population cervical cancer screening. In most automatic medical image classifications, these images are clean in background and without overlap between elements, which means that these images do not reflect reality and the model cannot be applied to directly obtained images from medical samples. The objectives of this study are to design and implement a Cell Merger Approach to improve the efficiency and realism of the PAP-smears classification model, by allowing overlapping and folding of different cells, to design and implement a Convolutional Neural Network for PAP-smears image classification, and to optimize and integrate the cell fusion approach with the neural network building a feasible, reliable and highly accurate system for cervical smears classification. The carried out experiments have validated both the CNN and the proposed Cell Merger Approach with very interesting results. The most outstanding results show that the Convolutional Neural Network models together with the Cell Merger Approach have a classification accuracy of 88.8% with a standard deviation of 1%, obtaining a sensitivity and specificity of 0.92 and 0.83 respectively. This classification level depicts a robust and accurate model that is comparable to an expert pathologist competencies. (C) 2020 Elsevier Ltd. All rights reserved.	187.9497563691453
983.	Deep learning convolutional neural network (CNN) is popular as being widely used for classification of unstructured data. Land use land cover (LULC) classification using remote sensing data can be used for crop identification also. Present study aims to examine the use of deep learning CNN for LULC classification on Indian Pines dataset and for crop identification on our study area dataset. In the present work, AVIRIS sensor's Indian Pines standard dataset has been used for LULC classification. Study area from Phulambri, Aurangabad, MH, India, has been used for crop classification. Data have been gathered from EO-1 Hyperion sensor. The accuracy of CNN model depends on optimizer, activation function, filter size, learning rate and batch size. Deep learning CNN is evaluated by changing these parameters. It has been observed that deep learning CNN using optimized combination of parameters has provided 97.58% accuracy for the Indian Pines dataset, while 79.43% accuracy for our study area dataset. The empirical results demonstrate that CNN works well in practice for unstructured data as well as for small size dataset.	187.94972125344066
984.	HIV-1 protease plays an important role in the processing of virus infection. Protease is an effective therapeutic target for the treatment of HIV-1. Our data set is based on a selection of 4855 HIV-1 protease inhibitors (PIs) from ChEMBL. A series of 15 classification models for predicting the active inhibitors were built by machine learning methods, including k-nearest neighors (K-NN), decision tree (DT), random forest (RF), support vector machine (SVM), and deep neural network (DNN). The molecular structures were characterized by (1) fingerprint descriptors including MACCS fingerprints and PubChem fingerprints and (2) physicochemical descriptors calculated by CORINA Symphony. The prediction accuracies of all of the models are more than 70% on the test set; the best accuracy of 83.07% was obtained by model 4A, which was built by the SVM method based on MACCS fingerprint descriptors. Nine consensus models were built with three kinds of different descriptors, which combined all of the machine learning methods using the "consensus prediction". Model C3(a) developed with MACCS fingerprint descriptors showed the highest accuracy on both training set (91.96%) and test set (83.15%). An external validation set including 35 989 compounds from DUD database and 239 active inhibitors from the recent literature was used to verify the performance of our model. The best prediction accuracy of 98.37% was obtained by model 3C, which was built by RF based on CORINA Symphony descriptors. In addition, from the analysis of molecular descriptors, it shows that the aromatic system and atoms related to hydrogen bonding provide important contributions to the bioactivity of PIs.	187.9496610277285
985.	Molten eutectic salts consisting of ZnCl2 and other alkali chlorides are promising thermal storage and heat transfer fluid materials in the next generation concentrated solar thermal power. To go deep into the thermal and transport properties for a high order mixture, the microstructure information, as well as thermodynamics properties of individual components, have to be identified first. This work develops interatomic potentials of molten ZnCl2 based on neural-network machine learning approach for the first time. The machine learning potential is trained by fitting to the energies and forces of liquid structures ab initio molecular dynamics calculations. The developed machine learning potential is validated by comparing partial radial distribution functions, coordination numbers, and partial structure factors with AIMD and PIM potential. The machine learning potential yields a more precise description of the microstructures than the PIM potential which suffers from the analytical form. Furthermore, structural and thermophysical evolution with temperature are studied and the results are in good agreement with experimental values. The efficient machine learning potential with DFT accuracy from our study will provide a promising scheme for accurate molecular simulations of structures and dynamics of molten ZnCl2 mixtures.	187.94962316802503
986.	Deducing the design parameters of semiconductor lasers from a desired spectrum and light-current (L-I) curve, etc., i.e. the inverse design technique, is highly demanded both academically and in industry. Here, we propose an approach to obtain the inverse design of a laser by combining the deep learning algorithm and the particle swarm optimization (PSO) method. The deep-learning neural network (NN) is trained by the traveling-wave model (TWM) calculated database, and is used to predict the output power for any given new set of design parameters. The standard deviation of the NN approximation can be as low as 0.31mW, and the CPU time as fast as 0.07s, which is much more efficient compared with the TWM numerical algorithm (of CPU time 125.57s), for the same L-I curve calculation. By combining NN with the PSO algorithm, laser parameters can be inversely designed and optimized according to the given/desired L-I curve. Speed of the this process can be improved by about 17,500 times, and the designed parameters are found to be close to their preset values in the test, which indicates its possibility to solve the nonlinear problem for the semiconductor laser process.	187.9495727940316
987.	Most existing fault diagnosis methods may fail in the following three scenarios: (1) serial correlations exist in the process data; (2) fault data are much less than normal data; and (3) it is impractical to obtain enough labeled data. In this paper, a novel form of the bidirectional gated recurrent unit (BGRU) is developed to underpin effective and efficient fault diagnosis using cost sensitive active learning. Specifically, BGRU is devised to consider the dynamic behavior of a complex process. In the training phase of BGRU, the idea of weighting each training example is proposed to reduce the effect of class imbalance. Besides, in order to explore the unlabeled data, cost sensitive active learning is utilized to select the candidate instances. The effectiveness of the proposed method is evaluated on the Tennessee Eastman (TE) dataset and a real plasma etching process dataset. The experiment results show that the proposed cost senstive active learning bidirectional gated recurrent unit (CSALBGRU) method achieves better performance in both binary fault diagnosis and multi-class fault diagnosis. (C) 2020 Elsevier B.V. All rights reserved.	187.94954819161413
988.	Quantitative image analysis has deep roots in the usage of positron emission tomography (PET) in clinical and research settings to address a wide variety of diseases. It has been extensively employed to assess molecular and physiological biomarkers in vivo in healthy and disease states, in oncology, cardiology, neurology, and psychiatry. Quantitative PET allows relating the time-varying activity concentration in tissues/organs of interest and the basic functional parameters governing the biological processes being studied. Yet, quantitative PET is challenged by a number of degrading physical factors related to the physics of PET imaging, the limitations of the instrumentation used, and the physiological status of the patient. Moreover, there is no consensus on the most reliable and robust image-derived PET metric(s) that can be used with confidence in clinical oncology owing to the discrepancies between the conclusions reported in the literature. There is also increasing interest in the use of artificial intelligence based techniques, particularly machine learning and deep learning techniques in a variety of applications to extract quantitative features (radiomics) from PET including image segmentation and outcome prediction in clinical oncology. These novel techniques are revolutionizing clinical practice and are now offering unique capabilities to the clinical molecular imaging community and biomedical researchers at large. In this report, we summarize recent developments and future tendencies in quantitative PET imaging and present example applications in clinical decision support to illustrate its potential in the context of clinical oncology. (C) 2018 Elsevier Inc. All rights reserved.	187.94951197845396
989.	Deep learning represents end-to-end machine learning in which feature selection from images and classification happen concurrently. This articles provides updates on how deep learning is being applied to the study of glioma and its genetic heterogeneity. Deep learning algorithms can detect patterns in routine and advanced MR imaging that elude the eyes of neuroradiologists and make predictions about glioma genetics, which impact diagnosis, treatment response, patient management, and long-term survival. The success of these deep learning initiatives may enhance the performance of neuroradiologists and add greater value to patient care by expediting treatment.	187.9494567959262
990.	Radiomics describes the extraction of multiple features from medical images, including molecular imaging modalities, that with bioinformatic approaches, provide additional clinically relevant information that may be invisible to the human eye. This information may complement standard radiological interpretation with data that may better characterize a disease or that may provide predictive or prognostic information. Progressing from predefined image features, often describing heterogeneity of voxel intensities within a volume of interest, there is increasing use of machine learning to classify disease characteristics and deep learning methods based on artificial neural networks that can learn features without a priori definition and without the need for preprocessing of images. There have been advances in standardization and harmonization of methods to a level that should support multicenter studies. However, in this relatively early phase of research in the field, there are limited aspects that have been adopted into routine practice. Most of the reports in the molecular imaging field describe radiomic approaches in cancer using 18F-fluorodeoxyglucose positron emission tomography (18F-FDG-PET). In this review, we will describe radiomics in molecular imaging and summarize the pertinent literature in lung cancer where reports are most prevalent and mature.	187.94943355691498
991.	Smart homes based on the Internet of Things have been rapidly developed. To improve the safety, comfort, and convenience of residents' lives with minimal cost, daily activity recognition aims to know resident's daily activity in non-invasive manner. The performance of daily activity recognition heavily depends on solving strategy of activity feature. However, the current common employed solving strategy based on statistical information of individual activity does not support well the activity recognition. To improve the common employed solving strategy, an activity feature solving strategy based on TF-IDF is proposed in this paper. The proposed strategy exploits statistical information related to both individual activity and the whole of activities. Two distinct datasets have been commissioned, to mitigate against any possible effect of coupling between dataset and sensor configuration. Finally, a number of machine learning (ML) techniques and deep learning technique have been evaluated to assess their performance for residents activity recognition.	187.9494089837155
992.	Adversarial attacks are small, carefully crafted perturbations, imperceptible to the naked eye; that when added to an image cause deep learning models to misclassify the image with potentially detrimental outcomes. With the rise of artificial intelligence models in consumer safety and security intensive industries such as self-driving cars, camera surveillance and face recognition, there is a growing need for guarding against adversarial attacks. In this paper, we present an approach that uses metamorphic testing principles to automatically detect such adversarial attacks. The approach can detect image manipulations that are so small, that they are impossible to detect by a human through visual inspection. By applying metamorphic relations based on distance ratio preserving affine image transformations which compare the behavior of the original and transformed image; we show that our proposed approach can determine whether or not the input image is adversarial with a high degree of accuracy.	187.94934346370397
993.	Existing single shot based human modeling methods generally cannot model the complete pose details (e.g., head and hand positions) without non-trivial interactions. We explore the merits of both RGB and depth images and propose a new method called Single RGB-D Fitting (SRDF) to generate a realistic 3D human model with a single RGB-D shot from a consumer-grade depth camera. Specifically, the state-of-the-art deep learning techniques for RGB images are incorporated into SRDF, so that: 1) A compound skeleton detection method is introduced to obtain accurate 3D skeletons with refined hands based on the combination of depth and RGB images; and 2) an RGB image segmentation assisted point cloud pre-processing method is presented to obtain smooth foreground point clouds. In addition, several novel constraints are also introduced into the energy minimization model, including the shape continuity constraint, the keypoint-guided head pose prior constraint, and the penalty-enforced point cloud prior constraint. The energy model is optimized in a two-pass way so that a realistic shape can be estimated from coarse to fine. Through extensive experiments and comparisons with the state of the art methods, we demonstrate the effectiveness and efficiency of the proposed method.	187.9492941819479
994.	Automatic and reliable fault diagnosis of rotating machinery cross working conditions is of practical importance. For this purpose, ensemble transfer convolutional neural networks (CNNs) driven by multi-channel signals are proposed in this paper. Firstly, a series of source CNNs modified with stochastic pooling and Leaky rectified linear unit (LReLU) are pre-trained using multi-channel signals. Secondly, the learned parameter knowledge of each individual source CNN is transferred to initialize the corresponding target CNN which is then fine-tuned by a few target training samples. Finally, a new decision fusion strategy is designed to flexibly fuse each individual target CNN to obtain the comprehensive result. The proposed method is used to analyze multi-channel signals measured from rotating machinery. The comparison result shows the superiorities of the proposed method over the existing deep transfer learning methods. (C) 2020 Elsevier B.V. All rights reserved.	187.94927948927648
995.	Few studies have explored how to simulate the experiential learning of professional knowledge domains in online graduate courses. This paper addresses how to provide the type of deep, socially situated learning that is achieved in professional practice by employing peer and vicarious learning in discussion forums. We start by describing what we have learned about scaffolding peer learning environments from prior studies. We distinguish vicarious learning, which exposes and sensitizes students to situated knowledge based on observation of peer discussions, from peer interactions which engage students actively in co-constructing knowledge about professional practice. Then we present findings from a 10-week graduate course in Information Systems Project Management. Our findings present evidence for vicarious learning from observing peer interactions, and of interactive peer learning that not only demonstrates the co-construction of knowledge across learners but also uncovers a collaborative process based on a sense of community identity. We end with a substantive theory of social cognition in community learning based on our findings. The intention is to provide a framework for the evaluation of collaborative knowledge construction, so that courses may support deep, experiential learning in graduate online professional education.	187.94925969927598
996.	The increasingly growing data traffic has posed great challenges for mobile operators to increase their data processing capacity, which incurs a significant energy consumption and deployment cost. With the emergence of the Cloud Radio Access Network (C-RAN) architecture, the data processing units can now be centralized in data centers and shared among base stations. By mapping a cluster of base stations with complementary traffic patterns to a data processing unit, the processing unit can be fully utilized in different periods of time, and the required capacity to be deployed is expected to be smaller than the sum of capacities of single base stations. However, since the traffic patterns of base stations are highly dynamic in different time and locations, it is challenging to foresee and characterize the traffic patterns in advance to make optimal clustering schemes. In this paper, we address these issues by proposing a deep-learning-based C-RAN optimization framework. First, we exploit a Multivariate Long Short-Term Memory (MuLSTM) model to learn the temporal dependency and spatial correlation among base station traffic patterns, and make accurate traffic forecast for a future period of time. Afterwards, we build a weighted graph to model the complementarity of base stations according to their traffic patterns, and propose a Distance-Constrained Complementarity-Aware (DCCA) algorithm to find optimal base station clustering schemes with the objectives of optimizing capacity utility and deployment cost. We evaluate the performance of our framework using data in two months from real-world mobile networks in Milan and Trentino, Italy. Results show that our method effectively increases the average capacity utility to 83.4% and 76.7%, and reduces the overall deployment cost to 48.4% and 51.7% of the traditional RAN architecture in the two datasets, respectively, which consistently outperforms the state-of-the-art baseline methods.	187.94923698594243
997.	Self-Driving Vehicle (SDV) is a promising technology that will establish its predominance in the near future. As the vehicles are autonomous, humans will experience a hassle-free travel. Autonomy abolishes disasters due to driver's negligence. The main challenge is to provide an unobstructed path to Emergency Vehicles (EVs). In this paper, the EVs are identified using Deep Learning (DL) based algorithms. Though they are driven by Neural Networks (NNs), there are some situations in which they have to mimic a human. SDVs should be incorporated with the knowledge of a fast approaching EV. The ability to perceive and respond is addressed in this paper.	187.94921760014722
998.	Mode decomposition (MD) is essential to reveal the intrinsic mode properties of fiber beams. However, traditional numerical MD approaches are relatively time-consuming and sensitive to the initial values. To solve these problems, deep learning technique is introduced to perform non-iterative MD. In this paper, we focus on the real-time MD ability of the pre-trained convolutional neural network. The numerical simulation indicates that the averaged correlation between the reconstructed patterns and measured patterns is 0.9987 and the decomposing rate can reach about 125 Hz. As for the experimental case, the averaged correlation is 0.9719 and the decomposing rate is 29.9 Hz, which is restricted by the maximum frame rate of the CCD camera. The results of both simulation and experiment show the superb real-time ability of the deep learning based MD methods.	187.94920407673203
999.	This paper presents a systematic literature review of academic staff experiences and perceptions of adopting Technology for Assessment OF/FOR/AS Learning in Higher Education. This paper is a qualitative synthesis of 65 peer-reviewed journal articles published between 2012 and 2017 reporting on the use of technology for assessment (TfA). The results suggest that there are some efficiencies for staff in implementing TfA but this can come with a cost at the set-up and maintenance phases. Furthermore, results indicated that assessment design is not of foremost concern to academic staff when introducing TfA, but that a wide variety of pressures and both educational and operational drivers are present. There were inconclusive findings in relation to understandings of appropriate institutional environments and supports for TfA to flourish in higher education. There is a need for empirical research, particularly longitudinal investigations, of academic experiences of implementations of TfA to investigate sustainability of adoption. The imperative of exploring the academic staff perspective as the instigator and manager of both the technology and the student learning experience requires deep consideration as TfA adoption progresses.	187.94914238020755
1000.	Elastography ultrasound (EUS) imaging has shown its effectiveness for diagnosis of tumors by providing additional information about tissue stiffness to the conventional B-mode ultrasound (BUS). However, due to the lack of EUS devices and experienced sonologists, EUS is not widely used, especially in rural areas. It is still a challenging task to improve the performance of the single-modal BUS-based computer-aided diagnosis (CAD) for tumors. In this work, we propose a novel transfer learning (TL)-based deep neural network (DNN) algorithm, named CW-PM-DNN, for the BUS-based CAD by transferring diagnosis knowledge from EUS during model training. CW-PM-DNN integrates both the feature-level and classifier-level knowledge transfer into a unified framework. In the feature-level TL, a bichannel DNN is learned by the cross-weight-based multimodal DL (MDL-CW) algorithm to transfer informative features from EUS to BUS. In the classifier-level TL, a projective model (PM)-based classifier is then embedded to the pretrained bichannel DNN to implement the parameter transfer in the classifier model at the second stage. The back-propagation procedure is then applied to optimize the whole CW-PM-DNN to further improve its performance. Experimental results on two bimodal ultrasound tumor datasets demonstrate that the proposed CW-PM-DNN achieves the best classification accuracy, sensitivity, and specificity of 89.02 +/- 1.54%, 88.37 +/- 4.72%, and 89.63 +/- 4.06%, respectively, for the breast ultrasound dataset, and the corresponding values of 80.57 +/- 3.41%, 76.67 +/- 3.85%, and 83.94 +/- 3.95%, respectively, for the prostate ultrasound dataset. The proposed two-stage TL-based CW-PM-DNN algorithm outperforms all the compared algorithms. It is also proved that the performance of the BUS-based CAD can be significantly improved by transferring the knowledge of EUS. It suggests that CW-PM-DNN has the potential for more applications in the field of medical image-based CAD.	187.9491236499531
1001.	Social media and Web services have provided a notable number of multimedia content. Due to such explosion of multimedia data, the multimedia community has been facing new challenges and exciting opportunities these days. This paper presents a new multimedia framework to address some of the main challenges in this area. In particular, it presents a multi-label multimodal framework for imbalanced data classification. For this purpose, it utilizes audio, visual, and textual data modalities and automatically generates static and temporal features using spatio-temporal deep neural networks. It also manages data with non-uniform distributions using a weighted multi-label classifier. To evaluate this framework, a video dataset containing natural disasters is used for multi-label classification. The supremacy of the proposed framework compared to the existing work is revealed with extensive experiments on this dataset.	187.94908766843918
1002.	Finding the right experts for data gathering through interview serves as a key for particular research works. However, most expert finding methods in the literature require great deals of technical knowledge, making them somewhat impracticable for business researchers without deep technical knowledge. Accordingly, there is a need for an expert finding solution for researchers without a deep technical background. As business researchers may have knowledge about business intelligence and its tools, the use of business intelligence tools can be used to solve such issue. The present paper discusses the process of using business intelligence tools to find potential experts for example topics. Subsequently, based on a literature review, criteria are presented for distinguishing different experts. Finally, the analytic hierarchy process is discussed for assigning weights to both selection criteria and potential experts. The audience of this paper is researchers who are familiar with business intelligence tools or would like to learn how to work with them.	187.9490074187049
1003.	Background Accurate prediction of inter-residue contacts of a protein is important to calculating its tertiary structure. Analysis of co-evolutionary events among residues has been proved effective in inferring inter-residue contacts. The Markov random field (MRF) technique, although being widely used for contact prediction, suffers from the following dilemma: the actual likelihood function of MRF is accurate but time-consuming to calculate; in contrast, approximations to the actual likelihood, say pseudo-likelihood, are efficient to calculate but inaccurate. Thus, how to achieve both accuracy and efficiency simultaneously remains a challenge. Results In this study, we present such an approach (called clmDCA) for contact prediction. Unlike plmDCA using pseudo-likelihood, i.e., the product of conditional probability of individual residues, our approach uses composite-likelihood, i.e., the product of conditional probability of all residue pairs. Composite likelihood has been theoretically proved as a better approximation to the actual likelihood function than pseudo-likelihood. Meanwhile, composite likelihood is still efficient to maximize, thus ensuring the efficiency of clmDCA. We present comprehensive experiments on popular benchmark datasets, including PSICOV dataset and CASP-11 dataset, to show that: i) clmDCA alone outperforms the existing MRF-based approaches in prediction accuracy. ii) When equipped with deep learning technique for refinement, the prediction accuracy of clmDCA was further significantly improved, suggesting the suitability of clmDCA for subsequent refinement procedure. We further present a successful application of the predicted contacts to accurately build tertiary structures for proteins in the PSICOV dataset. Conclusions Composite likelihood maximization algorithm can efficiently estimate the parameters of Markov Random Fields and can improve the prediction accuracy of protein inter-residue contacts.	187.94900133366548
1004.	In recent years, with the vigorous development of artificial intelligence and autonomous driving technology, the importance of scene perception technology is increasing. Unsupervised deep learning based methods have demonstrated a certain level of robustness and accuracy in some challenging scenes. By inferring depth from a single input image without any ground truth label, a lot of time and resources can be saved. However, unsupervised depth estimation has defects in robustness and accuracy under complex environment which could be improved by modifying network structure and incorporating other modal information. In this paper, we propose an unsupervised, monocular depth estimation network achieving high speed and accuracy, and a learning framework with our depth estimation network to improve depth performance by incorporating transformed images across different modalities. The depth estimator is an encoder-decoder network to generate the multi-scale dense depth map. The sub-pixel convolutional layer is adopted to obtain depth super-resolution by replacing the up-sample branches. The cross-modal depth estimation using near-infrared image and RGB image enhances the performance of depth estimation than pure RGB image. The training mode is to transfer both images to the same modality and then carry out super-resolved depth estimation for each stereo camera pair. Compared with the initial results of depth estimation using only RGB images, the experiment verifies that our depth estimation network with the cross-modal fusion system designed in this paper achieves better performance on public datasets and a multi-modal dataset collected by our stereo vision sensor.	187.94873002037306
1005.	For many three-dimensional (3D) measurement techniques based on fringe projection profilometry (FPP), measuring the objects with a large variation range of surface reflectivity is always a very tricky problem due to the limited dynamic range of camera. Many high dynamic range (HDR) 3D measurement methods are developed for static scenes, which are fragile for dynamic objects. In this paper, we address the problem of phase information loss in HDR scenes, in order to enable 3D reconstruction from saturated or dark images by deep learning. By using a specifically designed convolutional neural network (CNN), we can accurately extract phase information in both the low signal-to-noise ratio (SNR) and saturation situations after proper training. Experimental results demonstrate the success of our network in 3D reconstruction for both static and dynamic HDR objects. Our method can improve the dynamic range of three-step phase-shifting by a factor of 4.8 without any additional projected images or hardware adjustment during measurement. And the final 3D measurement speed of our method is about 13.89 Hz (off-line).	187.94870266038498
1006.	Detection of cell nuclei in microscopy images is a challenging research topic due to limitations in acquired image quality as well as due to the diversity of nuclear morphology. This has been a topic of enduring interest with promising success shown by deep learning methods. Recently, attention gating methods have been proposed and employed successfully in a diverse array of pattern recognition tasks. In this work, we introduce a novel attention module and integrate it with feature pyramid networks and the state-of-the-art Mask R-CNN network. We show with numerical experiments that the proposed model outperforms the state-of-the-art baseline.	187.94866621287045
1007.	The automatic image annotation is an effective computer operation that predicts the annotation of an unknown image by automatically learning potential relationships between the semantic concept space and the visual feature space in the annotation image dataset. Usually, the auto-labeling image includes the processing: learning processing and labeling processing. Existing image annotation methods that employ convolutional features of deep learning methods have a number of limitations, including complex training and high space/time expenses associated with the image annotation procedure. Accordingly, this paper proposes an innovative method in which the visual features of the image are presented by the intermediate layer features of deep learning, while semantic concepts are represented by mean vectors of positive samples. Firstly, the convolutional result is directly output in the form of low-level visual features through the mid-level of the pre-trained deep learning model, with the image being represented by sparse coding. Secondly, the positive mean vector method is used to construct visual feature vectors for each text vocabulary item, so that a visual feature vector database is created. Finally, the visual feature vector similarity between the testing image and all text vocabulary is calculated, and the vocabulary with the largest similarity used for annotation. Experiments on the datasets demonstrate the effectiveness of the proposed method; in terms of F1 score, the proposed method's performance on the Corel5k dataset and IAPR TC-12 dataset is superior to that of MBRM, JEC-AF, JEC-DF, and 2PKNN with end-to-end deep features.	187.94862127016296
1008.	We propose an automatic approach to anatomy partitioning on three-dimensional (3D) computed tomography (CT) images that divides the human torso into several volumes of interest (VOIs) according to anatomical definition. In the proposed approach, a deep convolutional neural network (CNN) is trained to automatically detect the bounding boxes of organs on two-dimensional (2D) sections of CT images. The coordinates of those boxes are then grouped so that a vote on a 3D VOI (called localization) for each organ can be obtained separately. We applied this approach to localize the 3D VOIs of 17 types of organs in the human torso and then evaluated the performance of the approach by conducting a four-fold cross-validation using a dataset consisting of 240 3D CT scans with the human-annotated ground truth for each organ region. The preliminary results showed that 86.7% of the 3D VOIs of the 3177 organs in the 240 test CT images were localized with acceptable accuracy (mean of Jaccard indexes was 72.8%) compared to that of the human annotations. This performance was better than that of the state-of-the-art method reported recently. The experimental results demonstrated that using a deep CNN for anatomy partitioning on 3D CT images was more efficient and useful compared to the method used in our previous work.	187.94862104877436
1009.	This paper introduces GPR B-scan database which contains 180 labelled images to facilitate research in developing presentation algorithm for this challenging scenario. Along with GPR B-scan images, there are several other detections of buried objects that are explored in the literature. The next contribution of this research is a novel multilevel deep dictionary learning-based presentation buried object detection algorithm that can discern different kinds of materials. An efficient layer by layer training approach is formulated to learn the deep dictionaries followed by different classifiers as types of shape for buried objects. By changing the number of layers in proposed algorithm, performances in different classifiers are compared. It is possible to integrate the proposed algorithm with real-time systems because it is supervised and has high classification accuracy with 94.4%.	187.9485748081849
1010.	We have developed a novel, hybrid QSAR-docking approach (called 'progressive docking') that can speed up the process of virtual screening by enhancing it with Deep Learning models trained on-the-go on produced docking scores. The developed method can, therefore, predict docking outcome for yet unprocessed molecular entries and hence to progressively remove unfavorable chemical structures from the remaining docking base. This approach provides 50-100X speed increase for the standard docking procedures while retaining >90% of qualified molecules. We demonstrate that the use of PD allows processing of about 360 million molecules just in 2 weeks using a standard 200 CPU setup.	187.94851603133884
1011.	This paper introduces a vision-based deep learning approach that enables the detection and recognition of occupants' activities within building spaces. The data can feed into building energy management systems through the establishment of occupancy heat emission profiles, which can help minimise unnecessary heating, ventilation, and air-conditioning (HVAC) energy loads and effectively manage indoor conditions. The proposed demand-driven method can enable HVAC systems to adapt and make a timely response to dynamic changes of occupancy, instead of using "static" or fixed occupancy operation schedules, historical load, and time factor. Based on a convolutional neural network, the model was developed to enable occupancy activity detection using a camera. Training data was obtained from online image sources and captured images of various occupant activities in office spaces. Tests were performed by real-time live detection and predictions of occupancy activities in buildings. Initial activities response includes sitting, standing, walking, and napping. Average detection accuracy of 80.62% was achieved. The detection formed the real-time occupancy heat emission profiles known as the Deep Learning Influenced Profile. Along with typical 'scheduled' office occupancy profiles, a building energy simulation (BES) tool was used to further assess the framework. An office space in Nottingham, UK was selected to test the proposed method and modelled using building simulation. Using the deep learning detection method, the results showed that the occupancy heat gains could be represented more accurately in comparison to using static office occupancy profiles. The accurate detection of occupants and their activities can also be used to effectively estimate CO2 concentration. The information can be useful for modulating ventilation systems leading to better indoor environmental quality. Overall, this initial approach of the study showed the capabilities of this framework for detecting occupancy activities and providing reliable predictions of building internal gains. (C) 2020 Elsevier B.V. All rights reserved.	187.94848642314787
1012.	In recent years, e-sports has rapidly developed, and the industry has produced large amounts of data with specifications, and these data are easily to be obtained. Due to the above characteristics, data mining and deep learning methods can be used to guide players and develop appropriate strategies to win games. As one of the world's most famous e-sports events, Dota2 has a large audience base and a good game system. A victory in a game is often associated with a hero's match, and players are often unable to pick the best lineup to compete. To solve this problem, in this paper, we present an improved bidirectional Long Short-Term Memory (LSTM) neural network model for Dota2 lineup recommendations. The model uses the Continuous Bag Of Words (CBOW) model in the Word2vec model to generate hero vectors. The CBOW model can predict the context of a word in a sentence. Accordingly, a word is transformed into a hero, a sentence into a lineup, and a word vector into a hero vector, the model applied in this article recommends the last hero according to the first four heroes selected first, thereby solving a series of recommendation problems.	187.94846337728984
1013.	We present a novel deep-learning-based approach for one-class transfer learning in which labeled data from an unrelated task is used for feature learning in one-class classification. The proposed method operates on top of a convolutional neural network (CNN) of choice and produces descriptive features while maintaining a low intra-class variance in the feature space for the given class. For this purpose two loss functions, compactness loss and descriptiveness loss, are proposed along with a parallel CNN architecture. A template matching-based framework is introduced to facilitate the testing process. Extensive experiments on publicly available anomaly detection, novelty detection, and mobile active authentication datasets show that the proposed deep one-class (DOC) classification method achieves significant improvements over the state-of-the-art.	187.9483758335603
1014.	Concept detection for a collection of images is an important topic and has recently been an emerging area of studies. Facing an imbalanced dataset is a great challenge in concept detection that has not yet been adequately investigated. To cope with this challenge, this paper proposes an image concept detection system based on the Convolutional Neural Network (CNN) method. The proposed method consists of three stages. At the first stage, a new algorithm is proposed to enhance the batch sampling in the CNN. At the second stage, some augmentation methods are used to improve learning process in CNN and at the final stage, a new ensemble of balanced convolutional neural network is presented in order to detect the concepts of images. Using Caltech-101 image dataset, the experimental results demonstrate the effectiveness of the proposed framework for concept detection in imbalanced datasets.	187.94828794151758
1015.	Deep transfer-learning-based diagnosis models are promising to apply diagnosis knowledge across related machines, but from which the collected data follow different distribution. To reduce the distribution discrepancy, Gaussian kernel induced maximum mean discrepancy (GK-MMD) is a widely used distance metric to impose constraints on the training of diagnosis models. However, the models using GK-MMD have three weaknesses: 1) GK-MMD may not accurately estimate distribution discrepancy because it ignores the high-order moment distances of data; 2) the time complexity of GK-MMD is high to require much computation cost; 3) the transfer performance of GK-MMD-based diagnosis models is sensitive to the selected kernel parameters. In order to overcome the weaknesses, a distance metric named polynomial kernel induced MMD (PK-MMD) is proposed in this article. Combined with PK-MMD, a diagnosis model is constructed to reuse diagnosis knowledge from one machine to the other. The proposed methods are verified by two transfer learning cases, in which the health states of locomotive bearings are identified with the help of data respectively from motor bearings and gearbox bearings in laboratories. The results show that PK-MMD enables to improve the inefficient computation of GK-MMD, and the PK-MMD-based diagnosis model presents better transfer results than other methods.	187.94823139744744
1016.	Summarization is an effective strategy to promote and enhance learning and deep comprehension of texts. However, summarization is seldom implemented by teachers in classrooms because the manual evaluation of students' summaries requires time and effort. This problem has led to the development of automated models of summarization quality. However, these models often rely on features derived from expert ratings of student summarizations of specific source texts and are therefore not generalizable to summarizations of new texts. Further, many of the models rely of proprietary tools that are not freely or publicly available, rendering replications difficult. In this study, we introduce an automated summarization evaluation (ASE) model that depends strictly on features of the source text or the summary, allowing for a purely text-based model of quality. This model effectively classifies summaries as either low or high quality with an accuracy above 80%. Importantly, the model was developed on a large number of source texts allowing for generalizability across texts. Further, the features used in this study are freely and publicly available affording replication.	187.94822951783772
1017.	Virus spread prediction is very important to actively plan actions. Viruses are unfortunately not easy to control, since speed and reach of spread depends on many factors from environmental to social ones. In this article we present research results on developing Neural Network model for COVID-19 spread prediction. Our predictor is based on classic approach with deep architecture which learns by using NAdam training model. For the training we have used official data from governmental and open repositories. Results of prediction are done for countries but also regions to provide possibly wide spectrum of values about predicted COVID-19 spread. Results of the proposed model show high accuracy, which in some cases reaches above 99%.	187.94804233639255
1018.	This letter proposes a hybrid control methodology to achieve full body collision avoidance in anthropomorphic robot manipulators. The proposal improves classical motion planning algorithms by introducing a Deep Reinforcement Learning (DRL) approach trained ad hoc for performing obstacle avoidance, while achieving a reaching task in the operative space. More specifically, a switching mechanism is enabled whenever a condition of proximity to the obstacles is met, thus conferring to the dual-mode architecture a self-configuring capability in order to cope with objects unexpectedly invading the workspace. The proposal has been finally tested relying on a realistic robot manipulator simulated in a V-REP environment.	187.9479933948984
1019.	Offline handwritten signature verification is a challenging pattern recognition task. One of the most significant limitations of the handwritten signature verification problem is inadequate data for training phases. Due to this limitation, deep learning methods that have obtained the state-of-the-art results in many areas achieve quite unsuccessful results when applied to signature verification. In this study, a new use of Cycle-GAN is proposed as a data augmentation method to address the inadequate data problem on signature verification. We also propose a novel signature verification system based on Caps-Net. The proposed data augmentation method is tested on four different convolutional neural network (CNN) methods, VGG16, VGG19, ResNet50, and DenseNet121, which are widely used in the literature. The method has provided a significant contribution to all mentioned CNN methods' success. The proposed data augmentation method has the best effect on the DenseNet121. We also tested our data augmentation method with the proposed signature verification system on two widely used databases: GPDS and MCYT. Compared to other studies, our verification system achieved the state-of-the-art results on MCYT database, while it reached the second-best verification result on GPDS.	187.9479783481488
1020.	Electrocardiogram (ECG) signal depicts electrical activity of the heart. It is primary used to obtain insight of heart abnormalities. Recently, it is found to be unique thus recommended to be used as a biometric modality like fingerprint and DNA. A lot of researches been performed to extract unique features and use it to identify individuals. To our limited knowledge, using deep neural networks for ECG identification is a salient area. In this paper, we utilize four layers of neural network to classify signals to its contributors. Based on the experimentation results, it is proven that deep learning network is as efficient as classical machine learning algorithms by obtaining 94.12% classification accuracy. Moreover, it continuously shines as dataset size increases, where traditional machine learning algorithms often fail to maintain high performance accuracy.	187.94783552013422
1021.	In this paper, we introduce a large-scale dataset, called SCUT-HCCDoc, to address challenging detection and recognition problems of handwritten Chinese text (HCT) in the camera-captured documents. Despite extensive studies of optical character recognition (OCR) and offline handwriting recognition for document images, text detection and recognition in the camera-captured documents remains an unsolved problem that is worth for extensive study and investigation. With recent advances in deep learning, researchers have proposed useful architectures for feature learning, detection, and recognition for the scene text. However, the performance of deep learning methods highly depends on the amount and diversity of training data. Previous OCR and offline HCT datasets were built under specific constraints, and most of the recent scene text datasets are for non-handwritten text. Hence, there is a lack of a comprehensive scene handwritten text benchmark. This study focuses on scenes with handwritten Chinese text. We introduce the SCUT-HCCDoc database for HCT detection, recognition and spotting. SCUT-HCCDoc contains 12,253 camera-captured document images with 116,629 text lines and 1,155,801 characters. The diversity of SCUT-HCCDoc can be described at three levels: (1) image-level diversity : image appearance and geometric variances caused by camera-captured settings (such as perspective, background, and resolution) and different applications (such as note-taking, test papers, and homework); (2) text-level diversity : variances of text line length, rotation, etc.; (3) character-level diversity : variances of character categories (up to 6109 classes with additional English letters, and digits), character size, individual writing style, etc. Three kinds of baseline experiments were conducted, where we used several popular text detection methods for text line detection, CTC-based/attention-based methods for text line recognition, and combine text detectors with CTC-based recognizer to achieve end-to-end text spotting. The results indicate the diversity of SCUT-HCCDoc and the challenges of HCT understanding in document images. The dataset is available at https://github.com/HCIILAB/SCUT-HCCDoc_Dataset_Release . (c) 2020 Elsevier Ltd. All rights reserved.	187.9477954365036
1022.	Deep learning-based hyperspectral image classification has become very popular recently. It has been widely used in the domain of classification of remote sensing hyperspectral images and has shown encouraging results. Although presence of many spectral bands in a hyperspectral image provides valuable features for the classification purposes, lack of adequate training samples makes training a deep learning model a challenging task. In this paper, we employed stacked auto-encoder (SAE) as the deep learning architecture to extract deep spectral features of the input data and to address the problem of absence of enough training samples, we proposed an effective data augmentation approach to boost the number of training data. Also, in order to alleviate the noise in the output image, we used the majority voting strategy to smooth the final classification map. We applied our method on the Indian Pines hyperspectral dataset including very few training examples. Experimental results show the superiority of our method comparing to some of the state of the arts algorithms.	187.94772921190173
1023.	Super resolution reconstruction can be used to recover a high resolution image from a low resolution image and is particularly beneficial for clinically significant medical images in diagnosis, treatment, and research applications. However, super resolution is a challenging inverse problem due to its ill-posed nature. In this paper, inspired by recent developments in deep learning, a super resolution algorithm (SR-DCNN) is proposed for medical images that is based on a neural network and employs a deconvolution operation. The purpose of the deconvolution is to effectively establish an end-to-end mapping between the low and high resolution images. First, training data consisting of 1500 medical images of the lung, brain, heart, and spine, was collected, down-sampled, and input into the neural network. Then, patch-based image features were extracted using a set of filters and the parametric rectified linear unit (PReLU) was subsequently applied as the activation function. Finally, these extracted image features were used to reconstruct high resolution images by minimizing the loss between the predicted output image and the original high resolution image. Various network structures and hyper parameter settings were explored to achieve a good trade-off between performance and computational efficiency, based on which a four layer network was found to achieve the best result in terms of the peak signal-to-noise ratio (PSNR), structural similarity measure (SSIM), information entropy (IE), and execution speed. The network was then validated on test data, and it was demonstrated that the proposed SR-DCNN algorithm quantitatively and qualitatively outperformed the current stateof-the-art methods. (C) 2018 Elsevier Inc. All rights reserved.	187.94771993046845
1024.	In this work, a deep neural network is presented which is trained on flamelet/progress variable (FPV) tables and validated in a combustion large eddy simulation (LES) of the Sydney/Sandia flame with inhomogeneous inlets. Using data scaling and transformation techniques, as well as novel network architectures as the residual skip connection we are able to store all combustion relevant quantities in one single network, thus reducing effectively the memory footprint compared to the FPV tables, while keeping data retrieval times similar to table interpolation. The accuracy of the deep neural networks (DNN) is compared to its FPV counterpart and achieves excellent agreement. The DNN is also able to accurately predict the stiff progress variable source termin the thin reaction zone. Finally, the DNN thermochemistry representation is validated in combustion simulations of a 2D laminar premixed flame and a 3D LES of the Sydney/Sandia piloted jet flame with inhomogeneous inlet. The DNN results are in very good agreement with the conventional tabulated FPV simulations and show a promising way to efficiently reduce the storage size of high dimensional pretabulated thermochemical state space in reactive flow simulations.	187.9476903272201
1025.	Mandible segmentation is an essential step in craniomaxillofacial surgery planning, which aims to segment mandible from multi-slice computed tomography (MSCT) images. One main disadvantage of most existing mandible segmentation methods is that they require numerous expert knowledge for semi-automatic segmentation. However, the high-quality expert knowledge is hard to achieve in practice due to the scarcity of experienced doctors and experts. To solve this problem, we propose an end-to-end trainable deep learning based method, which performs segmentation in an automatic, accurate and efficient manner. Different from the popular convolutional neural network (CNN), our proposed symmetric convolutional neural network (SCNN) enforces convolution and deconvolution computation to be symmetric as to achieve a good segmentation performance. Furthermore, benefiting from the manner of end-to-end, SCNN could automatically perform mandible segmentation from raw image data. Such advantages remarkably reduce the human effort and achieve competitive performance. To verify the effectiveness of our method, we build a multi-slice computer tomography mandible dataset which includes 93 cases. The experimental results show that the proposed SCNN is superior to several popular baselines in terms of the dice similarity coefficient (DSC).	187.9476890239011
1026.	In order to compensate for the low spatial resolution of laser illumination imaging system due to the single photon detector with small number of pixels. In order to solve this problem, we demonstrated a laser illumination imaging system with compressed coded and introduced the application of deep learning in compressed sensing (CS) image reconstruction based on residual network. Specifically, by considering the priori information of sparsity, the better imaging results with much higher resolution could be obtained with a small amount of observation data. The digital micro-mirror device (DMD) is used to achieve sparse coding in this work. We designed to use two detectors to collect information in two reflection directions of DMD, which can reduce samples by 50%. In addition, considering that the time complexity of traditional CS reconstruction methods is too high, so we introduced CS reconstruction method based on residual network into our work, and did the simulation experiments with our data. According to the experimental results, our method performed better at the perspective of image quality evaluation index PSNR and consumption time in reconstruction process.	187.94764607387407
1027.	Polyps in the colon can potentially become malignant cancer tissues where early detection and removal lead to high survival rate. Certain types of polyps can be difficult to detect even for highly trained physicians. Inspired by aforementioned problem our study aims to improve the human detection performance by developing an automatic polyp screening framework as a decision support tool. We use a small image patch based combined feature method. Features include shape and color information and are extracted using histogram of oriented gradient and hue histogram methods. Dictionary learning based training is used to learn features and final feature vector is formed using sparse coding. For classification, we use patch image classification based on linear support vector machine and whole image thresholding. The proposed framework is evaluated using three public polyp databases. Our experimental results show that the proposed scheme successfully classified polyps and normal images with over 95% of classification accuracy, sensitivity, specificity and precision. In addition, we compare performance of the proposed scheme with conventional feature based methods and the convolutional neural network (CNN) based deep learning approach which is the state of the art technique in many image classification applications. (C) 2018 Elsevier Ltd. All rights reserved.	187.94764436749574
1028.	Objectives: In order to confront diverse types of malware that evolve from moment to moment, it is important to instantly acquire deep knowledge related to the characteristics of malware samples. This paper proposes a method by which to extract important byte sequences of a given malware sample that characterize the functionality of the sample, which reduces the workload of human analysts who investigate the functionality of the sample. Design & methods: By applying a convolutional neural network (CNN) with an attention mechanism to an image converted from binary data, the proposed method enables calculation of an attention map, which is expected to specify regions having higher importance for classification. This distinction of regions enables the extraction of characteristic byte sequences peculiar to the malware family from the binary data and can provide useful information for human analysts without a priori knowledge. Results: The results of an evaluation experiment using a malware dataset reveal that the sequences extracted by the proposed method provide useful information for manual analysis. For example, in the case of BackdoorWin32.Agobot. It, the region with the highest importance in the attention map points at a function to receive commands from a remote server via IRC. This result characterizes the behavior of its family, Worm:Win32/Gaobot, which executes commands sent via IRC to construct a botnet. Conclusions: By taking advantage of a CNN with the attention mechanism, the proposed method is shown to provide important regions in the binaries selectively for manual analysis of malware samples. (C) 2019 Elsevier Ltd. All rights reserved.	187.94749528215044
1029.	In this paper, we propose a novel deep learning and blockchain-based energy framework for smart grids, entitled DeepCoin. The DeepCoin framework uses two schemes, a blockchain-based scheme and a deep learning-based scheme. The blockchain-based scheme consists of five phases: setup phase, agreement phase, creating a block phase and consensus-making phase, and view change phase. It incorporates a novel reliable peer-to-peer energy system that is based on the practical Byzantine fault tolerance algorithm and it achieves high throughput. In order to prevent smart grid attacks, the proposed framework makes the generation of blocks using short signatures and hash functions. The proposed deep learning-based scheme is an intrusion detection system (IDS), which employs recurrent neural networks for detecting network attacks and fraudulent transactions in the blockchain-based energy network. We study the performance of the proposed IDS on three different sources the CICIDS2017 dataset, a power system dataset, and a web robot (Bot)-Internet of Things (IoT) dataset.	187.94746859439329
1030.	The fundamental policy of marble industries is to establish sustainable high-quality products in a standardized manner. Identification and classification of different types of marbles is a critical task that is usually carried out by human experts. However, marble quality classification by humans can be time-consuming, error-prone, inconsistent, and subjective. Automated and computerized approaches are required to obtain faster, more reliable, and less subjective results. In this study, a deep learning model is developed to perform multi-classification of marble slab images with six different quality types. Blur filter, 5 ? 5 low-pass 2D linear separable convolution filter using Gaussian kernel, and erosion filter were applied to the images for data augmentation, and a special convolutional neural network (CNN) architecture was designed and implemented. It has been observed that the data augmentation approach for marble image samples has significantly improved the accuracy of the CNN model ranging between 0.922 and 0.961.	187.94743923903684
1031.	Acute kidney injury (AKI) after liver transplantation has been reported to be associated with increased mortality. Recently, machine learning approaches were reported to have better predictive ability than the classic statistical analysis. We compared the performance of machine learning approaches with that of logistic regression analysis to predict AKI after liver transplantation. We reviewed 1211 patients and preoperative and intraoperative anesthesia and surgery-related variables were obtained. The primary outcome was postoperative AKI defined by acute kidney injury network criteria. The following machine learning techniques were used: decision tree, random forest, gradient boosting machine, support vector machine, naive Bayes, multilayer perceptron, and deep belief networks. These techniques were compared with logistic regression analysis regarding the area under the receiver-operating characteristic curve (AUROC). AKI developed in 365 patients (30.1%). The performance in terms of AUROC was best in gradient boosting machine among all analyses to predict AKI of all stages (0.90, 95% confidence interval [CI] 0.86-0.93) or stage 2 or 3 AKI. The AUROC of logistic regression analysis was 0.61 (95% CI 0.56-0.66). Decision tree and random forest techniques showed moderate performance (AUROC 0.86 and 0.85, respectively). The AUROC of support the vector machine, naive Bayes, neural network, and deep belief network was smaller than that of the other models. In our comparison of seven machine learning approaches with logistic regression analysis, the gradient boosting machine showed the best performance with the highest AUROC. An internet-based risk estimator was developed based on our model of gradient boosting. However, prospective studies are required to validate our results.	187.94736506990935
1032.	The Fog Computing (FC) paradigm is rapidly becoming an appropriate framework for the infrastructure related to the Internet of Things (IoT). FC can be a good framework for mobile applications in the IoT. This architecture is referred to as the Mobile Fog Computing (MFC). Modules in the applications can be sent to the Fog or Cloud layer in the event of the lack of resources or increased runtime on the mobile. This increases the efficiency of the whole system. As data is entered sequentially, and the input is given to the modules, the number of executable modules increases. So, this research was conducted to find the best place in order to run the modules that can be on the mobile, Fog, or Cloud. According to the proposed method, first, the Fog Devices (FDs) were locally evaluated using a greedy technique; namely, the sibling nodes followed by the parent and in the second step, a Deep Reinforcement Learning (DRL) algorithm found the best destination to execute the module so as to create a compromise between the power consumption and execution time of the modules. The evaluation results obtained regarding the parameters of the power consumption, execution cost, delay, and network resource usage showed that the proposed method on average is better than the local execution, First-Fit (FF), and standard DRL by 18, 6, and 2%, respectively.	187.94730955795723
1033.	Banking transactions, such as online transactions, credit card transactions and the mobile wallet, are gaining popularity. People are shopping more and more using credit cards. Credit cards have become a necessity, to the virtual world, for digitized and paperless transactions. Millions of online transactions take place every day and all of these transactions are subject to various types of fraud. There are many techniques developed to analyze, detect and prevent credit card fraud, these techniques are no longer sufficient for current needs. In recent years, several studies have used machine Learning techniques to find solutions to this problem. In this paper, we present a comparative study of different techniques of machine learning, especially neural network, applied to the same dataset. Our analysis aims to propose a comprehensive guide to choose the best techniques for credit card fraud detection.	187.94727961586327
1034.	Portfolio traders strive to identify dynamic portfolio allocation schemes that can allocate their total budgets efficiently through the investment horizon. This study proposes a novel portfolio trading strategy in which an intelligent agent is trained to identify an optimal trading action using deep Q-learning. We formulate a Markov decision process model for the portfolio trading process that adopts a discrete combinatorial action space and determines the trading direction at a prespecified trading size for each asset, thus ensuring practical applicability. Our novel portfolio trading strategy takes advantage of three features to outperform other strategies in real-world trading. First, a mapping function is devised to handle and transform any action that is initially proposed but found to be infeasible into a similar and valuable feasible action. Second, by overcoming the dimensionality problem, this study establishes agent and Q network models to derive a multi-asset trading strategy in the predefined action space. Last, this study introduces a technique that can derive a well-fitted multi-asset trading strategy by designing an agent to simulate all feasible actions in each state. To validate our approach, we conduct backtesting for two representative portfolios and demonstrate superior results over the benchmark strategies. (C) 2020 Elsevier Ltd. All rights reserved.	187.94727650389916
1035.	Dynamic state estimation is of considerable importance to the system monitoring, advanced control, and energy management of electrified vehicles (EVs). Among the dynamic states of various vehicle systems, the brake pressure is a key state that reflects the braking intent and maneuver of a driver and is highly correlated with the safety and energy performance of an EV. Thus, it is worth formulating a high-precision estimation algorithm for the brake pressure to better identify the braking intent of a driver and further enhance the multiperformance of the EVs. In this article, an integrated time-series model (TSM) based on multivariate deep recurrent neural networks (RNN) with long short-term memory (LSTM) units is developed for the dynamic estimation of the brake pressure of EVs. The naturalistic driving data are collected using a real electric vehicle under standard driving cycle scenarios. The signals of the vehicle and system states are measured using the controller area network (CAN) bus and preprocessed for model training and prediction. Next, a real-time multivariate LSTM-RNN model for brake pressure estimation is constructed based on the integrated speed estimation model. The real-time scheme iteratively estimates the future velocity and integrates this signal with other vehicle states to estimate a precise value of the braking pressure. The proposed integrated TSM approach is compared with several existing baseline methods to demonstrate the advantage of the method. The testing results indicate that the proposed integrated TSM method can achieve a more reliable multistep prediction with a higher accuracy compared to that of the other methods, which demonstrates the feasibility and effectiveness of the proposed approach.	187.94722165254848
1036.	This paper proposes a two-stage convolutional neural network (CNN) fusion method that can obtain accurate decision map and deal with the problem of unclear fusion boundaries. In the first stage, an improved densenet is trained to classify whether the image patch is in focus or defocus, and then the corresponding fusion rule is utilized to acquire a perfect decision map. In addition, a multi-version blurred dataset is designed to improve the generalization ability of the network. In the second stage, edge-deblurring generative adversarial networks (EDGAN) is introduced to process the boundary. Furthermore, five different loss functions are applied to generate approving boundary deblurred images. At the same time, natural images are selected from the COCO dataset for special processing to simulate the boundary blurring situation to create the second-stage dataset. After two stages of processing, an image with rich details and decent fusion boundaries are attained. Experimental results demonstrate that the proposed algorithm is superior to other fusion algorithms in subjective vision and objective assessment. (C) 2020 Elsevier B.V. All rights reserved.	187.9471971887748
1037.	We propose a deep-learning-based channel estimation technique for wireless energy transfer. Specifically, we develop a channel learning scheme using the deep autoencoder, which learns the channel state information (CSI) at the energy transmitter based on the harvested energy feedback from the energy receiver, in the sense of minimizing the mean square error (mse) of the channel estimation. Numerical results demonstrate that the proposed scheme learns the CSI very well and significantly outperforms the conventional scheme in terms of the channel estimation mse as well as the harvested energy.	187.94715773274794
1038.	Disruptions to the earth's biosphere and to the natural environment stemming from the indiscreet human activity, have caused serious environmental problems which are tantamount to an extended and prolonged ecological crisis. Climate change is clearly reflected in the increase of the global average air and ocean temperatures, in the excessive melting of snow-ice, and in the rise of the global average sea level. One of the most serious impacts of climate change is the complex interaction of species in relation to their corresponding climatic survival factors, which favors the spread of invasive species (INSP). These species constitute a very serious and rapidly deteriorating threat to the natural biodiversity of the native environment, but also to the flora, fauna, and even to the local human population. This research proposes a Machine Hearing (MH) framework for real-time streaming analytics, employing Lambda Architecture (LARC). The hybrid modeling effort is based on timely and advanced Computational Intelligence (COIN) approaches. The Framework for Lambda Architecture Machine Hearing (FLAME_H) uses a combination of batch and streaming data. The FLAME_H applies the EL_GROSEMMARI (Extreme Learning Graph Regularized Online Sequential Multilayer Multiencoder Algorithm) to classify the batch data and the Adaptive Random Forest (ARF) in order to control the data streams in real time. The aim of the proposed framework is the intelligent identification and classification of invasive alien species, based on the sounds they produce. This would contribute to the protection of biodiversity and biosecurity in a certain area.	187.94709239722687
1039.	This paper proposes a new framework for medical data processing which is essentially designed based on deep autoencoder and energy spectral density (ESD) concepts. The main novelty of this framework is to incorporate ESD function as feature extractor into a unique deep sparse auto-encoders (DSAEs) architecture. This allows the proposed architecture to extract more qualified features in a shorter computational time compared with the conventional frameworks. In order to validate the performance of the proposed framework, it has been tested with a number of comprehensive medical waveform datasets with varying dimensionality, namely, Epilepsy Serious Detection, SPECTF Classification and Diagnosis of Cardiac Arrhythmias. Overall, the ESD function speeds up the deep auto-encoder processing time and increases the overall accuracy of the results which are compared to several studies in the literature and a promising agreement is achieved. (C) 2018 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences. Published by Elsevier B.V. All rights reserved.	187.94708646721742
1040.	A novel short-term solar power prediction model is presented in this work, by utilizing the learning ability of Long-Shot-Term-Memory network (LSTM) based deep learning (DL) technique and the concept of wavelet transform (WT). In this proposed WT-LSTM model, the WT is used to decompose the recorded solar energy time-series data into different frequency series followed by the statistical feature extraction process. The LSTM with dropout based DL model is proposed to predict the futuristic value of solar energy generation in different time-horizon (hourly and day basis), where the statistical WT based features combined with several other meteorological factors such as temperature, wind speed, pressure, cloudy-index, humidity and altimeter index are modelled as input to the LSTM model. The efficiency of the suggested WT-LSTM model has been proved by comparing statistical performance measures in terms of RMSE, MAPE, MAE and R-2 score, with other contemporary machine learning and deep-learning based models. (C) 2020 Elsevier Ltd. All rights reserved.	187.9470650275772
1041.	Forecasting a financial asset's price is important as one can lower the risk of investment decision- making with accurate forecasts. Recently, the deep neural network is popularly applied in this area of research; however, it is prone to overfitting owing to limited availability of data points for training. We propose a novel data augmentation approach for stock market index forecasting through our ModAugNet framework, which consists of two modules: an overfitting prevention LSTM module and a prediction LSTM module. The performance of the proposed model is evaluated using two different representative stock market data (S&P500 and Korea Composite Stock Price Index 200 (KOSPI200)). The results confirm the excellent forecasting accuracy of the proposed model. ModAugNet-c yields a lower test error than the comparative model (SingleNet) in which an overfitting prevention LSTM module is absent. The test mean squared error (MSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) for S&P500 decreased to 54.1%, 35.5%, and 32.7%, respectively, of the corresponding S&P500 forecasting errors of SingleNet, while the same for KOSPI200 decreased to 48%, 23.9%, and 32.7%, respectively, of the corresponding KOSPI200 forecasting errors of SingleNet. Furthermore, through the analyses of the trained ModAugNet-c, we found that test performance is entirely dependent on the prediction LSTM module. The contribution of this study is its applicability in various instances where it is challenging to artificially augment data, such as medical data analysis and financial time-series modeling. (C) 2018 Elsevier Ltd. All rights reserved.	187.94698942903526
1042.	Background: Knowledge concerning nursing students' experiences of the clinical learning environment and how supervision is carried out is largely lacking. This study compares nursing students' perceptions of the clinical learning environment and supervision in two different supervision models: peer learning in student-dedicated units, with students working together in pairs and supervised by a "preceptor of the day" (model A), and traditional supervision, in which each student is assigned to a personal preceptor (model B). Methods: The study was performed within the nursing programme at a university college in Sweden during students' clinical placements (semesters 3 and 4) in medical and surgical departments at three different hospitals. Data was collected using the Clinical Learning Environment, Supervision and Nurse Teacher evaluation scale, CLES+T, an instrument tested for reliability and validity, and a second instrument developed for this study to obtain deeper information regarding how students experienced the organisation and content of the supervision. Independent t-tests were used for continuous variables, Mann-Whitney U-tests for ordinal variables, and the chi-square or Fischer's exact tests for categorical variables. Results: Overall, the students had positive experiences of the clinical learning environment and supervision in both supervision models. Students supervised in model A had more positive experiences of the cooperation and relationship between student, preceptor, and nurse teacher, and more often than students in model B felt that the ward had an explicit model for supervising students. Students in model A were more positive to having more than one preceptor and felt that this contributed to the assessment of their learning outcomes. Conclusions: A good learning environment for students in clinical placements is dependent on an explicit structure for receiving students, a pedagogical atmosphere where staff take an interest in supervision of students and are easy to approach, and engagement among and collaboration between preceptors and nurse teachers. This study also indicates that supervision based on peer learning in student-dedicated rooms with many preceptors can be more satisfying for students than a model where each student is assigned to a single preceptor.	187.94682585001186
1043.	Recently, deep learning (DL) has emerged as a revolutionary and versatile tool transforming industry applications and generating new and improved capabilities for scientific discovery and model building. The adoption of DL in hydrology has so far been gradual, but the field is now ripe for breakthroughs. This paper suggests that DLbased methods can open up a complementary avenue toward knowledge discovery in hydrologic sciences. In the new avenue, machine-learning algorithms present competing hypotheses that are consistent with data. Interrogative methods are then invoked to interpret DL models for scientists to further evaluate. However, hydrology presents many challenges for DL methods, such as data limitations, heterogeneity and co-evolution, and the general inexperience of the hydrologic field with DL. The roadmap toward DL-powered scientific advances will require the coordinated effort from a large community involving scientists and citizens. Integrating process-based models with DL models will help alleviate data limitations. The sharing of data and baseline models will improve the efficiency of the community as a whole. Open competitions could serve as the organizing events to greatly propel growth and nurture data science education in hydrology, which demands a grassroots collaboration. The area of hydrologic DL presents numerous research opportunities that could, in turn, stimulate advances in machine learning as well.	187.94674803408427
1044.	Natural hazards have been resulting in severe damage to our cities, and flooding is one of the most disastrous in the U.S and worldwide. Therefore, it is critical to develop efficient methods for risk and damage assessments after natural hazards, such as flood depth estimation. Existing works primarily leverage photos and images capturing flood scenes to estimate flood depth using traditional computer vision and machine learning techniques. However, the advancement of deep learning (DL) methods make it possible to estimate flood depth more accurate. Therefore, based on state-of-the-art DL technique (i.e., Mask R-CNN) and publicly available images from the Internet, this study aims to investigate and improve the flood depth estimation. Specifically, human objects are detected and segmented from flooded images to infer the floodwater depth. This study provides a new framework to extract critical information from large accessible online data for rescue teams or even robots to carry out appropriate plans for disaster relief and rescue missions in the urban area, shedding lights on the real-time detection of the flood depth.	187.94672043600184
1045.	The recent rapid success of deep convolutional neural networks (CNN) on many computer vision tasks largely benefits from the well-annotated Pascal VOC, ImageNet, and MS COCO datasets. However, it is challenging to get ImageNet-like annotations (1000 classes) in the medical imaging domain due to the lack of clinical training in the lay crowdsourcing community. We address this problem by presenting a semi-supervised training method for neural networks with true-class and pseudo-class (un-annotated class) labels on partially annotated training data. The true-class labels are supervised annotations from clinical professionals. The pseudo-class labels are unsupervised clustering of un-annotated data. Our method rests upon the hypothesis of better coherent annotations with discriminative classes leading to better trained CNN models. We validated our method on extra-coronary calcification detection in low dose CT scans. The CNN trained with true-class and 10 pseudo-classes achieved a 78.0% sensitivity at 10 false positives per scan (0.3 false positive per slice), which significantly outperformed the CNN trained with true-class only (sensitivity=25.0% at 10 false positives per patient).	187.9466076748604
1046.	Rich image information is one of the important means through which unmanned surface vehicles effectively and reliably identify targets during autonomous navigation. However, the adaptability of traditional artificial design feature methods in target representation and differentiation remains limited due to the diversity of ship target types, different scales, and complex and dynamic outdoor scenes. This study proposed a ship target recognition method based on single shot multibox detector (SSD) deep learning. First, training and test sample sets were constructed by acquiring and creating a ship's target image and background image under different types and scenes in an actual river environment. Subsequently, the sample set was used to train and optimize the SSD depth model to achieve adaptive extraction and recognition of target features. Lastly, ship identification experiments with different background environments and foreground targets were performed to test the effectiveness of the proposed method. The support vector machine method based on artificial feature extraction was used for the comparative experiments. Experiment results showed that the SSD-based deep learning method achieved better results than the artificial design feature method in terms of recall and precision rates.	187.94653685201047
1047.	Background One of the main challenges for the CRISPR-Cas9 system is selecting optimal single-guide RNAs (sgRNAs). Recently, deep learning has enhanced sgRNA prediction in eukaryotes. However, the prokaryotic chromatin structure is different from eukaryotes, so models trained on eukaryotes may not apply to prokaryotes. Results We designed and implemented a convolutional neural network to predict sgRNA activity in Escherichia coli. The network was trained and tested on the recently-released sgRNA activity dataset. Our convolutional neural network achieved excellent performance, yielding average Spearman correlation coefficients of 0.5817, 0.7105, and 0.3602, respectively for Cas9, eSpCas9 and Cas9 with a recA coding region deletion. We confirmed that the sgRNA prediction models trained on prokaryotes do not apply to eukaryotes and vice versa. We adopted perturbation-based approaches to analyze distinct biological patterns between prokaryotic and eukaryotic editing. Then, we improved the predictive performance of the prokaryotic Cas9 system by transfer learning. Finally, we determined that potential off-target scores accumulated on a genome-wide scale affect on-target activity, which could slightly improve on-target predictive performance. Conclusions We developed convolutional neural networks to predict sgRNA activity for wild type and mutant Cas9 in prokaryotes. Our results show that the prediction accuracy of our method is improved over state-of-the-art models.	187.94651880187018
1048.	Deep learning has become a standard processing procedure in land cover mapping for remote sensing images. Instead of relying on hand-crafted features, deep learning algorithms, such as Convolutional Neural Networks (CNN) can automatically generate effective feature representations, in order to recognize objects with complex image patterns. However, the rich spatial information still remains unexploited, since most of the deep learning algorithms only focus on small image patches that overlook the contextual information at larger scales. To utilize these contextual information and improve the classification performance for high-resolution imagery, we propose a graph-based model in order to capture the contextual information over semantic segments of the image. First, we explore semantic segments which build on the top of deep features and obtain the initial classification result. Then, we further improve the initial classification results with a higher-order co-occurrence model by extending the existing conditional random field (HCO-CRF) algorithm. Compared to the pixel- and object-based CNN methods, the proposed model achieved better performance in terms of classification accuracy.	187.94650815449265
1049.	The methodology of deep learning, a component of machine learning and artificial intelligence, is introduced. The opportunity for this technology to automate some aspects of medical practice is reviewed. Finally, a discussion is provided on the integration of concepts from deep learning into medical education.	187.94650116355106
1050.	Deep reinforcement learning is gaining popularity in many different fields. An interesting sector is related to the definition of dynamic decision-making systems. A possible example is dynamic portfolio optimization, where an agent has to continuously reallocate an amount of fund into a number of different financial assets with the final goal of maximizing return and minimizing risk. In this work, a novel deep Q-learning portfolio management framework is proposed. The framework is composed by two elements: a set of local agents that learn assets behaviours and a global agent that describes the global reward function. The framework is tested on a crypto portfolio composed by four cryptocurrencies. Based on our results, the deep reinforcement portfolio management framework has proven to be a promising approach for dynamic portfolio optimization.	187.94634143847009
1051.	For many decades, ultrasonic imaging inspection has been adopted as a principal method to detectmultiple defects, e.g., void and corrosion. However, the data interpretation relies on an inspector's subjective judgment, thus making the results vulnerable to human error. Nowadays, advanced computer vision techniques reveal new perspectives on the high-level visual understanding of universal tasks. This research aims to develop an efficient automatic ultrasonic image analysis system for nondestructive testing (NDT) using the latest visual information processing technique. To this end, we first established an ultrasonic inspection image dataset containing 6849 ultrasonic scan images with full defect/no-defect annotations. Using the dataset, we performed a comprehensive experimental comparison of various computer vision techniques, including both conventional methods using hand-crafted visual features and the most recent convolutional neural networks (CNN) which generate multiple-layer stacking for representation learning. In the computer vision community, the two groups are referred to as shallow and deep learning, respectively. Experimental results make it clear that the deep learning-enabled system outperformed conventional (shallow) learning schemes by a large margin. We believe this benchmarking could be used as a reference for similar research dealing with automatic defect detection in ultrasonic imaging inspection.	187.94614115709558
1052.	Robust and precise defect detection is of great significance in the production of the high-quality printed circuit board (PCB). However, due to the complexity of PCB production environments, most previous works still utilise traditional image processing and matching algorithms to detect PCB defects. In this work, an improved bare PCB defect detection approach is proposed by learning deep discriminative features, which also greatly reduced the high requirement of a large dataset for the deep learning method. First, the authors extend an existing PCB defect dataset with some artificial defect data and affine transformations to increase the quantity and diversity of defect data. Then, a deep pre-trained convolutional neural network is employed to learn high-level discriminative features of defects. They fine-tune the base model on the extended dataset by freezing all the convolutional layers and training the top layers. Finally, the sliding window approach is adopted to further localise the defects. Extensive comparisons with three traditional shallow feature-based methods demonstrate that the proposed approach is more feasible and effective in PCB defect detection area.	187.94610534309618
1053.	Drug discovery studies have become increasingly expensive and time-consuming processes. In the early phase of drug discovery studies, an extensive search has been performed to find drug-like compounds, which then can be optimized over time to become a marketed drug. One of the conventional ways of detecting active compounds is to perform an HTS (high-throughput screening) experiment. As of July 2019, the PubChem repository contains 1.3 million bioassays that are generated through HTS experiments. This feature of PubChem makes it a great resource for performing machine learning algorithms to develop classification models to detect active compounds for drug discovery studies. However, data sets obtained from PubChem are highly imbalanced. This imbalanced nature of the data sets has a negative impact on the classification performance of machine learning algorithms. Here, we explored the classification performance of deep neural networks (DNN) on imbalance compound data sets after applying various data balancing methods. We used five confirmatory HTS bioassays from the PubChem repository and applied one undersampling and three oversampling methods as data balancing methods. We used a fully connected, two-hidden-layer DNN model for the classification of active and inactive molecules. To evaluate the performance of the network, we calculated six performance metrics, including balanced accuracy, precision, recall, F1 score, Matthews correlation coefficient, and area under the ROC curve. The study results showed that the effect of imbalanced data on network performance could be mitigated to a degree by applying the data balancing methods. The level of imbalance, however, has a negative effect on the performance of the network.	187.94610400862243
1054.	Current image quality assessment (IQA) methods require the original images for evaluation. However, recently, IQA methods that use machine learning have been proposed. These methods learn the relationship between the distorted image and the image quality automatically. In this paper, we propose an IQA method based on deep learning that does not require a reference image. We show that a convolutional neural network with distortion prediction and fixed filters improves the IQA accuracy.	187.94603870873755
1055.	The traditional environment maps built by robots include both metric ones and topological ones. These maps are navigation-oriented and not adequate for service robots to interact with or serve human users who normally rely on conceptual knowledge or semantic contents of the environment. Therefore, the construction of semantic maps becomes necessary for building an effective human-robot interface for service robots. In addition, due to the breakthrough results of the Deep Convolutional Neural Network in the field of target detection, this paper uses the DCNN to detect the target object effectively. Based on this, the SLAM algorithm is used to construct the map, and combined with the detection algorithm to realize the construction of the semantic map. Experiments show that the system can be applied to robot intelligent navigation.	187.9460338060557
1056.	Anomalies are those deviating significantly from the norm. Thus, anomaly detection amounts to finding data points located far away from their neighbors, i.e., those lying in low-density regions. Classic anomaly detection methods are largely designed for single data type such as continuous or discrete. However, real-world data is increasingly heterogeneous, where a data point can have both discrete and continuous attributes. Mixed data poses multiple challenges including (a) capturing the inter-type correlation structures and (b) measuring deviation from the norm under multiple types. These challenges are exaggerated under (c) high-dimensional regimes. In this paper, we propose a new scalable unsupervised anomaly detection method for mixed data based on Mixed-variate Restricted Boltzmann Machine (Mv. RBM). The Mv. RBM is a principled probabilistic method that estimates density of mixed data. We propose to use free energy derived from Mv. RBM as anomaly score as it is identical to data negative log-density up to an additive constant. We then extend this method to detect anomalies across multiple levels of data abstraction, an effective approach to deal with high-dimensional settings. The extension is dubbed MIXMAD, which stands for MIXed data Multilevel Anomaly Detection. In MIXMAD, we sequentially construct an ensemble of mixed-data Deep Belief Nets (DBNs) with varying depths. Each DBN is an energy-based detector at a predefined abstraction level. Predictions across the ensemble are finally combined via a simple rank aggregation method. The proposed methods are evaluated on a comprehensive suit of synthetic and real high-dimensional datasets. The results demonstrate that for anomaly detection, (a) a proper handling of mixed types is necessary, (b) free energy is a powerful anomaly scoring method, (c) multilevel abstraction of data is important for high-dimensional data, and (d) empirically Mv. RBM and MIXMAD are superior to popular unsupervised detection methods for both homogeneous and mixed data.	187.9459844532129
1057.	Patent classification is an essential task in patent information management and patent knowledge mining. However, this task is still largely done manually due to the unsatisfactory performance of current algorithms. Recently, deep learning methods such as convolutional neural networks (CNN) have led to great progress in image processing, voice recognition, and speech recognition, which has yet to be applied to patent classification. We proposed DeepPatent, a deep learning algorithm for patent classification based on CNN and word vector embedding. We evaluated the algorithm on the standard patent classification benchmark dataset CLEF-IP and compared it with other algorithms in the CLEF-IP competition. Experiments showed that DeepPatent with automatic feature extraction achieved a classification precision of 83.98%, which outperformed all the existing algorithms that used the same information for training. Its performance is better than the state-of-art patent classifier with a precision of 83.50%, whose performance is, however, based on 4000 characters from the description section and a lot of feature engineering while DeepPatent only used the title and abstract information. DeepPatent is further tested on USPTO-2M, a patent classification benchmark data set that we contributed with 2,000,147 records after data cleaning of 2,679,443 USA raw utility patent documents in 637 categories at the subclass level. Our algorithms achieved a precision of 73.88%.	187.9458942845775
1058.	Through well-designed counterfeit websites, phishing induces online users to visit forged web pages to obtain their private sensitive information, e.g., account number and password. Existing antiphishing approaches are mostly based on page-related features, which require to crawl content of web pages as well as accessing third-party search engines or DNS services. This not only leads to their low efficiency in detecting phishing but also makes them rely on network environment and third-party services heavily. In this paper, we propose a fast phishing website detection approach called PDRCNN that relies only on the URL of the website. PDRCNN neither needs to retrieve content of the target website nor uses any third-party services as previous approaches do. It encodes the information of an URL into a two-dimensional tensor and feeds the tensor into a novelly designed deep learning neural network to classify the original URL. We first use a bidirectional LSTM network to extract global features of the constructed tensor and give all string information to each character in the URL. After that, we use a CNN to automatically judge which characters play key roles in phishing detection, capture the key components of the URL, and compress the extracted features into a fixed length vector space. By combining the two types of networks, PDRCNN achieves better performance than just using either one of them. We built a dataset containing nearly 500,000 URLs which are obtained through Alexa and PhishTank. Experimental results show that PDRCNN achieves a detection accuracy of 97% and an AUC value of 99%, which is much better than state-of-the-art approaches. Furthermore, the recognition process is very fast: on the trained PDRCNN model, the average per URL detection time only cost 0.4 ms.	187.9457787840227
1059.	In recent years, deep learning has developed rapidly and gradually infiltrated into various fields. As a rookie, generation-based confrontation networks based on deep learning show excellent characteristics in many aspects. This study presents two innovative ideas, the same card force and generation cards algorithm. The generation of the equivalent cards force based on the generation of confrontation networks is studied. For the same period of time in the regular game, players will be issued different types of cards with similar card force, so as to distinguish the player level, the theory of the equal force is proposed. Based on the average and variance of scores obtained after the completion of a game, the cards are divided into ten different types of cards. On this basis, the use of generating a counterfeit network Generative Adversarial Nets generates a large number of cards of the equal card force. In the actual game, a network model is generated to generate a large number of game cards with the same force and distributed to different table numbers, so that the points scored by the landlords in different matches can have the characteristics of mutual appraisal.	187.94559278068112
1060.	Are we, as academics, stuck in a horizontal temporality, organised by the clock, that flattens our work, our words? In reading feminist work by Marta Tikkanen, Helene Cixous, and others, a rupture strikes, establishing another temporality: vertical time. Is it possible, I ask, to learn from these authors and engage in academic writing in verticality? The answer is: Yes! Through an in-depth reading of special pieces, I see clearly that when we use our scholarly voice to write from within our vulnerabilities, it becomes possible to climb all the way up or dig ourselves deep down. In other words, we can 'go deep' in the sense of touching that which is most important, as well as finding ways to 'fly high,' through writing. This shows that writing and temporality are always already interweaved with each other because writing produces temporalities just as temporality at play produces writing. In this writing-temporality meshwork, there seems to be no set genre for vertical writing. Rather, it consists of a multitude of practices, written in the instant, from within the urgency of articulating that which matters.	187.94546022912823
1061.	Traditional text emotion analysis methods are primarily devoted to studying extended texts, such as news reports and full-length documents. Microblogs are considered short texts that are often characterized by large noises, new words, and abbreviations. Previous emotion classification methods usually fail to extract significant features and achieve poor classification effect when applied to processing of short texts or micro-texts. This study proposes a microblog emotion classification model, namely, CNN_Text_Word2vec, on the basis of convolutional neural network (CNN) to solve the above-mentioned problems. CNN_Text_Word2vec introduces a word2vec neural network model to train distributed word embeddings on every single word. The trained word vectors are used as input features for the model to learn microblog text features through parallel convolution layers with multiple convolution kernels of different sizes. Experiment results show that the overall accuracy rate of CNN_Text_Word2vec is 7.0% higher than that achieved by current mainstream methods, such as SVM, LSTM and RNN. Moreover, this study explores the impact of different semantic units on the accuracy of CNN_Text_Word2vec, specifically in processing of Chinese texts. The experimental results show that comparing to using feature vectors obtained from training words, feature vector obtained from training Chinese characters yields a better performance.	187.94544150227844
1062.	Machine learning is a branch of artificial intelligence (AI) involving computer programs that are able to improve their own performance through experience (training). The diverse applications of new 'deep learning' approaches with neural networks are now expanding into the field of biology. But these applications to biological data require more scrutiny and caution to increase the standards of publishing and allow the AI revolution in biology to take off.	187.94544146407873
1063.	We investigate privacy-preserving action recognition in deep learning, a problem with growing importance in smart camera applications. A novel adversarial training framework is formulated to learn an anonymization transform for input videos such that the trade-off between target utility task performance and the associated privacy budgets is explicitly optimized on the anonymized videos. Notably, the privacy budget, often defined and measured in task-driven contexts, cannot be reliably indicated using any single model performance, because strong protection of privacy should sustain against any malicious model that tries to steal private information. To tackle this problem, we propose two new optimization strategies of model restarting and model ensemble to achieve stronger universal privacy protection against any attacker models. Extensive experiments have been carried out and analyzed. On the other hand, given few public datasets available with both utility and privacy labels, the data-driven (supervised) learning cannot exert its full power on this task. To further address this dataset challenge, we have constructed a new dataset, termed PA-HMDB51, with both target task labels (action) and selected privacy attributes (gender, age, race, nudity, and relationship) annotated on a per-frame basis. This first-of-its-kind video dataset and evaluation protocol can greatly facilitate visual privacy research.	187.9454088052719
1064.	This study proposed an automated method for manifesting construction activity scenes by image captioning - an approach rooted in computer vision and natural language generation. A linguistic description schema for manifesting the scenes is developed initially and two unique dedicated image captioning datasets are created for method validation. A general model architecture of image captioning is then instituted by combining an encoder -decoder framework with deep neural networks, followed by three experimental tests involving the selection of model learning strategies and performance evaluation metrics. It is demonstrated the method's performance is comparable with that of state-of-the-art computer vision methods in general. The paper concludes with a discussion of the feasibility of the practical application of the proposed approach at the current technical level.	187.94534333826098
1065.	This paper proposes Dirichlet Variational Autoencoder (DirVAE) using a Dirichlet prior. To infer the parameters of DirVAE, we utilize the stochastic gradient method by approximating the inverse cumulative distribution function of the Gamma distribution, which is a component of the Dirichlet distribution. This approximation on a new prior led an investigation on the component collapsing, and DirVAE revealed that the component collapsing originates from two problem sources: decoder weight collapsing and latent value collapsing. The experimental results show that 1) DirVAE generates the result with the best log-likelihood compared to the baselines; 2) DirVAE produces more interpretable latent values with no collapsing issues which the baselines suffer from; 3) the latent representation from DirVAE achieves the best classification accuracy in the (semi-)supervised classification tasks on MNIST, OMNIGLOT, COIL-20, SVHN, and CIFAR-10 compared to the baseline VAEs; and 4) the DirVAE augmented topic models show better performances in most cases. (C) 2020 Elsevier Ltd. All rights reserved.	187.94533899085292
1066.	A behavior is considered abnormal when it is seen as unusual under certain contexts. The definition for abnormal behavior varies depending on situations. For example, people running in a field is considered normal but is deemed abnormal if it takes place in a mall. Similarly, loitering in the alleys, fighting or pushing each other in public areas are considered abnormal under specific circumstances. Abnormal behavior detection is crucial due to the increasing crime rate in the society. If an abnormal behavior can be detected earlier, tragedies can be avoided. In recent years, deep learning has been widely applied in the computer vision field and has acquired great success for human detection. In particular, Convolutional Neural Network (CNN) has shown to have achieved state-of-the-art performance in human detection. In this paper, a CNN-based abnormal behavior detection method is presented. The proposed approach automatically learns the most discriminative characteristics pertaining to human behavior from a large pool of videos containing normal and abnormal behaviors. Since the interpretation for abnormal behavior varies across contexts, extensive experiments have been carried out to assess various conditions and scopes including crowd and single person behavior detection and recognition. The proposed method represents an end-to-end solution to deal with abnormal behavior under different conditions including variations in background, number of subjects (individual, two persons or crowd), and a range of diverse unusual human activities. Experiments on five benchmark datasets validate the performance of the proposed approach.	187.94529660365305
1067.	Composite materials are increasingly used as structural components in military and civilian aircraft. To ensure their high reliability, numerous non-destructive testing (NDT) techniques have been used to detect defects during production and maintenance. However, most of these techniques are non-automatic, with diagnostic results determined subjectively by operators. Some deep learning methods have been proposed to identify defects in images obtained through NDT, but they need labeled image samples with defects, which can be expensive or unavailable. We propose a deep transfer learning model to accurately extract features for the inclusion of defects in X-ray images of aeronautics composite materials (ACM), whose samples are scarce. We researched an automatic inclusion defect detection method for X-ray images of ACM using our proposed model. Experimental results show that the model can reach 96% classification accuracy (F1 measure) with satisfactory detection results.	187.94527488477974
1068.	Dewarping is a necessary preprocessing step to recognize text from a distorted camera captured document image. According to recent literature, deep learning-based approaches perform with higher accuracy in similar domains. The deep learning-based neural networks are not yet fully explored in the domain of dewarping. To fill this gap, we propose a dewarping approach based on the convolutional neural network. A large number of images are required to train such networks. However, it is a tedious job to capture such a large number of images. Hence, it is required to generate synthetic warped images for the training phase of the deep learning-based neural network. The existing synthetic warped image generation methods are heuristic-based. In this paper, we propose a novel mathematical model for the generation of warped images. The proposed model takes some parameters such as depth of the surface, camera angle, and camera position and generates the corresponding warped image. These parameters are the ground truth for that particular warped image. We use a Convolutional Neural Network (CNN) based model to estimate the warping parameters from a 2 D warped image for dewarping. In the training phase of CNN based model, the synthetic images and their corresponding ground truth are used. Next, the trained model is used to dewarp the unknown warped images. The performance of the proposed warping model is analyzed. Finally, the proposed dewarping method is compared with existing approaches. In both cases, the results are encouraging. (C) 2020 Elsevier Ltd. All rights reserved.	187.94512157079748
1069.	Sentiment analysis requires a lot of information coming from different sources and about different topics to be retrieved and fused. For this reason, one of the most important subtasks of sentiment analysis is subjectivity detection, i.e., the removal of 'factual' or 'neutral' comments that lack sentiment. It is possibly the most essential subtask of sentiment analysis as sentiment classifiers are often optimized to categorize text as either negative or positive and, hence, forcefully fit unopinionated sentences into one of these two categories. This article reviews hand-crafted and automatic models for subjectivity detection in the literature. It highlights the key assumptions these models make, the results they obtain, and the issues that still need to be explored to further our understanding of subjective sentences. Lastly, the advantages and limitations of each approach are compared. The methods can be broadly categorized as hand-crafted, automatic, and multi-modal. Hand-crafted templates work well on strong sentiments, however they are unable to identify weakly subjective sentences. Automatic methods such as deep learning provide a meta-level feature representation that generalizes well on new domains and languages. Multi-modal methods can combine the abundant audio and video forms of social data with text using multiple kernels. We conclude that the high-dimensionality of n-gram features and temporal nature of sentiments in long product reviews are the major challenges in sentiment mining from text.	187.94500876511293
1070.	This study aimed to examine junior college students' group dialogues on the use of high-level comprehension features in an EFL reading class. The participants were one high-ability group and one low-ability group in terms of discussion proficiency. Eight representative discussions conducted in the students' first language served as the major data source, which were analyzed for discourse features linked to high-level thinking and comprehension, based on the criteria identified by Soter et al. (2008). Interviews and students' reading logs were collected to provide supporting evidence of how the EFL learners undertook their group reading tasks. The results revealed that both focus groups, to some extent, were able to incorporate all discourse features that indicate high-level learning and comprehension of texts without regard to discussion proficiency. The major differences were that the high-ability group had more uptake questions, whereas the low-ability group engaged in longer and more numerous episodes of elaborated explanations and of exploratory talk. That the low-ability group exhibited more talk and indicators of quality discussion than the high-ability group could be possibly explained with the genre of reading materials, personal belief about reading stories, and the use of nonverbal information and of personal connections. Despite the differences, the two groups demonstrated the language of high-level comprehension to "interthink" deeply about the text. The study concludes that through incorporating discourse features linked to high-level comprehension, students could guide one another toward deeper engagement with the text in group reading.	187.9449655654845
1071.	Over the past few decades, advanced technologies have increased the number of vehicles, including cars and motorcycles. Because of the large increase of vehicles, the traffic flow becomes more complex and the traffic accidents increase as rapidly. To decrease the number of traffic accidents, a number of studies has been made for how to manage the traffic flow. Especially for motorcycles, in this paper, we propose a method that counts the motorcycles by Convolutional Neural Network (CNN). To reveal the effectiveness of the proposed method, a set of experiments were conducted and the experimental results show the proposed method can bring out a good performance that provides a good support for traffic management systems.	187.9448722479985
1072.	The field of Urban design considers how people utilize public open spaces (POS) when designing spaces such as parks, plazas, and streets. Current methods of observing public space use rely on visual observation which consumes much time and effort to detect users' physical activities in large POS; these methods also only provide qualitative observations of how patrons behave in these areas. Active sensors, such as wearable sensors and smart phones with GPS tracking capabilities, have high costs and cannot sense all users in a POS (namely, such sensors are "blind to" those without wearable sensors). Therefore, it is appealing to make use of video data from pre-installed surveillance cameras in POS to extract POS use information from video using computer vision methods. This paper proposes a sensing framework based on computer vision to measure human activities in POS. As part of the study, an extensively labeled datset of people and their activities in POS (termed OPOS) is used to train detectors. A case study of the proposed framework is presented using security camera feeds from a green-way at the Detroit Riverfront. The AP(0.50) results of the trained detector are 96.3% for pedestrian detection and 96.5% for cyclist detection, respectively. These results show such an approach can reliably track patrons in parks to ascertain their behavior and to inform future POS improvements.	187.9448569553475
1073.	Background The treatment of complex diseases by taking multiple drugs becomes increasingly popular. However, drug-drug interactions (DDIs) may give rise to the risk of unanticipated adverse effects and even unknown toxicity. DDI detection in the wet lab is expensive and time-consuming. Thus, it is highly desired to develop the computational methods for predicting DDIs. Generally, most of the existing computational methods predict DDIs by extracting the chemical and biological features of drugs from diverse drug-related properties, however some drug properties are costly to obtain and not available in many cases. Results In this work, we presented a novel method (namely DPDDI) to predict DDIs by extracting the network structure features of drugs from DDI network with graph convolution network (GCN), and the deep neural network (DNN) model as a predictor. GCN learns the low-dimensional feature representations of drugs by capturing the topological relationship of drugs in DDI network. DNN predictor concatenates the latent feature vectors of any two drugs as the feature vector of the corresponding drug pairs to train a DNN for predicting the potential drug-drug interactions. Experiment results show that, the newly proposed DPDDI method outperforms four other state-of-the-art methods; the GCN-derived latent features include more DDI information than other features derived from chemical, biological or anatomical properties of drugs; and the concatenation feature aggregation operator is better than two other feature aggregation operators (i.e., inner product and summation). The results in case studies confirm that DPDDI achieves reasonable performance in predicting new DDIs. Conclusion We proposed an effective and robust method DPDDI to predict the potential DDIs by utilizing the DDI network information without considering the drug properties (i.e., drug chemical and biological properties). The method should also be useful in other DDI-related scenarios, such as the detection of unexpected side effects, and the guidance of drug combination.	187.94475550638535
1074.	Fault detection and diagnosis (FDD) is one of the key technologies to ensure the safe operation of chemical processes. With the widespread application of automation technology in chemical plants and the era of big data, data-based methods have become a hot research topic in the field of fault diagnosis. How to effectively extract the fault characteristics from the data and determine the cause of the fault is the key to help the operator deal with the abnormal conditions. Stack auto-encoder is a deep learning model with strong feature extraction and generalization capabilities. This paper proposes a SAE-based chemical process fault diagnosis model and applies it to Tennessee Eastman process. The performance of the SAE-based model is illustrated by comparison with the results of other methods.	187.94475267884002
1075.	The article presents a review of 34 studies conducted from 1995 to 2017 focusing on face-to-face promotive interaction (FtFPI) factors that may lead to successful cooperative learning (CL) in small groups, as guided by the following research question: ?Which FtFPI factors lead to successful CL in small groups?? A manual and citation database search were used to find relevant studies. The findings indicate that students? interpersonal behavior, their experiences and active participation in the CL process, communication and support to each other, and teachers? influence on promoting students? interaction leading to successful CL in small groups. Moreover, these factors may lead to students? deep learning. However, the review suggests that systematic preparations must be made by both teachers and students if the CL is to be successful. Thus, more empirical research is needed to understand the complexity of students? FtFPI and to investigate the development of FtFPI based on students? and teachers? experiences in small CL groups.	187.94468855473215
1076.	Designing new experiments in physics is a challenge for humans; therefore, computers have become a tool to expand scientists' capabilities and to provide creative solutions. This Perspective article examines computer-inspired designs in quantum physics that led to laboratory experiments and inspired new scientific insights. The design of new devices and experiments has historically relied on the intuition of human experts. Now, design inspirations from computers are increasingly augmenting the capability of scientists. We briefly overview different fields of physics that rely on computer-inspired designs using a variety of computational approaches based on topological optimization, evolutionary strategies, deep learning, reinforcement learning or automated reasoning. Then we focus specifically on quantum physics. When designing new quantum experiments, there are two challenges: quantum phenomena are unintuitive, and the number of possible configurations of quantum experiments explodes exponentially. These challenges can be overcome by using computer-designed quantum experiments. We focus on the most mature and practical approaches to find new complex quantum experiments, which have subsequently been realized in the lab. These methods rely on a highly efficient topological search, which can inspire new scientific ideas. We review several extensions and alternatives based on various optimization and machine learning techniques. Finally, we discuss what can be learned from the different approaches and outline several future directions.	187.9445354589496
1077.	PURPOSE: Recently, brain tumor segmentation has made important progress. How-ever, the quality of manual labels plays an important role in the performance, while in practice, it could vary greatly and in turn could substantially mislead the learning process and decrease the accuracy. We need to design a mechanism to combine label correction and sample reweighting to improve the effectiveness of brain tumor segmentation. METHODS: We propose a novel sample reweighting and label refinement method, and a novel 3D generative adversarial network (GAN) is introduced to combine these two models into an united framework. RESULTS: Extensive experiments on the BraTS19 dataset have demonstrated that our approach obtains competitive results when compared with other state-of-the-art approaches when handling the false labels in brain tumor segmentation. CONCLUSIONS: The 3D GAN-based approach is an effective approach to handle false label masks by simultaneously applying label correction and sample reweighting. Our method is robust to variations in tumor shape and background clutter.	187.9444261839734
1078.	Detecting text located on the torsos of marathon runners and sports players in video is a challenging issue due to poor quality and adverse effects caused by flexible/colorful clothing, and different structures of human bodies or actions. This paper presents a new unified method for tackling the above challenges. The proposed method fuses gradient magnitude and direction coherence of text pixels in a new way for detecting candidate regions. Candidate regions are used for determining the number of temporal frame clusters obtained by K-means clustering on frame differences. This process in turn detects key frames. The proposed method explores Bayesian probability for skin portions using color values at both pixel and component levels of temporal frames, which provides fused images with skin components. Based on skin information, the proposed method then detects faces and torsos by finding structural and spatial coherences between them. We further propose adaptive pixels linking a deep learning model for text detection from torso regions. The proposed method is tested on our own dataset collected from marathon/sports video and three standard datasets, namely, RBNR, MMM and R-ID of marathon images, to evaluate the performance. In addition, the proposed method is also tested on the standard natural scene datasets, namely, CTW1500 and MS-COCO text datasets, to show the objectiveness of the proposed method. A comparative study with the state-of-the-art methods on bib number/text detection of different datasets shows that the proposed method outperforms the existing methods. (C) 2020 Elsevier Ltd. All rights reserved.	187.94440901062327
1079.	The importance of culture is often emphasized for continuous learning and quality improvement within health care organizations. Limited empirical evidence for cultivating a culture that supports continuous learning and quality improvement in health care settings is currently available. The purpose of this report is to characterize the evolution of a large division of physical therapists and occupational therapists in a pediatric hospital setting from 2005 to 2018 to identify key facilitators and barriers for cultivating a culture empowered to engage in continuous learning and improvement. An ethnographic methodology was used including participant observation, document review, and stakeholder interviews to acquire a deep understanding and develop a theoretical model to depict insights gained from the investigation. A variety of individual, social, and structural enablers and motivators emerged as key influences toward a culture empowered to support continuous learning and improvement. Features of the system that helped create sustainable, positive momentum (e.g., systems thinking, leaders with grit, and mindful design) and factors that hindered momentum (e.g., system uncertainty, staff turnover, slow barrier resolution, and competing priorities) were also identified. Individual-level, social-level, and structural-level elements all influenced the culture that emerged over a 12-year period. Several cultural catalysts and deterrents emerged as factors that supported and hindered progress and sustainability of the emergent culture. Cultivating a culture of continuous learning and improvement is possible. Purposeful consideration of the proposed model and identified factors from this report may yield important insights to advance understanding of how to cultivate a culture that facilitates continuous learning and improvement within a health care setting.	187.94440715656606
1080.	In this paper, a deep Q-learning (DQL)-based energy management strategy (EMS) is designed for an electric vehicle. Firstly, the energy management problem is reformulated to satisfy the condition of employing DQL by considering the dynamics of the system. Then, to achieve the minimum of electricity consumption and the maximum of the battery lifetime, the DQL-based EMS is designed to properly split the power demand into two parts: one is supplied by the battery and the other by supercapacitor. In addition, a hyperparameter tuning method, Bayesian optimization (BO), is introduced to optimize the hyperparameter configuration for the DQL-based EMS. Simulations are conducted to validate the improvements brought by BO and the convergence of DQL algorithm equipped with tuned hyperparameters. Simulations are also carried out on both training dataset and the testing dataset to validate the optimality and the adaptability of the DQL-based EMS, where the developed EMS outperforms a previously published rule-based EMS in almost all the cases.	187.94431697229703
1081.	The bruise dating can have important medicolegal implications in family violence and violence against women cases. However, studies show that the medical specialist has 50% accuracy in classifying a bruise by age, mainly due to the variability of the images and the color of the bruise. This research proposes a model, based on deep convolutional neural networks, for bruise dating using only images, by age ranges, ranging from 0-2 days to 17-30 days, and images of healthy skin. A 2140 experimental bruise photograph dataset was constructed, for which a data capture protocol and a preprocessing procedure are proposed. Similarly, 20 classification models were trained with the Inception V3, Resnet50, MobileNet, and MnasNet architectures, where combinations of learning transfer, cross-validation, and data augmentation were used. Numerical experiments show that classification models based on MnasNet have better results, reaching 97.00% precision and sensitivity, and 99.50% specificity, exceeding 40% precision reported in the literature. Also, it was observed that the precision of the model decreases with the age of the bruise.	187.94415623987717
1082.	Shadow detection and shadow removal are fundamental and challenging tasks, requiring an understanding of the global image semantics. This paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner. To achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (RNN) by introducing attention weights when aggregating spatial context features in the RNN. By learning these weights through training, we can recover direction-aware spatial context (DSC) for detecting and removing shadows. This design is developed into the DSC module and embedded in a convolutional neural network (CNN) to learn the DSC features at different levels. Moreover, we design a weighted cross entropy loss to make effective the training for shadow detection and further adopt the network for shadow removal by using a euclidean loss function and formulating a color transfer function to address the color and luminosity inconsistencies in the training pairs. We employed two shadow detection benchmark datasets and two shadow removal benchmark datasets, and performed various experiments to evaluate our method. Experimental results show that our method performs favorably against the state-of-the-art methods for both shadow detection and shadow removal.	187.94413690150157
1083.	This study proposes a convolutional neural network model trained from scratch to classify and detect the presence of pneumonia from a collection of chest X-ray image samples. Unlike other methods that rely solely on transfer learning approaches or traditional handcrafted techniques to achieve a remarkable classification performance, we constructed a convolutional neural network model from scratch to extract features from a given chest X-ray image and classify it to determine if a person is infected with pneumonia. This model could help mitigate the reliability and interpretability challenges often faced when dealing with medical imagery. Unlike other deep learning classification tasks with sufficient image repository, it is difficult to obtain a large amount of pneumonia dataset for this classification task; therefore, we deployed several data augmentation algorithms to improve the validation and classification accuracy of the CNN model and achieved remarkable validation accuracy.	187.94407417334133
1084.	Compromised computer systems on the Internet, namely botnets, receive commands and share information with their central malicious systems while executing frequent and common network activities. Former botnet detection methods such as blacklists and botnet's signature matching cannot timely and reliably discover evolving botnet variants. Analysis of botnet network communication flows can be used to discover behavior of botnets toward detection. A rich dataset constituted by both botnet and normal network traffic flow summaries can be used for training and testing purposes. Furthermore, neural networks along emerging parallelization computing tools and processors may improve classification statistical metric results in an efficient manner. A neural network built by a higher number of layers and its architecture enhances classification accuracy. In this paper, we present a combination of convolutional and recurrent neural network to identify botnets. To validate the effectiveness of the proposed method, we test and benchmark the proposed method with two publicly available datasets, which are CTU-13 and ISOT, involving both botnet and normal data traffic. We evaluate statistical metric results by tuning the neural network architecture and compare the results with respect to baseline classifiers. Our experiment results show that the presented deep network learning-based botnet detection method is reached at 99.3% level in accuracy and 99.1% in F-measure, respectively.	187.9440621620342
1085.	The proliferation of Internet of things (IoT) devices has lured hackers to launch attacks. Therefore, anomalies in IoT traffic must be detected to mitigate these attacks and protect services rendered by smart devices. The lacuna in the existing anomaly detection techniques is the nonscalable nature of anomaly detection systems, resulting in the mishandling of large-scale data generated from IoT devices. The issue of scalability is addressed and an anomaly detection framework in a fog environment is proposed herein using vector convolutional deep learning (VCDL) approach. The anomaly detection system could be scalable if the traffic can be distributed to the nodes in the fog layer for processing. This is effectively captured in the VCDL approach in which the training of IoT traffic is distributed and computations are performed in the fog nodes. The parameters required for training are shared by the master node in the fog layer. Further, the proposed anomaly detection algorithm classifies IoT traffic as either normal or attack and then passes it to the cloud for attack mitigation. Experiments were conducted on UNSW's Bot-IoT dataset and the results indicate that the proposed distributed deep learning approach can efficiently handle scalable data compared with the existing centralized deep learning approaches. Experimental results show that the proposed approach is significantly better in terms of accuracy, precision, and recall compared with the state-of-the-art anomaly detection systems. (C) 2020 Elsevier B.V. All rights reserved.	187.94405632523245
1086.	ST Math is a visual instructional game-based program that builds a deep conceptual understanding of mathematics through rigorous learning and creative problem solving. It is widely adopted in many elementary schools in the US. In this paper, we describe the exploratory data analysis we conducted on system log data of kindergarten students to discover patterns in students' interaction with the system, and to examine productivity and engagement of students with different profiles. The findings informed the implementation of the program in schools as well as improvement of individual games in the program to render more effective student learning.	187.94402895788681
1087.	Cloud detection, which is defined as the pixel-wise binary classification, is significant in satellite imagery processing. In current remote sensing literature, cloud detection methods are linked to the relationships of imagery bands or based on simple image feature analysis. These methods, which only focus on low-level features, are not robust enough on the images with difficult land covers, for clouds share similar image features such as color and texture with the land covers. To solve the problem, in this paper, we propose a novel deep learning method for cloud detection on satellite imagery by utilizing multilevel image features with two major processes. The first process is to obtain the cloud probability map from the designed deep convolutional neural network, which concatenates deep neural network features from low-level to high-level. The second part of the method is to get refined cloud masks through a composite image filter technique, where the specific filter captures multilevel features of cloud structures and the surroundings of the input imagery. In the experiments, the proposed method achieves 85.38% intersection over union of cloud in the testing set which contains 100 Gaofen-1 wide field of view images and obtains satisfactory visual cloud masks, especially for those hard images. The experimental results show that utilizing multilevel features by the combination of the network with feature concatenation and the particular filter tackles the cloud detection problem with improved cloud masks.	187.94399779905902
1088.	The rather impressive extension library of medical image-processing platform 3D Slicer lacks a wide range of machine-learning toolboxes. The authors have developed such a toolbox that incorporates commonly used machine-learning libraries. The extension uses a simple graphical user interface that allows the user to preprocess data, train a classifier, and use that classifier in common medical image-classification tasks, such as tumor staging or various anatomical segmentations without a deeper knowledge of the inner workings of the classifiers. A series of experiments were carried out to showcase the capabilities of the extension and quantify the symmetry between the physical characteristics of pathological tissues and the parameters of a classifying model. These experiments also include an analysis of the impact of training vector size and feature selection on the sensitivity and specificity of all included classifiers. The results indicate that training vector size can be minimized for all classifiers. Using the data from the Brain Tumor Segmentation Challenge, Random Forest appears to have the widest range of parameters that produce sufficiently accurate segmentations, while optimal Support Vector Machines' training parameters are concentrated in a narrow feature space.	187.9438912914759
1089.	Kinship verification is a very important technique in many real-world applications, e.g., personal album organization, missing person investigation and forensic analysis. However, it is extremely difficult to verify a family pair with generation gap, e.g., father and son, since there exist both age gap and identity variation. It is essential to well fight off such challenges to achieve promising kinship verification performance. To this end, we propose a towards-young cross-generation model for effective kinship verification by mitigating both age and identity divergences. Specifically, we explore a conditional generative model to bring in an intermediate domain to bridge each pair. Thus, we could extract more effective features through deep architectures with a newly-designed Sparse Discriminative Metric Loss (SDM-Loss), which is exploited to involve the positive and negative information. Experimental results on kinship benchmark demonstrate the superiority of our proposed model by comparing with the state-of-the-art kinship verification methods.	187.94388316145546
1090.	Various methods have been proposed for collecting vibrotactile information. However, the collection procedure requires manual scanning of texture, collection of vast information may be difficult. Owing to the fast progress of machine learning technologies, even with little information, there is a possibility to generate further virtual data from existing collected data by using Generative Advisory Network (GAN). In this paper, we proposed a generation model of vibrotactile information by Deep Convolutional GAN (DCGAN) from the collected acceleration data. We generated various vibrotactile information by using the proposed DCGAN, and compared the tactile stimulation based on the generated data with the actual texture.	187.94382900255883
1091.	Fingerprint matching, spoof mitigation and liveness detection are the trendiest biometric techniques, mostly because of their stability through life, uniqueness and their least risk of invasion. In recent decade, several techniques are presented to address these challenges over well-known data-sets. This study provides a comprehensive review on the fingerprint algorithms and techniques which have been published in the last few decades. It divides the research on fingerprint into nine different approaches including feature based, fuzzy logic, holistic, image enhancement, latent, conventional machine learning, deep learning, template matching and miscellaneous techniques. Among these, deep learning approach has outperformed other approaches and gained significant attention for future research. By reviewing fingerprint literature, it is historically divided into four eras based on 106 referred papers and their cumulative citations.	187.9438001567713
1092.	Two approaches are proposed for cross-pose face recognition, one is built on the handcrafted features extracted from the 3D reconstruction of facial components and the other is built on the learned features from a deep convolutional neural network (CNN). As both approaches rely on facial landmarks for alignment across large poses, we propose the Fast Hierarchical Model (FHM) for locating cross-pose facial landmarks in real time. Unlike most 3D approaches that consider holistic faces, the first proposed approach considers 3D facial components. It segments each 2D face in the gallery into components, reconstructs the 3D surface for each component, and recognizes a query face by component features. The core part of the CNN-based approach is a modified VGG network. We study the performance with different settings on the training set, including the synthesized data from 3D reconstruction, the real-life data from an in-the-wild database, and both types of data combined. The two recognition approaches and the FHM are evaluated in extensive experiments and compared with state-of-the-art methods to demonstrate their efficacy.	187.94379950475474
1093.	Due to the limited length and freely constructed sentence structures, it is a difficult classification task for short text classification. In this paper, a short text classification framework based on Siamese CNNs and few-shot learning is proposed. The Siamese CNNs will learn the discriminative text encoding so as to help classifiers distinguish those obscure or informal sentence. The different sentence structures and different descriptions of a topic are viewed as 'prototypes', which will be learned by few-shot learning strategy to improve the classifier's generalization. Our experimental results show that the proposed framework leads to better results in accuracies on twitter classifications and outperforms some popular traditional text classification methods and a few deep network approaches.	187.9437761649026
1094.	A Self-driving car using an end-to-end deep reinforcement learning[1] algorithms trained on lane-keeping task performs well in circuits that don't need decision making but cannot deal with situations like choosing to turn left or right in an upcoming crossroads, deciding when to leave a traffic circle or toward which path/destination to go. In this paper we propose a new Deep Reinforcement Learning architecture that supports external command as high-level input, that we call Steered Deep Reinforcement Learning (SDRL), we apply the SDRL architecture on the Deep Deterministic Policy Gradient algorithm DDPG and use CARLA a High-fidelity realistic driving simulator as a testbed environment to train and experiment the new model, since testing in ground truth turns out to be costly and risky. The Steered DDPG (SDDPG) model performs well on the road/roundabouts and responds correctly to the external commands that allow the driving agent to take the right turns.	187.94377351169047
1095.	Accurate short-term solar irradiance forecasting is crucial for ensuring the optimum utilization of photovoltaic power generation sources. This study addresses this issue by proposing a spatiotemporal correlation model based on deep learning. The proposed model first applies a convolutional neural network (CNN) to extract spatial features from a two-dimensional matrix composed of meteorological parameters associated with a target site and its neighboring sites. Then, a long short-term memory (LSTM) network is applied to extract temporal features from historical solar irradiance time-series data associated with the target site. Finally, the spatiotemporal correlations are merged to predict global horizontal irradiance one hour in advance. The prediction performance and generalization ability of the proposed CNN-LSTM model are evaluated within a whole year, under diverse seasons and sky conditions. Three datasets are involved for case studies, which are collected from 34 locations spread across three different climate zones in Texas, USA. Moreover, the performance of the CNN-LSTM model is compared with those obtained using the CNN, LSTM, and other benchmark models based on five evaluation metrics. The results indicate that the proposed model has advantages over the other models considered and provides a good alternative for short-term solar radiation prediction. (C) 2020 Elsevier Ltd. All rights reserved.	187.9435797335516
1096.	Classification using multimodal data arises in many machine learning applications. It is crucial not only to model cross-modal relationship effectively but also to ensure robustness against loss of part of data or modalities. In this paper, we propose a novel deep learning-based multimodal fusion architecture for classification tasks, which guarantees compatibility with any kind of learning models, deals with cross-modal information carefully, and prevents performance degradation due to partial absence of data. We employ two datasets for multimodal classification tasks, build models based on our architecture and other state-of-the-art models, and analyze their performance on various situations. The results show that our architecture outperforms the other multimodal fusion architectures when some parts of data are not available.	187.94356995593375
1097.	In outdoor low-level vision systems, not only is the resolution of the imaging system important, but rain corrupts the visibility of outdoor scenes and may cause computer vision systems to fail. We present a deep convolutional neural network (CNN) architecture for simultaneously performing single-image super-resolution and rain removal. Instead of learning an end-to-end mapping between the low-resolution rainy images and high-resolution clean images in the original image space, we train our network in the detail space, i.e., the space obtained by high-pass filtering the original image. The proposed CNN has a lightweight structure, yet it outperforms super-resolution and rain removal consecutively by a significantly large margin (>1 dB on average). (C) 2018 SPIE and IS&T	187.9435402850177
1098.	Numerous applications on human faces hinge on depth information. Often, facial stereo matching provides an opportunity to estimate disparity without active projectors. However, existing algorithms are less effective at night due to unclear texture and severe noises in RGB images. In this paper, we address this problem by estimating facial disparity maps from NIR-RGB pairs. We develop a neural network composed of a multispectral transfer network (MSTN) and a disparity estimation network (DEN). MSTN is used to produce a pseudo-NIR image aligned with the RGB view using a spatially weighted sum on the NIR one by a kernel prediction network (KPN). As the pseudo-NIR and the NIR images share the same appearance, the facial disparity map is predicted by the proposed DEN with the same-spectral stereo pair. The whole network can be trained in an end-to-end manner and the experimental results demonstrate that it performs favorably against state-of-the-art algorithms on both synthetic and real data.	187.9433831920361
1099.	An extensive study on the in-loop filter has been proposed for a high efficiency video coding (HEVC) standard to reduce compression artifacts, thus improving coding efficiency. However, in the existing approaches, the in-loop filter is always applied to each single frame, without exploiting the content correlation among multiple frames. In this paper, we propose a multi-frame in-loop filter (MIF) for HEVC, which enhances the visual quality of each encoded frame by leveraging its adjacent frames. Specifically, we first construct a large-scale database containing encoded frames and their corresponding raw frames of a variety of content, which can he used to learn the in-loop filter in HEVC. Furthermore, we find that there usually exist a number of reference frames of higher quality and of similar content for an encoded frame. Accordingly, a reference frame selector (RFS) is designed to identify these frames. Then, a deep neural network for MIF (known as MIF-Net) is developed to enhance the quality of each encoded frame by utilizing the spatial information of this frame and the temporal information of its neighboring higher-quality frames. The MIF-Net is built on the recently developed DenseNet, benefiting from its improved generalization capacity and computational efficiency. In addition, a novel block-adaptive convolutional layer is designed and applied in the MIF-Net, for handling the artifacts influenced by coding tree unit (CTU) structure in HEVC. Extensive experiments show that our MIF approach achieves on average 11.621% saving of the Bjontegaard delta bit-rate (BD-BR) on the standard test set, significantly outperforming the standard in-loop filter in HEVC and other state-of-the-art approaches.	187.94333774283547
1100.	Informative and accurate survival prediction with individualized dynamic risk profiles over time is critical for personalized disease prevention and clinical management. The massive genetic data, such as SNPs from genome-wide association studies (GWAS), together with well-characterized time-to-event phenotypes provide unprecedented opportunities for developing effective survival prediction models. Recent advances in deep learning have made extraordinary achievements in establishing powerful prediction models in the biomedical field. However, the applications of deep learning approaches in survival prediction are limited, especially with utilizing the wealthy GWAS data. Motivated by developing powerful prediction models for the progression of an eye disease, age-related macular degeneration (AMD), we develop and implement a multilayer deep neural network (DNN) survival model to effectively extract features and make accurate and interpretable predictions. Various simulation studies are performed to compare the prediction performance of the DNN survival model with several other machine learning-based survival models. Finally, using the GWAS data from two large-scale randomized clinical trials in AMD with over 7800 observations, we show that the DNN survival model not only outperforms several existing survival prediction models in terms of prediction accuracy (eg, c-index=0.76), but also successfully detects clinically meaningful risk subgroups by effectively learning the complex structures among genetic variants. Moreover, we obtain a subject-specific importance measure for each predictor from the DNN survival model, which provides valuable insights into the personalized early prevention and clinical management for this disease.	187.943296583383
1101.	The design of novel proteins has many applications but remains an attritional process with success in isolated cases. Meanwhile, deep learning technologies have exploded in popularity in recent years and are increasingly applicable to biology due to the rise in available data. We attempt to link protein design and deep learning by using variational autoencoders to generate protein sequences conditioned on desired properties. Potential copper and calcium binding sites are added to non-metal binding proteins without human intervention and compared to a hidden Markov model. In another use case, a grammar of protein structures is developed and used to produce sequences for a novel protein topology. One candidate structure is found to be stable by molecular dynamics simulation. The ability of our model to confine the vast search space of protein sequences and to scale easily has the potential to assist in a variety of protein design tasks.	187.94328875605262
1102.	To enhance the performance of deep auto-encoder (AE) under complex working conditions, a novel deep auto-encoder network method for rolling bearing fault diagnosis is proposed in this paper. First, multiscale analysis is adopted to extract the multiscale features from the raw vibration signals of rolling bearing. Second, the sparse penalty term and contractive penalty term are used simultaneously to regularize the loss function of auto-encoder to enhance the feature learning ability of networks. Finally, the cuckoo search algorithm (CS) is used to find the optimal hyperparameters automatically. The proposed method is applied to the experimental data analysis. The results indicate that the proposed method could more effectively distinguish fault categories and severities of rolling bearings under different working conditions than other methods.	187.94327923540808
1103.	Charge transport in deoxyribonucleic acid (DNA) is of immense interest in biology and molecular electronics. Electronic coupling between the DNA bases is an important parameter describing the efficiency of charge transport in DNA. A reasonable estimation of this electronic coupling requires many expensive first principle calculations. In this article, we present a machine learning (ML) based model to calculate the electronic coupling between the guanine bases of the DNA (in the same strand) of any length, thus avoiding expensive first-principle calculations. The electronic coupling between the bases are evaluated using density functional theory (DFT) calculations with the morphologies derived from fully atomistic molecular dynamics (MD) simulations. A new and simple protocol based on the coarse-grained model of the DNA has been used to extract the feature vectors for the DNA bases. A deep neural network (NN) is trained with the feature vector as input and the DFT-calculated electronic coupling as output. Once well trained, the NN can predict the DFT-calculated electronic coupling of new structures with a mean absolute error (MAE) of 0.02 eV.	187.94323353779572
1104.	Processes including particles, like fermentation, flocculation, precipitation, crystallization etc. are some of the most frequently used operations in the bio-based industries. These processes are today typically monitored using sensors that measure on liquid and gas phase properties. The lack of knowledge of the particles itself has made it difficult to monitor and control these processes. Recent advances in continuous in-situ sensors, that can measure a range of particle properties using advanced image analysis, have now however opened up for implementing novel monitoring and modeling strategies, providing more process insights at a relatively low cost. In this work, an automated platform for particle microscopy imaging is proposed. Furthermore, a model based deep learning framework for predictive monitoring of particles in various bioprocesses using images is suggested, and demonstrated on a case study for crystallization of lactose.	187.9432032663642
1105.	Deep convolutional neural networks (CNNs) have been widely used and achieved state-of-the-art performance in many image or video processing and analysis tasks. In particular, for image super-resolution (SR) processing, previous CNN-based methods have led to significant improvements, when compared with shallow learning-based methods. However, previous CNN-based algorithms with simple direct or skip connections are of poor performance when applied to remote sensing satellite images SR. In this study, a simple but effective CNN framework, namely deep distillation recursive network (DDRN), is presented for video satellite image SR. DDRN includes a group of ultra-dense residual blocks (UDB), a multi-scale purification unit (MSPU), and a reconstruction module. In particular, through the addition of rich interactive links in and between multiple-path units in each UDB, features extracted from multiple parallel convolution layers can be shared effectively. Compared with classical dense-connection-based models, DDRN possesses the following main properties. (1) DDRN contains more linking nodes with the same convolution layers. (2) A distillation and compensation mechanism, which performs feature distillation and compensation in different stages of the network, is also constructed. In particular, the high-frequency components lost during information propagation can be compensated in MSPU. (3) The final SR image can benefit from the feature maps extracted from UDB and the compensated components obtained from MSPU. Experiments on Kaggle Open Source Dataset and Jilin-1 video satellite images illustrate that DDRN outperforms the conventional CNN-based baselines and some state-of-the-art feature extraction approaches.	187.943126906006
1106.	A densely-sampled light field (LF) is highly desirable in various applications. However, it is costly to acquire such data. Although many computational methods have been proposed to reconstruct a densely-sampled LF from a sparsely-sampled one, they still suffer from either low reconstruction quality, low computational efficiency, or the restriction on the regularity of the sampling pattern. To this end, we propose a novel learning-based method, which accepts sparsely-sampled LFs with irregular structures, and produces densely-sampled LFs with arbitrary angular resolution accurately and efficiently. We also propose a simple yet effective method for optimizing the sampling pattern. Our proposed method, an end-to-end trainable network, reconstructs a densely-sampled LF in a coarse-to-fine manner. Specifically, the coarse sub-aperture image (SAI) synthesis module first explores the scene geometry from an unstructured sparsely-sampled LF and leverages it to independently synthesize novel SAIs, in which a confidence-based blending strategy is proposed to fuse the information from different input SAIs, giving an intermediate densely-sampled LF. Then, the efficient LF refinement module learns the angular relationship within the intermediate result to recover the LF parallax structure. Comprehensive experimental evaluations demonstrate the superiority of our method on both real-world and synthetic LF images when compared with state-of-the-art methods.	187.94299880683843
1107.	The coronavirus pandemic and its unprecedented consequences globally has spurred the interest of the artificial intelligence research community. A plethora of published studies have investigated the role of imaging such as chest X-rays and computer tomography in coronavirus disease 2019 (COVID-19) automated diagnosis. Omicronpen repositories of medical imaging data can play a significant role by promoting cooperation among institutes in a world-wide scale. However, they may induce limitations related to variable data quality and intrinsic differences due to the wide variety of scanner vendors and imaging parameters. In this study, a state-of-the-art custom U-Net model is presented with a dice similarity coefficient performance of 99.6% along with a transfer learning VGG-19 based model for COVID-19 versus pneumonia differentiation exhibiting an area under curve of 96.1%. The above was significantly improved over the baseline model trained with no segmentation in selected tomographic slices of the same dataset. The presented study highlights the importance of a robust preprocessing protocol for image analysis within a heterogeneous imaging dataset and assesses the potential diagnostic value of the presented COVID-19 model by comparing its performance to the state of the art.	187.94298988365995
1108.	Hyperspectral image (HSI) classification remains a challenging problem due to unique characteristics of HSI data (such as numerous bands and strong correlations in the spectral and spatial domains) and small sample size. To address such concerns, we propose a novel spectral-spatial feature extraction method for HSI classification by employing graph embedding and deep learning (DL) models. Since the conventional graph cannot capture the complex manifold relationship of HSI data, and there exist the observations of within-class variation as well as the similarity between different classes in the spectral domain, we construct the supervised within-class/between-class hypergraph (SWBH) to extract the spectral features ofHSI. Since it is difficult for DL models to learn representative features for HSI data when the labeled training samples are limited, we propose the random zero settings to newly generate a large amount of labeled HSI samples for the training of convolutional neural network (CNN). The designed sample expanded CNN (SECNN) is used to extract the HSI spatial features. Thus, the spectral-spatial features of HSI can be learned by integrating the features extracted from SWBH and SECNN, respectively. Experiments on three real HSI datasets demonstrate higher classification accuracy of the proposed SWBH-SECNN method.	187.94284845887523
1109.	Many aesthetic models in multimedia and computer vision suffer from two shortcomings: 1) the low descriptiveness and interpretability1 of the hand-crafted aesthetic criteria (i.e., fail to indicate region-level aesthetics) and 2) the difficulty of engineering aesthetic features adaptively and automatically toward different image sets. To remedy these problems, we develop a deep architecture to learn aesthetically relevant visual attributes from Flickr, 2 which are localized by multiple textual attributes in a weakly supervised setting. More specifically, using a bag of-words representation of the frequent Flickr image tags, a sparsity-constrained subspace algorithm discovers a compact set of textual attributes (i.e., each textual attribute is a sparse and linear representation of those frequent image tags) for each Flickr image. Then, a weakly supervised learning algorithm projects the textual attributes at image-level to the highly-responsive image patches. These patches indicate where humans look at appealing regions with respect to each textual attribute, which are employed to learn the visual attributes. Psychological and anatomical studies have demonstrated that humans perceive visual concepts in a hierarchical way. Therefore, we normalize these patches and further feed them into a five-layer convolutional neural network to mimic the hierarchy of human perceiving the visual attributes. We apply the learned deep features onto applications like image retargeting, aesthetics ranking, and retrieval. Both subjective and objective experimental results thoroughly demonstrate the superiority of our approach.	187.94281706782698
1110.	Exchange rate movements can significantly impact not only foreign trade, capital flows, and asset portfolio management, but also real economic activity. Therefore, the forecast of exchange rates has always been of great interest among academics, economic agents, and institutions. However, exchange rate series are essentially dynamic and nonlinear in nature and thus, forecasting exchange rates is a difficult task. On the other hand, deep learning models in solving time series forecasting tasks have been proposed in the last half-decade. But the number of formal comparative study in terms of exchange rate forecasting with deep learning models is quite limited. For this purpose, this study applies ten different models (Random Walk, Autoregressive Moving Average, Threshold Autoregression, Autoregressive Fractionally Integrated Moving Average, Support Vector Regression, Multilayer Perceptron, Recurrent Neural Network, Long Short Term Memory, Gated Recurrent Unit and Autoregressive Moving Average-Long Short Term Memory Hybrid Models) and two forecasting modes (recursive and rolling window) to predict three major exchange rate returnsnamely, the Canadian dollar, Australian dollar and British pound against the US Dollar in monthly terms. To evaluate the forecasting performances of the models, we used Model Confidence Set procedure as an advanced test. According to our results, the proposed hybrid model produced the best out-of-sample forecast performance in all samples, without exception.	187.94281343619969
1111.	MR brain tumor classification is one of the extensively utilized approaches in medical prognosis. However, analyzing and processing MR brain images is still quite a task for radiologists. To encounter this problem, the evaluation of existing canonical techniques has already been done. There are numeral MR brain tumor classification approaches that are being used for medical diagnosis. In this paper, we have developed an automated computer-aided network for diagnosis of MR brain tumor class, i.e., HGG and LGG. We have proffered a Gabor-modulated convolutional filter-based classifier for brain tumor classification. The inclusion of Gabor filter dynamics endows the competency to deal with spatial and orientational transformations. This mere modification (modulation) of conventional convolutional filters by Gabor filters empowers the proposed architecture to learn relatively smaller feature maps and thereby, decreasing network parameter requirement. We have introduced some skip connections to our modulated CNN architecture without introducing an extra network parameter. Pre-trained networks, i.e., Alex-Net, Google-Net (Inception V1), Res-Net and VGG 19 have been considered for performance evaluation of our proposed Gabor-modulated CNN. Additionally, some popular machine learning classification techniques have also been considered for comparative analysis. Experimental findings demonstrate that our proposed network has limited network parameters to learn; therefore, it is quite easy to train such networks.	187.94259352386155
1112.	Pneumonia is a severe inflammatory condition of the lungs that leads to the formation of pus and other liquids in the air sacs. The disease is reported to affect approximately 450 million people across the world, resulting in 2 million pediatric deaths every year. Chest X-ray (CXR) analysis is the most frequently performed radiographic examination for diagnosing the disease. Unlike pneumonia in adults, pediatric pneumonia is poorly studied. Computer-aided diagnostic (CADx) tools aim to improve disease diagnosis and supplement decision making while simultaneously bridging the gap in effective radiological interpretations during mobile field screening. These tools make use of handcrafted and/or convolutional neural networks (CNN) extracted image features for visual recognition. However, CNNs are perceived as black boxes since their performance lack explanations and poorly understood. The lack of transparency in the learned behavior of CNNs is a serious bottleneck in medical screening/diagnosis since poorly interpreted model behavior could unfavorably impact decision-making. Visualization tools are proposed to interpret and explain model predictions. In this study, we highlight the advantages of visualizing and explaining the activations and predictions of CNNs applied to the challenge of pneumonia detection in pediatric chest radiographs. We evaluate and statistically validate the models' performance to reduce bias, overfitting, and generalization errors.	187.94253028547487
1113.	We present a model-independent determination of the nuclear parton distribution functions (nPDFs) using machine learning methods and Monte Carlo techniques based on the NNPDF framework. The neutral-current deep-inelastic nuclear structure functions used in our previous analysis, nNNPDFLO, are complemented by inclusive and charm-tagged cross-sections from charged-current scattering. Furthermore, we include all available measurements of W and Z leptonic rapidity distributions in proton-lead collisions from ATLAS and CMS at A root s = 5.02 TeV and 8.16 TeV. The resulting nPDF determination, nNNPDF2.0, achieves a good description of all datasets. In addition to quantifying the nuclear modifications affecting individual quarks and antiquarks, we examine the implications for strangeness, assess the role that the momentum and valence sum rules play in nPDF extractions, and present predictions for representative phenomenological applications. Our results, made available via the LHAPDF library, highlight the potential of high-energy collider measurements to probe nuclear dynamics in a robust manner.	187.94240363865214
1114.	Building maps have a plethora of applications in government, industry and academia. In most cases, large scale maps can be retrieved from OpenStreetMap vector data. However, for certain rapidly changing built and semi-built environments, corresponding maps are not as accurate and contain label noise such as missing, incorrectly present, shifted labels, etc.; mainly because buildings in those regions are constantly being constructed, deconstructed, replaced and altered. One such case is extant in the Rohingya camps of southeastern border region of Bangladesh. Mass refugee influx in late 2017 and following population growth has necessitated the construction of buildings and expansion of camps. Consequently, reliable methods are necessary for detecting and documenting camp buildings. Ultra-high-resolution drone images of Rohingya camps are semantically segmented through fully convolutional U-Net deep learning systems for generating accurate building maps from noisy labels. A wide variety of noises are prevalent in the labels. Deep learning systems provide less noisy predictions compared to the classification tool in the most widely used Geographic Information System (GIS) software, ArcGIS. Data augmentation and regularization allows reliable learning, even in the presence of label noise. During testing, calculation of numeric performance metrics against noisy labels can grossly underestimate true skill and performance of the model. A subset of 22 million pixels of the testing data is relabelled by hand to obtain noise-free labels. Testing our generated maps against noisy and noise-free labels confirms that true performance is higher than otherwise indicated by freely available building maps. Empirical results reveal that utilized pipeline is able to learn from noisy data and produce labels which are more accurate and less noisy. Labels generated by our best performing system provide Intersection-over-Union (IoU) gain of 17.6% and Dice score gain of 13.6% over freely available labels from OpenStreetMap. Finally, spatio-temporal building maps are generated to portray the applicability of this research.	187.942333405177
1115.	The high mortality rate associated with brain tumors requires early detection in the early stages to treat and reduce mortality. Due to the complexity of brain tissue, manual diagnosis of the brain and tumor tissues is very time-consuming and operator dependent. Furthermore, there is a need for experts who can review the images to detect these effects, rendering traditional methods inefficient in their presence. Therefore, the use of automated procedures for the careful examination of tumors can prove useful. In this study, a new metaheuristic-based system is presented for the early detection of brain tumors. The proposed method implements three main steps, namely tumor segmentation, feature extraction, and classification based on a deep belief network. An improved version of the seagull optimization algorithm is adopted for optimal selection of the features and classification of the images. The simulation results of the proposed method are compared with a few existing methods. The final results demonstrate that the proposed method exhibits superior performance in terms of the CDR, FAR, and FRR indices compared with the other methods.	187.94226682525567
1116.	In recent years, the Ministry of Land, Infrastructure, and Transport of the Republic of Korea has been developing two land observation satellites, KAS500-1 and KAS500-2, to rapidly observe the territory of South Korea and maximize the utilization of satellite images. Essential data, such as high-quality satellite images and ground control points, must be quickly provided to users, to ensure the successful utilization of the land observation satellite images. Furthermore, the users should be able to easily use application technologies, such as land use (LU) classification and spatial feature extraction, which are essential for utilizing satellite images. Object-based methods are mainly used for extracting spatial features from submeter-grade high-resolution satellite images with a ground sample distance (GSD) of 0.5 m. In recent years, advances in artificial intelligence (AI) have led to an increase in the use of deep learning. Herein, an object-based spatial feature extraction software tool based on open-source software and a deep learning-based spatial feature extraction module are developed to successfully utilize the data from land observation satellites. Images from the KOMPSAT-3A satellite, which have specifications similar to those of the KAS500 satellite images, were used to extract road features, and a quality analysis of the two methods was performed. For the quality analysis, the object-based spatial feature extraction software developed in this study, a commercial software product, and the deep learning-based spatial extraction module were each used to extract road features, and the extracted road features were analyzed. The results showed that extraction of road features using the commercial software showed 84.1% accuracy and 54.0% recall, whereas that using the software developed in this study using an open-source software product showed 83.9% accuracy and 50.2% recall. Thus, the software developed in this study and the commercial software can extract spatial features at similar levels of accuracy and recall. Road features were extracted using the module based on deep learning with 88.6% accuracy and 29.7% recall.	187.94226375772854
1117.	A virtual machine with a conventional offloading scheme transmits and receives all context information to maintain program consistency during communication between local environments and the cloud server environment. Most overhead costs incurred during offloading are proportional to the size of the context information transmitted over the network. Therefore, the existing context information synchronization structure transmits context information that is not required for job execution when offloading, which increases the overhead costs of transmitting context information in low-performance Internet-of-Things (IoT) devices. In addition, the optimal offloading point should be determined by checking the server's CPU usage and network quality. In this study, we propose a context management method and estimation method for CPU load using a hybrid deep neural network on a cloud-based offloading service that extracts contexts that require synchronization through static profiling and estimation. The proposed adaptive offloading method reduces network communication overheads and determines the optimal offloading time for low-computing-powered IoT devices and variable server performance. Using experiments, we verify that the proposed learning-based prediction method effectively estimates the CPU load model for IoT devices and can adaptively apply offloading according to the load of the server.	187.94224918583643
1118.	(1) Background: Evidence-based policymaking requires data about the local population's socioeconomic status (SES) at detailed geographical level, however, such information is often not available, or is too expensive to acquire. Researchers have proposed solutions to estimate SES indicators by analyzing Google Street View images, however, these methods are also resource-intensive, since they require large volumes of manually labeled training data. (2) Methods: We propose a methodology for automatically computing surrogate variables of SES indicators using street images of parked cars and deep multiple instance learning. Our approach does not require any manually created labels, apart from data already available by statistical authorities, while the entire pipeline for image acquisition, parked car detection, car classification, and surrogate variable computation is fully automated. The proposed surrogate variables are then used in linear regression models to estimate the target SES indicators. (3) Results: We implement and evaluate a model based on the proposed surrogate variable at 30 municipalities of varying SES in Greece. Our model has R-2 = 0.76 and a correlation coefficient of 0.874 with the true unemployment rate, while it achieves a mean absolute percentage error of 0.089 and mean absolute error of 1.87 on a held-out test set. Similar results are also obtained for other socioeconomic indicators, related to education level and occupational prestige. (4) Conclusions: The proposed methodology can be used to estimate SES indicators at the local level automatically, using images of parked cars detected via Google Street View, without the need for any manual labeling effort.	187.94214021109624
1119.	While governments, researchers, and NGOs are exploring ways to leverage big data sources for sustainable development, household surveys are still a critical source of information for dozens of the 232 indicators for the Sustainable Development Goals (SDGs) in low- and middle-income countries (LMICs). Though some countries' statistical agencies maintain databases of persons or households for sampling, conducting household surveys in LMICs is complicated due to incomplete, outdated, or inaccurate sampling frames. As a means to develop or update household listings in LMICs, this paper explores the use of machine learning models to detect and enumerate building structures directly from satellite imagery in the Kaduna state of Nigeria. Specifically, an object detection model was used to identify and locate buildings in satellite images. In the test set, the model attained a mean average precision (mAP) of 0.48 for detecting structures, with relatively higher values in areas with lower building density (mAP = 0.65). Furthermore, when model predictions were compared against recent household listings from fieldwork in Nigeria, the predictions showed high correlation with household coverage (Pearson = 0.70; Spearman = 0.81). With the need to produce comparable, scalable SDG indicators, this case study explores the feasibility and challenges of using object detection models to help develop timely enumerated household lists in LMICs.	187.9420828822149
1120.	The computational time of HEVC encoder is increased mainly because of the hierarchical quad-tree-based structure, recursive coding units, and the exhaustive prediction search up to 35 modes. These advances improve the coding efficiency, but result in a very high computational complexity. Furthermore, selecting the optimal modes among all prediction modes is necessary for subsequent rate-distortion optimization process. Therefore, we propose a convolution neural network-based algorithm which learns the region-wise image features and performs a classification job. These classification results are later used in the encoder downstream systems for finding the optimal coding units in each of the tree blocks, and subsequently reduce the number of prediction modes. The experimental results show that our proposed learning-based algorithm reduces the encoder time saving up to 66.89% with a minimal Bjontegaard delta bit rate (BD-BR) loss of 1.31% over the state-of-the-art machine learning approaches. Furthermore, our method also reduces the mode selection by 45.83% with respect to the HEVC baseline.	187.9420718036516
1121.	The global incidence and mortality rate of colorectal cancer remains high. Colonoscopy is regarded as the gold standard examination for detecting and eradicating neoplastic lesion. However, there are some uncertainties in colonoscopy practice that are related to limitations in human performance. First, approximately one-fourth of colorectal neoplasms are missed on a single colonoscopy. Second, it is still difficult for non-experts to perform adequately regarding optical biopsy. Third, recording of some quality indicators (e.g. cecal intubation, bowel preparation, and withdrawal speed) which are related to adenoma detection rate, is sometimes incomplete. With recent improvements in machine learning techniques and advances in computer performance, artificial intelligence-assisted computer-aided diagnosis is being increasingly utilized by endoscopists. In particular, the emergence of deep-learning, data-driven machine learning techniques have made the development of computer-aided systems easier than that of conventional machine learning techniques, the former currently being considered the standard artificial intelligence engine of computer-aided diagnosis by colonoscopy. To date, computer-aided detection systems seem to have improved the rate of detection of neoplasms. Additionally, computer-aided characterization systems may have the potential to improve diagnostic accuracy in real-time clinical practice. Furthermore, some artificial intelligence-assisted systems that aim to improve the quality of colonoscopy have been reported. The implementation of computer-aided system clinical practice may provide additional benefits such as helping in educational poorly performing endoscopists and supporting real-time clinical decision making. In this review, we have focused on computer-aided diagnosis during colonoscopy reported by gastroenterologists and discussed its status, limitations, and future prospects.	187.94205738847364
1122.	Due to the complex biological and physical mechanisms, the correlations between the classification objects of clinical tasks and the medical imaging phenotype are always ambiguous and implied, which makes it difficult to train a powerful diagnostic convolutional neural network (CNN) model efficiently. In this study, we propose a generic multi-task learning (MTL) CNN framework to achieve higher classification accuracy and better generalization. The proposed framework is designed to carry out the major diagnostic task and several auxiliary tasks simultaneously. It encourages the models to learn more beneficial representation following the underlying relation among patients' clinical characteristics, obvious imaging findings and quantitative imaging phenotype. We evaluate our approach on two clinical applications, namely advanced gastric cancer (AGC) serosa invasion diagnosis and discrimination of lung invasive adenocarcinoma manifesting as ground-glass nodule (GGN). Two datasets are utilized, which contain 357 AGC patients' venous phase contrast-enhanced CT volumes and 236 GGN patients' non-contrast CT volumes respectively. Several subjective CT morphology characteristics and common clinical characteristics are collected and used as the auxiliary tasks. To evaluate the generality of our strategy, CNNs with and without natural image-based pre-training are successively incorporated into the framework. The experimental results demonstrate that the proposed MTL CNN framework is able to improve the diagnostic performance significantly (7.4%-12.8% AUC increase and 3.5%-7.9% accuracy increase).	187.94205198257708
1123.	As an important part of the intelligent transportation system (ITS), short-term traffic prediction has become a hot research topic in the field of traffic engineering. In recent years, with the emergence of rich traffic data and the development of deep learning technologies, neural networks have been widely used in short-term traffic forecasting. Among them, the Recurrent Neural Networks (RNN), especially the Long Short-Term Memory network (LSTM) shows the excellent ability of time-series tasks. To improve the prediction accuracy of the LSTM, some research uses the spatial-temporal matrix or Convolutional Neural Network (CNN) to extract the spatial features of the data for the LSTM network to use. In this article, we propose an attention CNN to predict traffic speed. The model uses three-dimensional data matrices constructed by traffic flow, speed, and occupancy. The spatial-temporal features extraction and the attention models are all performed by the convolution unit. Experiments on traffic data at 15-minute intervals show that the proposed algorithm has considerable advantages in predicting tasks compared to other commonly used algorithms, and the proposed algorithm has an improvement effect for cases with missing data. At the same time, by visualizing the weights generated by the attention model, we can see the influence of different spatial-temporal data on the forecasting task.	187.9419962362847
1124.	Visual tracking is challenging as target objects often undergo significant appearance changes caused by deformation, abrupt motion, background clutter and occlusion. In this paper, we propose to exploit the rich hierarchical features of deep convolutional neural networks to improve the accuracy and robustness of visual tracking. Deep neural networks trained on object recognition datasets consist of multiple convolutional layers. These layers encode target appearance with different levels of abstraction. For example, the outputs of the last convolutional layers encode the semantic information of targets and such representations are invariant to significant appearance variations. However, their spatial resolutions are too coarse to precisely localize the target. In contrast, features from earlier convolutional layers provide more precise localization but are less invariant to appearance changes. We interpret the hierarchical features of convolutional layers as a nonlinear counterpart of an image pyramid representation and explicitly exploit these multiple levels of abstraction to represent target objects. Specifically, we learn adaptive correlation filters on the outputs from each convolutional layer to encode the target appearance. We infer the maximum response of each layer to locate targets in a coarse-to-fine manner. To further handle the issues with scale estimation and re-detecting target objects from tracking failures caused by heavy occlusion or out-of-the-view movement, we conservatively learn another correlation filter, that maintains a long-term memory of target appearance, as a discriminative classifier. We apply the classifier to two types of object proposals: (1) proposals with a small step size and tightly around the estimated location for scale estimation; and (2) proposals with large step size and across the whole image for target re-detection. Extensive experimental results on large-scale benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art tracking methods.	187.941958999527
1125.	Background Training in medical ethics aims to educate health care professionals in dealing with daily care ethical issues. To guarantee quality of life and spiritual and emotional support, palliative care professionals have to develop ethical and relational skills. We propose the implementation and evaluation of a specialized training programme in medical ethics dedicated to a hospital-based Palliative Care Unit. Methods This study is a mixed-method before-after evaluation with data triangulation. Results The results highlight that participants developed their ethical knowledge, and a deeper ethical awareness. They also felt more confident and motivated to widely apply ethical reflections and reasonings in their daily practice. Conclusion The participants appreciated the innovative structure of the training, especially regarding the integration of the theoretical-interactive and practical parts. However, they recommended increasing the number of concrete occasions for ethical supervision and practical application of what they learned during the programme. The training programme also has some potential practical implications: the development of advanced ethical skills within a hospital-based PC team may improve the quality of life of the patients and their families. In addition, health care professionals with advanced ethical competencies are able to educate patients and their families towards more active participation in the decision-making process.	187.94193476061935
1126.	Deployment of deep neural networks on hardware platforms is often constrained by limited on-chip memory and computational power. The proposed weight quantization offers the possibility of optimizing weight memory alongside transforming the weights to hardware friendly data types. We apply dynamic fixed point (DFP) and power-of-two (Po2) quantization in conjunction with layer-wise precision scaling to minimize the weight memory. To alleviate accuracy degradation due to precision scaling, we employ quantization-aware fine-tuning. For fine-tuning, quantization-regularization (QR) and weighted QR are introduced to force the trained quantization by adding the distance of the weights to the desired quantization levels as a regularization term to the loss-function. While DFP quantization performs better when allowing different bit-widths for each layer, Po2 quantization in combination with retraining allows higher compression rates for equal bit-width quantization. The techniques are verified on an all-convolutional network. With accuracy degradation of 0.10% points, for DFP with layer-wise precision scaling we achieve compression ratios of 7.34 for CIFAR-10, 4.7 for CIFAR-100, and 9.33 for SVHN dataset.	187.94191423370313
1127.	Accurate segmentation of uterus, uterine fibroids, and spine from MR images is crucial for high intensity focused ultrasound (HIFU) therapy but remains still difficult to achieve because of 1) the large shape and size variations among individuals, 2) the low contrast between adjacent organs and tissues, and 3) the unknown number of uterine fibroids. To tackle this problem, in this paper, we propose a large kernel Encoder-Decoder Network based on a 2D segmentation model. The use of this large kernel can capture multi-scale contexts by enlarging the valid receptive field. In addition, a deep multiple atrous convolution block is also employed to enlarge the receptive field and extract denser feature maps. Our approach is compared to both conventional and other deep learning methods and the experimental results conducted on a large dataset show its effectiveness.	187.94180480600735
1128.	Hyperspectral image (HSI) sharpening, which aims at fusing an observable low spatial resolution (LR) HSI (LR-HSI) with a high spatial resolution (HR) multispectral image (HR-MSI) of the same scene to acquire an HR-HSI, has recently attracted much attention. Most of the recent HSI sharpening approaches are based on image priors modeling, which are usually sensitive to the parameters selection and time-consuming. This paper presents a deep HSI sharpening method (named DHSIS) for the fusion of an LR-HSI with an HR-MSI, which directly learns the image priors via deep convolutional neural network-based residual learning. The DHSIS method incorporates the learned deep priors into the LR-HSI and HR-MSI fusion framework. Specifically, we first initialize the HR-HSI from the fusion framework via solving a Sylvester equation. Then, we map the initialized HR-HSI to the reference HR-HSI via deep residual learning to learn the image priors. Finally, the learned image priors are returned to the fusion framework to reconstruct the final HR-HSI. Experimental results demonstrate the superiority of the DHSIS approach over existing state-of-the-art HSI sharpening approaches in terms of reconstruction accuracy and running time.	187.9417623325582
1129.	Security of applications running on remote devices has become an essential need of enterprises. For this purpose, several software-based solutions have been proposed. However, it has been observed that software solutions are vulnerable to several kinds of attacks. Moreover, they cannot protect and monitor all parts of the system. To overcome this problem, researchers have proposed to monitor a target system from an isolated hardware and store system's sensitive information in its tamper-proof memory locations. To realize such a solution, Trusted Computing Group (TCG) has proposed the specifications of a co-processor called Trusted Platform Module which is widely available in commodity hardware. Integrity Measurement Architecture is one of the well-known static techniques that brings TCG's attestation from kernel to the application level. However, this method cannot measure runtime behavior of applications, which is necessary to detect runtime attacks such as buffer overflow and return-oriented programming. In this paper, we have extended the base work which aims to detect runtime vulnerabilities. Current high-level-based attestation protocol has been extended for dynamic behavior collection and verification, and the dynamic behavior is verified via several machine learning algorithms. Our results justify the use of this approach and show that a high rate detection was achieved for datasets of real-world vulnerabilities in the popular Firefox browser.	187.94168472696313
1130.	Face recognition aims to establish the identity of a person based on facial characteristics. On the other hand, age group estimation is the automatic calculation of an individual's age range based on facial features. Recognizing age-separated face images is still a challenging research problem due to complex aging processes involving different types of facial tissues, skin, fat, muscles, and bones. Certain holistic and local facial features are used to recognize age-separated face images. However, most of the existing methods recognize face images without incorporating the knowledge learned from age group estimation. In this paper, we propose an age-assisted face recognition approach to handle aging variations. Inspired by the observation that facial asymmetry is an age-dependent intrinsic facial feature, we first use asymmetric facial dimensions to estimate the age group of a given face image. Deeply learned asymmetric facial features are then extracted for face recognition using a deep convolutional neural network (dCNN). Finally, we integrate the knowledge learned from the age group estimation into the face recognition algorithm using the same dCNN. This integration results in a significant improvement in the overall performance compared to using the face recognition algorithm alone. The experimental results on two large facial aging datasets, the MORPH and FERET sets, show that the proposed age group estimation based on the face recognition approach yields superior performance compared to some existing state-of-the-art methods.	187.9416819362227
1131.	BACKGROUND AND OBJECTIVE: Virus identification in electron microscopy (EM) images is considered as one of the front-line method in pathogen diagnosis and re-emerging infectious agents. However, the existing methods either focused on the detection of a single virus or required large amounts of manual labeling work to segment virus. In this work, we focus on the task of virus classification and propose an effective and simple method to identify different viruses. METHODS: We put forward a residual mixed attention network (RMAN) for virus classification. The proposed network uses channel attention, bottom-up and top-down attention, and incorporates a residual architecture in an end-to-end training manner, which is suitable for dealing with EM virus images and reducing the burden of manual annotation. RESULTS: We validate the proposed network through extensive experiments on a transmission electron microscopy virus image dataset. The top-1 error rate of our RMAN on 12 virus classes is 4.285%, which surpasses that of state-of-the-art networks and even human experts. In addition, the ablation study and the visualization of class activation mapping (CAM) further demonstrate the effectiveness of our method. CONCLUSIONS: The proposed automated method contributes to the development of medical virology, which provides virologists with a high-accuracy approach to recognize viruses as well as assist in the diagnosis of viruses.	187.94161386479323
1132.	Barrett's esophagus figured a swift rise in the number of cases in the past years. Although traditional diagnosis methods offered a vital role in early-stage treatment, they are generally time- and resource-consuming. In this context, computer-aided approaches for automatic diagnosis emerged in the literature since early detection is intrinsically related to remission probabilities. However, they still suffer from drawbacks because of the lack of available data for machine learning purposes, thus implying reduced recognition rates. This work introduces Generative Adversarial Networks to generate high-quality endoscopic images, thereby identifying Barrett's esophagus and adenocarcinoma more precisely. Further, Convolution Neural Networks are used for feature extraction and classification purposes. The proposed approach is validated over two datasets of endoscopic images, with the experiments conducted over the full and patch-split images. The application of Deep Convolutional Generative Adversarial Networks for the data augmentation step and LeNet-5 and AlexNet for the classification step allowed us to validate the proposed methodology over an extensive set of datasets (based on original and augmented sets), reaching results of 90% of accuracy for the patch-based approach and 85% for the image-based approach. Both results are based on augmented datasets and are statistically different from the ones obtained in the original datasets of the same kind. Moreover, the impact of data augmentation was evaluated in the context of image description and classification, and the results obtained using synthetic images outperformed the ones over the original datasets, as well as other recent approaches from the literature. Such results suggest promising insights related to the importance of proper data for the accurate classification concerning computer-assisted Barrett's esophagus and adenocarcinoma detection.	187.94160153971424
1133.	Deep learning based on deep neural networks of various structures and architectures has been powerful in many practical applications, but it lacks enough theoretical verifications. In this paper, we consider a family of deep convolutional neural networks applied to approximate functions on the unit sphere Sd-1 of Rd. Our analysis presents rates of uniform approximation when the approximated function lies in the Sobolev space Wr(Sd-1) with r>0 or takes an additive ridge form. Our work verifies theoretically the modelling and approximation ability of deep convolutional neural networks followed by downsampling and one fully connected layer or two. The key idea of our spherical analysis is to use the inner product form of the reproducing kernels of the spaces of spherical harmonics and then to apply convolutional factorizations of filters to realize the generated linear features.	187.9415067123286
1134.	Handwritten digit classification is a well-known and important problem in the field of optical character recognition (OCR). The primary challenge is correctly classifying digits which are highly varied in their visual characteristics primarily due to the writing styles of different individuals. In this paper, we propose the use of Convolutional Neural Networks (CNN) for the purpose of classifying handwritten Bangla and Hindi numerals. The major advantage that we face by using a CNN-based classifier is that no prior hand-crafted feature needs to be extracted from the images for efficient and accurate classification. An added benefit of a CNN classifier is that it provides translational invariance and a certain extent of rotational invariance during recognition. Applications can be found in real-time OCR systems where input images are often not perfectly oriented along a vertical axis. In this work, we use modified versions of the well-known LeNet CNN architecture. Extensive experiments have revealed a best-case classification accuracy of 98.2% for Bangla and 98.8% for Hindi numerals outperforming competitive models in the literature.	187.94148776619562
1135.	Mobile robots frequently operate in rough, uneven terrain. One way for them to identify easier to traverse paths is to use deep learning methods, such as a convolutional neural network (CNN). It is not clear, however, what input should be provided to the CNN to best enable it to classify different terrain. In this study, we investigate and compare several input formats for improving terrain classification using a CNN. All experiments take place in simulation, where we have complete control over terrain (e.g., shapes and textures) and information about our robot. Our experiments lead us to the following conclusions: (1) input formats should prefer grayscale over color images as color has a tendency to overfit the training data and (2) disparity maps also improve classification compared with raw image data. These results can be used to improve the performance of terrain classification; particularly as they apply to transformable-wheel robots.	187.94137717434765
1136.	This article aims to explore the under-researched topic of post-entry speed of internationalisation (PSI) in the context of international new ventures (INVs). We unbundle PSI and examine its relationship with both financial and non-financial export performance, considering three related, but conceptually distinct, dimensions of PSI: internationalisation intensity, spread and geographical diversity. Building on organisational learning theory, we highlight different mechanisms that contribute to post-entry performance outcomes among INVs. Our findings from a sample of 112 INVs in New Zealand provide evidence that the three dimensions of PSI are distinct and that they have different impacts on financial and non-financial export performance. This article contributes to the limited, yet growing body of literature on PSI by providing a deeper understanding of PSI and its constituent dimensions. In addition, this study offers new theoretical insights into how and why different dimensions of post-entry speed of internationalisation can contribute to stronger export performance.	187.9413393864662
1137.	Since wind turbines operate in a complex environment for long term, the fatigue behavior of the blades can be influenced by wind, illumination, moisture, temperature, and so forth. For wind turbine blade manufacturers, the determination of their fatigue limit before delivery is necessary and fatigue acceleration experiments usually require a lot of labor and experimental costs. As a machine learning paradigm, deep learning focuses on the inherent hierarchical models of data and has achieved notable success in computer vision, speech recognition, natural language processing, etc. Aimed at reducing the time and the costs during fatigue tests, this paper studies a training-based method for wind turbine blade stiffness prediction using time series stiffness data under fatigue tests. Based on deep learning methods including convolutional neural network, long-short term memory network and the hybrid network, the residual stiffness of the blade with fatigue life under fatigue tests is obtained by combining the fatigue historical data. The obtained results show that the developed models can learn features directly from raw stiffness data and complete the residual stiffness prediction in succession. White Gaussian noise with different signal-to-noise ratios is also added to all stiffness data to demonstrate the models' feasibility of stiffness prediction.	187.9412958969737
1138.	Massive open online courses (MOOCs) hold the promise of democratizing the learning process. However, providing effective feedback has proven hard to offer at scale since most methods require a teacher or tutor. Leveraging big data in MOOCs offers a mechanism to develop predictive models that can inform computer-based pedagogical tutors. We review research on grade prediction and examine the predictive power of a model based on user video-watching behavior. In a MOOC organized around weekly assignments, we find that frequency of video viewing per week is a better predictor than individual viewing features such as plays, pauses, seeking, and rate changes. This finding is useful for MOOCs that use assignments for course evaluations in addition or to the exclusion of in-video quizzes for formative assessment. Engaging, well-crafted assignments in MOOCs have the potential of boosting student retention and course completion by fostering a deeper understanding through application and practice.	187.9412913662391
1139.	Chiral indices determine important properties of carbon nanotubes (CNTs). Unfortunately, their determination from high-resolution transmission electron microscopy (HRTEM) images, the most accurate method for assigning chirality, is a tedious task. We develop a Convolutional Neural Network that automatizes this process. A large and realistic training data set of CNT images is obtained by means of atomistic computer simulations coupled with the multi-slice approach for image generation. In most cases, results of the automated assignment are in excellent agreement with manual classification, and the origin of failures is identified. The current approach, which combines HRTEM imaging and deep learning algorithms allows the analysis of a statistically significant number of HRTEM images of carbon nanotubes, paving the way for robust estimates of experimental chiral distributions. (C) 2020 Elsevier Ltd. All rights reserved.	187.94127286130117
1140.	Recent years have seen a significant amount of transportation data collected from multiple sources including road sensors, probe, GPS, CCTV and incident reports. Similar to many other industries, transportation has entered the generation of big data. With a rich volume of traffic data, it is challenging to build reliable prediction models based on traditional shallow machine learning methods. Deep learning is a new state-of-the-art machine learning approach which has been of great interest in both academic research and industrial applications. This study reviews recent studies of deep learning for popular topics in processing traffic data including transportation network representation, traffic flow forecasting, traffic signal control, automatic vehicle detection, traffic incident processing, travel demand prediction, autonomous driving and driver behaviours. In general, the use of deep learning systems in transportation is still limited and there are potential limitations for utilising this advanced approach to improve prediction models.	187.941259619125
1141.	In this paper, the ability of Bayesian and convolutional neural networks (CNNs), as two different machine learning methods, to recognize Arabic handwritten words is analyzed. Our contribution is threefold. First, we describe the main highlights of the dynamic Bayesian network (DBN) architecture, especially when compared to standard Bayesian networks. For that, some structural features are extracted from word image and considered as input for different architectures of Bayesian networks (BNs) such as Naive Bayes (NB), Tree Augmented Naive Bayes (TAN), Forest Augmented Naive Bayes (FAN) and Hidden Markov model (HMM). Features are extracted based on the word baseline which has been estimated to mainly cope with the problems of inclination and distortions. Decisions about word classification are then inferred using multiples models of BNs. Second, we model a deep learning architecture: a CNN that convolves learned features with input data and uses 2D convolutional layers that makes it well suited to 2D word image processing. Third, we compare the behavior of DBN-CNN and propose to combine them to exploit their advantages. Experiments are carried on the standard IFN-ENIT database. The obtained results show the relatively high accuracy of the DBN and CNN combination: 95.20% compared to the remaining models.	187.94124571899965
1142.	With time, AI technologies have matured well and resonated in various domains of applied sciences and engineering. The sub-domains of AI, machine learning (ML), deep learning (DL), and associated statistical tools are getting more attention. Therefore, various machine learning models are being created to take advantage of the data available and accomplish tasks, such as automatic prediction, classification, clustering, segmentation and anomaly detection, etc. Tasks like classification need labeled data used to train the models to achieve a reliable accuracy. This study shows the systematic review of promising research areas and applications of DL models in medical diagnosis and medical healthcare systems. The prevalent DL models, their architectures, and related pros, cons are discussed to clarify their prospects. Many deep learning networks have been useful in the field of medical image processing for prognosis and diagnosis of life-threatening ailments (e.g., breast cancer, lung cancer, and brain tumor, etc.), which stand as an error-prone and tedious task for doctors and specialists when performed manually. Medical images are processed using these DL methods to solve various tasks like prediction, segmentation, and classification with accuracy bypassing human abilities. However, the current DL models have some limitations that encourage the researchers to seek further improvement.	187.94121187941144
1143.	Modern industrial production technology is developing rapidly in recent decades. More and more traditional manual productions are becoming automatic when new automatic technologies are introduced among which machine vision plays an indispensable role. Aiming at the unmanned automatic production line of special steel castings in Shanghai MengTeng automatic technology co., LTD, in this paper an algorithm to recognize and position the special steel castings autonomously is proposed based on the binocular vision theory. The technologies including the pyramid hierarchical matching and the deep neural network are described in detain. The identification and positioning of special steel castings is realized. Its procedures are described completed. Some experiments are implemented by using manipulator to grasp the steel castings and running the proposed algorithm. It proves that the proposed algorithm achieves satisfactory results.	187.94115857406422
1144.	This article is a reflection on corporal movement and affectivities in the city of Quito, through a deep observation and a long reflection on these issues from the perspective of parkour, a motor practice dedicated to transit urban spaces in the most fluid and effective way possible, using only the body. Through the experience of learning and practice of parkour, among the activities of the Etre Fort collective, this study explores the transformations that the exercise of this discipline entails on the city, its spatial production and its inhabited territory, at the same time that reflects on the affective elements that arise in this practice, and their role in these transformations.	187.94110207844332
1145.	Long non-coding RNA (LncRNA) and microRNA (miRNA) are both non-coding RNAs that play significant regulatory roles in many life processes. There is cumulating evidence showing that the interaction patterns between lncRNAs and miRNAs are highly related to cancer development, gene regulation, cellular metabolic process, etc. Contemporaneously, with the rapid development of RNA sequence technology, numerous novel lncRNAs and miRNAs have been found, which might help to explore novel regulated patterns. However, the increasing unknown interactions between lncRNAs and miRNAs may hinder finding the novel regulated pattern, and wet experiments to identify the potential interaction are costly and time-consuming. Furthermore, few computational tools are available for predicting lncRNA-miRNA interaction based on a sequential level. In this paper, we propose a hybrid sequence feature-based model, LncMirNet (lncRNA-miRNA interactions network), to predict lncRNA-miRNA interactions via deep convolutional neural networks (CNN). First, four categories of sequence-based features are introduced to encode lncRNA/miRNA sequences including k-mer (k = 1, 2, 3, 4), composition transition distribution (CTD), doc2vec, and graph embedding features. Then, to fit the CNN learning pattern, a histogram-dd method is incorporated to fuse multiple types of features into a matrix. Finally, LncMirNet attained excellent performance in comparison with six other state-of-the-art methods on a real dataset collected from lncRNASNP2 via five-fold cross validation. LncMirNet increased accuracy and area under curve (AUC) by more than 3%, respectively, over that of the other tools, and improved the Matthews correlation coefficient (MCC) by more than 6%. These results show that LncMirNet can obtain high confidence in predicting potential interactions between lncRNAs and miRNAs.	187.94107588949535
1146.	Stereo matching is one of the most important computer vision tasks. Several methods can be used to compute a matching cost of two pictures. This paper proposes a method that uses convolutional neural networks to compute the matching cost. The network architecture is described as well as teaching process. The matching cost metric based on the result of neural network is applied to base method which uses support points grid (ELAS). The proposed method was tested on Middlebury benchmark images and showed an accuracy improvement compared to the base method.	187.9410530756988
1147.	In the remote sensing area, how to automatically and accurately extract buildings from images is a hot and challenging topic in these years. With the rapid development of sensor and computer hardware technologies, it gets easier to gain remote sensing images with very high-resolution and extract buildings from them by the popular deep learning models such as Fully Convolutional Networks (FCN). However, current FCN based models always lead to blurred building boundaries and have poor abilities on extracting small buildings. Therefore, in this paper, we propose the Gaussian Dilate Convolution, which is a cascade of a trainable Gaussian Filter and an dilate convolution with proper hyperparameter initializations. Also, we carefully design a hierarchical dense feature fusion structure following the dense connection manners. Finally, we embed the Gaussian Dilate Convolution into the hierarchical dense fusion structure and name it as Dense Hierarchical Spatial Gaussian Pool (Dense-HSGP). More specifically, the Gaussian Dilate Convolution has the advantages of the original dilate convolution but preserves much more context information, while the hierarchical dense connection structure of Dense-HSGP provides more abundant receptive fields and higher feature reused abilities within the model. We execute the experiments on the widely used Inrial Labelling Dataset to verify the efficiency of the proposed model. The experimental results show that the proposed model achieves 96.45 % average accuracy and 77.17% IoU respectively, which are distinct improvements rather than several recent state-of-the-art building extraction models.	187.9410152456399
1148.	Achieving accurate stock market models can provide investors with tools for making better data-based decisions. These models can help traders to reduce investment risk and select the most profitable stocks. Furthermore, creating advanced models enable the usage of non-traditional data like historical stock prices and news. There are several review articles about financial problems, including stock market analysis and forecast, currency exchange forecast, optimal portfolio selection, among others. However, the recent advances in machine learning techniques, like Deep Learning, Text Mining Techniques, and Ensemble Techniques, raises the need to perform an updated review. This study aims to fill this gap by providing an updated systematic review of the forecasting techniques used in the stock market, including their classification, characterization and comparison. The review is focused on studies on stock market movement prediction from 2014 to 2018, obtained from the scientific databases Scopus and Web of Science. Besides, it analyzes surveys and other reviews of recent studies published in the same time frame and the same databases. (C) 2020 Elsevier Ltd. All rights reserved.	187.94096634314485
1149.	The number of malware has exploded due to the openness of the Android platform, and the endless stream of malware poses a threat to the privacy, tariffs, and device of mobile phone users. A novel Android mobile malware detection system is proposed, which employs an optimized deep convolutional neural network to learn from opcode sequences. The optimized convolutional neural network is trained multiple times by the raw opcode sequences extracted from the decompiled Android file, so that the feature information can be effectively learned and the malicious program can be detected more accurately. More critically, thek-max pooling method with better results is adopted in the pooling operation phase, which improves the detection effect of the proposed method. The experimental results show that the detection system achieved the accuracy of 99%, which is 2%-11% higher than the accuracy of the machine learning detection algorithms when using the same data set. It also ensures that the indicators, such as F1-score, recall, and precision, are maintained above 97%. Based on the detection system, a multi-data set comparison experiment is carried out. The introducedk-max pooling is deeply studied, and the effect ofkofk-max pooling on the overall detection effect is observed.	187.94094039533837
1150.	Soil temperature (T-s) is an essential regulator of a plant's root growth, evapotranspiration rates, and hence soil water content. Over the last few years, in response to the climatic change, significant amount of research has been conducted worldwide to understand the quantitative link between soil temperature and the climatic factors, and it was highlighted that the hydrothermal conditions in the soil are continuously changing in response to the change of the hydro-meteorological factors. A large amount of the models have been developed and used in the past for the analysis and modelling of soil temperature, however, none of them has investigated the robustness and feasibilities of the deep echo state network (Deep ESN) model. A more accurate model for forecastingT(s)presents many worldwide opportunities in improving irrigation efficiency in arid climates and help attain sustainable water resources management. This research compares the application of the novel Deep ESN model versus three conventional machine learning models for soil temperature forecasting at 10 and 20 cm depths. We combined several critical daily hydro-meteorological data into six different input combinations for constructing the Deep ESN model. The accuracy of the developed soil temperature models is evaluated using three deterministic indices. The results of the evaluation indicate that the Deep ESN model outperformed conventional machine learning methods and can reduce the root mean square error (RMSE) accuracy of the traditional models between 30 and 60% in both stations. In the test phase, the most accurate estimation was obtained by Deep ESN at depths of 10 cm by RMSE = 2.41 degrees C and 20 cm by RMSE = 1.28 degrees C in Champaign station and RMSE = 2.17 degrees C (10 cm) and RMSE = 1.52 degrees C (20 cm) in Springfield station. The superior performance of the Deep ESN model confirmed that this model can be successfully applied for modellingT(s)based on meteorological paarameters.	187.94090393237963
1151.	Most existing hashing methods resort to binary codes for large scale similarity search, owing to the high efficiency of computation and storage. However, binary codes lack enough capability in similarity preservation, resulting in less desirable performance. To address this issue, we propose Nonlinear Asymmetric Multi-Valued Hashing (NAMVH) supported by two distinct non-binary embeddings. Specifically, a real-valued embedding is used for representing the newly-coming query by an ideally nonlinear transformation. Besides, a multi-integer-embedding is employed for compressing the whole database, which is modeled by Binary Sparse Representation (BSR) with fixed sparsity. With these two non-binary embeddings, NAMVH preserves more precise similarities between data points and enables access to the incremental extension with database samples evolving dynamically. To perform meaningful asymmetric similarity computation for efficient semantic search, these embeddings are jointly learnt by preserving the pairwise label-based similarity. Technically, this results in a mixed integer programming problem, which is efficiently solved by a well-designed alternative optimization method. Extensive experiments on seven large scale datasets demonstrate that our approach not only outperforms the existing binary hashing methods in search accuracy, but also retains their query and storage efficiency.	187.94085637961854
1152.	Efficient automated detection of flux-transient, re-occurring flux-variable, and moving objects is increasingly important for large-scale astronomical surveys. We present BRAAI, a convolutional-neural-network, deep-learning real/bogus classifier designed to separate genuine astrophysical events and objects from false positive, or bogus, detections in the data of the Zwicky Transient Facility (ZTF), a new robotic time-domain survey currently in operation at the Palomar Observatory in California, USA. BRAAI demonstrates a state-of-the-art performance as quantified by its low false negative and false positive rates. We describe the open-source software tools used internally at Caltech to archive and access ZTF's alerts and light curves (KOWALSKI), and to label the data (ZWICKYVERSE). We also report the initial results of the classifier deployment on the Edge Tensor Processing Units that show comparable performance in terms of accuracy, but in a much more (cost-) efficient manner, which has significant implications for current and future surveys.	187.94074593830078
1153.	Recent advances in single-view 3D hair digitization have made the creation of high-quality CG characters scalable and accessible to end-users, enabling new forms of personalized VR and gaming experiences. To handle the complexity and variety of hair structures, most cutting-edge techniques rely on the successful retrieval of a particular hair model from a comprehensive hair database. Not only are the aforementioned data-driven methods storage intensive, but they are also prone to failure for highly unconstrained input images, complicated hairstyles, and failed face detection. Instead of using a large collection of 3D hair models directly, we propose to represent the manifold of 3D hairstyles implicitly through a compact latent space of a volumetric variational autoencoder (VAE). This deep neural network is trained with volumetric orientation field representations of 3D hair models and can synthesize new hairstyles from a compressed code. To enable end-to-end 3D hair inference, we train an additional embedding network to predict the code in the VAE latent space from any input image. Strand-level hairstyles can then be generated from the predicted volumetric representation. Our fully automatic framework does not require any ad-hoc face fitting, intermediate classification and segmentation, or hairstyle database retrieval. Our hair synthesis approach is significantly more robust and can handle a much wider variation of hairstyles than state-of-the-art data-driven hair modeling techniques with challenging inputs, including photos that are low-resolution, overexposured, or contain extreme head poses. The storage requirements are minimal and a 3D hair model can be produced from an image in a second. Our evaluations also show that successful reconstructions are possible from highly stylized cartoon images, non-human subjects, and pictures taken from behind a person. Our approach is particularly well suited for continuous and plausible hair interpolation between very different hairstyles.	187.94073214689598
1154.	In peer-to-peer (P2P) lending, it is important to predict default of borrowers because the lenders would suffer financial loss if the borrower fails to pay money. The huge lending transaction data generated online helps to predict repayment of the borrowers, but there are limitations in extracting features based on the complex information. Convolutional neural networks (CNN) can automatically extract useful features from large P2P lending data. However, as deep CNN becomes more complex and deeper, the information about input vanishes and overfitting occurs. In this paper, we propose a deep dense convolutional networks (DenseNet) for default prediction in P2P social lending to automatically extract features and improve the performance. DenseNet ensures the flow of loan information through dense connectivity and automatically extracts discriminative features with convolution and pooling operations. We capture the complex features of lending data and reuse loan information to predict the repayment of the borrower. Experimental results show that the proposed method automatically extracts useful features from Lending Club data, avoids overfitting, and is effective in default prediction. In comparison with deep CNN and other machine learning methods, the proposed method has achieved the highest performance with 79.6%. We demonstrate the usefulness of the proposed method as the 5-fold cross-validation to evaluate the performance.	187.9407225297746
1155.	The problem of cross-domain face recognition aims to identify facial images obtained across different domains, which attracts increasing attentions because of its wide applications on law-enforcement identification and camera surveillance. The problem is challenging due to the huge domain discrepancy. Despite great progress achieved in recent years, existing algorithms usually fail to fully exploit the semantic information for identifying cross-domain faces, which could be a strong clue for recognition. In this article, we propose an effective algorithm for cross-domain face recognition by exploiting semantic information integrated with deep convolutional neural networks (CNN). We first introduce a soft face parsing algorithm where the boundaries of facial components are measured as probabilistic values. By taking the original face image as the guidance to improve face parsing result, each pixel may belong partially to the facial component to avoid inaccurate segmentation around component boundaries. We then propose a hierarchical soft semantic representation framework for cross-domain face recognition. Both the soft semantic level and contour level deep features obtained via CNN are computed and combined together, which could fully exploit the identical semantic clue among cross-domain faces. We provide extensive experiments to demonstrate that the proposed soft semantic representation algorithm performs superior against state-of-the-art methods.	187.94065894852062
1156.	Two-stream networks have provided an alternate way of exploiting the spatiotemporal information for action recognition problem. Nevertheless, most of the two-stream variants perform the fusion of homogeneous modalities which cannot efficiently capture the action-motion dynamics from the videos. Moreover, the existing studies cannot extend the streams beyond the number of modalities. To address these limitations, we propose a hybrid and hierarchical fusion (HHF) networks. The hybrid fusion handles non-homogeneous modalities and introduces a cross-modal learning stream for effective modeling of motion dynamics while extending the networks from existing two-stream variants to three and six streams. On the other hand, the hierarchical fusion makes the modalities consistent by modeling long-term temporal information along with the combination of multiple streams to improve the recognition performance. The proposed network architecture comprises of three fusion tiers: the hybrid fusion itself, the long-term fusion pooling layer which models the long-term dynamics from RGB and optical flow modalities, and the adaptive weighting scheme for combining the classification scores from several streams. We show that the hybrid fusion has different representations from the base modalities for training the cross-modal learning stream. We have conducted extensive experiments and shown that the proposed six-stream HHF network outperforms the existing two- and four-stream networks, achieving the state-of-the-art recognition performance, 97.2% and 76.7% accuracies on UCF101 and HMDB51 datasets, respectively, which are widely used in action recognition studies.	187.94043203092363
1157.	In order to provide benchmark performance for Urdu text document classification, the contribution of this paper is manifold. First, it provides a publicly available benchmark dataset manually tagged against 6 classes. Second, it investigates the performance impact of traditional machine learning-based Urdu text document classification methodologies by embedding 10 filter-based feature selection algorithms which have been widely used for other languages. Third, for the very first time, it assesses the performance of various deep learning-based methodologies for Urdu text document classification. In this regard, for experimentation, we adapt 10 deep learning classification methodologies which have produced best performance figures for English text classification. Fourth, it also investigates the performance impact of transfer learning by utilizing Bidirectional Encoder Representations from Transformers approach for Urdu language. Fifth, it evaluates the integrity of a hybrid approach which combines traditional machine learning-based feature engineering and deep learning-based automated feature engineering. Experimental results show that feature selection approach named as normalized difference measure along with support vector machine outshines state-of-the-art performance on two closed source benchmark datasets CLE Urdu Digest 1000k, and CLE Urdu Digest 1Million with a significant margin of 32% and 13%, respectively. Across all three datasets, normalized difference measure outperforms other filter-based feature selection algorithms as it significantly uplifts the performance of all adopted machine learning, deep learning, and hybrid approaches. The source code and presented dataset are available at Github repository https://github.com/minixain/Urdu-Text-Classification.	187.94041047507514
1158.	The absorption and scattering effects of light source during the transmission of biological tissues make it difficult to identify heterogeneity in multi-spectral images. This paper firstly proposes a combination method of modulation-demodulation-frame accumulation technique (MDFAT), spatial pyramid matching (SPM) model and deep learning to realize heterogeneous detection in multi-spectral images. Firstly, the acquisition experiment of phantom image is designed. Then, the high-quality multi-spectral images are obtained by the MDFAT and SPM model. Finally, the pseudo-color maps of high-quality multi-spectral images fusion are served as the input of Faster-RCNN and Single Shot Multi-Box Detector (SSD) network models to realize heterogeneous detection. The results show that Faster-RCNN and SSD both have good detection results. Among them, Faster-RCNN model has the best detection effect on the images containing three types of heterogeneity, and the mean average precision (mAP) reaches 93.91%. SSD model has the most ideal detection effect for the images containing two and five types of heterogeneity, with mAP reaching 94.16% and 94.78% respectively. In conclusion, this paper has verified the feasibility of detecting heterogeneities in multi-spectral images through deep learning network (Faster-RCNN and SSD), which will promote the clinical application of multi-spectral transmission imaging in early screening of breast tumors.	187.94036885385503
1159.	The nanostructures produced by oblique-incidence broad beam ion bombardment of a solid surface are usually modelled by the anisotropic Kuramoto-Sivashinsky equation. This equation has five parameters, each of which depend on the target material and the ion species, energy, and angle of incidence. We have developed a deep learning model that uses a single image of the surface to estimate all five parameters in the equation of motion with root-mean-square errors that are under 3% of the parameter ranges used for training. This provides a tool that will allow experimentalists to quickly ascertain the parameters for a given sputtering experiment. It could also provide an independent check on other methods of estimating parameters such as atomistic simulations combined with the crater function formalism.	187.94030747071048
1160.	Flow, transport, mechanical, and fracture properties of porous media depend on their morphology and are usually estimated by experimental and/or computational methods. The precision of the computational approaches depends on the accuracy of the model that represents the morphology. If high accuracy is required, the computations and even experiments can be quite time-consuming. At the same time, linking the morphology directly to the permeability, as well as other important flow and transport properties, has been a long-standing problem. In this paper, we develop a new network that utilizes a deep learning (DL) algorithm to link the morphology of porous media to their permeability. The network is neither a purely traditional artificial neural network (ANN), nor is it a purely DL algorithm, but, rather, it is a hybrid of both. The input data include three-dimensional images of sandstones, hundreds of their stochastic realizations generated by a reconstruction method, and synthetic unconsolidated porous media produced by a Boolean method. To develop the network, we first extract important features of the images using a DL algorithm and then feed them to an ANN to estimate the permeabilities. We demonstrate that the network is successfully trained, such that it can develop accurate correlations between the morphology of porous media and their effective permeability. The high accuracy of the network is demonstrated by its predictions for the permeability of a variety of porous media.	187.94022391691917
1161.	Crop classification is a representative problem in multispectral remote sensing image (RSI) classification, and has significance in country food security, ecological security, production estimate, crop growth supervision, and so on. It has attracted increasing attention of many researchers around the world especially after the development of convolutional neural networks (CNN). General CNN-based multispectral RSI classification methods may be not suitable for labeled samples with limited numbers and areas. Other pixel-based classification methods are always affected by noise and ignore spatial information. Focusing on these problems, this paper presents an approach based on lightened CNN for crop classification with a small number of tiny size labeled samples in multispectral images. The contribution of this work is to construct a lightened CNN model for crop classification with small samples in multispectral image. It avoids overfitting of deep CNN and reduces the requirement for the size of training samples. We adopt two-layer fully convolutional network (FCN) to extract features. The first layer uses a convolutional kernel of size 1 and outputs 16-band feature map to obtain spectral band information. Spatial information is extracted in the sequential layer using convolutional kernel of size 3, step 1 and padding 1. Thus the feature map after FCN and the labeled area have the same size. Finally, we use a fully connected layer and a softmax classifier for classification. Our experiment was conducted on 8-band multispectral image of size 50362-by-17810 pixels. There are 5 classes in the multispectral image, namely rice, soy, corn, non-crop, and uncertainty. The experimental result which achieves 86.28% accuracy indicates the good performance of our network for crop classification in multispectral RSIs.	187.94018057432402
1162.	To investigate accurate and real-time pedestrian detection results is a mainstream trend in the field of intelligent security. Avoiding too many external disturbances causing the errors and omissions, in order to obtain a reliable and discriminative detection. This paper proposes a deep learning method based on improved YOLO model to efficiently detect pedestrians. It addresses two necessary above issues: (1) leverage real-time saliency region detection through surveillance camera; and (2) extract more detail discriminative feature with human parsing. The results show that our deep real-time saliency and detail discriminative feature with human parsing based on improved YOLO model, successfully learn both spatial and temporal cues, making pedestrian detection further ensures the accuracy and timeliness in practical application scenes.	187.94016208804402
1163.	Artificial intelligence-based fault diagnosis has recently been the subject of extensive research. However, the model learned from source data exhibits poor performance in target pattern recognition due to different data distributions caused by variable working conditions. Therefore, the transfer learning (TL) method, which reuses acquired knowledge and diagnoses the target domain fault without labels, has elicited the attention of researchers. The common deep TL method reduces the distance between the source and target domains in accordance with a certain divergence criterion that should be designed differently for specific tasks, leading to poor generalization results. In this study, we propose a knowledge mapping-based adversarial domain adaptation (KMADA) method with a discriminator and a feature extractor to generalize knowledge from target to source domain. The discriminator achieves the distance metric of the neural network wherein the target feature extractor maps the target data into the source feature space to explore domain-invariant knowledge. To accelerate the adversarial training process, KMADA fully utilizes the parameters obtained from the supervised pre-training. In addition, comparison analysis with other TL methods indicates the irreplaceable superiority of the KMADA, which achieves the highest diagnosis accuracy. Moreover, the visualization results demonstrate that the proposed model extracts the domain-invariant feature to realize knowledge mapping diagnosis, and thus, the model exhibits considerable research prospects. (C) 2020 Elsevier Ltd. All rights reserved.	187.94012587136217
1164.	A novel centerline extraction framework is reported which combines an end-to-end trainable multi-task fully convolutional network (FCN) with a minimal path extractor. The FCN simultaneously computes centerline distance maps and detects branch endpoints. The method generates single-pixel-wide centerlines with no spurious branches. It handles arbitrary tree-structured object with no prior assumption regarding depth of the tree or its bifurcation pattern. It is also robust to substantial scale changes across different parts of the target object and minor imperfections of the object's segmentation mask. To the best of our knowledge, this is the first deep-learning based centerline extraction method that guarantees single-pixel-wide centerline for a complex tree-structured object. The proposed method is validated in coronary artery centerline extraction on a dataset of 620 patients (400 of which used as test set). This application is challenging due to the large number of coronary branches, branch tortuosity, and large variations in length, thickness, shape, etc. The proposed method generates well-positioned centerlines, exhibiting lower number of missing branches and is more robust in the presence of minor imperfections of the object segmentation mask. Compared to a state-of-the-art traditional minimal path approach, our method improves patient-level success rate of centerline extraction from 54.3% to 88.8% according to independent human expert review.	187.940119904122
1165.	Accurate delineation of gross tumor volume (GTV) is essential for head and neck cancer radiotherapy. Complexity of morphology and potential image artifacts usually cause inaccurate manual delineation and interobserver variability. Manual delineation is also time consuming. Motivated by the recent success of deep learning methods in natural and medical image processing, we propose an automatic GTV segmentation approach based on 3D-Unet to achieve automatic GTV delineation. One innovative feature of our proposed method is that PET/CT multi-modality images are integrated in the segmentation network. 175 patients are included in this study with manually drawn GTV by physicians. Based on results from 5-fold cross validation, our proposed method achieves a dice loss of 0.82 +/- 0.07 which is better than the model using PET image only (0.79 +/- 0.09). In conclusion, automatic GTV segmentation is successfully applied to head and neck cancer patients using deep learning network and multi-modality images, which brings unique benefits for radiation therapy planning.	187.94009034452557
1166.	To maintain profitability of cotton growing areas of Australia, information of nutrient management and water-use efficiency are needed. In this regard, information about clay is required. This is a time-consuming and expensive laboratory analysis to undertake. An alternative is to use visible-near infrared (vis-NIR) spectroscopy, which has shown potential at different scales (e.g., local and global). Here, we predicted clay using a machine learning algorithm (Cubist) from vis-NIR acquired from topsoil (0-0.3 m) and subsurface (0.3-0.6 m) in seven cotton growing areas. The first aim was to assess the ability of soil samples from each area to predict clay independently. The second aim was to determine the ability of the samples of six areas to predict clay in an area withheld from the calibration. The third aim was to explore the potential to improve prediction using "spiking". The fourth was to determine how much data was necessary to establish a suitable library. We conclude that establishing a calibration from each area independently was more accurate than making a calibration from six areas and predicting clay from the area withheld from the calibration. We also found that improvements in model performance were possible using spiking. When using samples from topsoil or subsurface only, over 93 samples were required to obtain an accurate library. We also conclude that a combined dataset from topsoil and subsurface samples enabled a more consistent set of data with no loss of calibration and prediction accuracy, especially when considering the availability of calibration samples.	187.94004775236215
1167.	Current neural networks for predictions of molecular properties use quantum chemistry only as a source of training data. This paper explores models that use quantum chemistry as an integral part of the prediction process. This is done by implementing self-consistent-charge Density-Functional-Tight Binding (DFTB) theory as a layer for use in deep learning models. The DFTB layer takes, as input, Hamiltonian matrix elements generated from earlier layers and produces, as output, electronic properties from self-consistent field solutions of the corresponding DFTB Hamiltonian. Backpropagation enables efficient training of the model to target electronic properties. Two types of input to the DFTB layer are explored, splines and feed-forward neural networks. Because overfitting can cause models trained on smaller molecules to perform poorly on larger molecules, regularizations are applied that penalize nonmonotonic behavior and deviation of the Hamiltonian matrix elements from those of the published DFTB model used to initialize the model. The approach is evaluated on 15 700 hydrocarbons by comparing the root-mean-square error in energy and dipole moment, on test molecules with eight heavy atoms, to the error from the initial DFTB model. When trained on molecules with up to seven heavy atoms, the spline model reduces the test error in energy by 60% and in dipole moments by 42%. The neural network model performs somewhat better, with error reductions of 67% and 59%, respectively. Training on molecules with up to four heavy atoms reduces performance, with both the spline and neural net models reducing the test error in energy by about 53% and in dipole by about 25%.	187.9399477905451
1168.	COVID-19, responsible of infecting billions of people and economy across the globe, requires detailed study of the trend it follows to develop adequate short-term prediction models for forecasting the number of future cases. In this perspective, it is possible to develop strategic planning in the public health system to avoid deaths as well as managing patients. In this paper, proposed forecast models comprising autoregressive integrated moving average (ARIMA), support vector regression (SVR), long shot term memory (LSTM), bidirectional long short term memory (Bi-LSTM) are assessed for time series prediction of confirmed cases, deaths and recoveries in ten major countries affected due to COVID-19. The performance of models is measured by mean absolute error, root mean square error and r2_score indices. In the majority of cases, Bi-LSTM model outperforms in terms of endorsed indices. Models ranking from good performance to the lowest in entire scenarios is Bi-LSTM, LSTM, GRU, SVR and ARIMA. Bi-LSTM generates lowest MAE and RMSE values of 0.0070 and 0.0077, respectively, for deaths in China. The best r2_score value is 0.9997 for recovered cases in China. On the basis of demonstrated robustness and enhanced prediction accuracy, Bi-LSTM can be exploited for pandemic prediction for better planning and management.	187.9399337905962
1169.	Neutron spectrum is essential to the safe operation of reactors. Traditional online neutron spectrum measurement methods still have room to improve accuracy for the application cases of wide energy range. From the application of artificial neural network (ANN) algorithm in spectrum unfolding, its accuracy is difficult to be improved for lacking of enough effective training data. In this paper, an adaptive deviation-resistant neutron spectrum unfolding method based on transfer learning was developed. The model of ANN was trained with thousands of neutron spectra generated with Monte Carlo transport calculation to construct a coarse-grained unfolded spectrum. In order to improve the accuracy of the unfolded spectrum, results of the previous ANN model combined with some specific eigenvalues of the current system were put into the dataset for training the deeper ANN model, and fine-grained unfolded spectrum could be achieved through the deeper ANN model. The method could realize accurate spectrum unfolding while maintaining universality, combined with detectors covering wide energy range, it could improve the accuracy of spectrum measurement methods for wide energy range. This method was verified with a fast neutron reactor BN-600. The mean square error (MSE), average relative deviation (ARD) and spectrum quality (Qs) were selected to evaluate the final results and they all demonstrated that the developed method was much more precise than traditional spectrum unfolding methods. (C) 2020 Korean Nuclear Society, Published by Elsevier Korea LLC.	187.93984564548933
1170.	Interpretability of deep learning (DL) systems is gaining attention in medical imaging to increase experts' trust in the obtained predictions and facilitate their integration in clinical settings. We propose a deep visualization method to generate interpretability of DL classification tasks in medical imaging by means of visual evidence augmentation. The proposed method iteratively unveils abnormalities based on the prediction of a classifier trained only with image-level labels. For each image, initial visual evidence of the prediction is extracted with a given visual attribution technique. This provides localization of abnormalities that are then removed through selective inpainting. We iteratively apply this procedure until the system considers the image as normal. This yields augmented visual evidence, including less discriminative lesions which were not detected at first but should be considered for final diagnosis. We apply the method to grading of two retinal diseases in color fundus images: diabetic retinopathy (DR) and age-related macular degeneration (AMD). We evaluate the generated visual evidence and the performance of weakly-supervised localization of different types of DR and AMD abnormalities, both qualitatively and quantitatively. We show that the augmented visual evidence of the predictions highlights the biomarkers considered by experts for diagnosis and improves the final localization performance. It results in a relative increase of 11.2 2.0% per image regarding sensitivity averaged at 10 false positives/image on average, when applied to different classification tasks, visual attribution techniques and network architectures. This makes the proposed method a useful tool for exhaustive visual support of DL classifiers in medical imaging.	187.9397924108087
1171.	The detection of Adverse Medical Events (AMEs) plays an important role in disease management in ensuring efficient treatment delivery and quality improvement of health services. Recently, with the rapid development of hospital information systems, a large volume of Electronic Health Records (EHRs) have been produced, in which AMEs are regularly documented in a free-text manner. In this study, we are concemed with the problem of AME detection by utilizing a large volume of unstructured EHR data. To address this challenge, we propose a neural attention network-based model to incorporate the contextual information of words into AME detection. Specifically, we develop a context-aware attention mechanism to locate salient words with respect to the target AMEs in patient medical records. And then we combine the proposed context attention mechanism with the deep learning tactic to boost the performance of AME detection. We validate our proposed model on a real clinical dataset that consists of 8845 medical records of patients with cardiovascular diseases. The experimental results show that our proposed model advances state-of-the-art models and achieves competitive performance in terms of AME detection.	187.9397769116362
1172.	Scene text detection is an important step in the scene text reading system. The main challenges lie in significantly varied sizes and aspect ratios, arbitrary orientations, and shapes. Driven by the recent progress in deep learning, impressive performances have been achieved for multi-oriented text detection. Yet, the performance drops dramatically in detecting the curved texts due to the limited text representation (e.g., horizontal bounding boxes, rotated rectangles, or quadrilaterals). It is of great interest to detect the curved texts, which are actually very common in natural scenes. In this paper, we present a novel text detector named TextField for detecting irregular scene texts. Specifically, we learn a direction field pointing away from the nearest text boundary to each text point. This direction field is represented by an image of 2D vectors and learned via a fully convolutional neural network. It encodes both binary text mask and direction information used to separate adjacent text instances, which is challenging for the classical segmentation-based approaches. Based on the learned direction field, we apply a simple yet effective morphological-based post-processing to achieve the final detection. The experimental results show that the proposed TextField outperforms the state-of-the-art methods by a large margin (28% and 8%) on two curved text datasets: Total-Text and SCUT-CTW1500, respectively; TextField also achieves very competitive performance on multi-oriented datasets: ICDAR 2015 and MSRA-TD500. Furthermore, TextField is robust in generalizing unseen datasets.	187.9397239230948
1173.	Estimation of optical aberrations from volumetric intensity images is a key step in sensorless adaptive optics for 3D microscopy. Recent approaches based on deep learning promise accurate results at fast processing speeds. However, collecting ground truth microscopy data for training the network is typically very difficult or even impossible thereby limiting this approach in practice. Here, we demonstrate that neural networks trained only on simulated data yield accurate predictions for real experimental images. We validate our approach on simulated and experimental datasets acquired with two different microscopy modalities and also compare the results to non-learned methods. Additionally, we study the predictability of individual aberrations with respect to their data requirements and find that the symmetry of the wavefront plays a crucial role. Finally, we make our implementation freely available as open source software in Python.	187.93970545298268
1174.	Shortness of breath is a major reason that patients present to the emergency department (ED) and point-of-care ultrasound (POCUS) has been shown to aid in diagnosis, particularly through evaluation for artifacts known as B-lines. B-line identification and quantification can be a challenging skill for novice ultrasound users, and experienced users could benefit from a more objective measure of quantification. We sought to develop and test a deep learning (DL) algorithm to quantify the assessment of B-lines in lung ultrasound. We utilized ultrasound clips ( n = 400 ) from an existing database of ED patients to provide training and test sets to develop and test the DL algorithm based on deep convolutional neural networks. Interpretations of the images by algorithm were compared to expert human interpretations on binary and severity (a scale of 0-4) classifications. Our model yielded a sensitivity of 93% (95% confidence interval (CI) 81%-98%) and a specificity of 96% (95% CI 84%-99%) for the presence or absence of B-lines compared to expert read, with a kappa of 0.88 (95% CI 0.79-0.97). Model to expert agreement for severity classification yielded a weighted kappa of 0.65 (95% CI 0.56-074). Overall, the DL algorithm performed well and could be integrated into an ultrasound system in order to help diagnose and track B-line severity. The algorithm is better at distinguishing the presence from the absence of B-lines but can also be successfully used to distinguish between B-line severity. Such methods could decrease variability and provide a standardized method for improved diagnosis and outcome.	187.93961123205543
1175.	An approach that employs deep learning technology is presented to recognize satellites based on radar high-resolution range profile (HRRP) data. We focus on extracting effective satellite recognition features in this paper. Thus, a deep learning model is constructed by gated recurrent unit (GRU) neural network and support vector machine (SVM) to extract more abstract and accurate features. Firstly, the radar HRRP data of four satellites is obtained by simulation. And data preprocessing has been done according to HRRP characteristic. Next, a GRU-SVM model is set up and some deep learning skills, such as dropout and cross validation, have been applied to improve recognition accuracy. The training results of GRU neural network show their effectiveness. In order to demonstrate the superiority of this approach, five other feature extraction methods have been used as a comparison based on clean satellite HRRP data and noisy data. The experiment results show that the presented GRU- SVM model could recognize satellites effectively and accurately, and has better recognition performance and noise robustness compared with five other methods.	187.93946210822736
1176.	Post-fault prediction of transient stability of power systems has a great impact on the performance of wide area monitoring, protection and control systems. Situational awareness capabilities of a power system are improved by fast detection of instabilities after severe fault occurrences. This allows sufficient time to take necessary corrective control actions. In this paper, a novel method based on stacked sparse autoencoder is proposed to predict the post-fault transient stability status of the power system directly after clearing the fault. A dataset is generated off-line to train a stacked sparse autoencoder, and then the trained stacked sparse autoencoder is used in an online application of predicting any transient instability. The stacked sparse autoencoder is fed by the inputs, which are specific points extracted from the fault-on voltage magnitude measurements collected from the phasor measurement units. The effectiveness of the proposed method is demonstrated and compared with the conventional approaches that adopt multilayer perceptrons or post-fault measurements as it is applied to the 127-bus WSCC test system and to the Turkish power system.	187.93932983564542
1177.	The application of a class of advanced machine learning techniques, namely deep learning, has been applied to automating the confirmation/classification of potential meteor tracks in video imagery. Deep learning is shown to perform remarkably well, even surpassing human performance, and will likely supplant the need for human visual inspection and review of collected meteor imagery. When applied to time series measurements of meteor track centroid positions and integrated intensities obtained from each video frame, a recurrent neural network (RNN) has achieved 98.1 per cent recall, which is defined as the number of true meteors properly classified as meteors. The RNN allowed only 2.1 per cent leakage, defined herein as the number of false positives that were incorrectly identified as meteors. The desire is to maximize recall to avoid missed orbit estimations, while also minimizing false alarms leaking through to the next processing stage of multisite trajectory and orbit estimation. When twodimensional spatial imagery is available or the temporal image sequence can be reconstructed, these results climb to 99.94 per cent recall and only 0.4 per cent leakage when employing a convolutional neural network (CNN). This has been further generalized from a baseline of interleaved analogue video to modern progressive scan digital imagery with equivalent results. The trained CNN, nicknamed MeteorNet, will be used for post-detection automated screening of potential meteor tracks and explored in future as a potential upstream meteor detector.	187.93928964037508
1178.	A deep-learning architecture based on Convolutional Neural Networks (CNN) and a cost-effective computer vision module were used to detect defective apples on a four-line fruit sorting machine at a speed of 5 fruits/s. A CNN based classification architecture was trained and tested, with the accuracy, recall, and specificity of 96.5%, 100.0%, and 92.9%, respectively, for the testing set. An inferior performance was obtained by a traditional image processing method based on candidate defective regions counting and a support vector machine (SVM) classifier, with the accuracy, recall, and specificity of 87.1%, 90.9%, and 83.3%, respectively. The CNN-based model was loaded into the custom software to validate its performance using independent 200 apples, obtaining an accuracy of 92% with a processing time below 72 ms for six images of an apple fruit. The overall results indicated that the proposed CNN-based classification model had great potential to be implemented in commercial packing line.	187.93925729796138
1179.	Continuous monitoring of wind turbine health using early fault detection methods can improve turbine reliability and reduce maintenance costs before they reach a catastrophic stage. To achieve anomaly detection and fault analysis of wind turbine components, this paper proposes a deep learning method based on a deep auto-encoder (DAE) network using operational supervisory control and data acquisition (SCADA) data of wind turbines. First, a component DAE network model using multiple restricted Boltzmann machines (RBM) was constructed. Previously collected normal SCADA data from wind turbines were used to train this multilayer network model layer-wise to extract the relationships between SCADA variables. Then, a reconstruction error (R-e) was calculated by using the DAE network input and its output reconstruction value, which was defined as the condition detection index to reflect the component health condition. Due to the acute changes and disturbances of wind speed in actual operation, the calculated detection index always has an extreme distribution that can cause false alarms. Therefore, an adaptive threshold determined by the extreme value theory was proposed and used as the rule of anomaly judgement. The method can not only implement early warning of fault components but also deduce the physical location of a faulted component by DAE residuals. Finally, the effectiveness of the proposed method was verified by some reported failure cases of wind turbine components. (C) 2018 Elsevier Ltd. All rights reserved.	187.9392095908201
1180.	Dementia is a very complex disease that affects the ability to think and remember. The thinking ability affects the daily living activities (DLAs) pattern of the people with dementia (PwD) and thus the caregivers and the healthcare professionals that are responsible for assisting PwD can take preventive actions when anomalies in DLAs are identified to improve the health condition of PwD. The main contributions of the article are: (1) the development of an approach for the anomalies detection (AD) in the DLAs of the PwD, (2) the description of the preprocessing of the DLAs data, (3) the presentation of an approach for the detection of the baseline of PwD using Random Forest (RF), (4) the presentation of an approach based on a Sequential Model (SM) for the detection of the baseline of PwD and (5) the AD in DLAs of PwD using the predicted baseline and the data monitored in a day.	187.9392037094209
1181.	Face identification is employed in security system. Recently, it is gaining reliable result thanks to the deep learning method. However, the deep learning-based methods are prone against adversarial attack that leads to wrong prediction in presence of simple alteration on the pixel values. Thus the reliability of such system is compromised. This paper proposed a simple defense strategy to improve the reliability of a system in the presence of adversarial attack. By combining the prediction from few samples of altered input image, the effect of adversarial attack can be reduced effectively. The proposed method has been tested using public face dataset in the presence of strong attacks. Experiment results shows that the proposed method is reliable to suppress the adversarial attacks.	187.93916432858438
1182.	Recently in Japan, camera traps have been used for wildlife monitoring. Modern camera traps operate at a high-performance, thus, over thousands of images can be obtained. Ultimately, this can cause a disadvantage, as checking a large quantity of images is extremely laborious for researchers. This study attempted to decrease the labor involved with the use of the latest technology of image classification, "deep learning", to recognize the presence of animals, animal species, and the number of heads automatically. Over 110,000 annotated images taken by camera traps were used for constructing our model. In this study, the sika deer (Cervus nippon), wild boar (Sus scrofa), Japanese serow (Capricomis crispus), and Asian black bear (Ursus thibetanus) were targeted. For animal recognition, our model achieved a 15.7% false-positive rate whilst maintaining a 99% true-positive rate. This drastically reduces the quantity of images that researchers must scan through to 43.3% of the original value. When an image of one of the four target species was input, our model successfully returned each species 79.6%, 76.4%, 82.1%, and 76.6% of the time as top-hit category, respectively. For the animal count, when images containing animals were input, each target species reached an accuracy of 91.9%, 84.4%, 91.6%, and 86.4%, respectively. These results suggest that deep learning in camera trap analysis can be a useful tool for reducing the labor cost.	187.93908862305767
1183.	Recently developed regularization techniques improve the networks generalization by only considering the global context. Therefore, the network tends to focus on a few most discriminative subregions of an image for prediction accuracy, leading the network being sensitive to unseen or noisy data. To address this disadvantage, we introduce the concept of local context mapping by predicting patch-level labels and combine it with a method of local data augmentation by grid-based mixing, called GridMix. Through our analysis of intermediate representations, we show that our GridMix can effectively regularize the network model. Finally, our evaluation results indicate that GridMix outperforms state-of-the-art techniques in classification and adversarial robustness, and it achieves a comparable performance in weakly supervised object localization. (C) 2020 Elsevier Ltd. All rights reserved.	187.93885191880543
1184.	This paper proposes a novel incremental training mode to address the problem of Deep Reinforcement Learning (DRL) based path planning for a mobile robot. Firstly, we evaluate the related graphic search algorithms and Reinforcement Learning (RL) algorithms in a lightweight 2D environment. Then, we design the algorithm based on DRL, including observation states, reward function, network structure as well as parameters optimization, in a 2D environment to circumvent the time-consuming works for a 3D environment. We transfer the designed algorithm to a simple 3D environment for retraining to obtain the converged network parameters, including the weights and biases of deep neural network (DNN), etc. Using these parameters as initial values, we continue to train the model in a complex 3D environment. To improve the generalization of the model in different scenes, we propose to combine the DRL algorithm Twin Delayed Deep Deterministic policy gradients (TD3) with the traditional global path planning algorithm Probabilistic Roadmap (PRM) as a novel path planner (PRM+TD3). Experimental results show that the incremental training mode can notably improve the development efficiency. Moreover, the PRM+TD3 path planner can effectively improve the generalization of the model.	187.93877285366239
1185.	Recent advances in remote sensing have shown great potential for different kinds of applications such as vegetation and crop supervision. Using hyperspectral image processing, this process can be used to assess large areas of land, allowing for a fast and non-invasive analysis of variables such as water stress, diseases, and type of crops. In this context, representative spatial-spectral features are crucial for developing the data classification process of hyperspectral remote sensing images. In this way, extended attribute profiles (EAPs) are a powerful tool for efficiently capturing spatial and spectral properties. In addition, deep learning networks have shown a remarkable feature extraction performance in many applications, such as in the processing of hyperspectral images. In this paper, a data classification model is proposed that uses EAPs and an inception network to generate deep spatial-spectral features, which are labelled using a Riemannian classifier as a fine-tuning stage. This model was validated using three different datasets. Results obtained shows that the classification strategy proposed in this paper has better performance regarding the results generated by a traditional model of stacked convolutional neural networks (CNNs). Quantitatively speaking, the overall accuracy for the experiments with the proposed model and the tested data sets is greater than 99%.	187.93875320625614
1186.	This paper presents a damage identification method for offshore jacket platforms using partially measured modal results and based on artificial intelligence neural networks. Damage identification indices are first proposed combining information of six modal results and natural frequencies. Then, finite element models are established, and damages in structural members are assumed by reducing the structural elastic modulus. From the finite element analysis for a training sample, both the damage identification indices and the damages are obtained, and neural networks are trained. These trained networks are further tested and used for damage prediction of structural members. The calculation results show that the proposed method is quite accurate. As the considered measurement points of the jacket platform are near the waterline, the prediction errors keep below 8% when the damaged members are close to the waterline, but may rise to 16.5% when the damaged members are located in deeper waters.	187.93873309186063
1187.	Most of the traditional fault diagnosis methods rely on the expert knowledge of artificial extraction features and related fields, and these algorithms are not accurate, and the robustness and generalization ability are poor. Convolutional neural network is one of the most widely used deep learning models. Based on its unique convolution-pooling network structure, convolutional neural network has powerful feature extraction and expression capabilities. In this paper, based on the characteristics of one-dimensional vibration signals, a fault diagnosis algorithm model based on one-dimensional convolutional neural network is proposed. Through the experiment of the bearing fault public data set, the proposed algorithm has more than 99% fault recognition rate.	187.93872569978197
1188.	Video frame interpolation is a technology that generates high frame rate videos from low frame rate videos by using the correlation between consecutive frames. Presently, convolutional neural networks (CNN) exhibit outstanding performance in image processing and computer vision. Many variant methods of CNN have been proposed for video frame interpolation by estimating either dense motion flows or kernels for moving objects. However, most methods focus on estimating accurate motion. In this study, we exhaustively analyze the advantages of both motion estimation schemes and propose a cascaded system to maximize the advantages of both the schemes. The proposed cascaded network consists of three autoencoder networks, that process the initial frame interpolation and its refinement. The quantitative and qualitative evaluations demonstrate that the proposed cascaded structure exhibits a promising performance compared to currently existing state-of-the-art-methods.	187.93869378673384
1189.	Objective: Atrial fibrillation is a common type of heart rhythm abnormality caused by a problem with the heart's electrical system. Early detection of this disease has important implications for stroke prevention and management. Our objective is to construct an intelligent tool that assists cardiologists in identifying automatically cardiac arrhythmias and noise in electrocardiogram (ECG) recordings. Approach: Our base deep classifier combined a convolutional neural network (CNNs) and a sequence of long short-term memory units, with pooling, dropout and normalization techniques to improve their accuracy. The network predicted a classification at every 18th input sample and the final prediction was selected for classification. Ten standalone models that used our base classifier architecture were first cross-validated separately on 90% of the PhysioNet/CinC Challenge 2017 dataset and then tested on 10%. An ensemble classifier selected the label of the best average probability from the ten sub-models to improve prediction quality. Main results: Our original result submitted to the challenge gave a mean F-1-measure of 80%. The new proposed method improved the test score to 82%, which was tied for the third-highest score in the follow-up phase of the challenge. Significance: Without employing a time-consuming feature engineering step, the ensemble classifier trained with this architecture provided a robust solution to the problem of detecting cardiac arrhythmia from noisy ECG signals. In addition, interpretation of the classifier by inspection of its network parameters and predictions revealed what aspects of the ECG signal the classifier considered most discriminating.	187.9386748580952
1190.	In this study, we propose a deep-learning-based method to correct motion artifacts in optical resolution photoacoustic microscopy (OR-PAM). The method is a convolutional neural network that establishes an end-to-end map from input raw data with motion artifacts to output corrected images. First, we performed simulation studies to evaluate the feasibility and effectiveness of the proposed method. Second, we employed this method to process images of rat brain vessels with multiple motion artifacts to evaluate its performance for in vivo applications. The results demonstrate that this method works well for both large blood vessels and capillary networks. In comparison with traditional methods, the proposed method in this study can be easily modified to satisfy different scenarios of motion corrections in OR-PAM by revising the training sets.	187.93866345614333
1191.	Background: Liver sinusoidal endothelial cells (LSECs) display unique fenestrated morphology. Alterations in the size and number of fenestrae play a crucial role in the progression of various liver diseases. While their features have been visualized using atomic force microscopy (AFM), the in situ imaging methods and off-line analyses are further required for fenestra quantification. Methods: Primary mouse LSECs were cultured on a collagen-I-coated culture dish, or a polydimethylsiloxane (PDMS) or polyacrylamide (PA) hydrogel substrate. An AFM contact mode was applied to visualize fenestrae on individual fixed LSECs. Collected images were analyzed using an in-house developed image recognition program based on fully convolutional networks (FCN). Results: Key scanning parameters were first optimized for visualizing the fenestrae on LSECs on culture dish, which was also applicable for the LSECs cultured on various hydrogels. The intermediate-magnification morphology images of LSECs were used for developing the FCN-based, fenestra recognition program. This program enabled us to recognize the vast majority of fenestrae from AFM images after twice trainings at a typical accuracy of 81.6% on soft substrate and also quantify the statistics of porosity, number of fenestrae and distribution of fenestra diameter. Conclusions: Combining AFM imaging with FCN training is able to quantify the morphological distributions of LSEC fenestrae on various substrates. Significance: AFM images acquired and analyzed here provided the global information of surface ultramicroscopic structures over an entire cell, which is fundamental in understanding their regulatory mechanisms and pathophysiological relevance in fenestra-like evolution of individual cells on stiffness-varied substrates.	187.9386531658332
1192.	COVID-19 originally known as Corona VIrus Disease of 2019, has been declared as a pandemic by World Health Organization (WHO) on 11th March 2020. Unprecedented pressures have mounted on each country to make compelling requisites for controlling the population by assessing the cases and properly utilizing available resources. The rapid number of exponential cases globally has become the apprehension of panic, fear and anxiety among people. The mental and physical health of the global population is found to be directly proportional to this pandemic disease. The current situation has reported more than twenty four million people being tested positive worldwide as of 27th August, 2020. Therefore, it is the need of the hour to implement different measures to safeguard the countries by demystifying the pertinent facts and information. This paper aims to bring out the fact that tweets containing all handles related to COVID-19 and WHO have been unsuccessful in guiding people around this pandemic outbreak appositely. This study analyzes two types of tweets gathered during the pandemic times. In one case, around twenty three thousand most re-tweeted tweets within the time span from 1st Jan 2019 to 23rd March 2020 have been analyzed and observation says that the maximum number of the tweets portrays neutral or negative sentiments. On the other hand, a dataset containing 226,668 tweets collected within the time span between December 2019 and May 2020 have been analyzed which contrastingly show that there were a maximum number of positive and neutral tweets tweeted by netizens. The research demonstrates that though people have tweeted mostly positive regarding COVID-19, yet netizens were busy engrossed in re-tweeting the negative tweets and that no useful words could be found in WordCloud or computations using word frequency in tweets. The claims have been validated through a proposed model using deep learning classifiers with admissible accuracy up to 81%. Apart from these the authors have proposed the implementation of a Gaussian membership function based fuzzy rule base to correctly identify sentiments from tweets. The accuracy for the said model yields up to a permissible rate of 79%.	187.93859556209134
1193.	We consider detection based on deep learning, and show it is possible to train detectors that perform well without any knowledge of the underlying channel models. Moreover, when the channel model is known, we demonstrate that it is possible to train detectors that do not require channel state information (CSI). In particular, a technique we call a sliding bidirectional recurrent neural network (SBRNN) is proposed for detection where, after training, the detector estimates the data in real time as the signal stream arrives at the receiver. We evaluate this algorithm, as well as other neural network (NN) architectures, using the Poisson channel model, which is applicable to both optical and molecular communication systems. In addition, we also evaluate the performance of this detection method applied to data sent over a molecular communication platform, where the channel model is difficult to model analytically. We show that SBRNN is computationally efficient, and can perform detection under various channel conditions without knowing the underlying channel model. We also demonstrate that the hit error rate performance of the proposed SBRNN detector is better than that of a Viterbi detector with imperfect CSI as well as that of other NN detectors that have been previously proposed. Finally, we show that the SBRNN can perform well in rapidly changing channels, where the coherence time is on the order of a single symbol duration.	187.93854087186227
1194.	This research develops a novel computer vision approach named a spatial-channel hierarchical network (SCHNet), which is feasible to support the automated and reliable concrete crack segmentation at the pixel level. Specifically, SCHNet with a base net Visual Geometry Group 19 (VGG19) contains a self-attention mechanism, which is realized by three parallel modules, including the feature pyramid attention module, the spatial attention module, and the channel attention module. It can not only consider the semantic interdependencies in spatial and channel dimensions, but also adaptively integrate local features into their global dependencies. The segmentation performance is evaluated by a metric named Mean Intersection over Union (IoU) in a public dataset containing 11,000 cracked and non-cracked images with a unified resolution at 256 x 256 pixels (px). The experimental results confirm the effectiveness of the three attention modules, since they can individually increase Mean IoU by 1.62% (74.16%-72.54%), 5.15% (79.31%-74.16%), and 5.76% (79.92%-74.16%), respectively. With the help of new strategies like the data augmentation and multi-grid method, SCHNet can boost Mean IoU to 85.31%. In a comparison of the state-of-the-art models (i.e. U-net, DeepLab-v2, PSPNet, Ding, Dilated FCN) on the test dataset, SCHNet can outperform others with an improvement of at least 7.51% in Mean IoU. Moreover, SCHNet is robust to noises with a better generalization ability under various conditions, including shadows, roughness surfaces, and holes. Overall, this research contributes to developing SCHNet to integrate spatial and channel information in feature extraction, resulting in a more accurate and efficient crack detection process.	187.9384776641192
1195.	In this letter, we study the numerical solutions of a class of elliptic type of Hamilton-Jacobi-Bellman (HJB) equations, which arise from stochastic control and multiplayer stochastic game problems with random terminal time. Two closely related algorithms are proposed. One of them is to use value iteration on approximating Markov decision processes, and the other is to use a deep-learning approach solving Bellman equations. The convergence is shown by using a viscosity solution approach.	187.9384432547905
1196.	Gastric cancer is the fourth leading cause of cancer-related mortality across the globe, with a 5-year survival rate of less than 40%. In recent years, several applications of artificial intelligence (AI) have emerged in the gastric cancer field based on its efficient computational power and learning capacities, such as image-based diagnosis and prognosis prediction. AI-assisted diagnosis includes pathology, endoscopy, and computerized tomography, while researchers in the prognosis circle focus on recurrence, metastasis, and survival prediction. In this review, a comprehensive literature search was performed on articles published up to April 2020 from the databases of PubMed, Embase, Web of Science, and the Cochrane Library. Thereby the current status of AI-applications was systematically summarized in gastric cancer. Moreover, future directions that target this field were also analyzed to overcome the risk of overfitting AI models and enhance their accuracy as well as the applicability in clinical practice.	187.93841045641838
1197.	Wireless powered mobile-edge computing (MEC) has recently emerged as a promising paradigm to enhance the data processing capability of low-power networks, such as wireless sensor networks and internet of things (IoT). In this paper, we consider a wireless powered MEC network that adopts a binary offloading policy, so that each computation task of wireless devices (WDs) is either executed locally or fully offloaded to an MEC server. Our goal is to acquire an online algorithm that optimally adapts task offloading decisions and wireless resource allocations to the time-varying wireless channel conditions. This requires quickly solving hard combinatorial optimization problems within the channel coherence time, which is hardly achievable with conventional numerical optimization methods. To tackle this problem, we propose a Deep Reinforcement learning-based Online Offloading (DROO) framework that implements a deep neural network as a scalable solution that learns the binary offloading decisions from the experience. It eliminates the need of solving combinatorial optimization problems, and thus greatly reduces the computational complexity especially in large-size networks. To further reduce the complexity, we propose an adaptive procedure that automatically adjusts the parameters of the DROO algorithm on the fly. Numerical results show that the proposed algorithm can achieve near-optimal performance while significantly decreasing the computation time by more than an order of magnitude compared with existing optimization methods. For example, the CPU execution latency of DROO is less than 0.1 second in a 30-user network, making real-time and optimal offloading truly viable even in a fast fading environment.	187.9383998730361
1198.	Objectives The goal of the present study was to classify the most common types of plain radiographs using a neural network and to validate the network's performance on internal and external data. Such a network could help improve various radiological workflows. Methods All radiographs from the year 2017 (n = 71,274) acquired at our institution were retrieved from the PACS. The 30 largest categories (n = 58,219, 81.7% of all radiographs performed in 2017) were used to develop and validate a neural network (MobileNet v1.0) using transfer learning. Image categories were extracted from DICOM metadata (study and image description) and mapped to the WHO manual of diagnostic imaging. As an independent, external validation set, we used images from other institutions that had been stored in our PACS (n = 5324). Results In the internal validation, the overall accuracy of the model was 90.3% (95%CI: 89.2-91.3%), whereas, for the external validation set, the overall accuracy was 94.0% (95%CI: 93.3-94.6%). Conclusions Using data from one single institution, we were able to classify the most common categories of radiographs with a neural network. The network showed good generalizability on the external validation set and could be used to automatically organize a PACS, preselect radiographs so that they can be routed to more specialized networks for abnormality detection or help with other parts of the radiological workflow (e.g., automated hanging protocols; check if ordered image and performed image are the same). The final AI algorithm is publicly available for evaluation and extension.	187.93839928995592
1199.	To design a stable laser vision seam-tracking system, an advanced weld image processing algorithm based on Siamese networks is investigated and proposed to resist the interference of arc and spatter in the welding process. This specially designed neural network, combined with powerful feature expression capabilities of deep learning, takes two welding images with different sizes as inputs and generates a target confidence map in a single forward pass by using the cross-correlation algorithm. To prevent the error accumulation and model drift, an online update strategy via local cosine similarity is developed. The use of metal inert-gas welding can realize real-time and precious tracking under the condition that the strong arc continuously shields the welding seam feature points. (C) 2018 Optical Society of America.	187.93828649356666
1200.	This article reviews the history of artificial intelligence and introduces the reader to major events that prompted interest in the field, as well as pitfalls and challenges that have slowed its development. The purpose of this article is to provide a high-level historical perspective on the development of the field over the past decades, highlighting the potential of the field for transforming health care, but also the importance of setting realistic expectations for artificial intelligence applications to avoid repeating historical cyclical trends and a third "artificial intelligence winter."	187.93825728534858
1201.	BACKGROUND: Machine learning models may help localize the site of origin of ventricular tachycardia (VT) using 12-lead electrocardiograms. However, population-based models suffer from inter-subject anatomical variations within ECG data, while patient-specific models face the open challenge of what pacing data to collect for training. METHODS: This study presents and validates the first hybrid model that combines population and patient-specific machine learning for rapid "computer-guided pace-mapping". A population-based deep learning model was first trained offline to disentangle inter-subject variations and regionalize the site of VT origin. Given a new patient with a target VT, an on-line patient-specific model -- after being initialized by the population-based prediction -- was then built in real time by actively suggesting where to pace next and improving the prediction with each added pacing data, progressively guiding pace-mapping towards the site of VT origin. RESULTS: The population model was trained on pace-mapping data from 38 patients and the patient-specific model was subsequently tuned on one patient. The resulting hybrid model was tested on a separate cohort of eight patients in localizing 1) 193 LV endocardial pacing sites, and 2) nine VTs with clinically determined exit sites. The hybrid model achieved a localization error of 5.32.6mm using 5.42.5 pacing sites in localizing LV pacing sites, achieving a significantly higher accuracy with a significantly smaller amount of training sites in comparison to models without active guidance. CONCLUSION: The presented hybrid model has the potential to assist rapid pace-mapping of interventional targets in VT.	187.93825242465357
1202.	Age prediction based on appearances of different anatomies in medical images has been clinically explored for many decades. In this paper, we used deep learning to predict a person's age on Chest X-Rays. Specifically, we trained a CNN in regression fashion on a large publicly available dataset. Moreover, for interpretability, we explored activation maps to identify which areas of a CXR image are important for the machine (i.e. CNN) to predict a patient's age, offering insight. Overall, amongst correctly predicted CXRs, we see areas near the clavicles, shoulders, spine and mediastinum being most activated for age prediction, as one would expect biologically. As CXR is the most commonly requested imaging exam, a potential use case for estimating age may be found in the preventative counselling of patient health status compared to their age-expected average, particularly when there is a large discrepancy between predicted age and the real patient age.	187.93823239386498
1203.	The electronic Schrodinger equation can only be solved analytically for the hydrogen atom, and the numerically exact full configuration-interaction method is exponentially expensive in the number of electrons. Quantum Monte Carlo methods are a possible way out: they scale well for large molecules, they can be parallelized and their accuracy has, as yet, been only limited by the flexibility of the wavefunction ansatz used. Here we propose PauliNet, a deep-learning wavefunction ansatz that achieves nearly exact solutions of the electronic Schrodinger equation for molecules with up to 30 electrons. PauliNet has a multireference Hartree-Fock solution built in as a baseline, incorporates the physics of valid wavefunctions and is trained using variational quantum Monte Carlo. PauliNet outperforms previous state-of-the-art variational ansatzes for atoms, diatomic molecules and a strongly correlated linear H-10, and matches the accuracy of highly specialized quantum chemistry methods on the transition-state energy of cyclobutadiene, while being computationally efficient.	187.93820306120483
1204.	Software Defined Networking (SDN) is a promising paradigm to provide centralized traffic control. Multimedia traffic control based on SDN is crucial but challenging for Quality of Experience (QoE) optimization. It is very difficult to model and control multimedia traffic because solutions mainly depend on an understanding of the network environment, which is complicated and dynamic. Inspired by the recent advances in artificial intelligence (AI) technologies, we study the adaptive multimedia traffic control mechanism leveraging Deep Reinforcement Learning (DRL). This paradigm combines deep learning with reinforcement learning, which learns solely from rewards by trial-and-error. Results demonstrate that the proposed mechanism is able to control multimedia traffic directly from experience without referring to a mathematical model.	187.93819405251782
1205.	Mask-based lensless imaging cameras have many applications due to their smaller volumes and lower costs. However, due to the ill-nature of the inverse problem, the reconstructed images have low resolution and poor quality. In this article, we use a mask based on almost perfect sequence which has an excellent autocorrelation property for lensless imaging and propose a Learned Analytic solution Net for image reconstruction under the framework of unrolled optimization. Our network combines a physical imaging model with deep learning to achieve high-quality image reconstruction. The experimental results indicate that our reconstructed images at a resolution of 512*512 have excellent performances in both visual effects and objective evaluations.	187.93815595486438
1206.	Currently, breast tissue images are primarily classified by pathologists, which is time-consuming and subjective. Deep learning, however, can perform this task with the utmost precision. In order to achieve an improved performance, a large number of annotated datasets are required to train the network, which is a challenging task in the medical field. In this paper, we propose an intelligent system, based on generative adversarial networks (GANs) and a convolution neural network (CNN) for the automatic classification of breast cancer, using optical coherence tomography (OCT) images. In this network, the GAN is used to generate synthetic datasets and to further utilize these synthetic datasets to increase the quantity of information, so as to improve the classification performance of the CNN. Our method is demonstrated by means of a limited set of OCT images of breast tissue. The classification performance of our method, using only the classic data increase, yielded a sensitivity level of 93.6%, with 90.8% specificity and 91.7% accuracy, based on the test datasets. By adding the synthetic data increase, the accuracy of the training datasets increased to 93.7% from 92.0%. We believe that this approach will help radiologists and pathologists to improve their diagnotic capability.	187.9381082076172
1207.	Recently, deep learning has been successfully applied to molecular graph generation. Nevertheless, mitigating the computational complexity, which increases with the number of nodes in a graph, has been a major challenge. This has hindered the application of deep learning-based molecular graph generation to large molecules with many heavy atoms. In this study, we present a molecular graph compression method to alleviate the complexity while maintaining the capability of generating chemically valid and diverse molecular graphs. We designate six small substructural patterns that are prevalent between two atoms in real-world molecules. These relevant substructures in a molecular graph are then converted to edges by regarding them as additional edge features along with the bond types. This reduces the number of nodes significantly without any information loss. Consequently, a generative model can be constructed in a more efficient and scalable manner with large molecules on a compressed graph representation. We demonstrate the effectiveness of the proposed method for molecules with up to 88 heavy atoms using the GuacaMol benchmark.	187.93808410219557
1208.	Recently, deep convolutional neural networks (CNN) have become popular for indoor visual localisation, where the networks learn to regress the camera pose from images directly. However, these approaches perform a 3D image-based reconstruction of the indoor spaces beforehand to determine camera poses, which is a challenge for large indoor spaces. Synthetic images derived from 3D indoor models have been used to eliminate the requirement of 3D reconstruction. A limitation of the approach is the low accuracy that occurs as a result of estimating the pose of each image frame independently. In this article, a visual localisation approach is proposed that exploits the spatio-temporal information from synthetic image sequences to improve localisation accuracy. A deep Bayesian recurrent CNN is fine-tuned using synthetic image sequences obtained from a building information model (BIM) to regress the pose of real image sequences. The results of the experiments indicate that the proposed approach estimates a smoother trajectory with smaller inter-frame error as compared to existing methods. The achievable accuracy with the proposed approach is 1.6 m, which is an improvement of approximately thirty per cent compared to the existing approaches. A Keras implementation can be found in our Github repository.	187.93808233789133
1209.	Gliomas are the most infiltrative and life-threatening brain tumors with exceptionally quick development. Gliomas segmentation using computer-aided diagnosis is a challenging task, due to irregular shape and diffused boundaries of tumor with the surrounding area. Magnetic resonance imaging (MRI) is the most widely used method for imaging structures of interest in human brain. In this study, a deep learning-based method that uses different modalities of MRI is presented for the segmentation of brain tumor. The proposed hybrid convolutional neural network architecture uses patch-based approach and takes both local and contextual information into account, while predicting output label. The proposed network deals with over-fitting problem by utilizing dropout regularizer alongside batch normalization, whereas data imbalance problem is dealt with by using two-phase training procedure. The proposed method contains a preprocessing step, in which images are normalized and bias field corrected, a feed-forward pass through a CNN and a post-processing step, which is used to remove small false positives around the skull portion. The proposed method is validated on BRATS 2013 dataset, where it achieves scores of 0.86, 0.86 and 0.91 in terms of dice score, sensitivity and specificity for whole tumor region, improving results compared to the state-of-the-art techniques.	187.93807271916867
1210.	Manual seizure detection in clinical electroencephalography (EEG) is time consuming and requires extensive training. In addition, the seizure origin and spreading pattern is valuable for therapeutic planning but cannot always be manually disambiguated. Prior work in automated seizure detection has focused on engineering new features that better capture the seizure activity. However, these methods ignore crucial information in the data and are not sensitive enough to track the seizure propagation. In this work we introduce a hybrid Probabilistic Graphical Model-Convolutional Neural Network (PGM-CNN) for seizure tracking in multichannel EEG. Our model leverages the power of deep learning for data driven analysis of the raw EEG time series while retaining clinically relevant information through the latent PGM prior. We validate our hybrid model on clinical EEG data from two hospitals with distinct patient populations. Our system achieves better detection performance than baseline methods, which exclusively use PGMs or neural networks.	187.9380378078416
1211.	Accurate segmenting nuclei instances is a crucial step in computer-aided image analysis to extract rich features for cellular estimation and following diagnosis as well as treatment. While it still remains challenging because the wide existence of nuclei clusters, along with the large morphological variances among different organs make nuclei instance segmentation susceptible to over-/under-segmentation. Additionally, the inevitably subjective annotating and mislabeling prevent the network learning from reliable samples and eventually reduce the generalization capability for robustly segmenting unseen organ nuclei. To address these issues, we propose a novel deep neural network, namely Contour-aware Informative Aggregation Network (CIA-Net) with multilevel information aggregation module between two task-specific decoders. Rather than independent decoders, it leverages the merit of spatial and texture dependencies between nuclei and contour by bi-directionally aggregating task-specific features. Furthermore, we proposed a novel smooth truncated loss that modulates losses to reduce the perturbation from outliers. Consequently, the network can focus on learning from reliable and informative samples, which inherently improves the generalization capability. Experiments on the 2018 MICCAI challenge of Multi-Organ-Nuclei-Segmentation validated the effectiveness of our proposed method, surpassing all the other 35 competitive teams by a significant margin.	187.93802494378835
1212.	In this paper, we propose an enhanced bi-prediction scheme based on the convolutional neural network (CNN) to improve the rate-distortion performance in video compression. In contrast to the traditional bi-prediction strategy which computes the linear superposition as the predictive signals with pixel-to-pixel correspondence, the proposed scheme employs CNN to directly infer the predictive signals in a data-driven manner. As such, the predicted blocks are fused in a nonlinear fashion to improve the coding performance. Moreover, the patch-to-patch inference strategy with CNN also improves the prediction accuracy since the patch-level information for the prediction of each individual pixel can be exploited. The proposed enhanced bi-prediction scheme is further incorporated into the high-efficiency video coding standard, and the experimental results exhibit a significant performance improvement under different coding configurations.	187.9379833783637
1213.	Owing to recent advancements, very deep convolutional neural networks (CNNs) have found application in image denoising. However, while deeper models lead to better restoration performance, they are marred by a high number of parameters and increased training difficulty. To address these issues, we propose a CNN-based framework, named dilated residual encode-decode networks (DRED-Net), for image denoising, which learns direct end-to-end mappings from corrupted images to obtain clean images using few parameters. Our proposed network consists of multiple layers of convolution and deconvolution operators; in addition, we use dilated convolutions to boost the performance of our network without increasing the depth of the model or its complexity. Extensive experiments on synthetic noisy images are conducted to evaluate DRED-Net, and the results are compared with those obtained using state-of-the-art denoising methods. Our experimental results show that DRED-Net leads to results comparable with those obtained using other state-of-the-art methods for image denoising tasks. (C) 2018 SPIE and IS&T	187.93781026330822
1214.	Advances in large-scale connectivity mapping of the brain require efficient computational tools to detect fine structures across large volumes of images, which poses challenges. The authors introduce a hybrid architecture that incorporates topological priors of neuronal structures with deep learning models to improve semantic segmentation of neuroanatomical image data. Understanding of neuronal circuitry at cellular resolution within the brain has relied on neuron tracing methods that involve careful observation and interpretation by experienced neuroscientists. With recent developments in imaging and digitization, this approach is no longer feasible with the large-scale (terabyte to petabyte range) images. Machine-learning-based techniques, using deep networks, provide an efficient alternative to the problem. However, these methods rely on very large volumes of annotated images for training and have error rates that are too high for scientific data analysis, and thus requires a substantial volume of human-in-the-loop proofreading. Here we introduce a hybrid architecture combining prior structure in the form of topological data analysis methods, based on discrete Morse theory, with the best-in-class deep-net architectures for the neuronal connectivity analysis. We show significant performance gains using our hybrid architecture on detection of topological structure (for example, connectivity of neuronal processes and local intensity maxima on axons corresponding to synaptic swellings) with precision and recall close to 90% compared with human observers. We have adapted our architecture to a high-performance pipeline capable of semantic segmentation of light-microscopic whole-brain image data into a hierarchy of neuronal compartments. We expect that the hybrid architecture incorporating discrete Morse techniques into deep nets will generalize to other data domains.	187.9377794746283
1215.	Objectives: A deep learning-based early warning system is proposed to predict sepsis prior to its onset. Design: A novel algorithm was devised to detect sepsis 6 hours prior to its onset based on electronic medical records. Setting: Retrospective cohorts from three separate hospitals are used in this study. Sepsis onset was defined based on Sepsis-3. Algorithms are evaluated based on the score function used in the Physionet Challenge 2019.Patients: Over 60,000 ICU patients with 40 clinical variables (vital signs, laboratory results) for each hour of a patient's ICU stay were used. Interventions: None. Measurements and Main Results: The proposed algorithm predicted the onset of sepsis in the precedingnhours (wheren= 4, 6, 8, or 12). Furthermore, the proposed method compared how many sepsis patients can be predicted in a short time with other methods. To interpret a given result in a clinical perspective, the relationship between input variables and the probability of the proposed method were presented. The proposed method achieved superior results (area under the receiver operating characteristic curve, area under the precision-recall curve, and score) and predicted more sepsis patients in advance. In official phase, the proposed method showed the utility score of -0.101, area under the receiver operating characteristic curve 0.782, area under the precision-recall curve 0.041, accuracy 0.786, and F-measure 0.046. Conclusions: Using Physionet Challenge 2019, the proposed method can accurately and early predict the onset of sepsis. The proposed method can be a practical early warning system in the environment of real hospitals.	187.93768652519162
1216.	Weakly supervised semantic segmentation receives much research attention since it alleviates the need to obtain a large amount of dense pixel-wise ground-truth annotations for the training images. Compared with other forms of weak supervision, image labels are quite efficient to obtain. In this paper, we focus on the weakly supervised semantic segmentation with image label annotations. Recent progress for this task has been largely dependent on the quality of generated pseudo-annotations. In this paper, inspired by spatial neural-attention for image captioning, we propose a decoupled spatial neural attention network for generating pseudo-annotations. Our decoupled attention structure could simultaneously identify the object regions and localize the discriminative parts, which generates high-quality pseudo-annotations in one forward path. The generated pseudo-annotations lead to the segmentation results that achieve the state of the art in weakly supervised semantic segmentation.	187.93764689373745
1217.	The understanding of mangrove forest structure and dynamics at species level is essential for mangrove conservation and management. To classify mangrove species, remote-sensing technologies provide a better way with high spatial resolution image. The spatial structure is usually viewed as effective complementary information for classification. However, it is still a challenge to design handcrafted features for mangrove species due to their non-structure texture. To leverage the advantage of convolutional neural networks (CNNs) in abstract feature exploration, a small patch-based CNN is proposed to overcome the requirement of fixed and large input which limits the applicability of CNNs to fringe mangrove forests. The function of down-sampling technology was substantially reduced to make deeper network for small input in our work. Meanwhile, the inception structure is used to exploit the multi-scale features of mangrove forests. Furthermore, the network is optimized with lesser convolution kernels and a single fully connected layer to reduce overfitting via reducing the training parameters. Compared to the features of grey level co-occurrence matrix with support vector machine, our proposed CNN shows better performance in classification accuracy. Moreover, the differences between mangrove species can be perceptive via CNN visualization, which offers better understanding of mangrove forests.	187.93746788901524
1218.	This paper considers the problem of positive unlabeled (PU) learning. In this context, we propose a two-stage GAN-based model. More specifically, the main contribution is to incorporate a biased PU risk within the standard GAN discriminator loss function. In this manner, the discriminator is constrained to steer the generator to converge towards the unlabeled samples distribution while diverging from the positive samples distribution. Consequently, the proposed model, referred to as D-GAN, exclusively learns the counter-examples distribution without prior knowledge. Experimental results on simple and complex image datasets demonstrate that our approach outperforms state-of-the-art PU methods without prior by overcoming issues such as sensitivity to prior knowledge or first-stage overfitting. (C) 2020 Elsevier Ltd. All rights reserved.	187.93745557728084
1219.	Electronic health records (EHR) are an important source of information to detect adverse events in patients. In-hospital fall incidents represent the largest category of adverse event reports. The detection of such incidents leads to better understanding of the event and improves the quality of patient health care. In this work, we evaluate several language models with state-of-the art recurrent neural networks (RNN) to detect fall incidents in progress notes. Our experiments show that the deep-learning approach outperforms previous works in the task of detecting fall events. Vector representation of words in the biomedical domain was able to detect falls with an F-Measure of 90%. Additionally, we made available an annotated dataset with 1,078 de-identified progress notes for replication purposes.	187.93743255831055
1220.	With the emergence of mobile and wearable devices, push notification becomes a powerful tool to connect and maintain the relationship with app users, but sending inappropriate or too many messages at the wrong time may result in the app being removed by the users. In order to maintain the retention rate and the delivery rate of advertisement, we adopt deep neural network (DNN) to develop a pop-up recommendation system "Click-sequence-aware deeP neural network (DNN)-based Pop-uPs recOmmendation (C-3PO)" enabled by collaborative filtering-based hybrid user behavioral analysis. We further verified the system with real data collected from the product security master, clean master, and CM browser, supported by Leopard Mobile Inc. (Cheetah Mobile Taiwan Agency). In this way, we can know precisely about users' preference and frequency to click on the push notification/pop-ups, decrease the troublesome to users efficiently, and meanwhile increase the click-through rate of push notifications/pop-ups.	187.93737242757015
1221.	This research describes "EspiNet", a Deep Learning Convolutional Neural Network model, in conjunction with a Markov Decision Process (MDP) tracker for detection and tracking of occluded motorcycles in urban environments. The model is trained and evaluated, using a new public dataset with up to 10,000 annotated images, created for this research, and captured in real urban traffic scenes. Images were captured using a moving camera mounted in a drone, where more than 60% of the motorcycles are affected by occlusions. The network design involves many tests, where a promising result of 88.84% in average precision (AP) is achieved, despite the considerable number of occluded vehicles, the movement of the camera and the low angle used for capture. The model predictions are used as input to an MDP tracker, reaching results up to 85.2% in Multiple Object Tracking Accuracy (MOTA). The proposed network architecture outperforms state of the art YOLO (You Look Only Once) v3.0 and Faster R-CNN (VGG16 based) detection models, producing also better tracking results in comparison with the use of the other two models as detector base for the MDP tracker.	187.93733321548436
1222.	Hyperspectral imaging is a widely used technique in remote sensing in which an imaging spectrometer collects hundreds of images (at different wavelength channels) for the same area on the surface of the earth. In the last two decades, several methods (unsupervised, supervised, and semisupervised) have been proposed to deal with the hyperspectral image classification problem. Supervised techniques have been generally more popular, despite the fact that it is difficult to collect labeled samples in real scenarios. In particular, deep neural networks, such as convolutional neural networks (CNNs), have recently shown a great potential to yield high performance in the hyperspectral image classification. However, these techniques require sufficient labeled samples in order to perform properly and generalize well. Obtaining labeled data is expensive and time consuming, and the high dimensionality of hyperspectral data makes it difficult to design classifiers based on limited samples (for instance, CNNs overfit quickly with small training sets). Active learning (AL) can deal with this problem by training the model with a small set of labeled samples that is reinforced by the acquisition of new unlabeled samples. In this paper, we develop a new AL-guided classification model that exploits both the spectral information and the spatial-amtextual information in the hyperspectral data. The proposed model makes use of recently developed Bayesian CNNs. Our newly developed technique provides robust classification results when compared with other state-of-the-art techniques for hyperspectral image classification.	187.9372454888652
1223.	Since the curvature induced variations of mode interference in multimode fiber (MMF) can be well represented by the fiber specklegrams, a bending recognition scheme based on the analysis of MMF specklegrams is proposed and verified. Amounts of specklegrams from the facet of MMF under different bendings were detected and used for training and testing in an image recognition algorithm based on deep learning. Good recognition results are provided by the specklegrams from MMF with diameter being 105 and 200 mu m, for which the average accuracies of bending status recognition are respectively 92.8% and 96.6%. Because specklegram can represent the status of the whole section of MMF, such scheme indicates the capability to distinguish the specklegrams even when the MMF is under complicated bending. In this sense, the scheme presents the potential of a single MMF being used as a bending indicator or status monitor independently, which may find applications in distinguishing the status of certain structures, such as robotic arms, mechanical fingers and some disabled auxiliary equipments.	187.9372390696192
1224.	The automation and intellectualization of the manufacturing processes in the iron and steel industry needs the strong support of inspection technologies, which play an important role in the field of quality control. At present, visual inspection technology based on image processing has an absolute advantage because of its intuitive nature, convenience, and efficiency. A major breakthrough in this field can be achieved if sufficient research regarding visual inspection technologies is undertaken. Therefore, the purpose of this article is to study the latest developments in steel inspection relating to the detected object, system hardware, and system software, existing problems of current inspection technologies, and future research directions. The paper mainly focuses on the research status and trends of inspection technology. The network framework based on deep learning provides space for the development of end-to-end mode inspection technology, which would greatly promote the implementation of intelligent manufacturing.	187.93722390014878
1225.	Acute Leukemia is a life-threatening disease common both in children and adults that can lead to death if left untreated. Acute Lymphoblastic Leukemia (ALL) spreads out in children's bodies rapidly and takes the life within a few weeks. To diagnose ALL, the hematologists perform blood and bone marrow examination. Manual blood testing techniques that have been used since long time are often slow and come out with the less accurate diagnosis. This work improves the diagnosis of ALL with a computer-aided system, which yields accurate result by using image processing and deep learning techniques. This research proposed a method for the classification of ALL into its subtypes and reactive bone marrow (normal) in stained bone marrow images. A robust segmentation and deep learning techniques with the convolutional neural network are used to train the model on the bone marrow images to achieve accurate classification results. Experimental results thus obtained and compared with the results of other classifiers Naive Bayesian, KNN, and SVM. Experimental results reveal that the proposed method achieved 97.78% accuracy. The obtained results exhibit that the proposed approach could be used as a tool to diagnose Acute Lymphoblastic Leukemia and its sub-types that will definitely assist pathologists.	187.9371719584475
1226.	The essential sequences in breast magnetic resonance imaging (MRI) are the dynamic contrast-enhanced (DCE) images, which are widely used in clinical settings. Diffusion-weighted imaging (DWI) MRI also plays an important role in many diagnostic applications and in developing novel imaging bio-makers. Compared to DCE MRI, technical advantages of DWI include a shorter acquisition time, no need for administration of any contrast agent, and availability on most commercial scanners. Segmenting the whole-breast region is an essential pre-processing step in many quantitative and radiomics breast MRI studies. However, it is a challenging task for computerized methods due to the low contrast of intensity along breast chest wall boundaries. While several studies have reported computational methods for automated whole-breast segmentation in DCE MRI, the segmentation in DWI MRI is still underdeveloped. In this paper, we propose to use deep learning and transfer learning methods to segment the whole-breast in DWI MRI, by leveraging pre-training on a DCE MRI dataset. Experiments are reported in multiple breast MRI datasets including an external evaluation dataset and encouraging results are demonstrated.	187.93710694610155
1227.	Polar mesocyclones (MCs) are small marine atmospheric vortices. The class of intense MCs, called polar lows, are accompanied by extremely strong surface winds and heat fluxes and thus largely influencing deep ocean water formation in the polar regions. Accurate detection of polar mesocyclones in high-resolution satellite data, while challenging, is a time-consuming task, when performed manually. Existing algorithms for the automatic detection of polar mesocyclones are based on the conventional analysis of patterns of cloudiness and they involve different empirically defined thresholds of geophysical variables. As a result, various detection methods typically reveal very different results when applied to a single dataset. We develop a conceptually novel approach for the detection of MCs based on the use of deep convolutional neural networks (DCNNs). As a first step, we demonstrate that DCNN model is capable of performing binary classification of 500 x 500 km patches of satellite images regarding MC patterns presence in it. The training dataset is based on the reference database of MCs manually tracked in the Southern Hemisphere from satellite mosaics. We use a subset of this database with MC diameters falling in the range of 200-400 km. This dataset is further used for testing several different DCNN setups, specifically, DCNN built from scratch, DCNN based on VGG16 pre-trained weights also engaging the Transfer Learning technique, and DCNN based on VGG16 with Fine Tuning technique. Each of these networks is further applied to both infrared (IR) and a combination of infrared and water vapor (IR + WV) satellite imagery. The best skills (97% in terms of the binary classification accuracy score) is achieved with the model that averages the estimates of the ensemble of different DCNNs. The algorithm can be further extended to the automatic identification and tracking numerical scheme and applied to other atmospheric phenomena that are characterized by a distinct signature in satellite imagery.	187.93695413448927
1228.	We propose a hybrid sequential prediction model called "Deep Sequence", integrating radiomics-engineered imaging features, demographic, and visual factors, with a recursive neural network (RNN) model in the same platform to predict the risk of exudation within a future time-frame in non-exudative AMD eyes. The proposed model provides scores associated with risk of exudation in the short term (within 3 months) and long term (within 21 months), handling challenges related to variability of OCT scan characteristics and the size of the training cohort. We used a retrospective clinical trial dataset that includes 671 AMD fellow eyes with 13,954 observations before any signs of exudation for training and validation in a tenfold cross validation setting. Deep Sequence achieved high performance for the prediction of exudation within 3 months (0.96 +/- 0.02 AUCROC) and within 21 months (0.97 +/- 0.02 AUCROC) on cross-validation. Training the proposed model on this clinical trial dataset and testing it on an external real-world clinical dataset showed high performance for the prediction within 3-months (0.82 AUCROC) but a clear decrease in performance for the prediction within 21-months (0.68 AUCROC). While performance differences at longer time intervals may be derived from dataset differences, we believe that the high performance and generalizability achieved in short-term predictions may have a high clinical impact allowing for optimal patient follow-up, adding the possibility of more frequent, detailed screening and tailored treatments for those patients with imminent risk of exudation.	187.93688413332856
1229.	Crop evapotranspiration (ETc) is one of the most basic components of the hydrologic cycle that is effective in irrigation system design and management, water resources planning and scheduling, and hydrologic water balance. Thus, precise estimation of ETc is valuable for various applications of agricultural water engineering, especially in developing countries such as Egypt, which has lack of meteorological data, high cost and time to calculate ETc, and lack of information on future ETc values to consider management scenarios and increase production potential. Also, due to the existence of different climates in Egypt, the estimate of ETc has become a challenge. To this end, the aim of this study was to estimate the ETc to eliminate the limitations mentioned, and analyze the long-term dynamics of ETc based on limited climate data and simple method. Three Egyptian governorates namely Ad Daqahliyah, Ash Sharqiyah, and Kafr ash Shaykh of Nile Delta, were selected as major wheat-producing sites. The required historical required climatic data were collected from open access data library while future data were from two extreme scenarios of the Representative Concentration Pathways (RCP) i.e., RCP 4.5, and RCP 8.5. The available dataset was divided into three parts: (i) calibration from 1970-2000, (ii) validation from 2000-2017, and (iii) prediction from 2022-2035. The deep neural network (DNN) was employed for incorporating historical data and predicting future ETc. For the evaluation of generated DNN models, the research finding indicates that the correlation coefficients between actual versus predicted monthly ETc were found to be 0.95, 0.96, and 0.97 for calibration period, and 0.94, 0.95 and 0.95 for validation at Ad Daqahliyah, Kafr ash Shaykh, and Ash Sharqiyah regions, respectively. For the simulation of future climatic data, maximum temperature (T-max) will increased by 5.19 %, 4.22 %, and 20.82 %, minimum temperature (T-min) will increased by 1.62 %, 36.44 %, and 27.80 %, and solar radiation (SR) will increased by 6.53 %, 18.74 %, and 28.83 % for the study locations, respectively. Moreover, the DNN model exposed that the Kafr ash Shaykh attain the highest values of ETc with an increase of 11.31 %, slightly increased of 1.38 % for Ad Daqahliyah, and decreased by 15.09 % for Ash Sharqiyah in comparison to the historical data. Thus, the proposed model of crop water-use prediction effectively estimated ETc of wheat and make an efficient decision. The developed models produced satisfactory results for water managers to save water and achieve the sustainability of agricultural water.	187.93684158850752
1230.	With the application of new high throughput sequencing technology, a large number of protein sequences is becoming available. Determination of the functional characteristics of these proteins by experiments is an expensive endeavor that requires a lot of time. Furthermore, at the organismal level, such kind of experimental functional analyses can be conducted only for a very few selected model organisms. Computational function prediction methods can be used to fill this gap. The functions of proteins are classified by Gene Ontology (GO), which contains more than 40,000 classifications in three domains, Molecular Function (MF), Biological Process (BP), and Cellular Component (CC). Additionally, since proteins have many functions, function prediction represents a multi-label and multi-class problem. We developed a new method to predict protein function from sequence. To this end, natural language model was used to generate word embedding of sequence and learn features from it by deep learning, and additional features to locate every protein. Our method uses the dependencies between GO classes as background information to construct a deep learning model. We evaluate our method using the standards established by the Computational Assessment of Function Annotation (CAFA) and have noticeable improvement over several algorithms, such as FFPred, DeepGO, GoFDR and other methods compared on the CAFA3 datasets.	187.93677686729063
1231.	This work presents a novel approach to finding linkage/association between multimodal brain imaging data, such as structural MRI (sMRI) and functional MRI (fMRI). Motivated by the machine translation domain, we employ a deep learning model, and consider two different imaging views of the same brain like two different languages conveying some common facts. That analogy enables finding linkages between two modalities. The proposed translation-based fusion model contains a computing layer that learns "alignments" (or links) between dynamic connectivity features from fMRI data and static gray matter patterns from sMRI data. The approach is evaluated on a multi-site dataset consisting of eyes-closed resting state imaging data collected from 298 subjects (age- and gender matched 154 healthy controls and 144 patients with schizophrenia). Results are further confirmed on an independent dataset consisting of eyes-open resting state imaging data from 189 subjects (age- and gender matched 91 healthy controls and 98 patients with schizophrenia). We used dynamic functional connectivity (dFNC) states as the functional features and ICA-based sources from gray matter densities as the structural features. The dFNC states characterized by weakly correlated intrinsic connectivity networks (ICNs) were found to have stronger association with putamen and insular gray matter pattern, while the dFNC states of profuse strongly correlated ICNs exhibited stronger links with the gray matter pattern in precuneus, posterior cingulate cortex (PCC), and temporal cortex. Further investigation with the estimated link strength (or alignment score) showed significant group differences between healthy controls and patients with schizophrenia in several key regions including temporal lobe, and linked these to connectivity states showing less occupancy in healthy controls. Moreover, this novel approach revealed significant correlation between a cognitive score (attention/vigilance) and the function/structure alignment score that was not detected when data modalities were considered separately.	187.9367561274944
1232.	The aim is to develop a computer vision-based method for automatic recognition of nursing interactions under commercial farm conditions by using spatial and temporal information of nursing behaviour. For spatial information extraction, the spatial distribution between the mother sow and her piglets during nursing was used to detect the possible nursing episodes. Sows were segmented accurately by a fully convolutional network, and udder zones were calculated dynamically by the geometrical properties of the nursing sow and the piglet length. Spatial information from piglets was extracted in the self-adaptive udder zones. For temporal information extraction, to distinguish behaviours similar to nursing, temporal motion information about the intensity of motion and the occupation index was extracted from optical flow of the udder zones. Six sows with 64 piglets, each on different days postpartum, were captured on videos. From these videos, 507 episodes of videos of two sows were selected as training set and 502 episodes of another two sows were used as test set. The accuracy, sensitivity and specificity achieved 96.4%, 92.0% and 98.5%, respectively. In addition, our method was used to recognise the nursing behaviour in four extended videos of the two remaining sows. The accuracy achieved reached 97.6% with a sensitivity of 90.9% and with a specificity of 99.2%. The results show that the recognition method designed represents a significant step forward in automatically identifying nursing behaviour in commercial pig farms. (C) 2018 IAgrE. Published by Elsevier Ltd. All rights reserved.	187.9366071557574
1233.	Pedestrian detection has achieved great improvements in recent years, while complex occlusion handling and high-accurate localization are still the most important problems. To take advantage of the body part semantic information and the contextual information for pedestrian detection, we propose the part and context network (PCN) in this paper. A PCN is composed of three branches: the basic branch; the part branch; and the context branch. It specially utilizes two branches to detect the pedestrians through the body part semantic information and the contextual information, respectively. In the part branch, the semantic information of body parts can communicate with each other via long short-term memory (LSTM). In the context branch, we adopt a local competition mechanism (maxout) for adaptive context scale selection. By combining the outputs of all branches, we develop a strong complementary pedestrian detector with a lower miss rate and higher localization accuracy, especially for the occlusion pedestrian. The combination of the body part semantic information and the contextual information in pedestrian detection is fully explored in this paper. Comprehensive evaluations on three challenging pedestrian detection datasets (i.e., Caltech, INRIA and KITTI) well demonstrate the effectiveness of our proposed PCN.	187.93658442937658
1234.	The advent of big data and deep learning algorithms has promoted a major shift toward data-driven methods in medical image analysis recently. However, the medical image analysis field has a long and rich history inclusive of both knowledge-driven and data-driven methodologies. In the present article, we provide a historical review of an illustrative sample of medical image analysis methods and locate them along a knowledge-driven versus data-driven continuum. In doing so, we highlight the historical importance as well as current-day relevance of more traditional, knowledge-based artificial intelligence approaches and their complementarity with fully data-driven techniques such as deep learning.	187.93655287196128
1235.	Nowadays, Satellite images are used for various analysis, including building detection and road extraction, which are directly beneficial to governmental applications, such as urbanization and monitoring the environment. Spatial resolution is an element of crucial impact on the usage of remote sensing imagery. High spatial resolution means satellite images provide more detailed information. To improve the spatial resolution at the sensor level, many factors are ought to be taken into consideration, such as the manufacturing process. Moreover, once the satellite is launched, no further action can be taken from the perspective of hardware. Therefore, a more practical solution to improve the resolution of a satellite image is to use Single Image Super Resolution (SISR) techniques. This research proposal deals with the re-design, implementation, and evaluation of SISR technique using Deep Convolutional Neural Network with Skip Connections and Network in Network (DCSCN) for enlarging multispectral remote sensing images captured by DubaiSat-2 (DS-2) and estimating the missing high frequency details. The goal is to achieve high performance in terms of quality, and to test whether training the network using luminance channel only, which is extracted from YCbCr domain, can achieve high quality results. For this purpose, DCSCN is trained, evaluated, and tested using a dataset collected from DS-2. A single low resolution DS-2 image is used to construct its high resolution version by training the model from scratch and fine-tuning its hyper-parameters to produce optimal results. The performance is evaluated using various quality indices, such as Structural Similarity Index Measurement (SSIM), Peak Signal-to-Noise Ratio (PSNR), and Wavelet domain Signal-to-Noise Ratio (WSNR). The performance is compared to other state-of-the-art methods, such as Bil-inear, Bi-cubic, and Lanczos interpolation.	187.9364745095616
1236.	In comparison with static image object detection, focusing on video objects has greater research significance in realizing intelligent monitoring and automatic anomaly detection. However, it may be challenging to apply the most advanced image recognition networks to video data, as the number of static frame files represented in a video is often huge, thereby causing the problem of the slow evaluation speed, in addition to other issues, such as motion blur, low resolution, occlusion, and object deformation. In the present study, to mitigate these deficiencies, we applied sparse feature propagation to improve the detection speed and dense feature aggregation to refine the detection accuracy. Moreover, we utilized the key frame scheduling strategy relying on the consistency of feature information. Implementing these technologies allowed steadily improving the detection speed and accuracy to achieve high performance. To verify the applicability of the optimized video detection strategy proposed in this paper, we selected the part of the video data in the ImageNet VID training dataset. Then, the other part of this dataset was used to conduct the experiments, including the calculation and comparison of mean average precision (MAP) and frames per second (FPS).	187.93639134905817
1237.	Accurate knowledge of the vehicle states is the foundation of vehicle motion control. However, in real implementations, sensory signals are always corrupted by delays and noises. Network induced time-varying delays and measurement noises can be a hazard in the active safety of over-actuated electric vehicles (EVs). In this paper, a brain-inspired proprioceptive system based on state-of-the-art deep learning and data fusion technique is proposed to solve this problem in autonomous four-wheel actuated EVs. A deep recurrent neural network (RNN) is trained by the noisy and delayed measurement signals to make accurate predictions of the vehicle motion states. Then unscented Kalman predictor, which is the adaption of unscented Kalman filter in time-varying-delay situations, combines the predictions of the RNN and corrupted sensory signals to provide better perceptions of the locomotion. Simulations with a high-fidelity, CarSim, full-vehicle model are carried out to show the effectiveness of our RNN framework and the entire proprioceptive system.	187.93637070713208
1238.	Semantic segmentation is an end-to-end task that requires both semantic and spatial accuracy. It is important for deep learning-based segmentation methods to effectively utilize the high-level feature map whose semantic information is abundant and the low-level feature map whose spatial information is accurate. However, existing segmentation networks typically cannot take full advantage of these two kinds of feature maps, leading to inferior performance. This paper attempts to overcome this challenge by introducing two novel structures. On the one hand, we propose a structure called stride spatial pyramid pooling (SSPP) to capture multiscale semantic information from the high-level feature map. Compared with existing pyramid pooling methods based on the atrous convolution, the SSPP structure is able to gather more information from the high-level feature map with faster inference speed, which improves the utilization efficiency of the high-level feature map significantly. On the other hand, we propose a dual attention decoder consisting of a channel attention branch and a spatial attention branch to make full use of the high- and low-level feature maps simultaneously. The dual attention decoder can result in a more "semantic" low-level feature map and a high-level feature map with more accurate spatial information, which bridges the gap between these two kinds of feature maps and benefits their fusion. We evaluate the proposed model on several publicly available semantic image segmentation benchmarks including PASCAL VOC 2012, Cityscapes and COCO-Stuff. The qualitative and quantitative results demonstrate that our method can achieve the state-of-the-art performance. (C) 2020 Elsevier Ltd. All rights reserved.	187.93634090947205
1239.	BACKGROUND: Traditional endoscopy is an invasive and painful method of examining the gastrointestinal tract (GIT) not supported by the physicians and patients. To handle this issue, video endoscopy (VE) or wireless capsule endoscopy (WCE) is recommended and utilized for GIT examination. Furthermore, manual assessment of captured images is not possible for an expert physician because it's a time taking task to analyze thousands of images thoroughly. Hence, there comes the need for a Computer-Aided-Diagnosis (CAD) method to help doctors in the analysis of images. Many researchers have proposed techniques for automated recognition and classification of abnormality in captured images. INTRODUCTION: In this article, existing methods for automated classification, segmentation and detection of several GI diseases are discussed. Paper gives a comprehensive detail about these state-of-the-art methods. Furthermore, literature is divided into several subsections based on preprocessing techniques, segmentation techniques, handcrafted features based techniques and deep learning based techniques. Finally, issues, challenges and limitations are also undertaken. CONCLUSION: This comprehensive review article combines information related to a number of GI diseases diagnosis methods at one place. Study of this article will facilitate the researchers to develop new algorithms and approaches for early detection of GI diseases detection with more promising results as compared to the existing ones of literature. RESULTS: A comparative analysis of different approaches for the detection and classification of GI infections.	187.93632968585197
1240.	Subspace clustering aims to separate the data into clusters under the hypothesis that the samples within the same cluster will lie in the same low-dimensional subspace. Due to the tough pairwise constraints, k-subspace clustering is sensitive to outliers and initialization. In this letter, we present a novel deep architecture for k-subspace clustering to address this issue, called as Deep Weighted k-Subspace Clustering (DWSC). Specifically, our framework consists of autoencoder and weighted k-subsapce network. We first use the autoencoder to non-linearly compress the samples into the low-dimensional latent space. In the weighted k-subspace network, we feed the latent representation into the assignment network to output soft assignments which represent the probability of data belonging to the according subspace. Subsequently, the optimal k subspaces are identified by minimizing the projection residuals of the latent representations to all subspaces, using the learned soft assignments as a weighting vector. Finally, we jointly optimize the representation learning and clustering in a unified framework. Experimental results show that our approach outperforms the state-of-the-art subspace clustering methods on two benchmark datasets.	187.93632678104373
1241.	Our goal is to investigate using only case-level labels extracted automatically from radiology reports to construct a multi-disease classifier for CT scans with deep learning method. We chose four lung diseases as a start: atelectasis, pulmonary edema, nodule and pneumonia. From a dataset of approximately 5,000 chest CT cases from our institution, we used a rule-based model to analyze those radiologist reports, labeling disease by text mining to identify cases with those diseases. From those results, we randomly selected the following mix of cases: 275 normal, 170 atelectasis, 175 nodule, 195 pulmonary edema, and 208 pneumonia. As a key feature of this study, each chest CT scan was represented by only 10 axial slices (taken at regular intervals through the lungs), and furthermore all slices shared the same label based on the radiology report. So the label was weak, because often disease will not appear in all slices. We used ResNet-50[1] as our classification model, with 4-fold cross-validation. Each slice was analyzed separately to yield a slice-level performance. For each case, we chose the 5 slices with highest probability and used their mean probability as the final patient-level probability. Performance was evaluated using the receiver operating characteristic (ROC) area under the curve (AUC). For the 4 diseases separately, the slice-based AUCs were 0.71 for nodule, 0.79 for atelectasis, 0.96 for edema, and 0.90 for pneumonia. The patient-based AUC were 0.74 for nodule, 0.83 for atelectasis, 0.97 for edema, and 0.91 for pneumonia. We backprojected the activations of last convolution layer and the weights from prediction layer to synthesize a heat map [2]. This heat map could be an approximate disease detector, also could tell us feature patterns which ResNet-50 focus on.	187.93626248619336
1242.	In the person reidentification system, the retrieved person image will have large posture differences, complex changes in perspectives, and misalignment of person images in the detection frame. In order to solve these problems, a reidentification algorithm is proposed, which can directly use the key point information of the human body for person image alignment and extract multi-granularity features based on this alignment. First, the posture prediction model is used to locate the key points of the human skeleton, and the person image is directly aligned according to the extracted skeleton key points, and then the multi-granularity features are extracted from the person image. The evaluation phase uses posture information combined with multi-granularity features for similarity matching. The experiment is carried out only using the identity(ID) loss function on the three public datasets of Market1501, CUHK03, and DukeMTMC-reID. The results show that the proposed algorithm has certain advantages.	187.93625851896374
1243.	Address matching is a crucial step in geocoding, which plays an important role in urban planning and management. To date, the unprecedented development of location-based services has generated a large amount of unstructured address data. Traditional address matching methods mainly focus on the literal similarity of address records and are therefore not applicable to the unstructured address data. In this study, we introduce an address matching method based on deep learning to identify the semantic similarity between address records. First, we train the word2vec model to transform the address records into their corresponding vector representations. Next, we apply the enhanced sequential inference model (ESIM), a deep text-matching model, to make local and global inferences to determine if two addresses match. To evaluate the accuracy of the proposed method, we fine-tune the model with real-world address data from the Shenzhen Address Database and compare the outputs with those of several popular address matching methods. The results indicate that the proposed method achieves a higher matching accuracy for unstructured address records, with its precision, recall, and F1 score (i.e., the harmonic mean of precision and recall) reaching 0.97 on the test set.	187.9362459723974
1244.	Intelligent traffic signal control helps to reduce traffic congestion and thus has been studied for a few decades. Multi-intersection cooperative traffic signal control (CTSC), which is more practical than single-intersection traffic signal control, has attracted much attention and research in recent years. Existing works on multi-intersection CTSC make responsive policies based on the sequence of agents' actions. One issue in multi-intersection CTSC is that every agent's actions are mapped from its own road information and some useful information, e.g., the distance of adjacent agents, is ignored, which may lead to suboptimal traffic signal control policies. To address this issue, in this paper a decentralized coordination graph algorithm, referred to as Multi-step return and Off-policy Asynchronous Advantage Actor-Critic Graph (MOA3CG) algorithm, is proposed. The MOA3CG algorithm is based on an asynchronous method of multiagent deep reinforcement learning and a coordination graph; the proposed algorithm makes traffic signal control policies based on current traffic states, the history of observations and other information. A new reward function and An Adjusting Matrix of Traffic Signal Phase Control (AMTSPC) are proposed, which are used by the MOA3CG algorithm in the policy-making process; the AMTSPC is to alter selection of actions by considering the distance of adjacent agents. Experimental results on real-world road scenarios show that the proposed algorithm outperforms other four state-of-the-art algorithms in terms of average delay, average traveling time of vehicles, and the throughput of vehicles, thus eventually helps to mitigate traffic congestion. (C) 2019 Elsevier B.V. All rights reserved.	187.9362302631309
1245.	Background The number grain per panicle of rice is an important phenotypic trait and a significant index for variety screening and cultivation management. The methods that are currently used to count the number of grains per panicle are manually conducted, making them labor intensive and time consuming. Existing image-based grain counting methods had difficulty in separating overlapped grains. Results In this study, we aimed to develop an image analysis-based method to quickly quantify the number of rice grains per panicle. We compared the counting accuracy of several methods among different image acquisition devices and multiple panicle shapes on both Indica and Japonica subspecies of rice. The linear regression model developed in this study had a grain counting accuracy greater than 96% and 97% for Japonica and Indica rice, respectively. Moreover, while the deep learning model that we used was more time consuming than the linear regression model, the average counting accuracy was greater than 99%. Conclusions We developed a rice grain counting method that accurately counts the number of grains on a detached panicle, and believe this method can be a huge asset for guiding the development of high throughput methods for counting the grain number per panicle in other crops.	187.9362247820584
1246.	Self-driving cars and autonomous vehicles are revolutionizing the automotive sector, shaping the future of mobility altogether. Although the integration of novel technologies such as Artificial Intelligence (AI) and Cloud/Edge computing provides golden opportunities to improve autonomous driving applications, there is the need to modernize accordingly the whole prototyping and deployment cycle of AI components. This paper proposes a novel framework for developing so-called AI Inference Engines for autonomous driving applications based on deep learning modules, where training tasks are deployed elastically over both Cloud and Edge resources, with the purpose of reducing the required network bandwidth, as well as mitigating privacy issues. Based on our proposed data driven V-Model, we introduce a simple yet elegant solution for the AI components development cycle, where prototyping takes place in the cloud according to the Software-in-the-Loop (SiL) paradigm, while deployment and evaluation on the target ECUs (Electronic Control Units) is performed as Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework is demonstrated using two real-world use-cases of AI inference engines for autonomous vehicles, that is environment perception and most probable path prediction.	187.93611635007613
1247.	Natural language summaries of source codes are important during software development and maintenance. Recently, deep learning based models have achieved good performance on the task of automatic code summarization, which encode token sequence or abstract syntax tree (AST) of code with neural networks. However, there has been little work on the efficient combination of lexical and syntactical information of code for better summarization quality. In this paper, we propose two general and effective approaches to leveraging both types of information: a convolutional neural network that aims to better extract vector representation of AST node for downstream models; and a Switch Network that learns an adaptive weight vector to combine different code representations for summary generation. We integrate these approaches into a comprehensive code summarization model, which includes a sequential encoder for token sequence of code and a tree based encoder for its AST. We evaluate our model on a large Java dataset. The experimental results show that our model outperforms several state-of-the-art models on various metrics, and the proposed approaches contribute a lot to the improvements.	187.93601364766826
1248.	With the development of deep learning, its application in diagnosis of benign and malignant thyroid nodules has been widely concerned. However, it is difficult to obtain medical images, resulting in insufficient number of data, which contradicts the large amount of data required for acquiring effective deep learning diagnostic models. A multi-view ensemble learning based on voting mechanism is proposed herein to boost the performance of the models trained by small-dataset thyroid nodule ultrasound images. The method integrates three kinds of diagnosis results which are obtained from 3-view dataset which is composed of thyroid nodule ultrasound images, medical features extracted based on U-Net output and useful features selected by mRMR from the statistical features and texture features. To obtain preliminary diagnosis results, the images are utilized for training GoogleNet. For improving the results, supplementary methods were proposed based on the medical features and the selected features. To analyze the contribution of these features and acquire two groups of diagnosis results, the designed Xgboost classifier is utilized for obtaining two groups of features respectively. Subsequently, the boosting final results are obtained through majority voting mechanism. Furthermore, the proposed method is utilized to diagnose sequence images (the images extracted by frame from videos) to solve the poor results caused by slight differences. Finally, better final results are obtained for both of the normal dataset and the sequence dataset (consisting of sequence images). Compared with the accuracies obtained by only training deep learning models with small datasets, the diagnostic accuracies of the above two datasets are improved to 92.11% and 92.54% respectively by utilizing the proposed method.	187.9360098022558
1249.	According to research statistics that there are about 70% of Prostate Cancer (PCa) has been occurred in Peripheral Zone (PZ). Automatic segmentation of the prostate peripheral zone on T2 weighted (T2w) images is a necessary clinical applications for prostate cancer diagnosis. However, the low contrast, blur contour, and significantly varies of shape serious challenges to accurate segmentation of peripheral zone. In this paper, we first present a deep learning method to segment the peripheral zone automatically. For extracting and encoding multi-level features about peripheral zone more effectively, multi-scale dilated convolution (MDC) and pooling block (MPB) were embedded in the baseline model U-Net. Then, we integrated a soft attention mechanism to focus on the salient features useful for segmentation of PZ. In addition, the joint adversarial loss could enhance the model performance of recognition. Experimental results show that the proposed method yield satisfactory segmentation. The mean DICE coefficient arrived at about 88% as compared to the ground truth. The quantitative and qualitative evaluation demonstrates that the modified generative adversarial network is more effective.	187.93595785024172
1250.	At present, China has great difficulty in obtaining the reliability of teaching data sources. In order to further improve the effectiveness of data mining and reduce the difficulty of data acquisition, this paper studies the design and simulation of integrated education information teaching system based on fuzzy logic. Bayesian algorithm can perform data mining, feature recognition and classification on data in big data, so that it can effectively process massive data sources. By weighting the different network structures, the number of undirected edges in the network is reduced, and then small data sets that can be processed by multiple traditional algorithms are sampled from the big data set, and data is generated by using the Bayesian network toolkit Samiam. The modules respectively generate data sets of different sizes and construct a teaching data source generation model. The experimental results show that RSEM on Child and Alarm data can take less time and achieve an accuracy of 86.17% compared with the whole data set under the same effect. This paper proposes a Bayesian network structure integration model, which can solve the problem of data acquisition difficulties, and is also a further improvement of data mining technology.	187.93585949301178
1251.	Training deep models of video recognition usually requires sufficient labeled videos in order to achieve good performance without over-fitting. However, it is quite labor-intensive and time-consuming to collect and annotate a large amount of videos. Moreover, training deep neural networks on large-scale video datasets always demands huge computational resources which further hold hack many researchers and practitioners. To resolve that, collecting and training on annotated images are much easier. However, thoughtlessly applying images to help recognize videos may result in noticeable performance degeneration due to the well-known domain shift and feature heterogeneity. This proposes a novel symmetric adversarial learning approach for heterogeneous image-to-video adaptation, which augments deep image and video features by learning domain-invariant representations of source images and target videos. Primarily focusing on an unsupervised scenario where the labeled source images are accompanied by unlabeled target videos in the training phrase, we present a data-driven approach to respectively learn the augmented features of images and videos with superior transformability and distinguishability. Starting with learning a common feature space (called image-frame feature space) between images and video frames, we then build new symmetric generative adversarial networks (Sym-GANs) where one GAN maps image-frame features to video features and the other maps video features to image-frame features. Using the Sym-GANs, the source image feature is augmented with the generated video-specific representation to capture the motion dynamics while the target video feature is augmented with the image-specific representation to take the static appearance information. Finally, the augmented features from the source domain are fed into a network with fully connected layers for classification. Thanks to an end-to-end training procedure of the Sym-GANs and the classification network, our approach achieves better results than other state-of-the-arts, which is clearly validated by experiments on two video datasets, i.e., the UCT101 and HMDB51 datasets.	187.93585026573703
1252.	Edge computing has emerged as a trend to improve scalability, overhead, and privacy by processing large-scale data, e.g., in deep learning applications locally at the source. In IoT networks, edge devices are characterized by tight resource constraints and often dynamic nature of data sources, where existing approaches for deploying Deep/Convolutional Neural Networks (DNNs/CNNs) can only meet IoT constraints when severely reducing accuracy or using a static distribution that cannot adapt to dynamic IoT environments. In this paper, we propose DeepThings, a framework for adaptively distributed execution of CNN-based inference applications on tightly resource-constrained IoT edge clusters. DeepThings employs a scalable Fused Tile Partitioning (FTP) of convolutional layers to minimize memory footprint while exposing parallelism. It further realizes a distributed work stealing approach to enable dynamic workload distribution and balancing at inference runtime. Finally, we employ a novel work scheduling process to improve data reuse and reduce overall execution latency. Results show that our proposed FTP method can reduce memory footprint by more than 68% without sacrificing accuracy. Furthermore, compared to existing work sharing methods, our distributed work stealing and work scheduling improve throughput by 1.7 x -2.2 x with multiple dynamic data sources. When combined, DeepThings provides scalable CNN inference speedups of 1.7 x-3.5 x on 2-6 edge devices with less than 23 MB memory each.	187.93581876437028
1253.	Severity stage classification of diabetic foot ulcers is a vital way to improve the decision support on treatment planning and diagnostic performance. Nevertheless, the precise manual identification of ulcer severity stage is challenging since vision may vary upon the consultant, tedious and time-consuming. Accordingly, automatic severity stage classification is of significant prominence. Yet a comprehensive computer-aided Wagner scale based severity stage classification system for diabetic foot ulcers is not available in the literature. In this paper, we propose to use a convolutional neural network engineered from DenseNet-201 based architecture as the feature extractor paradigm followed by a global average pooling (GAP) layer to predict six-class severity stages of diabetic foot ulcers. Furthermore, we use a practice of optimizing processing time and memory consumption while conserving the accuracy of the classification model through feature extraction with SVD. The proposed architecture could achieve an accuracy of over 96%. Moreover, we evaluated how different pre-trained CNN state of the art architectures (DenseNet, ResNet, Xception, InceptionV3, InceptionResNetV2, and VGG) which can be used for the task of transfer learning.	187.93579965060096
1254.	Supervised deep learning methods for segmentation require large amounts of labelled training data, without which they are prone to overfitting, not generalizing well to unseen images. In practice, obtaining a large number of annotations from clinical experts is expensive and time-consuming. One way to address scarcity of annotated examples is data augmentation using random spatial and intensity transformations. Recently, it has been proposed to use generative models to synthesize realistic training examples, complementing the random augmentation. So far, these methods have yielded limited gains over the random augmentation. However, there is potential to improve the approach by (i) explicitly modeling deformation fields (non-affine spatial transformation) and intensity transformations and (ii) leveraging unlabelled data during the generative process. With this motivation, we propose a novel task-driven data augmentation method where to synthesize new training examples, a generative network explicitly models and applies deformation fields and additive intensity masks on existing labelled data, modeling shape and intensity variations, respectively. Crucially, the generative model is optimized to be conducive to the task, in this case segmentation, and constrained to match the distribution of images observed from labelled and unlabelled samples. Furthermore, explicit modeling of deformation fields allows synthesizing segmentation masks and images in exact correspondence by simply applying the generated transformation to an input image and the corresponding annotation. Our experiments on cardiac magnetic resonance images (MRI) showed that, for the task of segmentation in small training data scenarios, the proposed method substantially outperforms conventional augmentation techniques.	187.93577062030658
1255.	Approaches to cross-cultural learning within education curricula have predominantly focused on events of history, object, rituals and practices. We argue that there is a need to encourage deeper approaches of learning that engage affective and cognitive aspects, and that digital tools have an important role in scaffolding this form of learning. We ran a digitally supported Enquiry Based Learning (EBL) activity in two schools in India and England. Students in the two schools conducted real-world research and used the information to design a knowledge artefact using a digital content-creation tool. Our study establishes that a combination of EBL and relevant digital tools nurtures peer-based, real-world enquiry and fosters deep learning which we reckon are key requisites to embed meaningful cross-cultural knowledge in school curriculum.	187.9357401910875
1256.	With the increasing availability of high-resolution satellite imagery it is important to improve the efficiency and accuracy of satellite image indexing, retrieval and classification. Furthermore, there is a need for utilizing all available satellite imagery in identifying general land cover types and monitoring their changes through time irrespective of their spatial, spectral, temporal and radiometric resolutions. Therefore, in this study, we developed deep learning models able to efficiently and accurately classify cloud, shadow and land cover scenes in different high-resolution (< 10 m) satellite imagery. Specifically, we trained deep convolutional neural network (CNN) models to perform multi-label classification of multi-modal, high-resolution satellite imagery at the scene level. Multi-label classification at the scene level (a.k.a. image indexing), as opposed to the pixel level, allows for faster performance, higher accuracy (although at the cost of detail) and higher generalizability. We investigated the generalization ability (i.e. cross-dataset and geographic independence) of individual and ensemble CNN models trained on multi-modal satellite imagery (i.e. PlanetScope and Sentinel-2). The models trained on PlanetScope imagery collected over the Amazon performed well when applied to PlanetScope and Sentinel-2 imagery collected over the Wet Tropics of Australia with an F-2 score of 0.72 and 0.69, respectively. Similarly, PlanetScope-based CNN models trained on imagery collected over the Wet Tropics of Australia performed well when applied to Sentinel-2 imagery with an F-2 score of 0.76, and the reverse scenario resulted in the same F-2 score of 0.76. This suggests that our CNN models have high cross-dataset generalization ability and are suitable for classifying cloud, shadow and land cover classes in satellite imagery with resolutions from 3 m (PlanetScope) to 10 m (Sentinel-2). The performance of our CNN models was also comparable to the state-of-the-art methods (i.e. Sen2Cor and MACCS) developed specifically for classifying cloud and shadow classes in Sentinel-2 imagery. Finally, we show the potential of our CNN models to mask cloud and shadow contaminated areas from PlanetScope- and Sentinel-2-derived NDVI time-series.	187.93562509491827
1257.	Deep learning methods have been introduced for fault diagnosis of rotating machinery. Most methods have good performance when processing bearing data at a certain rotating speed. However, most rotating machinery in industrial practice has variable working speed. When processing the bearing data with variable rotating speed, the existing methods have low accuracies, or need complex parameter adjustments. To solve this problem, a fault diagnosis method based on continuous wavelet transform scalogram (CWTS) and Pythagorean spatial pyramid pooling convolutional neural network (PSPP-CNN) is proposed in this paper. In this method, continuous wavelet transform is used to decompose vibration signals into CWTSs with different scale ranges according to the rotating speed. By adding a PSPP layer, CNN can process CWTSs in different sizes. Then the fault diagnosis of variable rotating speed bearing can be carried out by a single CNN model without complex parameter adjustment. Compared with a spatial pyramid pooling (SPP) layer that has been used in CNN, a PSPP layer locates as front layer of CNN. Thus, the features obtained by PSPP layer can be delivered to convolutional layers for further feature extraction. According to experiment results, this method has higher diagnosis accuracy for variable rotating speed bearing than other methods. In addition, the PSPP- CNN model trained by data at some rotating speeds can be used to diagnose bearing fault at full working speed.	187.93541107560713
1258.	Coronavirus is an epidemic that spreads very quickly. For this reason, it has very devastating effects in many areas worldwide. It is vital to detect COVID-19 diseases as quickly as possible to restrain the spread of the disease. The similarity of COVID-19 disease with other lung infections makes the diagnosis difficult. In addition, the high spreading rate of COVID-19 increased the need for a fast system for the diagnosis of cases. For this purpose, interest in various computer-aided (such as CNN, DNN, etc.) deep learning models has been increased. In these models, mostly radiology images are applied to determine the positive cases. Recent studies show that, radiological images contain important information in the detection of coronavirus. In this study, a novel artificial neural network, Convolutional CapsNet for the detection of COVID-19 disease is proposed by using chest X-ray images with capsule networks. The proposed approach is designed to provide fast and accurate diagnostics for COVID-19 diseases with binary classification (COVID-19, and No-Findings), and multi-class classification (COVID-19, and No-Findings, and Pneumonia). The proposed method achieved an accuracy of 97.24%, and 84.22% for binary class, and multi-class, respectively. It is thought that the proposed method may help physicians to diagnose COVID-19 disease and increase the diagnostic performance. In addition, we believe that the proposed method may be an alternative method to diagnose COVID-19 by providing fast screening.	187.93536082518062
1259.	Computer-aided diagnosis tools for Retinopathy of Prematurity (ROP) base their decisions on handcrafted retinal features that highly correlate with expert diagnoses, such as arterial and venous curvature, tortuosity and dilation. Deep learning leads to performance comparable to those of expert physicians, albeit not ensuring that the same clinical factors are learned in the deep representations. In this paper, we investigate the relationship between the handcrafted and the deep learning features in the context of ROP diagnosis. Average statistics on the handcrafted features for each input image were expressed as retinal concept measures. Three disease severity grades, i.e. normal, pre-plus and plus, were classified by a deep convolutional neural network. Regression Concept Vectors (RCV) were computed in the network feature space for each retinal concept measure. Relevant concept measures were identified by bidirectional relevance scores for the normal and plus classes. Results show that the curvature, diameter and tortuosity of the segmented vessels are indeed relevant to the classification. Among the potential applications of this method, the analysis of borderline cases between the classes and of network faults, in particular, can be used to improve the performance.	187.93534604639171
1260.	Day-ahead electricity market (DAM) volatility and price forecast errors have grown in recent years. Changing market conditions, epitomised by increasing renewable energy production and rising intraday market trading, have spurred this growth. If forecast accuracies of DAM prices are to improve, new features capable of capturing the effects of technical or fundamental price drivers must be identified. In this paper, we focus on identifying/engineering technical features capable of capturing the behavioural biases of DAM traders. Technical indicators (TIs), such as Bollinger Bands, Momentum indicators, or exponential moving averages, are widely used across financial markets to identify behavioural biases. To date, TIs have never been applied to the forecasting of DAM prices. We demonstrate how the simple inclusion of TI features in DAM forecasting can significantly boost the regression accuracies of machine learning models; reducing the root mean squared errors of linear, ensemble, and deep model forecasts by up to 4.50%, 5.42%, and 4.09%, respectively. Moreover, tailored TIs are identified for each of these models, highlighting the added explanatory power offered by technical features.	187.9352843720094
1261.	COVID-19 pandemic has challenged the world science. The international community tries to find, apply, or design novel methods for diagnosis and treatment of COVID-19 patients as soon as possible. Currently, a reliable method for the diagnosis of infected patients is a reverse transcription-polymerase chain reaction. The method is expensive and time-consuming. Therefore, designing novel methods is important. In this paper, we used three deep learning-based methods for the detection and diagnosis of COVID-19 patients with the use of X-Ray images of lungs. For the diagnosis of the disease, we presented two algorithms include deep neural network (DNN) on the fractal feature of images and convolutional neural network (CNN) methods with the use of the lung images, directly. Results classification shows that the presented CNN architecture with higher accuracy (93.2%) and sensitivity (96.1%) is outperforming than the DNN method with an accuracy of 83.4% and sensitivity of 86%. In the segmentation process, we presented a CNN architecture to find infected tissue in lung images. Results show that the presented method can almost detect infected regions with high accuracy of 83.84%. This finding also can be used to monitor and control patients from infected region growth.	187.93526711999738
1262.	Training can improve motor skills and modify neural activity at rest and during movement execution. Learning-related modulations may also concern motor preparation but the neural correlates and the potential behavioral relevance of such adjustments remain unclear. In humans, preparatory processes have been largely investigated using transcranial magnetic stimulation (TMS) with several studies reporting decreased corticospinal excitability (CSE) relative to a baseline measure at rest; a phenomenon called preparatory suppression. Here, we investigated the effect of motor training on such preparatory suppression, in relation to resting CSE, in humans. We trained participants to initiate quick movements in an instructed-delay reaction time (RT) task and used TMS to investigate changes in CSE over the practice blocks. Training on the task speeded up RTs, with no repercussion on error rates. Training also increased resting CSE. Most interestingly, we found that CSE during action preparation did not mirror the training-related increase observed at rest. Rather, compared to the rising baseline, the degree of preparatory suppression strengthened with practice. This training-related change in preparatory suppression (but not the changes in baseline CSE) predicted RT gains: the subjects showing a greater strengthening of preparatory suppression were also those exhibiting larger gains in RTs. Finally, such relationship between RTs and preparatory suppression was also evident at the single-trial level, though only in the non-selected effector: RTs were generally faster in trials where preparatory suppression was deeper. These findings suggest training induces changes in motor preparatory processes, that are linked to an enhanced ability to initiate fast movements.	187.93522304683773
1263.	Cervical cancer affects 570,000 women globally and is among the most common causes of cancer-related deaths. Cervical cancer is caused due to the Human Papilloma Virus (HPV) which leads to abnormal growth of cells in the cervix region. Regular testing for HPV in women has helped reduce the death rate in developed countries. However, developing nations are still struggling to provide low-cost solutions due to the lack of affordable medical facilities. The skewed ratio of the oncologists to patients has also aggravated the problem. Motivated by the Deep Learning solutions in Bio-medical imaging, we propose a novel CervixNet methodology which performs image enhancement on cervigrams followed by Segmenting the Region of Interest (RoI) and then classifying the RoI to determine the appropriate treatment. For the classification task, a novel Hierarchical Convolutional Mixture of Experts (HCME) algorithm is proposed. HCME is capable of tackling the problem of overfitting, given that small datasets are an inherent problem in the field of biomedical imaging. Our proposed methodology has outperformed all the existing methodologies on publicly available Intel and Mobile-ODT Kaggle dataset giving an Accuracy of 96.77% and kappa score of 0.951. Hence, the results obtained validate our approach to provide first level screening at a low cost.	187.9352119872142
1264.	Verification code is a human-machine test method that is widely used in the Internet. It can essentially distinguish between human and network robots. However, with the development of technology, more and more problems has been found in the verification code. This paper takes the digital verification codes commonly used in university student management system as the research object. The verification code after scaling and graying is used as the data set. The eight-layer ALexNet convolutional neural network is constructed by using the Google deep learning framework TensorFlow to train the verification code. The data set is tested to obtain a network model that can identify different complexity digital verification codes. The recognition rate of digital verification codes commonly used in college student management systems can reach 99%.	187.93520436828294
1265.	Using high-precision sensors to monitor and predict the deformation trend of supertall buildings is a hot research topic for a long time. And in terms of deformation trend prediction, the main way to realized deformation trend prediction is the deep learning algorithm, but the accuracy of prediction result needs to be improved. To solve the problem described above, firstly, based on the conditional deep belief network (CDBN) model, the levenberg-marquardt (LM) was used to optimize the CDBN model; the LM-CDBN model has been constructed. Then taking CITIC tower, the tallest building in Beijing as the research object, the real-time monitoring data of the shape acceleration array (SAA) as an example, we used LM-CDBN model to analyse and predict the building deformation. Finally, to verify the accuracy and robustness of LM-CDBN model, the prediction results of the LM-CDBN model are compared with the prediction results of the CDBN model, the extreme learning machine (ELM) model, and the unscented Kalman filter-support vector regression (UKF-SVR) model, and we evaluated the result from three aspects: training error, fitness, and stability of prediction results. The results show that the LM-CDBN model has higher precision and fitting degree in the prediction of deformation trend of supertall buildings. And the MRE, MAE, and RMSE of the LM-CDBN model prediction results are only 0.0060, 0.0023mm, and 0.0031mm, and the prediction result was more in line with the actual deformation trend.	187.9351979248858
1266.	How to obtain reliable permeability data is universally considered as one of the critical work that guides geologists to explore oil-gas accumulation zones underground. Many significant researches related to permeability prediction have revealed that permeability can be directly calculated from logging data under usage of some complex non-linear equations. In this way, the key of permeability prediction is how to establish relational expression between permeability and logging data. Support vector regression is one of the best mathematical models using to explain complex mapping relationship between independent and dependent variables, and thus it can be viewed as an ideal approach to predict permeability. However, such model cannot be effective when different kinds of input data have high correlation or network parameters are not evaluated well. Then other two mathematical models, continuous restricted Boltzmann machine and particle swarm optimization, are referred to use to support the application of SVR. CRBM is functional to make a new data separation from the raw data, and network parameters can be optimized after PSO process. Therefore a new data-driven permeability prediction model CRBM-PSO-SVR is provided in this article. Data source used for method validation derives from five coring wells of the IARA oilfield, Santos Basin, Brazil. In two self-designed experiments, the accuracy rates of new method are respectively 67.34% and 76.67%, both of which are higher than those of other comparison methods. Experiment results well demonstrate the effectiveness of new method in permeability prediction when only logging data is available.	187.93515049470363
1267.	The rapid development of the Internet of Things (IoT) and cognitive cyber-physical systems (CPS) has made people's daily lives more intelligent. Additionally, emerging technologies, such as wearable devices and machine learning, have demonstrated the potential for acquiring and processing large amounts of data from the physical world. In the medical field, effectively utilizing the collected medical data and providing more intelligent systems for doctors and patients to assist in diagnoses have also become important research topics. This paper presents a deep neural network-based cognitive system named DDA (dermatosis discrimination assistant) for classifying the dermatosis images generated by confocal laser scanning microscopes. Considering the lack of labels, we increase the labeled data automatically using an incremental model based on a small amount of labeled data and propose a disease discrimination model to distinguish and diagnose the categories of the disease images. In this system, the diagnoses of seborrheic keratosis (SK) and flat wart (FW) are used as examples, and experiments are conducted using the proposed models. Experimental results show that this system performs almost as well as individual dermatologists and can identify and diagnose other common dermatoses. (C) 2018 Published by Elsevier B.V.	187.93489255309677
1268.	Circular RNAs (circRNA) are a special kind of covalently closed single-stranded RNA molecules. They have been shown to control and coordinate various biological processes. Recent researches show that circRNAs are closely associated with numerous chronic human diseases. Identification of circRNA-disease associations will contribute towards diagnosing the pathogenesis of diseases. Experimental methods for finding the relation between the diseases and their causal circRNAs are difficult and time-consuming. So computational methods are of critical need for predicting the associations between circRNAs and various human diseases. In this study, we propose an ensemble approach AE-DNN, which relies on autoencoder and deep neural networks to predict new circRNA-disease relationships. We utilized circRNA sequence similarity, disease semantic similarity, and Gaussian interaction profile kernel similarities of circRNAs and diseases for feature construction. The constructed features are fed to a deep autoencoder, and the extracted compact, high-level features are fed to the deep neural network for association prediction. We conducted 5-fold and 10-fold cross-validation experiments to assess the performance; AE-DNN could achieve AUC scores of 0.9392 and 0.9431, respectively. Experimental results and case studies indicate the robustness of our model in circRNA-disease association prediction.	187.93486296520192
1269.	Capsule Neural Networks (CapsNet) serve as an attempt to model the neural organization in biological neural networks. Through the routing-by-agreement algorithm, the attention mechanism is implemented as individual capsules that focus on specific upstream capsules while ignoring the rest. By using the routing algorithm, CapsNets are able to attend overlapping digits from the MNIST dataset. In this work, we evaluate the attention capabilities of Capsule Networks using the routing-by-agreement with occluded shape stimuli as presented in neurophysiology. We do so by implementing a more compact type of capsule network. Our results in classifying the non-occluded as well as the occluded shapes show that indeed, CapsNets are able to differentiate occlusions from near-occlusion situations as in real biological neurons. In our experiments, performing the reconstruction of the occluded stimuli also shows promising results.	187.93486149944349
1270.	Many data processing technologies have been utilized for pavement distress detection (e.g., reflection cracks, water-damage pits, and uneven settlements) using ground penetrating radar (GPR). However, the various real-world conditions have resulted in challenges of the accuracy and generalization ability of these techniques. To overcome these challenges, we proposed a deep-learning method, called faster region convolutional neural network (Faster R-ConvNet), to complete the task. The 30 Faster R-ConvNets were trained, validated, and tested using 2,557, 614, and 614 GPR images, respectively. The optimal anchor size and ratio were determined based on the validation results. The stability, superiority, real-time of the optimal Faster R-ConvNet were verified based on the test results. The results demonstrated that the optimal Faster R-ConvNet achieved 89.13% precision and 86.24% IoU. The stability of the model in different pavement structures was desirable. The comparative study indicated that the optimal Faster R-ConvNet outperformed other supervised learning methods in distress detection. Additionally, a real-time detection using optimal Faster R-ConvNet was conducted with acceptable accuracy. (C) 2020 Elsevier Ltd. All rights reserved.	187.93485910888978
1271.	Background There is interest in using convolutional neural networks (CNNs) to analyze medical imaging to provide computer-aided diagnosis (CAD). Recent work has suggested that image classification CNNs may not generalize to new data as well as previously believed. We assessed how well CNNs generalized across three hospital systems for a simulated pneumonia screening task. Methods and findings A cross-sectional design with multiple model training cohorts was used to evaluate model generalizability to external sites using split-sample validation. A total of 158,323 chest radiographs were drawn from three institutions: National Institutes of Health Clinical Center (NIH; 112,120 from 30,805 patients), Mount Sinai Hospital (MSH; 42,396 from 12,904 patients), and Indiana University Network for Patient Care (IU; 3,807 from 3,683 patients). These patient populations had an age mean (SD) of 46.9 years (16.6), 63.2 years (16.5), and 49.6 years (17) with a female percentage of 43.5%, 44.8%, and 57.3%, respectively. We assessed individual models using the area under the receiver operating characteristic curve (AUC) for radiographic findings consistent with pneumonia and compared performance on different test sets with DeLong's test. The prevalence of pneumonia was high enough at MSH (34.2%) relative to NIH and IU (1.2% and 1.0%) that merely sorting by hospital system achieved an AUC of 0.861 (95% CI 0.855-0.866) on the joint MSH-NIH dataset. Models trained on data from either NIH or MSH had equivalent performance on IU (Pvalues 0.580 and 0.273, respectively) and inferior performance on data from each other relative to an internal test set (i.e., new data from within the hospital system used for training data; Pvalues both <0.001). The highest internal performance was achieved by combining training and test data from MSH and NIH (AUC 0.931, 95% CI 0.927-0.936), but this model demonstrated significantly lower external performance at IU (AUC 0.815, 95% CI 0.7450.885, P= 0.001). To test the effect of pooling data from sites with disparate pneumonia prevalence, we used stratified subsampling to generate MSH-NIH cohorts that only differed in disease prevalence between training data sites. When both training data sites had the same pneumonia prevalence, the model performed consistently on external IU data (P= 0.88). When a 10-fold difference in pneumonia rate was introduced between sites, internal test performance improved compared to the balanced model (10x MSH risk P < 0.001; 10x NIH P = 0.002), but this outperformance failed to generalize to IU (MSH 10x P< 0.001; NIH 10x P= 0.027). CNNs were able to directly detect hospital system of a radiograph for 99.95% NIH (22,050/22,062) and 99.98% MSH (8,386/8,388) radiographs. The primary limitation of our approach and the available public data is that we cannot fully assess what other factors might be contributing to hospital system-specific biases. Conclusion Pneumonia-screening CNNs achieved better internal than external performance in 3 out of 5 natural comparisons. When models were trained on pooled data from sites with different pneumonia prevalence, they performed better on new pooled data from these sites but not on external data. CNNs robustly identified hospital system and department within a hospital, which can have large differences in disease burden and may confound predictions.	187.9347595675173
1272.	Atom probe tomography is known for its accurate compositional analysis at the nanoscale. However, the patterns created by successive hits on the single particle detector during experiments often contain complementary information about the specimen's crystallography, including structure and orientation. This information remains in most cases unexploited because it is, up to now, retrieved predominantly manually. Here, we propose an approach combining image analysis techniques for feature selection and deep-learning to automatically interpret the patterns. Application of unsupervised machine learning techniques allows to build and train a deep neural network, based on a library generated from theoretically known crystallographic angular relationships. This approach enables direct interpretation of the detector hit maps, as shown here on the example of numerous pure-Al, and is robust enough to function under various conditions of base temperature, pulsing mode and pulse fraction. We benchmark our approach against recent attempts to automate the pattern identification via Hough-transform and discuss the current limitations of our approach. This new automated approach renders crystallographic atom probe tomography analysis more efficient, feature-sensitive, robust, user-independent and reliable. With that, deep-learning algorithms show a great potential to give access to combined atom probe crystallographic and compositional analysis to a large community of users.	187.93469500197688
1273.	Research strongly suggests that learning outcomes improve with increased parental involvement in school settings, and policy in Australia aligns by encouraging schools to work in 'partnership' with parents and communities. The Australian Institute for Teaching and School Leadership endorses the requirement of graduate teachers to 'engage with the parents/carers' and encourages parents in classrooms. However, a research gap exists regarding exactly what it is that parents might contribute to the classroom and how these contributions improve learning outcomes for all children. This case study reports on a parent-instigated program in one school, affording deeper insight into the potential of parent contributions to support learning outcomes for all students. An ecological stance on learning (applying theory from both ecological and environmental psychology) frames the research, and findings reveal some insights into the legitimacy of parent contributions that can support teachers to engage parents in pedagogical ways, enabling functional parent-school partnerships at the local community level.	187.9345706185125
1274.	At present, there are two obvious problems in radar-based gait recognition. First, the traditional radar frequency band is difficult to meet the requirements of fine identification with due to its low carrier frequency and limited micro-Doppler resolution. Another significant problem is that radar signal processing is relatively complex, and the existing signal processing algorithms are poor in real-time usability, robustness and universality. This paper focuses on the two basic problems of human gait detection with radar and proposes a human gait classification and recognition method based on millimeter-wave array radar. Based on deep-learning technology, a multi-channel three-dimensional convolution neural network is proposed on the basis of improving the residual network, which completes the classification and recognition of human gait through the hierarchical extraction and fusion of multi-dimensional features. Taking the three-dimensional coordinates, motion speed and intensity of strong scattering points in the process of target motion as network inputs, multi-channel convolution is used to extract motion features, and the classification and recognition of typical daily actions are completed. The experimental results show that we have more than 92.5% recognition accuracy for common gait categories such as jogging and normal walking.	187.93448015778097
1275.	Artificial intelligence involves a wide range of smart techniques that are applicable to medical services including nuclear medicine. Recent advances in computer power, availability of accumulated digital archives containing large amount of patient images, and records bring new opportunities for the implementation of artificial techniques in nuclear medicine. As a subset of artificial intelligence, machine learning is an emerging tool that can possibly perform many clinical tasks. Nuclear medicine community needs to adapt to this fast approaching smart era, to exploit the opportunities and tackle the problems associated with artificial intelligence tools. It is aimed in this editorial to outline the opportunities and challenges of artificial intelligence applications in nuclear medicine.	187.93445619647215
1276.	Children with fragile X syndrome (FXS) exhibit deficits in a variety of cognitive processes within the executive function domain. As working memory (WM) is known to support a wide range of cognitive, learning and adaptive functions, WM computer-based training programs have the potential to benefit people with FXS and other forms of intellectual and developmental disability (IDD). However, research on the effectiveness of WM training has been mixed. The current study is a follow-up "deep dive" into the data collected during a randomized controlled trial of Cogmed (Stockholm, Sweden) WM training in children with FXS. Analyses characterized the training data, identified training quality metrics, and identified subgroups of participants with similar training patterns. Child, parent, home environment and training quality metrics were explored in relation to the clinical outcomes during the WM training intervention. Baseline cognitive level and training behavior metrics were linked to gains in WM performance-based assessments and also to reductions in inattention and other behaviors related to executive functioning during the intervention. The results also support a recommendation that future cognitive intervention trials with individuals with IDD such as FXS include additional screening of participants to determine not only baseline feasibility, but also capacity for training progress over a short period prior to inclusion and randomization. This practice may also better identify individuals with IDD who are more likely to benefit from cognitive training in clinical and educational settings.	187.9344498332452
1277.	Deep convolutional neural network (CNN) has achieved great success in image restoration. However, previous methods ignore the complementarity between low-level and high-level features, thereby leading to limited image reconstruction quality. In this paper, we propose a two-stream sparse network (TSSN) to explicitly learn shallow and deep features to enforce their respective contribution to image restoration. The shallow stream learns shallow features (e.g., texture edges), and the deep stream learns deep features (e.g., salient semantics). In each stream, sparse residual block (SRB) is proposed to efficiently aggregate hierarchical features by constructing sparse connections among layers in the local block. Spatial-wise and channel-wise attention are used to fuse the shallow and deep stream which recalibrates features by weight assignment in both spatial and channel dimensions. A novel loss function called Softmax-L-1 loss is proposed to increase penalties of pixels that have large L-1 loss (i.e., hard pixels). TSSN is evaluated with three representative IR applications, i.e., single image super-resolution, image denoising and JPEG deblocking. Extensive experiments demonstrate that TSSN outperforms most of state-of-the-art methods on benchmark datasets on both quantitative metric and visual quality.	187.9344377745357
1278.	Transient identification of condition monitoring data in nuclear reactor is important for system health assessment. Conventionally, the operating transients are correlated with the pre-designed ones by human operators during operations. However, due to necessary conservatism and significant differences between the operating and pre-designed transients, it has been less effective to manually identify transients, that usually contribute to different system degradation modes. This paper proposes a deep learning-based unsupervised representation clustering method for automatic transient pattern recognition based on the on-site condition monitoring data. Sample entropy is used as indicator for transient extraction, and a pre-training stage is implemented using an auto-encoder architecture for learning high-level features. An iterative representation clustering algorithm is further proposed to enhance the clustering effects, where a novel distance metric learning strategy is integrated. Experiments on a real-world nuclear reactor condition monitoring dataset validate the effectiveness and superiority of the proposed method, which provides a promising tool for transient identification in the real industrial scenarios. This study offers a new perspective in exploring unlabeled data with deep learning, and the end-to-end implementation scheme facilitates applications in the real nuclear industry. (C) 2020 Elsevier B.V. All rights reserved.	187.93439482423452
1279.	Collaborative filtering (CF) is a common recommendation mechanism that relies on useritem ratings. However, the intrinsic sparsity of user-item rating data can be problematic in many domains and settings, limiting the ability to generate accurate predictions and effective recommendations. At present, most algorithms use two-valued trust relationship of social network to improve recommendation quality but fail to take into account the difference of trust intensity of each friend and user's comment information. To this end, the recommendation system within a social network adopts topical attention and probabilistic matrix factorization (STAPMF) is proposed. We combine the trust information in social networks and the topical information from review documents by proposing a novel algorithm combining probabilistic matrix factorization and attention-based recurrent neural networks to extract item underlying feature vectors, user's personal potential feature vectors, and user's social hidden feature vectors, which represent the features extracted from the user's trusted network. Using real-world datasets, we show a significant improvement in recommendation performance comparing with the prevailing state-of-the-art algorithms for social network-based recommendation.	187.93427919052644
1280.	The quality of iris images on mobile devices is significantly degraded due to hardware limitations and less constrained environments. Traditional iris recognition methods cannot achieve high identification rate using these low- quality images. To enhance the performance of mobile identification, we develop a deep feature fusion network that exploits the complementary information presented in iris and periocular regions. The proposed method first applies maxout units into the convolutional neural networks (CNNs) to generate a compact representation for each modality and then fuses the discriminative features of two modalities through a weighted concatenation. The parameters of convolutional filters and fusion weights are simultaneously learned to optimize the joint representation of iris and periocular biometrics. To promote the iris recognition research on mobile devices under near-infrared (NIR) illumination, we publicly release the CASIA-Iris-Mobile-V1.0 database, which in total includes 11 000 NIR iris images of both eyes from 630 Asians. It is the largest NIR mobile iris database as far as we know. On the newly built CASIA-Iris-M1-S3 data set, the proposed method achieves 0.60% equal error rate and 2.32% false non-match rate at false match rate = 10(-5), which are obviously better than unimodal biometrics as well as traditional fusion methods. Moreover, the proposed model requires much fewer storage spaces and computational resources than general CNNs.	187.93424513347824
1281.	Reinforcement learning is a powerful tool for developing personalized treatment regimens from healthcare data. Yet training reinforcement learning agents through direct interactions with patients is often impractical for ethical reasons. One solution is to train reinforcement learning agents using an 'environment model,' which is learned from retrospective patient data and can simulate realistic patient trajectories. In this study, we propose transitional variational autoencoders (tVAE), a generative neural network architecture that learns a direct mapping between distributions over clinical measurements at adjacent time points. Unlike other models, the tVAE requires few distributional assumptions and benefits from identical training and testing architectures. This model produces more realistic patient trajectories than state-of-the-art sequential decision-making models and generative neural networks, and can be used to learn effective treatment policies.	187.93424494995196
1282.	Critical engineering components in the process of designing have employed fail-safe approaches and damage tolerance in industry optimization intelligent processing. Different types of geometrical intricacies were occurring in designing of pressure vessels while considering the parameters. The failures may be due to manufacturing defects or pre-existing flaws present in the cylinder. Even in the probabilistic method of determining failure the structural integrity of the components changes on compressive and tensile loadings. The failures cause the pressure vessels in not adopting its design for the requirement. Normally Inherent Flaw Models (IFM) was used to design wide tensile specimens effectively since the fundamental aspects of material failure can be assessed. DL based Inherent flaw models (IFM) was utilized to generate Failure Assessment Diagrams (FAD) and also to estimate the notched tensile strength of different cracked geometry. IFM is limited only of the wide through cracked tensile specimens. The present work utilizes modified IFM and by converting the pressure vessel failure design data to that of a wide tensile plate by changing its equivalent crack length obtained from an axial crack present in the cylinder. Failure pressure estimation based on fracture criterion is found to be a good coincidence with the data series. Finite Element Analysis (FEA) procedures were utilized to determine plastic zone size of the plate for better validation of the results. Crack Initiation and subsequent growth were identified from the plastic zone. (c) 2020 Elsevier Ltd. All rights reserved.	187.93406940043536
1283.	Mining induced stress, especially discontinuous redistribution and stress drop, is a major issue of structural stability in deep coal mining. Only considering the yield criterion as the continuous stress equation solution without failure criterion leads to excessive plastic zone and support ability. The discontinuous distribution is illustrated by abutment pressure rather than horizontal stress. First, the weakening of the stress boundary by substituting the Mohr-Coulomb yield equation into the differential equations of stress is discussed. We propose an elastic solution and discontinuous stress boundary for the stress state of coal ahead of working face. Second, it is pointed out that introducing the statistical yield criterion to the stress equilibrium equation can be used for determination of the broken zone. The failure criterion is proposed at the elastoplastic boundary considering the behavior transition for avoiding excessive stress concentration. The equation of stress drop at the transition boundary is proposed for the discontinuous solutions. The influence of the internal friction angle and cohesion on the discontinuous distribution of abutment pressure as well as the peak stress coefficient is discussed. The results show that the discontinuous equations of mining-induced stress distribution effectively represent the stress state in the broken zone. The equitant damage is defined in the broken zone based on the deterioration of rock due to crack generation. The stress drop at the elastoplastic boundary is compared quantitatively by MohrCoulomb's solution and the statistical solution equation. When the uniaxial compressive strength is below the original in situ stress, the peak stress concentration is mainly a function of the internal friction angle. As the damage increases, the peak stress in the broken zone decreases and the stress drop increases. The experimental results from excavation induced testing by loading multi-stage confining pressures are consistent with theoretical solutions. Finally, the mining-induced unloading ratio is proposed to learn the excavation speed or disturbance intensity. There is a positive linear correlation between the unloading rates and the peak coefficients, and the mining-induced behavior depends on the discontinuous unloading path and rates.	187.93404089587702
1284.	Electromagnetic (EM) metasurfaces have attracted great attention from both engineers and researchers due to their unique physical responses. With the rapid development of complex metasurfaces, the design and optimization processes have also become extremely time-consuming and computational resource-consuming. Here we proposed a deep learning model (DLM) based on a convolutional autoencoder network and inverse design network, which can help to establish the complex relationships between the geometries of metasurfaces and their EM responses. As a typical example, a metasurface absorber consisting of polymethacrylimide foam/metal ring alternating multilayers is chosen to demonstrate the capability of the DLM. The relative spectral error of the two desired spectra is only 5.80 and 5.49, respectively. Our model shows great predictive power and may be used as an effective tool to accelerate the design and optimization of metasurfaces.	187.93399943642027
1285.	We introduce a machine learning method in which energy solutions from the Schrodinger equation are predicted using symmetry adapted atomic orbital features and a graph neural-network architecture. OrbNet is shown to outperform existing methods in terms of learning efficiency and transferability for the prediction of density functional theory results while employing low-cost features that are obtained from semi-empirical electronic structure calculations. For applications to datasets of drug-like molecules, including QM7b-T, QM9, GDB-13-T, DrugBank, and the conformer benchmark dataset of Folmsbee and Hutchison [Int. J. Quantum Chem. (published online) (2020)], OrbNet predicts energies within chemical accuracy of density functional theory at a computational cost that is 1000-fold or more reduced.	187.9339951646585
1286.	Manually counting hens in battery cages on large commercial poultry farms is a challenging task: time-consuming and often inaccurate. Therefore, the aim of this study was to develop a machine vision system that automatically counts the number of hens in battery cages. Automatically counting hens can help a regulatory agency or inspecting officer to estimate the number of living birds in a cage and, thus animal density, to ensure that they conform to government regulations or quality certification requirements. The test hen house was 87 m long, containing 37 battery cages stacked in 6-story high rows on both sides of the structure. Each cage housed 18 to 30 hens, for a total of approximately 11 000 laying hens. A feeder moves along the cages. A camera was installed on an arm connected to the feeder, which was specifically developed for this purpose. A wide-angle lens was used in order to frame an entire cage in the field of view. Detection and tracking algorithms were designed to detect hens in cages; the recorded videos were first processed using a convolutional neural network (CNN) object detection algorithm called Faster R-CNN, with an input of multi-angular view shifted images. After the initial detection, the hens' relative location along the feeder was tracked and saved using a tracking algorithm. Information was added with every additional frame, as the camera arm moved along the cages. The algorithm count was compared with that made by a human observer (the 'gold standard'). A validation dataset of about 2000 images achieved 89.6% accuracy at cage level, with a mean absolute error of 2.5 hens per cage. These results indicate that the model developed in this study is practicable for obtaining fairly good estimates of the number of laying hens in battery cages.	187.93396902284974
1287.	The overestimation caused by function approximation is a well-known property in Q-learning algorithms, especially in single-critic models, which leads to poor performance in practical tasks. However, the opposite property, underestimation, which often occurs in Q-learning methods with double critics, has been largely left untouched. In this article, we investigate the underestimation phenomenon in the recent twin delay deep deterministic actor-critic algorithm and theoretically demonstrate its existence. We also observe that this underestimation bias does indeed hurt performance in various experiments. Considering the opposite properties of single-critic and double-critic methods, we propose a novel triplet-average deep deterministic policy gradient algorithm that takes the weighted action value of three target critics to reduce the estimation bias. Given the connection between estimation bias and approximation error, we suggest averaging previous target values to reduce per-update error and further improve performance. Extensive empirical results over various continuous control tasks in OpenAI gym show that our approach outperforms the state-of-the-art methods.	187.93386848725612
1288.	Rolling bearing plays a significant part in enhancing the reliability and security of locomotive. Therefore, how to accurately and automatically identify the rolling bearing faults is becoming more and more urgent. For this purpose, an adaptive rolling bearing fault diagnosis method is proposed in this paper. Firstly, deep gated recurrent unit is constructed to effectively learn the features of bearing vibration signals. Secondly, artificial fish swarm algorithm is applied to obtain the key parameters of deep gated recurrent unit. Finally, extreme learning machine is used to accurately classify the learned features and provide final diagnosis result. The proposed method is verified by the measured locomotive bearing vibration signals and the results indicate the feature learning ability of deep gated recurrent unit is powerful and the proposed method achieves more accurate and robust performance than other diagnosis methods.	187.93385388195185
1289.	The vast amount of design freedom in disordered systems expands the parameter space for signal processing. However, this large degree of freedom has hindered the deterministic design of disordered systems for target functionalities. Here, we employ a machine learning approach for predicting and designing wave-matter interactions in disordered structures, thereby identifying scale-free properties for waves. To abstract and map the features of wave behaviors and disordered structures, we develop disorder-to-localization and localization-to-disorder convolutional neural networks, each of which enables the instantaneous prediction of wave localization in disordered structures and the instantaneous generation of disordered structures from given localizations. We demonstrate that the structural properties of the network architectures lead to the identification of scale-free disordered structures having heavy-tailed distributions, thus achieving multiple orders of magnitude improvement in robustness to accidental defects. Our results verify the critical role of neural network structures in determining machine-learning-generated real-space structures and their defect immunity. The performance of a trained neural network may be biased even by generic features of its architecture. Yu et al. ask for the disordered lattice of atoms producing a certain wave localization and the network prefers to answer with power-law distributed displacements.	187.93381481766065
1290.	Medical tools used to bolster decision-making by medical specialists who offer malaria treatment include image processing equipment and a computer-aided diagnostic system. Malaria images can be employed to identify and detect malaria using these methods, in order to monitor the symptoms of malaria patients, although there may be atypical cases that need more time for an assessment. This research used 7000 images of Xception, Inception-V3, ResNet-50, NasNetMobile, VGG-16 and AlexNet models for verification and analysis. These are prevalent models that classify the image precision and use a rotational method to improve the performance of validation and the training dataset with convolutional neural network models. Xception, using the state of the art activation function (Mish) and optimizer (Nadam), improved the effectiveness, as found by the outcomes of the convolutional neural model evaluation of these models for classifying the malaria disease from thin blood smear images. In terms of the performance, recall, accuracy, precision, and F1 measure, a combined score of 99.28% was achieved. Consequently, 10% of all non-dataset training and testing images were evaluated utilizing this pattern. Notable aspects for the improvement of a computer-aided diagnostic to produce an optimum malaria detection approach have been found, supported by a 98.86% accuracy level.	187.93376518406714
1291.	The size of the human eye opening and closing plays a certain role in the human-computer interaction platform, such as the PERCLOS parameter commonly used in driver fatigue detection. Considering that the image in the actual application scene is often accompanied by distance, blur, etc., this paper proposes an algorithm based on BiseNet and Vgg methods which can segment the pupil and iris while outputting the realtime opening ratio of the eye.	187.9337427994334
1292.	Accurate bearing degradation assessment and remaining useful life (RUL) prediction may effectively avoid major disasters in manufacturing. With the rapid development of the computer industry, deep learning has emerged as a reliable algorithm for time-series prediction and has shown good performance. In this paper, the journal bearing seizure experiment was performed. The collected multi-sensor failure dataset is used for feature extraction and degradation indicator (DI) construction. The DI and working condition information are applied for degradation stage (DS) division by the fuzzy c-means (FCM) algorithm. Considering the transition of different DSs, the one-stage and multi-stage iteration prediction models based on the Long Short-Term Memory (LSTM) neural network for RUL prediction are proposed. The particle swarm optimization (PSO) is used to optimize model hyperparameters. The results show that the multi-stage iteration prediction may achieve the early warning of seizure failure and outperform the one-stage iteration prediction and traditional machine learning prediction. (C) 2020 Published by Elsevier Ltd.	187.93371239926245
1293.	Vehicle detection is one of the most important environment perception tasks for autonomous vehicles. The traditional vision-based vehicle detection methods are not accurate enough especially for small and occluded targets, while the light detection and ranging- (lidar-) based methods are good in detecting obstacles but they are time-consuming and have a low classification rate for different target types. Focusing on these shortcomings to make the full use of the advantages of the depth information of lidar and the obstacle classification ability of vision, this work proposes a real-time vehicle detection algorithm which fuses vision and lidar point cloud information. Firstly, the obstacles are detected by the grid projection method using the lidar point cloud information. Then, the obstacles are mapped to the image to get several separated regions of interest (ROIs). After that, the ROIs are expanded based on the dynamic threshold and merged to generate the final ROI. Finally, a deep learning method named You Only Look Once (YOLO) is applied on the ROI to detect vehicles. The experimental results on the KITTI dataset demonstrate that the proposed algorithm has high detection accuracy and good real-time performance. Compared with the detection method based only on the YOLO deep learning, the mean average precision (mAP) is increased by 17%.	187.93370897505923
1294.	Research on Multi-person pose estimation is partly improved by deep learning and the computer vision. Multi-person pose estimation is expected to be involved in many applications, such as fitness training, pedestrian recognition, military training, and so on. The prospect of multi-person estimation development is promising and challenging. This paper provides a brief survey on four major multi-person pose estimation methods - DeepCut, DeeperCut, OpenPose and AlphaPose, and presents the advantages and disadvantages of these methods.	187.9335519091099
1295.	The explosion of medical imaging data along with the advent of big data analytics has launched an exciting era for clinical research. One factor affecting the ability to aggregate large medical image collections for research is the lack of infrastructure for automated data annotation. Among all imaging modalities, annotation of magnetic resonance (MR) images is particularly challenging due to the non-standard labeling of MR image types. In this work, we aimed to train a deep neural network to annotate MR image sequence type for scans of brain tumor patients. We focused on the four most common MR sequence types within neuroimaging: T1-weighted (T1W), T1-weighted post-gadolinium contrast (T1Gd), T2-weighted (T2W), and T2-weighted fluid-attenuated inversion recovery (FLAIR). Our repository contains images acquired using a variety of pulse sequences, sequence parameters, field strengths, and scanner manufacturers. Image selection was agnostic to patient demographics, diagnosis, and the presence of tumor in the imaging field of view. We used a total of 14,400 two-dimensional images, each visualizing a different part of the brain. Data was split into train, validation, and test sets (9600, 2400, and 2400 images, respectively) and sets consisted of equal-sized groups of image types. Overall, the model reached an accuracy of 99% on the test set. Our results showed excellent performance of deep learning techniques in predicting sequence types for brain tumor MR images. We conclude deep learning models can serve as tools to support clinical research and facilitate efficient database management.	187.93353579584797
1296.	Automatic vehicle detection and recognition play a vital role in intelligent transport systems (ITS). However, study results in this field remain certain limitations in terms of accuracy and processing time. This article proposes a solution to improve the accuracy of vehicle recognition in order to support traffic monitoring on vehicle restricted roads. The proposed solution to vehicle recognition consists of two basic stages: (1) Vehicle detection, (2) vehicle recognition. This study focuses on proposing solutions for improving the accuracy of vehicle recognition (stage 2). The vehicle recognition solution is based on the combination of architectural development in deep neural networks, SVM model, and data augmenting solutions. It aims at achieving a greater accuracy than traditional approaches. The proposed solution is experimented, evaluated, and compared with different approaches to the same set of data. Experimental results have shown that the proposed solution brings a higher accuracy than other approaches. Along with an acceptable processing time, this promising solution is able to be applied in practical systems.	187.93351154333837
1297.	Visual object tracking has attracted widespread interests recently. Due to the complementary features provided by visible and infrared images, fusion tracking based on visible and infrared images can boost the tracking performance under adverse challenging conditions. RGB-infrared fusion tracking has become an active research topic and various algorithms have been proposed in recent years. In this paper, we present a review on RGB-infrared fusion tracking. We summarize all major RGB-infrared trackers in the literature and categorize them into several major groups for better understanding. We also discuss the development of RGB-infrared datasets, and analyze the main results on public datasets. We observe that deep learning-based methodsachieve the state-of-the-art performances. Besides, the graph-based and correlation filter-based methods give a bit worse but still competitive performances. In conclusion, we give some suggestions on future research directions of fusion tracking based on our observations. This review can serve as a reference for researchers in RGB-infrared fusion tracking, image fusion, and related fields.	187.9332062695525
1298.	Fine-Grained ship classification is quite challenging because the visual differences between the subcategories are small. Due to the large intra-class similarity, it is very difficult to classify the ship objects without bounding box/part annotations. In this paper, we propose a model that combines multiple deep CNN features and use fusion strategies to explore of multi-scale features relationship. Because different levels/depths CNN features have different properties, so we combine multiple low-level local CNN features with high-level global CNN feature for object classification. The model shows a good way of tailoring pre-trained CNN models to fine-grained ship classification, which have lower cost in computation and storage compared with some state-of-the-art CNN methods and achieves the significant classification performances in FGVC-Aircraft and Stanford Cars datasets.	187.9330417954463
1299.	Existing object trackers are mostly based on correlation filtering and neural network frameworks. Correlation filtering is fast but has poor accuracy. Although a neural network can achieve high precision, a large amount of computation increases the tracking time. To address this problem, we utilize a convolutional neural network (CNN) to learn object direction. We propose a target direction classification network based on CNNs that has a directional shortcut to the tracking target, unlike the particle filter that randomly finds the target. Our network uses an end-to-end approach to determine scale variation that has good robustness to scale variation sequences. In the pretraining stage, the Visual Object Tracking Challenges (VOT) dataset is used to train the network for learning positive and negative sample classification and direction classification. In the online tracking stage, the sliding window operation is performed by using the obtained directional information to determine the exact position of the object. The network only calculates a single sample, which guarantees a low computational burden. The positive and negative sample redetection strategies can successfully ensure that the samples are not lost. The one-pass evaluation (OPE) evaluation results of the object tracking benchmark (OTB) demonstrate that the algorithm is very robust and is also faster than several deep trackers.	187.93292171838124
1300.	Neighbors Embedding based pansharpening methods have received increasing interests in recent years. However, image patches do not strictly follow the similar structure in the shallow MultiSpectral (MS) and PANchromatic (PAN) image spaces, consequently leading to a bias to the pansharpening. In this paper, a new deep metric learning method is proposed to learn a refined geometric multi-manifold neighbor embedding, by exploring the hierarchical features of patches via multiple nonlinear deep neural networks. First of all, down-sampled PAN images from different satellites are divided into a large number of training image patches and are then grouped coarsely according to their shallow geometric structures. Afterwards, several Stacked Sparse AutoEncoders (SSAE) with similar structures are separately constructed and trained by these grouped patches. In the fusion, image patches of the source PAN image pass through the networks to extract features for formulating a deep distance metric and thus deriving their geometric labels. Then, patches with the same geometric labels are grouped to form geometric manifolds. Finally, the assumption that MS patches and PAN patches form the same geometric manifolds in two distinct spaces, is cast on geometric groups to formulate geometric multi-manifold embedding for estimating high resolution MS image patches. Some experiments are taken on datasets acquired by different satellites. The experimental results demonstrate that our proposed method can obtain better fusion results than its counterparts in terms of visual results and quantitative evaluations. (C) 2018 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.	187.93288339855883
1301.	Cervical cancer causes the fourth most cancer-related deaths of women worldwide. Early detection of cervical intraepithelial neoplasia (CIN) can significantly increase the survival rate of patients. In this paper, we propose a deep learning framework for the accurate identification of LSIL+ (including CIN and cervical cancer) using time-lapsed colposcopic images. The proposed framework involves two main components, i.e., key-frame feature encoding networks and feature fusion network. The features of the original (pre-acetic-acid) image and the colposcopic images captured at around 60s, 90s, 120s and 150s during the acetic acid test are encoded by the feature encoding networks. Several fusion approaches are compared, all of which outperform the existing automated cervical cancer diagnosis systems using a single time slot. A graph convolutional network with edge features (E-GCN) is found to be the most suitable fusion approach in our study, due to its excellent explainability consistent with the clinical practice. A large-scale dataset, containing time-lapsed colposcopic images from 7,668 patients, is collected from the collaborative hospital to train and validate our deep learning framework. Colposcopists are invited to compete with our computer-aided diagnosis system. The proposed deep learning framework achieves a classification accuracy of 78.33%-comparable to that of an in-service colposcopist-which demonstrates its potential to provide assistance in the realistic clinical scenario.	187.9328727359284
1302.	People counting in surveillance cameras is a key technology for understanding the flow population and generating heat maps. In recent years, people detection performance has been greatly improved with the development of object detection algorithms using deep learning. However, in places where people are crowded, the detection rate is low as people are often occluded by other people. We proposed a people-counting method using a stereo camera to resolve the non-detection problem due to the occlusion. We applied stereo matching to extract the depth image and convert the camera view to top view using depth information. People were detected using a height map and an occupancy map, and people were tracked and counted using a Kalman filter-based tracker. We operated the proposed method on the NVIDIA Jetson TX2 to check the real-time operation possibility on the embedded board. Experimental results showed that the proposed method had higher accuracy than the existing methods and that real-time processing is possible.	187.93285212018276
1303.	Identifying and counting fish individuals on photos and videos is a crucial task to cost-effectively monitor marine biodiversity, yet it remains difficult and time-consuming. In this paper, we present a method to assist the identification of fish species on underwater images, and we compare our model performances to human ability in terms of speed and accuracy. We first tested the performance of a convolutional neural network (CNN) trained with different photographic databases while accounting for different post-processing decision rules to identify 20 fish species. Finally, we compared the performance of species identification of our best CNN model with that of humans on a test database of 1197 fish images representing nine species. The best CNN was the one trained with 900,000 images including (i) whole fish bodies, (ii) partial fish bodies and (iii) the environment (e.g. reef bottom or water). The rate of correct identification was 94.9%, greater than the rate of correct identification by humans (89.3%). The CNN was also able to identify fish individuals partially hidden behind corals or behind other fish and was more effective than humans to identify fish on smallest or blurry images while humans were better to identify fish individuals in unusual positions (e.g. twisted body). On average, each identification by our best CNN using a common hardware took 0.06 s. Deep Learning methods can thus perform efficient fish identification on underwater images and offer promises to build-up new video-based protocols for monitoring fish biodiversity cheaply and effectively.	187.9328195113111
1304.	Mid-spatial-frequency (MSF) error on optical surfaces can do great harm to high-performance laser systems. A non-interferometric way of measuring it is phase retrieval, which has already proved its effectiveness in previous studies. However, the performance of phase retrieval is limited by its long-time iterative process and relies heavily on reliable initial solution. Therefore, in this paper, we put forward a method for fast measurement of MSF error, by introducing advanced deep learning technique into traditional computational imaging methods. Results show that the proposed method simultaneously gains an improvement on convergence speed and a reduction on residual error. The proposed method takes much fewer iterations to converge to the same error level, and has much smaller average residual error than that of the conventional algorithm in the numerical experiments.	187.9328119351935
1305.	In this paper, we introduce a new feature engineering approach for deep learning-based acoustic modeling, which utilizes input feature contributions. For this purpose, we propose an auxiliary deep neural network (DNN) called a feature contribution network (FCN) whose output layer is composed of sigmoid-based contribution gates. In our framework, the FCN tries to learn element-level discriminative contributions of input features and an acoustic model network (AMN) is trained by gated features generated by element-wise multiplication between contribution gate outputs and input features. In addition, we also propose a regularization method for the FCN, which helps the FCN to activate the minimum number of the gates. The proposed methods were evaluated on the TED-LIUM release 1 corpus. We applied the proposed methods to DNN- and long short-term memory-based AMNs. Experimental results results showed that AMNs with the FCNs consistently improved recognition performance compared with AMN-only frameworks.	187.9327351423177
1306.	Intelligent diagnosis algorithms can monitor faults with industrial production of a timely manner via their powerful learning ability. Multi-sensor diagnosis systems can more comprehensively describe the state of equipment and avoid the influence of incorrect data acquisition locations, which is beneficial to fault diagnosis. The fusion of the original data is a difficult problem, and it is hard to express effective information via traditional algorithms. This paper presents an adaptive data fusion strategy based on deep learning called the convolutional neural network with atrous convolution for the adaptive fusion of multiple source data (FAC-CNN). Specifically, an adaptive-sized convolution kernel that matches the channel of data sources is constructed to capture multi-source data without tedious preprocessing, and the channel of data sources is not limited. The atrous convolution kernel is introduced to expand the field of view of the FAC-CNN and extracts fusion sequence features without repeated computation, resulting in improved stability. The 1D-CNN is added to extract features after atrous convolution. In addition, batch normalization optimizes the distribution of fusion data and the structure of the model. The parametric rectified linear unit activation function and global average pooling are also introduced to improve network performance. The proposed method is validated on an industrial fan system with non-manufacturing faults and a centrifugal pump. Compared with other fusion methods and diagnosis algorithms based on feature engineering, namely CNN, ANN, and SVM, the FAC-CNN model is found to exhibit superior performance. (c) 2020 Elsevier Ltd. All rights reserved.	187.93244936853654
1307.	Harsh weather and deep waters create challenging environments for offshore drilling and production facilities, resulting in increased chances of failure. These necessitate improving the resilience of engineering systems. Having a robust power system is an essential element of an offshore facility. A power management system interacts with other engineering systems to maximize performance and limit potential failures. Ensuring a safe and continuous operation requires technological advancement, increased reliability of integrated operations, and improvement of power system resiliency. This paper identifies the main requirements for an improved resilience of an offshore power management scheme. Different potential failure scenarios are identified and analyzed to quantify the resilience of the system. The object-oriented Bayesian network format is adopted to model resilience as a function of anticipated reactions, system adaptability, absorptive capability and restoration. Sensitivity analysis is conducted to study the impact and interdependencies among different variables and strategies used to quantify resilience of an offshore power system, and also to improve the system performance during certain failures by adapting control measures.	187.9324308665632
1308.	The novel coronavirus disease 2019 (COVID-19), detected in Wuhan City, Hubei Province, China in late December 2019, is rapidly spreading and affecting all countries in the world. Real-time reverse transcription-polymerase chain reaction (RT-PCR) test has been described by the World Health Organization (WHO) as the standard test method for the diagnosis of the disease. However, considering that the results of this test are obtained between a few hours and two days, it is very important to apply another diagnostic method as an alternative to this test. The fact that RT-PCR test kits are limited in number, the test results are obtained in a long time, and the high probability of healthcare personnel becoming infected with the disease during the test, necessitates the use of other diagnostic methods as an alternative to these test kits. In this study, a hybrid model consisting of two-dimensional (2D) curvelet transformation, chaotic salp swarm algorithm (CSSA) and deep learning technique is developed in order to determine the patient infected with coronavirus pneumonia from X-ray images. In the proposed model, 2D Curvelet transformation is applied to the images obtained from the patient's chest X-ray radiographs and a feature matrix is formed using the obtained coefficients. The coefficients in the feature matrix are optimized with the help of the CSSA and COVID-19 disease is diagnosed by the EfficientNet-B0 model, which is one of the deep learning methods. Experimental results show that the proposed hybrid model can diagnose COVID-19 disease with high accuracy from chest X-ray images.	187.93240558349225
1309.	We developed a novel ensemble three-dimensional residual network (E3D-ResNet) for the reduction of false positives (FPs) in computer-aided detection (CADe) of polyps for CT colonography (CTC). To capture the volumetric multiscale information of CTC images, each polyp candidate was represented by three different sizes of volumes of interest (VOIs), which were enlarged to a common size. Each type of VOI was subjected to one of three 3D-ResNets. The final polyp likelihood was obtained as the maximum of the polyp-likelihood probabilities calculated by the 3D-ResNets. We compared the classification performance of the E3D-ResNet with that of a non-ensemble 3D-ResNet, ensemble 2.5D-ResNet, and ensemble of 2.5D- and 3D-convolutional neural network (CNN) models. All models were trained and evaluated with 21,021 VOIs of polyps and 19,557 VOIs of FPs that were sampled with data augmentation from the CADe detections on the CTC data of 20 patients. We used two types of data augmentation, one based on linear transformations of the VOIs and another based on a self-attention generative adversarial network. We evaluated the classification performance of the models with receiver operating characteristics (ROC) analysis using 5-fold cross-validation, where the area under the ROC curve (AUC) was used as the figure of merit. Preliminary results showed that the AUC value of the E3D-ResNet (0.98) was significantly higher than that of the reference models (P < 0.001), indicating that the E3D-ResNet has the potential of substantially reducing FPs in CADe of polyps for CTC.	187.93238481111467
1310.	Click-through rate (CTR) prediction is a critical task in online advertising systems. Models like Deep Neural Networks (DNNs) are simple but stateless. They consider each target ad independently and cannot directly extract useful information contained in users' historical ad impressions and clicks. In contrast, models like Recurrent Neural Networks (RNNs) are stateful but complex. They model temporal dependency between users' sequential behaviors and can achieve improved prediction performance than DNNs. However, both the offline training and online prediction process of RNNs are much more complex and time-consuming. In this paper, we propose Memory Augmented DNN (MA-DNN) for practical CTR prediction services. In particular, we create two external memory vectors for each user, memorizing high-level abstractions of what a user possibly likes and dislikes. The proposed MA-DNN achieves a good compromise between DNN and RNN. It is as simple as DNN, but has certain ability to exploit useful information contained in users' historical behaviors as RNN. Both offline and online experiments demonstrate the effectiveness of MA-DNN for practical CTR prediction services. Actually, the memory component can be augmented to other models as well (e.g., the Wide&Deep model).	187.93237765506086
1311.	Semantic image segmentation is essential for scene understanding. Several state-of-the-art deep learning-based approaches achieved remarkable results by increasing the network depth to improve performance. Using this principle, we introduce a novel encoder-decoder network architecture for semantic image segmentation of outdoor scenes called SAsiANet. SAsiANet utilizes multi-scale cascaded autoencoders at the decoder section of an autoencoder to achieve high accuracy pixel-wise prediction and involves exploiting features across multiple scales when upsampling the output of the encoder to obtain better spatial and contextual information effectively. The proposed network architecture is trained using the cross-entropy loss function but without incorporating any class balancing technique to the loss function. Our experimental results on two challenging outdoor scenes: the CamVid urban scenes dataset and the Freiburg forest dataset demonstrate that SAsiANet provides an effective way of producing accurate segmentation maps since it achieved state-of-the-art results on the test set of both datasets, 72.40% mIoU, and 89.90% mIoU, respectively.	187.93234530868423
1312.	Microbes from the three domains of life,Bacteria,Archaea, andEukarya, share the need to sense and respond to changes in the external and internal concentrations of protons. When the proton concentration is high, acidic conditions prevail and cells must respond appropriately to ensure that macromolecules and metabolic processes are sufficiently protected to sustain life. While, we have learned much in recent decades about the mechanisms that microbes use to cope with acid, including the unique challenges presented by organic acids, there is still much to be gained from developing a deeper understanding of the effects and responses to acid in microbes. In this perspective article, we survey the key molecular mechanisms known to be important for microbial survival during acid stress and discuss how this knowledge might be relevant to microbe-based applications and processes that are consequential for humans. We discuss the research approaches that have been taken to investigate the problem and highlight promising new avenues. We discuss the influence of acid on pathogens during the course of infections and highlight the potential of using organic acids in treatments for some types of infection. We explore the influence of acid stress on photosynthetic microbes, and on biotechnological and industrial processes, including those needed to produce organic acids. We highlight the importance of understanding acid stress in controlling spoilage and pathogenic microbes in the food chain. Finally, we invite colleagues with an interest in microbial responses to low pH to participate in the EU-funded COST Action network called EuroMicropH and contribute to a comprehensive database of literature on this topic that we are making publicly available.	187.93212049647408
1313.	Spoken language understanding is an important part of the human-machine dialogue system, intent detection is a sub-task of spoken language understanding, and it is very important. The accuracy of intent detection is directly related to the performance of semantic slot filling, and it is helpful to the following research of the dialogue system. Considering the difficulty of intent detection in human-machine dialogue system, the traditional machine learning method cannot understand the deep semantic information of user's discourse. This paper mainly analyzes, compares and summarizes the deep learning methods applied in the research of intent detection in recent years, and further considers how to apply deep learning model to multi-intent detection task, so as to promote the research of multi-intent detection methods based on deep neural network.	187.93208267824133
1314.	This paper addresses the challenges of small training data in deep learning. We share our experiences in the medical domain and present promises and limitations. In particular, we show through experimental results that GANs are ineffective in generating quality training data to improve supervised learning. We suggest plausible research directions to remedy the problems.	187.93191863698954
1315.	Falls are the most common cause of fatal injuries in elderly people, causing even death if there is no immediate assistance. Fall detection systems can be used to alert and request help when this type of accident happens. Certain types of these systems include wearable devices that analyze bio-medical signals from the person carrying it in real time. In this way, Deep Learning algorithms could automate and improve the detection of unintentional falls by analyzing these signals. These algorithms have proven to achieve high effectiveness with competitive performances in many classification problems. This work aims to study 16 Recurrent Neural Networks architectures (using Long Short-Term Memory and Gated Recurrent Units) for falls detection based on accelerometer data, reducing computational requirements of previous research. The architectures have been tested on a labeled version of the publicly available SisFall dataset, achieving a mean F1-score above 0.73 and improving state-of-the-art solutions in terms of network complexity.	187.93188063025423
1316.	Purpose: To assess the utility of deep learning in the detection of geographic atrophy (GA) from color fundus photographs and to explore potential utility in detecting central GA (CGA). Design: A deep learning model was developed to detect the presence of GA in color fundus photographs, and 2 additional models were developed to detect CGA in different scenarios. Participants: A total of 59 812 color fundus photographs from longitudinal follow-up of 4582 participants in the Age-Related Eye Disease Study (AREDS) dataset. Gold standard labels were from human expert reading center graders using a standardized protocol. Methods: A deep learning model was trained to use color fundus photographs to predict GA presence from a population of eyes with no AMD to advanced AMD. A second model was trained to predict CGA presence from the same population. A third model was trained to predict CGA presence from the subset of eyes with GA. For training and testing, 5-fold cross-validation was used. For comparison with human clinician performance, model performance was compared with that of 88 retinal specialists. Main Outcome Measures: Area under the curve (AUC), accuracy, sensitivity, specificity, and precision. Results: The deep learning models (GA detection, CGA detection from all eyes, and centrality detection from GA eyes) had AUCs of 0.933-0.976, 0.939-0.976, and 0.827-0.888, respectively. The GA detection model had accuracy, sensitivity, specificity, and precision of 0.965 (95% confidence interval [CI], 0.959-0.971), 0.692 (0.560-0.825), 0.978 (0.970-0.985), and 0.584 (0.491-0.676), respectively, compared with 0.975 (0.971-0.980), 0.588 (0.468-0.707), 0.982 (0.978-0.985), and 0.368 (0.230-0.505) for the retinal specialists. The CGA detection model had values of 0.966 (0.957-0.975), 0.763 (0.641-0.885), 0.971 (0.960-0.982), and 0.394 (0.341-0.448). The centrality detection model had values of 0.762 (0.725-0.799), 0.782 (0.618-0.945), 0.729 (0.543-0.916), and 0.799 (0.710-0.888). Conclusions: A deep learning model demonstrated high accuracy for the automated detection of GA. The AUC was noninferior to that of human retinal specialists. Deep learning approaches may also be applied to the identification of CGA. The code and pretrained models are publicly available at https://github.com/ncbi-nlp/DeepSeeNet. Published by Elsevier on behalf of the American Academy of Ophthalmology	187.93186259752605
1317.	Knowledge-based question answering has attracted a lot of attention in the research communities of natural language processing and information retrieval. However, existing studies do not adequately address the problem of answering complex questions which involve multiple entities and require extraction of facts from multiple relations. To address this issue, we propose a novel approach which learns the distributional representations of questions and candidate answers in a unified deep-learning framework based on directed-acyclic-graph-structured long short-term memory and memory networks. Specifically, the questions are encoded to match candidate directed acyclic subgraphs of the knowledge base, which are able to include information related to multiple entities and relations in the complex questions. The experimental results show that the proposed approach outperforms other methods on the widely used dataset SPADES, especially when dealing with complex questions with multiple entities. (C) 2019 Elsevier Ltd. All rights reserved.	187.93172225969784
1318.	In an online social network (like Twitter), a botmaster (i.e., leader among a group of social bots) establishes a social relationship among legitimate participants to reduce the probability of social bot detection. Social bots generate fake tweets and spread malicious information by manipulating the public opinion. Therefore, the detection of social bots in an online social network is an important task. In this paper, we consider social attributes, such as tweet-based attributes, user profile-based attributes and social graph-based attributes for detecting the social bots among legitimate participants. We design a deep Q-network architecture by incorporating a Deep Q-Learning (DQL) model using the social attributes in the Twitter network for detection of social bots based on updating Q-value function (i.e., state-action value function). We consider each social attribute of a user as a state and the learning agent's movement from one state to another state is considered as an action. For Q-value function, we consider all the state-action pairs in order to construct the state transition probability values between the state-action pairs. In the proposed DQL algorithm, the learning agent chooses a specific learning action with an optimal Q-value in each state for social bot detection. Further, we also propose an approach that identifies the most influential users (which are influenced by the social bots) based on tweets and the users' interactions. The experimentation using the datasets collected from Twitter network illustrates the efficacy of proposed model.	187.93167429518974
1319.	The detection and classification of maritime objects in a harbour environment or coastal areas using a terrestrial hyperspectral system in combination with a high-resolution RGB sensor is a challenging task since the large number of spectral channels requires a robust analytical method. Recently, deep learning methods have shown a good performance in many computer vision applications. In this paper, we present a general analysis workflow for ship detection and classification based on fused terrestrial RGB and hyperspectral images, which employs a deep learning network for the localization of ships in the high-resolution images and a following convolutional neural network based multi-input model for the classification of each detected object. During a measurement campaign, images of various ship types were collected under distinct weather conditions for the training and evaluation of the network model. In the first part of the workflow, ship candidates were located using the Mask R-CNN framework based on the RGB images. For the following classification process, which was trained to separate different ship type classes, we developed a multi-input convolutional neural network using the RGB and the hyperspectral images as input data. For the pre-processing procedure of the hyperspectral data a principal component analysis was applied to reduce the number of input channels for the network while still maintaining a large fraction of the initial information. For the architecture of the RGB classification branch, the structure and the weights of a pre-trained model were integrated and fine-tuned. Since only limited training data was available, regularization methods and data augmentation were employed. The detection and the multi-input classification network was finally evaluated and showed that the classification performance can be increased when integrating additional information from a hyperspectral sensor.	187.93146247556876
1320.	Object tracking in challenging videos is a hot topic in machine vision. Recently, novel training-based detectors, especially using the powerful deep learning schemes, have been proposed to detect objects in still images. However, there is still a semantic gap between the object detectors and higher level applications like object tracking in videos. This paper presents a comparative study of outstanding learning-based object detectors such as ACF, Region-Based Convolutional Neural Network (RCNN), FastRCNN, FasterRCNN and You Only Look Once (YOLO) for object tracking. We use an online and offline training method for tracking. The online tracker trains the detectors with a generated synthetic set of images from the object of interest in the first frame. Then, the detectors detect the objects of interest in the next frames. The detector is updated online by using the detected objects from the last frames of the video. The offline tracker uses the detector for object detection in still images and then a tracker based on Kalman filter associates the objects among video frames. Our research is performed on a TLD dataset which contains challenging situations for tracking. Source codes and implementation details for the trackers are published to make both the reproduction of the results reported in this paper and the re-use and further development of the trackers for other researchers. The results demonstrate that ACF and YOLO trackers show more stability than the other trackers.	187.93142875114575
1321.	Fetal magnetic resonance imaging (MRI) is challenged by uncontrollable, large, and irregular fetal movements. It is, therefore, performed through visual monitoring of fetal motion and repeated acquisitions to ensure diagnostic-quality images are acquired. Nevertheless, visual monitoring of fetal motion based on displayed slices, and navigation at the level of stacks-of-slices is inefficient. The current process is highly operator-dependent, increases scanner usage and cost, and significantly increases the length of fetal MRI scans which makes them hard to tolerate for pregnant women. To help build automatic MRI motion tracking and navigation systems to overcome the limitations of the current process and improve fetal imaging, we have developed a new real-time image-based motion tracking method based on deep learning that learns to predict fetal motion directly from acquired images. Our method is based on a recurrent neural network, composed of spatial and temporal encoder-decoders, that infers motion parameters from anatomical features extracted from sequences of acquired slices. We compared our trained network on held-out test sets (including data with different characteristics, e.g. different fetuses scanned at different ages, and motion trajectories recorded from volunteer subjects) with networks designed for estimation as well as methods adopted to make predictions. The results show that our method outperformed alternative techniques, and achieved real-time performance with average errors of 3.5 and 8 degrees for the estimation and prediction tasks, respectively. Our real-time deep predictive motion tracking technique can be used to assess fetal movements, to guide slice acquisitions, and to build navigation systems for fetal MRI.	187.9313503893368
1322.	Content-based medical image retrieval (CBMIR) is an active field of research and a complementary decision support tool for the diagnosis of breast cancer. Current CBMIR systems employ hand-engineered image descriptors which are not effective enough at retrieval phase. Besides this drawback, the so-called semantic gap in the CBMIR is not still addressed leaving the room for further improvements. To fill in the two mentioned existing gaps, we proposed a new retrieval method which exploited a deep pre-trained convolutional neural network model to extract class-specific and patient-specific tumorous descriptor to firstly train a binary breast cancer classifier and then a multi-patient classifier aiming for reducing dimensions of the raw deeply transferred features and obtaining semantic scores which significantly enhanced the performance in terms of mean average precision. We evaluated the method on scalable BreakHis dataset of histopathological breast cancer images. After conducting five sets of experiments, results demonstrated the superior effectiveness of the proposed semantic-driven retrieval methods by means of increased mean average precision and decreased dimensionality and retrieval time. In overall, an improvement of 29.03% was obtained by the proposed class-driven semantic retrieval method.	187.93130333744082
1323.	Traffic flow in a road network is mutually interactive and interdependent with each other. It is challenging to describe the dynamics of traffic network flow by using analytical methods. In this article, the deep convolutional neural network (DCNN) model is employed to address traffic network flow prediction. To improve the parameter learning efficiency confronting traffic big data, a parallel training approach is developed for the DCNN prediction model. The theoretical foundation is developed for the parallel training algorithm of the DCNN model. A master-slave parallel computing solution for traffic network flow prediction is implemented on the Spark cloud. Real data of traffic network flow are applied to verify the effectiveness of the DCNN prediction model and the parallel training algorithm. The experimental results demonstrate that the DCNN prediction model for traffic network flow outperforms the typical prediction models based on backpropagation neural networks, support vector regressions, radial basis functions, and decision tree regressions. The proposed parallel training method can improve the training efficiency and obtain global features of the entire dataset from local learning with regard to the respective data subsets.	187.93123259157275
1324.	Prognostics for lithium-ion batteries is very critical in many industrial applications, and accurate prediction of battery state of health (SOH) is of great importance for health management. This paper proposes a novel deep learning-based prognostic method for lithium-ion batteries with on-line validation. An effective variant of recurrent neural network, i.e. long short-term memory structure, is used with variable input dimension, that facilitates network training with additional labeled samples. Adaptive time-series predictions are carried out for prognostics. An on-line validation method is further proposed for parameter optimization in real time based on the available system information, which allows for continuous model improvement. Experiments on a popular lithium-ion battery dataset are implemented to validate the effectiveness and superiority of the proposed method. The experimental results show the prognostic performances are promising both for the multi-steps-ahead predictions and long-horizon SOH estimations. (C) 2020 Elsevier Ltd. All rights reserved.	187.93115369884669
1325.	With increased focus on in situ analytics, artificial intelligence (AI) algorithms are getting deployed on embedded devices at the network edge. Growing popularity of Deep Learning (DL) and inference largely due to minimization of feature engineering, availability of pre-trained models and fine-tunable datasets especially in image and video analytics, have made these de-facto standard. However, the embedded systems employing these models are often resource constrained and fail to handle scenarios where arrival rate and input data volume increase over a given time period. This has a direct effect on the storage and network usage of such devices, rendering the traditional strategies of input buffering and network offloading ineffective. This paper investigates the use of dynamic layer-wise partitioning and partial execution of DL inference phase to enable inelastic embedded systems to support varying sensing rates and large data volume. The proposed partial execution scheme and partitioning algorithm perform better than standard frame-wise inference methods, when evaluated using workloads of few popular CNNs used in standard object detection models.	187.93112603217202
1326.	We report our experience with developing an assurance case for a deep learning system used for retinal disease diagnosis and referral. We investigate how an assurance case could clarify the scope and structure of the primary argument and identify sources of uncertainty. We also explore the need for an assurance argument pattern that could provide developers with a reusable template for communicating and structuring the different claims and evidence and clarifying the clinical context rather than merely focusing on meeting or exceeding performance measures.	187.93102809968212
1327.	Over the past few years, the application of deep learning models to finance has received much attention from investors and researchers. Our work continues this trend, presenting an application of a Deep learning model, long-term short-term memory (LSTM), for the forecasting of commodity prices. The obtained results predict with great accuracy the prices of commodities including crude oil price (98.2 price(88.2 on the variability of the commodity prices. This involved checking at the correlation and the causality with the Ganger Causality method. Our results reveal that the coronavirus impacts the recent variability of commodity prices through the number of confirmed cases and the total number of deaths. We then investigate a hybrid ARIMA-Wavelet model to forecast the coronavirus spread. This analyses is interesting as a consequence of the strong causal relationship between the coronavirus(number of confirmed cases) and the commodity prices, the prediction of the evolution of COVID-19 can be useful to anticipate the future direction of the commodity prices.	187.93100133366428
1328.	Convolutional neural networks (CNNs)-based deep features have been demonstrated with remarkable performance in various vision tasks, such as image classification and face verification. Compared with the hand-crafted descriptors, deep features exhibit more powerful representation ability. Typically, higher layer features contain more semantic information, while lower layer features can provide more low-level description. In addition, it turns out that the fusion of different layer features will lead to superior performance. Here, we propose a novel approach for human ear identification by combining hierarchical deep features. First, hierarchical deep features are extracted from ear images using CNN pre-trained on large-scale data set. To enhance the feature representation and reduce the high dimension of deep features, the discriminant correlation analysis (DCA) is adopted for fusing deep features from different layers for further improvement. Owing to the lack of ear images per person, the authors propose to transform the ear identification problem to the binary classification by composing pairwise samples and resolve it with the pairwise support vector machine (SVM). Experiments are conducted on four public databases: USTB I, USTB II, IIT Delhi I, and IIT Delhi II. The proposed method achieves promising recognition rate and exhibits decent performance compared with the state-of-the-art methods.	187.9309933154869
1329.	Recently, a modularized smart grid (SG) architecture, entitled the Internet of Things (IoT) grid, is developed that accommodates the IoT technology into the dc-dc converters to build a programmable grid with a single voltage bus. This modern architecture can be established with low computing hardware that facilitates the control and management of the IoT-based grids. Due to the uncertainties originated from the integration of the IoT technology and power electronic converters, the deterministic methodologies are unable to precisely model the SG anymore. In response to these challenges, this article addresses a novel adaptive data-driven method based on the active disturbance rejection controller (ADRC) for the voltage regulation of an IoT-based dc-dc buck converter feeding constant power loads. In particular, a deep deterministic policy gradient (DDPG) with the actor-critic architecture is adopted for the online adjusting of the ADRC controller. The established DDPG takes into account the ADRC controller coefficients into the design objective and offers the ADRC controller with the online coefficient setting ability through the neural network learning. The IoT-based system is tested on a real-time testbed with the constrained application protocol protocol and IEEE 802.11 (Wi-Fi) network to assess the applicability of the suggested controller in the presence of network degradations. The impact of both packet loss and interfering traffic on the reduction performance of the DDPG adaptive ADRC controller is investigated, simultaneously. The supremacy of the suggested adaptive data-driven controllers is verified by a comprehensive comparative analysis with the state-of-the-art methodologies.	187.93095757019097
1330.	This work is devoted to an assessment of the application of machine learning algorithms in the prediction of a fracture's aspect ratio caused by the hydraulic fracturing. By the aspect ratio in this work is assumed the ratio of the larger half-axis of the fracture to the smaller one. The study shows the prospects of applying data-driven surrogate model methods (deep neural networks learning from data simulated by means of traditional solvers) to particle dynamics modelling of hydraulic fracturing. The solution obtained allows to predict the aspect ratio value quickly, and thus, to evaluate the volume of the hydraulic fracturing fluid injection necessary to achieve the required fracture length.	187.93095221119404
1331.	Deep learning represents state-of-the-art results in various machine learning tasks, but for applications that require real-time inference, the high computational cost of deep neural networks becomes a bottleneck for the efficiency. To overcome the high computational cost of deep neural networks, spiking neural networks (SNN) have been proposed. Herein, we propose a hardware implementation of the SNN with gated Schottky diodes as synaptic devices. In addition, we apply L1 regularization for connection pruning of the deep spiking neural networks using gated Schottky diodes as synaptic devices. Applying L1 regularization eliminates the need for a re-training procedure because it prunes the weights based on the cost function. The compressed hardware-based SNN is energy efficient while achieving a classification accuracy of 97.85% which is comparable to 98.13% of the software deep neural networks (DNN).	187.93093433878857
1332.	Purpose: Prompt diagnosis and quantitation of pneumothorax impact decisions pertaining to patient management. The purpose of our study was to develop and evaluate the accuracy of a deep learning (DL)-based image classification program for detection of pneumothorax on chest CT. Method: In an IRB approved study, an eight-layer convolutional neural network (CNN) using constant-size (36*36 pixels) 2D image patches was trained on a set of 80 chest CTs, with (n= 50) and without (n= 30) pneumothorax. Image patches were classified based on their probability of representing pneumothorax with subsequent generation of 3D heat-maps. The heat maps were further defined to include 1) pneumothorax area size, 2) relative location of the region to the lung boundary, and 3) a shape descriptor based on regional anisotropy. A support vector machine (SVM) was trained for classification. Result: We assessed performance of our program in a separate test dataset of 200 chest CT examinations, with (160/200, 75%) and without (40/200, 25%) pneumothorax. Data were analyzed to determine the accuracy, sensitivity, specificity. The subject-wise sensitivity was 100% (all 160/160 pneumothoraces detected) and specificity was 82.5% (33 true negative/40). False positive classifications were primarily related to emphysema and/or artifacts in the test images. Conclusion: This deep learning-based program demonstrated high accuracy for automatic detection of pneumothorax on chest CTs. By implementing it on a high-performance computing platform and integrating the domain knowledge of radiologists into the analytics framework, our method can be used to rapidly pre-screen large numbers of cases for presence of pneumothorax, a critical finding.	187.9308353742388
1333.	With the development of science and technology, unmanned aerial vehicle (UAV) is more and more widely used to bring a lot of convenience to the society, but also led to serious threats to public security, personal privacy, military security and other aspects. Therefore, it is increasingly important to find unknown drones quickly and accurately. In UAV detection, the technologies based on acoustic, radio and radar detection are common, but these technologies usually require expensive equipment and strict configuration. However, the method based on machine vision has the advantages of low cost and simple configuration. In addition, detection and recognition methods based on deep learning have been fully developed, but most of them are for a single visible image, and the detection and recognition effect is limited. In this paper, a fast detection and identification method based is proposed based on the backbone of YOLOv3 (You Only Look Once version3). And dual-channel detectors were used as data sources. In this method, infrared and visible images are simultaneously input into the network for feature extraction, and the extracted depth features are concatenated. Then the multi-scale prediction network is used to regression the target location to obtain the final detection and recognition results. Finally, by collecting real UAV data sets, the network is trained and tested for comparative experiments. Experimental results show that the mAP of method in this paper is worthy of improvement, and the detection speed remains at 27images/s.	187.93053840160655
1334.	Deep learning neural networks have been widely used in general 2D image processing tasks. However, its application to process high-dimensional medical images is impeded by the need to tailor the network for specific considerations on imaging systems and/or biological characteristics, and the high memory/computation cost as the image dimensionality increases. This study aims to design an assembly 2.5D image segmentation framework based on native 2D convolutional neural network (CNN), which is naturally adaptable to problem dimensionality changes in an economical way and intrinsically amicable to parallel processing. In particular, we perform soft segmentation along each 2D fiber using one native 2D CNN, aggregate such decisions based on Bayesian rule, and apply an (optional) polish step to geometrically regularize the raw segmentation. Validation experiments on volumetric CT liver segmentation demonstrate higher segmentation accuracy with pronounced cost saving benefit, compared to the state-of-the-art 3D CNN and triplanar approaches.	187.93046555071172
1335.	IoVs have been envisioned to improve road safety and efficiency, and provide Internet access on the move, by providing a myriad of safety and infotainment applications to drivers and passengers. However, with limited spectrum resource, harsh wireless channel, and variable vehicle density, IoV communication faces severe challenges to achieve scalability, efficiency, and reliability. In this article, we propose a context-aware IoV paradigm design to enhance the communication performance, where the high-level contextual information is utilized to bring intelligence in the design. Specifically, through big data analytics on large-scale IoV communication traces collected from an extensive experiment conducted in Shanghai, we investigate the impacts of different contextual information on V2V communication performance. We reveal that among many types of contextual information, the NLoS link condition is a major one that significantly affects V2V link performance. Based on that observation, we discuss three critical but challenging communication paradigm designs with context awareness of V2V link conditions: smart medium resource allocation, efficient routing establishment, and reliable safety message broadcasting. Furthermore, we present a case study of a cooperative beaconing scheme, where machine learning methods are utilized to learn the real-time link contextual information, and vehicles in deep NLoS condition choose helpers to enhance the overall beaconing reliability.	187.93040274289376
1336.	The deployment of machine learning (ML) models in the health care domain can increase the speed and accuracy of diagnosis and improve treatment planning and patient care. Translating academic research to applications that are deployable in clinical settings requires the ability to generalize and high reproducibility, which are contingent on a rigorous and sound methodology for the development and evaluation of ML models. This article describes the fundamental concepts and processes for ML model evaluation and highlights common workflows. It concludes with a discussion of the requirements for the deployment of ML models in clinical settings.	187.93029949325637
1337.	Frontera is the largest NSF-funded cluster in the US and comprises of 8,008 nodes equipped with the latest Intel Xeon processors (Cascade-Lake). In this paper, we explore the potential of Frontera for training state-of-the-art Deep Learning (DL) models at scale. Most DL studies present performance data from large-scale GPU clusters that are equipped with NVIDIA GPUs. However, our earlier performance characterization studies have helped us achieve comparable performance with CPU-only clusters as well. Based on this, we configure three important DL frameworks; 1) TensorFlow, 2) PyTorch, and 3) MXNet, using Horovod and two Message Passing Interface (MPI) libraries on Frontera: 1) MVAPICH2 and 2) Intel MPI. We provide a systematic performance comparison for TensorFlow using MVAPICH2 and Intel MPI on 2,048 Frontera nodes. Using a four process per node configuration, we observe near-linear scaling for ResNet-50 training for TensorFlow up to 8,192 MPI processes (on 2,048 nodes) offering sustained performance of 250,000 images/second. In addition, we provide insights into process per node and batch size configurations for TensorFlow as well as for PyTorch and MXNet. Based on single-node performance behavior, we scale all three DL frameworks up to 1,024 processes (256 nodes) for various models like ResNet-50/101/152 and Inception-v3/v4.	187.93025309698908
1338.	Electric power line equipment such as insulators, cut-out-switches, and lightning-arresters play important roles in ensuring a safe and uninterrupted power supply. Unfortunately, their continuous exposure to rugged environmental conditions may cause physical or electrical defects in them which may lead to the failure to the electrical system. In this paper, we present an automatic real-time electrical equipment detection and defect analysis system. Unlike previous handcrafted feature-based approaches, the proposed system utilizes a Convolutional Neural Network (CNN)-based equipment detection framework, making it possible to detect 17 different types of powerline insulators in a highly cluttered environment. We also propose a novel rotation normalization and ellipse detection method that play vital roles in the defect analysis process. Finally, we present a novel defect analyzer that is capable of detecting gunshot defects occurring in electrical equipment. The proposed system uses two cameras; a low-resolution camera that detects insulators from long-shot images, and a high-resolution camera which captures close-shot images of the equipment at high-resolution that helps for effective defect analysis. We demonstrate the performances of the proposed real-time equipment detection with up to 93% recall with 92% precision, and defect analysis system with up to 98% accuracy, on a large evaluation dataset. Experimental results show that the proposed system achieves state-of-the-art performance in automatic powerline equipment inspection.	187.9300692424082
1339.	Training deep neural networks usually requires a large amount of labeled data to obtain good performance. However, in medical image analysis, obtaining high-quality labels for the data is laborious and expensive, as accurately annotating medical images demands expertise knowledge of the clinicians. In this paper, we present a novel relation-driven semi-supervised framework for medical image classification. It is a consistency-based method which exploits the unlabeled data by encouraging the prediction consistency of given input under perturbations, and leverages a self-ensembling model to produce high-quality consistency targets for the unlabeled data. Considering that human diagnosis often refers to previous analogous cases to make reliable decisions, we introduce a novel sample relation consistency (SRC) paradigm to effectively exploit unlabeled data by modeling the relationship information among different samples. Superior to existing consistency-based methods which simply enforce consistency of individual predictions, our framework explicitly enforces the consistency of semantic relation among different samples under perturbations, encouraging the model to explore extra semantic information from unlabeled data. We have conducted extensive experiments to evaluate our method on two public benchmark medical image classification datasets, i.e., skin lesion diagnosis with ISIC 2018 challenge and thorax disease classification with ChestX-ray14. Our method outperforms many state-of-the-art semi-supervised learning methods on both single-label and multi-label image classification scenarios.	187.93003564126565
1340.	Presently Analysing clinical data of patients using machine learning techniques enhances both outcomes for patients and operations in hospitals. Moreover, the implementation of machine-learning-based patient data processing is influenced by heterogeneous patient data and inefficient in analysing feature-learning methods. Recently, Smart healthcare applications are being fitted with wearable sensors, which are mainly used to monitor and strengthen the Human activity recognition (HAR) using supervised and unsupervised learning methods which fail to attain minimized computation time to on-nodule wearable sensors and during the processing of data in the network, it fails to reduce the reconstruction error rate with optimized accuracy during classification. Therefore, this paper suggested, an innovative, unsupervised Deep learning assisted reconstructed coder (UDR-RC) which optimize the data during pre-processing at on-nodule wearable sensors to get minimized computation time of 11.25 ns for test set size and improves recognition performance in the feature selection and extraction inside the neural network for HAR activity mechanism. In this work, Coder architecture has been fused with a Z-layer scheme to model the deep learning framework to improve accuracy and to reduce reconstruction error, Further, data analytics technique has been introduced during pre-processing to minimize the computation time. Evidence of the proposed research is performed on a Wireless Sensor Data Mining (WISDM) laboratory dataset which is open to the public. Furthermore, the findings indicate that the classification accuracy of 97.5% and Mean Squared Error rate of 0.52% has been numerically validated on-nodule wearable sensor at lab scale analysis. (C) 2020 Elsevier Ltd. All rights reserved.	187.9299564021617
1341.	The traditional monophonic singing voice separation system usually consists of two modules: melody extraction and time-frequency masking. In recent years, with the rapid development of neural networks, end-to-end music separation system that based on deep learning has become more and more popular. Deep neural networks are very useful for processing complex nonlinear data, this paper describes a system based on the framework of the traditional separation system, which uses ResNet to extract the melody of music signals, and combines NMF's soft masking separation algorithm Compared with the existing module, our separation system is proved that can get better separation effect.	187.9299229782948
1342.	Event-based online social platforms, such as Meetup and Plancast, have experienced increased popularity and rapid growth in recent years. In EBSN setup, selecting suitable venues for hosting events, which can attract a great turnout, is a key challenge. In this paper, we present a deep learning based venue recommendation system DeepVenue which provides context driven venue recommendations for the Meetup event-hosts to host their events. The crux of the proposed model relies on the notion of similarity between multiple Meetup entities such as events, venues, groups, etc. We develop deep learning techniques to compute a compact descriptor for each entity, such that two entities (say, venues) can be compared numerically. Notably, to mitigate the scarcity of venue related information in Meetup, we leverage on the cross domain knowledge transfer from popular LBSN service Yelp to extract rich venue related content. For hosting an event, the proposed DeepVenue model computes a success score for each candidate venue and ranks those venues according to the scores and finally recommend the top k venues. Our rigorous evaluation on the Meetup data collected for the city of Chicago shows that DeepVenue significantly outperforms the baselines algorithms. Precisely, for 84 percent of events, the correct hosting venue appears in the top 5 of the DeepVenue recommended list.	187.9298528908341
1343.	Recognizing multiple labels of an image is a practical yet challenging task, and remarkable progress has been achieved by searching for semantic regions and exploiting label dependencies. However, current works utilize RNN/LSTM to implicitly capture sequential region/label dependencies, which cannot fully explore mutual interactions among the semantic regions/labels and do not explicitly integrate label co-occurrences. In addition, these works require large amounts of training samples and have limited generalization ability to new categories. To address these issues, we propose a knowledge-guided graph routing (KGGR) framework, which unifies prior knowledge of statistical label correlations with deep neural networks. The framework exploits prior knowledge to guide adaptive information propagation among different categories to facilitate multi-label analysis and reduce the dependency of training samples. Specifically, it first builds a structured knowledge graph to correlate different labels based on statistical label co-occurrence. Then, it introduces the label semantics to guide learning semantic-specific features to initialize the graph, and it exploits a graph propagation network to explore graph node interactions, enabling learning contextualized image feature representations. We conduct extensive experiments on the traditional multi-label image recognition (MLR) and multi-label few-shot learning (ML-FSL) tasks and show that our KGGR framework outperforms the current state-of-the-art methods.	187.92985279638128
1344.	The future of humanity depends increasingly on the performance of cities. Big data provide new and powerful ways of studying and improving coupled urban environmental, social, and economic systems to achieve urban sustainability. However, the term big data has been defined variably, and its urban applications have so far been sporadic in terms of research topic and location. A comprehensive review of big data-based urban environment, society, and sustainability (UESS) research is much needed. The aim of this study was to summarize the big data-based UESS research using a systematic review approach in combination with bibliometric and thematic analyses. The results showed that the numbers of publications and citations of related articles have been increasing exponentially in recent years. The most frequently used big data in UESS research are human behavior data, and the major analytical methods are of five types: classification, clustering, regression, association rules, and social network analysis. The major research topics of big data-based UESS research include urban mobility, urban land use and planning, environmental sustainability, public health and safety, social equity, tourism, resources and energy utilization, real estate, and retail, accommodation and catering. Big data benefit UESS research by proving a people-oriented perspective, timely and real-time information, and fine-resolution spatial dynamics. In addition, several obstacles were identified to applying big data in UESS research, which are related to data quality and acquisition, data storage and management, data security and privacy, data cleaning and preprocessing, and data analysis and information mining. To move forward, future research should integrate multiple big data sources, develop and utilize new methods such as deep learning and cloud computing, and expand the application fields to focus on the interactions between human activities and urban environments. This review can contribute to understanding the current situation of big data-based UESS research, and provide a reference for studies of this topic in the future. (C) 2020 Elsevier Ltd. All rights reserved.	187.92972301012048
1345.	Multilingual models for Automatic Speech Recognition (ASR) are attractive as they have been shown to benefit from more training data, and better lend themselves to adaptation to under-resourced languages. However, initialisation from monolingual context-dependent models leads to an explosion of context-dependent states. Connectionist Temporal Classification (CTC) is a potential solution to this as it performs well with monophone labels. We investigate multilingual CTC training in the context of adaptation and regularisation techniques that have been shown to be beneficial in more conventional contexts. The multilingual model is trained to model a universal International Phonetic Alphabet (IPA)-based phone set using the CTC loss function. Learning Hidden Unit Contribution (LHUC) is investigated to perform language adaptive training. During cross-lingual adaptation, the idea of extending the multilingual output layer to new phonemes is introduced and investigated. In addition, dropout during multilingual training and cross-lingual adaptation is also studied and tested in order to mitigate the overfitting problem. Experiments show that the performance of the universal phoneme-based CTC system can be improved by applying dropout and LHUC and it is extensible to new phonemes during cross-lingual adaptation. Updating all acoustic model parameters shows consistent improvement on limited data. Applying dropout during adaptation can further improve the system and achieve competitive performance with Deep Neural Network / Hidden Markov Model (DNN/HMM) systems on limited data.	187.92970555204133
1346.	Mull-focus image fusion is an effective technique to extend the depth-of-field of optical lenses by creating an all-in-focus image from a set of partially focused images of the same scene. In the last few years, great progress has been achieved in this field along with the rapid development of image representation theories and approaches such as mull-scale geometric analysis, sparse representation, deep learning, etc. This survey paper first presents a comprehensive overview of existing mull-focus image fusion methods. To keep up with the latest development in this field, a new taxonomy is introduced to classify existing methods into four main categories: transform domain methods, spatial domain methods, methods combining transform domain and spatial domain, and deep learning methods. For each category, representative fusion methods are introduced and summarized. Then, a comparative study for 18 representative fusion methods is conducted based on 30 pairs of commonly-used mull-focus images and 8 popular objective fusion metrics. All the relevant resources including source images, objective metrics and fusion results are released online, aiming to provide a benchmark for the future study of multi-focus image fusion. Finally, several major challenges remained in the current research of this field are discussed and some future prospects are put forward.	187.92967361621186
1347.	Purpose In madrasahs around the world, teaching and learning methods regarding the memorisation of the Qur'an follow the same notion of repetition and the need for embodiment, going beyond rote memorisation, to include a form of active learning. The process of memorisation for automaticity and inculcation of the Qur'an is seen when an individual can accurately recite the text in an illuminating way. This approach of repeatedly reciting, reading and writing Qur'anic texts is seen as an enduring method for achieving accuracy, fluency and automaticity. The purpose of this study is to extend the existing body of knowledge in the field by proposing that memorisation in the Islamic context is evident through embodied interactions in the spiritual and physical realm. Educational research on madrasahs is scarce, and the limited research that has been conducted focuses primarily on children's madrasahs. This study is unique, in that its focus is British madrasahs for adults. Design/methodology/approach After conducting observations and interviews at three British adult madrasahs, a narrative analysis using a "holistic-form" approach to gain complete narratives of recitation, oral repetition and embodied learning in the Islamic context was performed. It was found that memorisation and the desire for embodied learning were an integral part of madrasah life and the foundation of the pedagogical approach and of students' relationship with the teachers. This study concludes that the pedagogical approach used in the madrasahs reflects deep learning through an action-oriented methodology. This study's fieldwork provides insights into the distinctiveness of the madrasah approach. Findings The study provides insights into the characteristics of the memorisation process as represented in the embodied actions of the learner. The results indicate that, in the future, the Islamic memorisation methodology must continue to support deep learning where rote memorisation is integral to an iterative process of practice. Originality/value The Islamic memorisation methodology needs to retain an approach that supports higher learning where rote memorisation is integral to an iterative process of practice and in this study, some, in achieving embodied learning. This in turn is instrumental in sustaining an Islamic epistemological perspective of the inseparable nature of knowledge and the sacred. This study provides some insights into the "heart" of the Islamic approach towards memorisation for embodiment that represents a complex process of individual renewal based on the notion of adab through an approach to deep learning.	187.92960384661433
1348.	Grinding wheel condition is considered as the key factor affecting grinding performance, and therefore, accurate monitoring of wheel wear is necessary to prevent the deterioration of part quality. An intelligent wheel wear monitoring system is introduced in this article to realize processing of grinding signal, extraction of signal features, selection of optimal feature subset, and prediction of wheel wear. Physical information generated during the grinding of C-250 maraging steel is collected by a dynamometer, accelerometer, and acoustic emission sensor, and a large quantity of features in time domain and frequency domain are extracted from the processed grinding signals. To reduce feature redundancy and increase relevancy of feature to wheel wear, a two-stage feature selection approach combining filter and wrapper framework is proposed. The filter preselects individual features by minimum Redundancy Maximum Relevance method, while the wrapper evaluates different feature subsets by the model performance. A deep learning network structure named Long Short-Term Memory network is adopted to develop the wheel wear monitoring model and is compared with a conventional machine learning algorithm, Random Forest. The results have shown that the two-stage feature selection method is able to provide the globally optimal feature subset for the model. Long Short-Term Memory model achieves an R-2 of 0.994 and a root-mean-square error of 0.240 with four features, while Random Forest model obtains an R-2 of 0.980 and a root-mean-square error of 0.463 with seven features, which indicates that Long Short-Term Memory model is capable of predicting wheel wear more accurately even with less features.	187.9296032083712
1349.	Background: Dendritic spines are structural correlates of excitatory synapses in the brain. Their density and structure are shaped by experience, pointing to their role in memory encoding. Dendritic spine imaging, followed by manual analysis, is a primary way to study spines. However, an approach that analyses dendritic spines images in an automated and unbiased manner is needed to fully capture how spines change with normal experience, as well as in disease. New method: We propose an approach based on fully convolutional neural networks (FCNs) to detect dendritic spines in two-dimensional maximum-intensity projected images from confocal fluorescent micrographs. We experiment on both fractionally strided convolution and efficient sub-pixel convolutions. Dendritic spines far from the dendritic shaft are pruned by extraction of the shaft to reduce false positives. Performance of the proposed method is evaluated by comparing predicted spine positions to those manually marked by experts. Results: The averaged distance between predicted and manually annotated spines is 2.81 +/- 2.63 pixels (0.082 +/- 0.076 microns) and 2.87 +/- 2.33 pixels (0.084 +/- 0.068 microns) based on two different experts. FCN-based detection achieves F scores > 0.80 for both sets of expert annotations. Comparison with existing methods: Our method significantly outperforms two well-known software, NeuronStudio and Neurolucida (p-value < 0.02). Conclusions: FCN architectures used in this work allow for automated dendritic spine detection. Superior outcomes are possible even with small training data-sets. The proposed method may generalize to other datasets on larger scales.	187.9295503351496
1350.	Potentially suspicious breast neoplasms could be masked by high tissue density, thus increasing the probability of a false-negative diagnosis. Furthermore, differentiating breast tissue type enables patient pre-screening stratification and risk assessment. In this study, we propose and evaluate advanced machine learning methodologies aiming at an objective and reliable method for breast density scoring from routine mammographic images. The proposed image analysis pipeline incorporates texture [Gabor filters and local binary pattern (LBP)] and gradient-based features [histogram of oriented gradients (HOG) as well as speeded-up robust features (SURF)]. Additionally, transfer learning approaches with ImageNet trained weights were also used for comparison, as well as a convolutional neural network (CNN). The proposed CNN model was fully trained on two open mammography datasets and was found to be the optimal performing methodology (AUC up to 87.3%). Thus, the findings of this study indicate that automated density scoring in mammograms can aid clinical diagnosis by introducing artificial intelligence-powered decision-support systems and contribute to the 'democratization' of healthcare by overcoming limitations, such as the geographic location of patients or the lack of expert radiologists.	187.92953039070994
1351.	Hyperspectral imaging provides a useful tool for extracting complex information when visual spectral bands are not enough to solve certain tasks. However, processing hyperspectral images (HSIs) is usually computationally expensive due to the great amount of both spatial and spectral data they incorporate. We present a low-cost convolutional neural network designed for HSI classification. Its architecture consists of two parts: a series of densely connected three-dimensional (3-D) convolutions used as a feature extractor, and a series of two-dimensional (2-D) separable convolutions used as a spatial encoder. We show that this design involves fewer trainable parameters compared to other approaches, yet without detriment to its performance. What is more, we achieve comparable state-of-the-art results testing our architecture on four public remote sensing datasets: Indian Pines, Pavia University, Salinas, and EuroSAT; and a dataset of Kochia leaves [Bassia scoparia] with three different levels of herbicide resistance. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)	187.92951801496002
1352.	Blood pressure monitoring is one avenue to monitor people's health conditions. Early detection of abnormal blood pressure can help patients to get early treatment and reduce mortality associated with cardiovascular diseases. Therefore, it is very valuable to have a mechanism to perform real-time monitoring for blood pressure changes in patients. In this paper, we propose deep learning regression models using an electrocardiogram (ECG) and photoplethysmogram (PPG) for the real-time estimation of systolic blood pressure (SBP) and diastolic blood pressure (DBP) values. We use a bidirectional layer of long short-term memory (LSTM) as the first layer and add a residual connection inside each of the following layers of the LSTMs. We also perform experiments to compare the performance between the traditional machine learning methods, another existing deep learning model, and the proposed deep learning models using the dataset of Physionet's multiparameter intelligent monitoring in intensive care II (MIMIC II) as the source of ECG and PPG signals as well as the arterial blood pressure (ABP) signal. The results show that the proposed model outperforms the existing methods and is able to achieve accurate estimation which is promising in order to be applied in clinical practice effectively.	187.9294770016387
1353.	There has been a recent growing interest for cardiac computed tomography (CT) imaging in the electrophysiological community. This imaging modality indeed allows to locate and assess post-infarct scar heterogeneity, allowing to predict zones of abnormal electrical activity and even personalise EP models. To this end, most of the literature uses manually segmented CT images where one fundamental information is extracted, the myocardial wall thickness. In this paper, we evaluate the impact of using an automated deep learning (DL) methodology to segment the left ventricular wall and extract relevant scar information on the resulting personalised models. Using CT images from 8 patients that were not used during the DL training, we show that the automated segmentation is very similar to the manual one (median Dice score: 0.9). Thickness information obtained this way is also very close to the manual one (median difference: 0.7 mm). A wavefront propagation model personalisation framework based on this thickness information does not show relevant differences in its output (median difference in local activation time: 2ms), proving its robustness. Bipolar electrograms, simulated through a novel approach, do not differ significantly between manual and automated segmentations (Pearson's r: 0.99).	187.92942621501555
1354.	Due to the advantages of low storage cost and high retrieval efficiency, cross-modal hashing has received considerate attention. Most existing deep cross-modal hashing adopt a symmetric strategy to learn same deep hash functions for both query instances and database instances. However, the training of these symmetric deep cross-modal hashing methods is time-consuming, which makes them hard to effectively utilize the supervised information for cases with large-scale datasets. Inspired by the latest advance in the asymmetric hashing scheme, in this paper, we propose a discriminative deep asymmetric supervised hashing (DDASH) for cross-modal retrieval. Specifically, asymmetric hashing only learns hash codes of query instances by deep hash functions while learning the hash codes of the database instances by hand-crafted matrices. It cannot only make full use of the information in large-scale datasets, but also reduce the training time. Besides, we introduce discrete optimization to reduce the binary quantization error. Furthermore, a mapping matrix which maps generated hash codes into the corresponding labels is introduced to ensure that the hash codes are discriminative. We also calculate the level of similarity between instances as supervised information. Experiments on three common datasets for cross-modal retrieval show that DDASH outperforms state-of-the-art cross-modal hashing methods. (C) 2020 Elsevier B.V. All rights reserved.	187.9293408702337
1355.	This paper involves an application of prediction models to study quality of incoming raw materials of a tapioca starch manufacturer in Thailand. The objectives are to estimate starch content of fresh cassava roots and to identify significant factors that affect starch content in cassava roots. Three prediction models, including multiple regression, artificial neural network (ANN), and hybrid deep belief network (HDBN), are implemented. Input data were collected from 242 farmers from 49 different sub-districtsin Nakhon Ratchasima province in the Northeast of Thailand, who supply fresh cassava roots to the manufacturing plant. Potential factors are classified into four categories: farmers' demographics, cultivation activities, harvesting activities, and logistics activities, a total of 38 variables. Regression models, ANNs with one hidden layer, and HDBNs were constructed for starch content prediction. Prediction performances were evaluated using the root mean square error (RMSE) and mean absolute percentage errors (MAPE), which were 2.44 percent of starch content and 7.283% for the best regression model; 2.41 and 7.055% for the best ANN, and 2.35 and 6.226% for the best HDBN, respectively. The results indicate that HDBN outperforms the other two models in terms of prediction performance. The final regression model and the best ANN are primarily used to identify seven important factors that can potentially describe starch content. These include harvest age, planting density, growing season, farm location, type of soil, cassava variety, and weed control method.	187.92923006102487
1356.	The combination of artificial intelligence methods and IoT based sensor data will play a critical and crucial role in various environments. Flight landing safety is a research hotspot of aviation field for a long time. Accurately predicting the landing speed is conducive to reducing the landing accidents. In this paper, we proposed an accurate aircraft landing speed prediction model based on the long-short term memory (LSTM) with flight sensor data. Firstly, we analyze and pre-process the dataset with statistical method including randomness tests and stationary tests. Secondly, we design the features by random forest algorithm and reduce the dimensionality of features with principal component analysis. Thirdly, we develop a deep architecture based on long-short term memory to predict the aircraft landing speed. Experiment results prove that it has better performance with higher prediction accuracy compared with the state of the art, indicating that the proposed model is accurate and effective. The findings are expected to be applied into flight operation practice for further preventing of landing accidents and improving the air management for air traffic controllers. (C) 2018 Elsevier B.V. All rights reserved.	187.9292105367236
1357.	Diabetes is considered as one of the deadliest and chronic diseases in several countries. All of them are working to prevent this disease at early stage by diagnosing and predicting the symptoms of diabetes using several methods. The motive of this study is to compare the performance of some Machine Learning algorithms, used to predict type 2 diabetes diseases. In this paper, we apply and evaluate four Machine Learning algorithms (Decision Tree, K-Nearest Neighbours, Artificial Neural Network and Deep Neural Network) to predict patients with or without type 2 diabetes mellitus. These techniques have been trained and tested on two diabetes databases: The first obtained from Frankfurt hospital (Germany), and the second is the well-known Pima Indian dataset. These datasets contain the same features composed of mixed data; risk factors and some clinical data. The performances of the experimented algorithms have been evaluated in both the cases i.e. dataset with noisy data (before pre-processing/some data with missing values) and dataset set without noisy data (after preprocessing). The results compared using different similarity metrics like Accuracy, Sensitivity, and Specificity gives best performance with respect to state of the art.	187.92919677366865
1358.	The emergence of 5G technology has enabled a fast development of the wireless communication based on Big Data, Internet of Things (IoT), cloud computing, edge and fog computing. The development has contributed to enhance the lifestyle of the citizens in smart cities. Different applications are provided with 5G technologies to solve problems of the citizens. In this article, we take advantage of the 5G technology to develop a framework of images' classification to satisfy consumers in smart cities. As a case, study, we develop an automatic date fruits classification system in the framework to satisfy date fruits consumers interest. In the proposed system, a deep learning approach is utilized with fine-tuning pre -trained models. The edge computing and caching are used to provide a low latency and real-time transmission of the date fruits' images. The experimental results show the viability of the proposed framework. (C) 2018 Elsevier B.V. All rights reserved.	187.92916698061742
1359.	Endoscopic diagnosis is an important means for gastric polyp detection. In this paper, a panoramic image of gastroscopy is developed, which can display the inner surface of the stomach intuitively and comprehensively. Moreover, the proposed automatic detection solution can help doctors locate the polyps automatically and reduce missed diagnosis. The main contributions of this paper are firstly, a gastroscopic panorama reconstruction method is developed. The reconstruction does not require additional hardware devices and can solve the problem of texture dislocation and illumination imbalance properly; secondly, an end-to-end multiobject detection for gastroscopic panorama is trained based on a deep learning framework. Compared with traditional solutions, the automatic polyp detection system can locate all polyps in the inner wall of the stomach in real time and assist doctors to find the lesions. Thirdly, the system was evaluated in the Affiliated Hospital of Zhejiang University. The results show that the average error of the panorama is less than 2mm, the accuracy of the polyp detection is 95%, and the recall rate is 99%. In addition, the research roadmap of this paper has guiding significance for endoscopy-assisted detection of other human soft cavities.	187.92914897809442
1360.	During natural learning, synaptic plasticity is thought to evolve dynamically and redistribute within and among subcircuits. This process should emerge in plastic neural networks evolving under behavioral feedback and should involve changes distributed across multiple synaptic sites. In eyeblink classical conditioning (EBCC), the cerebellum learns to predict the precise timing between two stimuli, hence EBCC represents an elementary yet meaningful paradigm to investigate the cerebellar network functioning. We have simulated EBCC mechanisms by reconstructing a realistic cerebellar microcircuit model and embedding multiple plasticity rules imitating those revealed experimentally. The model was tuned to fit experimental EBCC human data, estimating the underlying learning time-constants. Learning started rapidly with plastic changes in the cerebellar cortex followed by slower changes in the deep cerebellar nuclei. This process was characterized by differential development of long-term potentiation and depression at individual synapses, with a progressive accumulation of plasticity distributed over the whole network. The experimental data included two EBCC sessions interleaved by a trans-cranial magnetic stimulation (TMS). The experimental and the model response data were not significantly different in each learning phase, and the model goodness-of-fit was > 0.88 for all the experimental conditions. The models fitted on TMS data revealed a slowed down re-acquisition (sessions-2) compared to the control condition (< 0.01). The plasticity parameters characterizing each model significantly differ among conditions, and thus mechanistically explain these response changes. Importantly, the model was able to capture the alteration in EBCC consolidation caused by TMS and showed that TMS affected plasticity at cortical synapses thereby altering the fast learning phase. This, secondarily, also affected plasticity in deep cerebellar nuclei altering learning dynamics in the entire sensory-motor loop. This observation reveals dynamic redistribution of changes over the entire network and suggests how TMS affects local circuit computation and memory processing in the cerebellum.	187.92901615616051
1361.	Rapid and accurate evaluation of the damage state of structures after a seismic event is critical for postevent emergency response and recovery. The existing rapid damage evaluation methodology is typically based on fragility curves incorporated into earthquake alerting platforms. However, the extent of damage predicted solely based on the fragility curves can vary significantly depending on ground motion characteristics. This paper presents a methodology for damage assessment of structures while accounting for temporal and spectral nonstationarity of ground motions using continuous wavelet transform and image-analysis techniques. The methodology involves the establishment of a prediction model for wavelet transform of ground motions and damage state of a structure using convolutional neural networks. The methodology is demonstrated in this paper through two case studies: (1) a low-rise nonductile concrete building frame in California and (2) a four-span concrete box-girder bridge in California. The proposed methodology identified damage states with an accuracy greater than 75% in both cases. DOI: 10.1061/(ASCE)ST.1943-541X.0002793. (c) 2020 American Society of Civil Engineers.	187.92892625159502
1362.	An improved pyramid deconvolutional neural network is proposed to fine-grained segment pulmonary nodules of CT scan images. The fully convolutional neural network (FCN) can train images end-to-end, pixel-to-pixel, realizing object detection, segmentation and classification in one single CNN structure. However, the original FCN is utilized by the natural object tasks, which can hardly maintain the precision degree required by the medical images. To further improve the detection precision and segment accuracy, we improve the FCN by fusing more pooling layers, because the deconvolution of higher convolution layers give the coarser segmentations and lower convolution layers generate detail contour. The experiment is based on LIDC- IDRI datasets. Tenfold cross-validation is used to train and evaluate the performance. The experiment shows that the detection precise and the fineness of segmentation ascend with the number of the fused pooling layers. The detection rate can be achieved as high as 0.931 +/- 0.042. Meanwhile, for the segmentation performance evaluation, the score of intersection over Union (IoU) is applied, reaching 0.628 +/- 0.065. And the overlap rate (i.e. the overlap percentage of the segment result compared with the original label) is also calculated. The same as the detect accuracy, the improved architecture, which fuses more pooling layers, achieves the highest overlap rate, which is 0.739 +/- 0.076.	187.92870613233617
1363.	Background Diffuse lung diseases (DLDs) are a diverse group of pulmonary disorders, characterized by inflammation of lung tissue, which may lead to permanent loss of the ability to breathe and death. Distinguishing among these diseases is challenging to physicians due their wide variety and unknown causes. Computer-aided diagnosis (CAD) is a useful approach to improve diagnostic accuracy, by combining information provided by experts with Machine Learning (ML) methods. Objectives Exploring the potential of dimensionality reduction combined with ML methods for diagnosis of DLDs; improving the classification accuracy over state-of-theart methods. Methods A data set composed of 3252 regions of interest (ROIs) was used, from which 28 features were extracted per ROI. We used Principal Component Analysis, Linear Discriminant Analysis, and Stepwise Selection - Forward, Backward, and Forward-Backward to reduce feature dimensionality. The feature subsets obtained were used as input to the following ML methods: Support Vector Machine, Gaussian Mixture Model, k-Nearest Neighbor, and Deep Feedforward Neural Network. We also applied a Deep Convolutional Neural Network directly to the ROIs. Results We achieved the maximum reduction from 28 to 5 dimensions using LDA. The best classification results were obtained by DFNN, with 99.60% of overall accuracy. Conclusions This work contributes to the analysis and selection of features that can efficiently characterize the DLDs studied.	187.92869370665434
1364.	The result of object detection based on deep learning may have errors or omissions due to the occlusion and background in object detection, which is an intractable problem. An effective method of improving object detection performance using multiple viewpoint images are proposed. By performing feature point matching on objects in the overlap between different views, groups of points with semantic information can be obtained. These point groups can be used to generate new detection boxes, which can correct error ones in the raw results. Experiments show that the proposed method is a viable solution, the recall is significantly improved.	187.92868045569378
1365.	Our goal is to develop a 2.5D CNN model to detect multiple diseases in multiple organs in CT scans. In this study we investigated detection of 4 common diseases in the lungs, which are atelectasis, edema, pneumonia and nodule. Most existing algorithms for computer-aided diagnosis (CAD) of CT use 2D models for the axial slices. Our hypothesis is that by using information from all of the three views (coronal, sagittal and axial), we may achieve a better classification result, because some diseases may be more obvious from a different view or from the combination of multi-views. Our data consisted of 1089 CT scans, which contains 288 normal cases, 224 atelectasis cases, 156 edema cases, 225 pneumonia cases and 196 nodule cases. The cases were selected from approximately 5,000 chest CTs from Duke University Health System, and case-level labels were automatically extracted by simple rule-based filtering of the unstructured text from the radiology report. Each of these 5 categories excluded the others, which indicates that cases from each category will have either only one of the four diseases or no disease. To create 2.5D volume patches, we combined together three channels representing parallel slices in each of the three intersecting, orthogonal directions, resulting in sparsely sampled cubes of 20.2 x 20.2 x 20.2 mm. For each CT scan, the volume containing the lungs was identified with thresholding, and 30 patches were randomly sampled within that volume. Then three 3-channel images in each patch representing those 3 different directions were entered into 3 independent CNN paths separately, which were finally fused by a fully connected layer. We used a 4 fold cross-validation and evaluated our results using receiver operating characteristic (ROC) area under the curve (AUC). We achieved an average AUC of 0.891 for classifying normal vs. atelectasis disease, 0.940 for edema disease, 0.869 for pneumonia disease and 0.784 for nodule disease. We also implemented a train-validation-test process for each disease to evaluate the generalization of our model and again got comparable test results, 0.818 for atelectasis, 0.963 for edema, 0.878 for pneumonia and 0.784 for nodule. Despite the limitation of the small dataset scale, we demonstrated that we developed a generalizable 2.5D CNN model for detection of multiple lung diseases.	187.92850906080014
1366.	Quantifying tree biomass is a critical process for carbon stock estimation at the stand, landscape, and national levels. A major challenge for forest managers is the amount of effort involved to document carbon storage levels, especially in terms of human labor. In this paper, we propose a method to quantify the amount of carbon in forest stands. In our approach, we obtain aerial images from where we build 3D reconstructions of the terrain. Using the resulting orthomosaics, we identify individual trees and process their point clouds to extract information to estimate tree the height and to infer the diameter, which we employ in allometric equations to compute carbon content. We compare our results with carbon estimates obtained from allometric equations applied to manual tree diameter and height measurements.	187.9284851126999
1367.	Purpose Amyloid PET which has been widely used for noninvasive assessment of cortical amyloid burden is visually interpreted in the clinical setting. As a fast and easy-to-use visual interpretation support system, we analyze whether the deep learning-based end-to-end estimation of amyloid burden improves inter-reader agreement as well as the confidence of the visual reading. Methods A total of 121 clinical routines [F-18]Florbetaben PET images were collected for the randomized blind-reader study. The amyloid PET images were visually interpreted by three experts independently blind to other information. The readers qualitatively interpreted images without quantification at the first reading session. After more than 2-week interval, the readers additionally interpreted images with the quantification results provided by the deep learning system. The qualitative assessment was based on a 3-point BAPL score (1: no amyloid load, 2: minor amyloid load, and 3: significant amyloid load). The confidence score for each session was evaluated by a 3-point score (0: ambiguous, 1: probably, and 2: definite to decide). Results Inter-reader agreements for the visual reading based on a 3-point scale (BAPL score) calculated by Fleiss kappa coefficients were 0.46 and 0.76 for the visual reading without and with the deep learning system, respectively. For the two reading sessions, the confidence score of visual reading was improved at the visual reading session with the output (1.27 +/- 0.078 for visual reading-only session vs. 1.66 +/- 0.63 for a visual reading session with the deep learning system). Conclusion Our results highlight the impact of deep learning-based one-step amyloid burden estimation system on inter-reader agreement and confidence of reading when applied to clinical routine amyloid PET reading.	187.92843053072534
1368.	Purpose: An end-to-end deep convolutional neural network (CNN) based on deep residual network (ResNet) was proposed to efficiently reconstruct reliable T-2 mapping from single-shot overlapping-echo detachment (OLED) planar imaging. Methods: The training dataset was obtained from simulations that were carried out on SPROM (Simulation with PRoduct Operator Matrix) software developed by our group. The relationship between the original OLED image containing two echo signals and the corresponding T-2 mapping was learned by ResNet training. After the ResNet was trained, it was applied to reconstruct the T-2 mapping from simulation and in vivo human brain data. Results: Although the ResNet was trained entirely on simulated data, the trained network was generalized well to real human brain data. The results from simulation and in vivo human brain experiments show that the proposed method significantly outperforms the echo-detachment-based method. Reliable T-2 mapping with higher accuracy is achieved within 30 ms after the network has been trained, while the echo-detachment-based OLED reconstruction method took approximately 2 min. Conclusion: The proposed method will facilitate real-time dynamic and quantitative MR imaging via OLED sequence, and deep convolutional neural network has the potential to reconstruct maps from complex MRI sequences efficiently.	187.92838790414154
1369.	Automatic recognition and classification of leukocytes helps medical practitioners to diagnose various blood-related diseases by analysing their percentages. Different researchers have come up with different algorithms that use traditional learning for the classification of different types of leukocytes. In contrast to traditional learning, in which no knowledge is retained that can be transferred from one model to another, our proposed algorithm uses deep learning approach for segmentation and classification. The proposed algorithm has two-stage pipelining consisting of semantic segmentation and transfer learning-based classification. Here, we have used pre-trained networks, utilizing knowledge from previously learned tasks, called DeepLabv3+ for segmentation of leukocytes and AlexNet to classify five categories of leukocytes in peripheral blood from whole blood smear microscopic images. For experimentation, a microscopic blood image dataset consisting of 257cells belonging to five types of leukocytes was used. The results obtained from experiments show that the proposed algorithm attained a mean average precision of 98.42% (@IoU=0.7) in white blood cell localization and a classification accuracy of 98.87  1% compared to existing methods.	187.9283744963243
1370.	Image retrieval aims to search specific image from large-scale datasets. Traditional text-based and content-based image retrieval approaches have shown competitive performance. However, both of which are limited by semantic gap, i.e., they cannot reflect human perception of images. To narrow semantic gap in image retrieval, this paper proposes a deep neural network (DNN) based image retrieval method, where saliency map is derived to form human gaze shifting paths by constraint metrics. More specifically, we first design a DNN-based image saliency prediction. Subsequently, we leverage image quality assessment (IQA) algorithm to select high-quality salient regions, which will be concatenated in sequence by using proposed constraint metrics to mimic human visual perception. Afterwards, we leverage the CNN-based architecture for deep representation acquisition of each images, where spatial structure among salient regions can be well preserved. Subsequently, based on the quality score of the query image, a series of candidate images whose quality scores are similar to that of the query image are derived. Finally, we engineer a ranking distance metric to refine the candidate images to achieve image retrieval. Extend experiments demonstrate that our method outperforms several state-of-the-art algorithms. (C) 2020 Elsevier B.V. All rights reserved.	187.92833562081668
1371.	This explanatory mixed method research study investigates instructor and student perceptions regarding the factors that enhance or inhibit the self-directedness of American Sign Language (ASL) I students enrolled in institutions of higher education. Twenty students participated in the Self-Directed Learning Readiness Scale (SDLRS), also known as the Learning Preference Assessment (LPA), developed by Lucy Guglielmino (1978). The SDLRS survey answered the first research question.We then conducted video recorded interviews with ten participants, both students and instructors. As shown in research, the interviews clarified the assessment results with personal narratives to support the development of the conclusion of the study.A total of three themes emerged from this study to answer the six research questions.The goal of this explanatory mixed method study was to gain more knowledge about what the students in the introductory ASL class perceive their self-direction to be and to identify learning strategies that work for them. Findings from this study could provide deeper understanding and a rich source of information for future ASL instructors to help reduce frustration among ASL students.	187.92833445902278
1372.	In this paper, we aim to address the unsupervised domain adaptation problem where the data in the target domain are much more diverse compared with the data in the source domain. In particular, this problem is formulated as discovering and incorporating latent domains underlying target data of interest for unsupervised domain adaptation. More specifically, the discovery of the latent target domains is based on three criteria, including the maximization of compactness and distinctiveness of the data in the individual latent target-domain, as well as the minimization of total divergence from the latent target-domains to the source domain. For each pair formed by a latent target domain and the source domain, we learn a feature space where the discrepancy between the source domain and the specific latent target domain is shrunk. Finally, we consider the projected source domain data on the learned latent feature spaces as different views of the source domain, and propose an extended multiple kernel learning algorithm to train a more robust and precise classifier for predicting the unlabeled target data. The effectiveness of our proposed method is demonstrated on various benchmark datasets for object recognition and human activity recognition. Moreover, we also show that our proposed method can be treated as an effective complement to the deep learning based unsupervised domain adaptation. (C) 2020 Elsevier Ltd. All rights reserved.	187.92823101197672
1373.	Objectives The purpose of this study was to develop an automatic tracking method for the muscle cross-sectional area (CSA) on ultrasound (US) images using a convolutional neural network (CNN). The performance of the proposed method was evaluated and compared with that of the state-of-the art muscle segmentation method. Methods A real-time US image sequence was obtained from the rectus femoris muscle during voluntary contraction. A CNN was built to segment the rectus femoris muscle and calculate the CSA in each US frame. This network consisted of 2 stages: feature extraction and score map reconstruction. The training of the network was divided into 3 steps with output score map resolutions of one-fourth, one-half, and all of the original image. We evaluated the segmentation performance of our method with 5-fold cross-validation. The mean precision, recall, and dice similarity score were calculated. Results The mean precision, recall, and Dice's coefficient (DSC) +/- SD were 0.936 +/- 0.029, 0.882 +/- 0.045, and 0.907 +/- 0.023, respectively. Compared with the state-of-the-art muscle segmentation method (constrained mutual-information-based free-form deformation), the proposed method using CNN showed high performance. Conclusions The automated method proposed in this study provides an accurate and efficient approach to the estimation of the muscle CSA during muscle contraction.	187.9281643482978
1374.	Aiming at the limitations of traditional communication modulation recognition algorithms, a novel recognition algorithm based on deep learning network far communication signal features is proposed in this paper. By introducing the two different computation mechanisms of STFT, two unsupervised feature-learning networks based on Restrict Boltzmann Machine (RBM) are respectively adopted for communication signal, where the network based on RBM is greatly improved in computing performance compared to the network based on convolutional Restrict Boltzmann Machine (CRBM), and greatly reduces the requirement for high-performance hardware in deep learning networks. In addition, as for signal modulation recognition and signal detection problems in communications, two modulation recognition networks are constructed by using the learning-to-STFT networks and the Back Propagation Neural Network (BPNN) classifier. Compared with the traditional modulation algorithms, our proposed algorithm in the paper can obtain better performance in the recognition accuracy, especially under the condition of low SNR.	187.9281030703219
1375.	The automatic and unsupervised analysis of biomedical time series is of primary importance for diagnostic and preventive medicine, enabling fast and reliable data processing to reveal clinical insights without the need for human intervention. Representation learning (RL) methods perform an automatic extraction of meaningful features that can be used, e.g., for a subsequent classification of the measured data. The goal of this study is to explore and quantify the benefits of RL techniques of varying degrees of complexity, focusing on modern deep learning (DL) architectures. We focus on the automatic classification of atrial fibrillation (AF) events from noisy single-lead electrocardiographic signals (ECG) obtained from wireless sensors. This is an important task as it allows the detection of sub-clinical AF which is hard to diagnose with a short in-clinic 12-lead ECG. The effectiveness of the considered architectures is quantified and discussed in terms of classification performance, memory/data efficiency and computational complexity.	187.92802154955723
1376.	A key component of many robotics model-based planning and control algorithms is physics predictions, that is, forecasting a sequence of states given an initial state and a sequence of controls. This process is slow and a major computational bottleneck for robotics planning algorithms. Parallel-in-time integration methods can help to leverage parallel computing to accelerate physics predictions and thus planning. The Parareal algorithm iterates between a coarse serial integrator and a fine parallel integrator. A key challenge is to devise a coarse model that is computationally cheap but accurate enough for Parareal to converge quickly. Here, we investigate the use of a deep neural network physics model as a coarse model for Parareal in the context of robotic manipulation. In simulated experiments using the physics engine Mujoco as fine propagator we show that the learned coarse model leads to faster Parareal convergence than a coarse physics-based model. We further show that the learned coarse model allows to apply Parareal to scenarios with multiple objects, where the physics-based coarse model is not applicable. Finally, we conduct experiments on a real robot and show that Parareal predictions are close to real-world physics predictions for robotic pushing of multiple objects. Code (https://doi.org/10.5281/zenodo.3779085) and videos (https://youtu.be/wCh2o1rf-gA) are publicly available.	187.92784488704086
1377.	Deep CNN based semantic segmentation has been developed for several years and many models are proposed. However, most of them are designed for natural scene images such as PASCAL VOC, and cannot perform very well on remote sensing images, in which objects are much smaller and more densely distributed than those in natural scene images. In this paper, we demonstrate the importance of high-resolution feature maps and the problem of large dilated convolutional kernels in semantic segmentation of remote sensing images. Furthermore, we propose a Stepwise-Refined Large-Kernel Deconvolutional Network with a focus on small and densely-distributed objects such as houses and buildings, or long and narrow ones such as roads and rivers. Experiments on a public available ISPRS Vaihingen Challenge Dataset and our self-compiled Fujian Dataset show that our model outperforms the state-of-the-art models in semantic segmentation of remote sensing images.	187.9278249250956
1378.	Plant disease is one of the primary causes of crop yield reduction. With the development of computer vision and deep learning technology, autonomous detection of plant surface lesion images collected by optical sensors has become an important research direction for timely crop disease diagnosis. In this paper, an anthracnose lesion detection method based on deep learning is proposed. Firstly, for the problem of insufficient image data caused by the random occurrence of apple diseases, in addition to traditional image augmentation techniques, Cycle-Consistent Adversarial Network (CycleGAN) deep learning model is used in this paper to accomplish data augmentation. These methods effectively enrich the diversity of training data and provide a solid foundation for training the detection model. In this paper, on the basis of image data augmentation, densely connected neural network (DenseNet) is utilized to optimize feature layers of the YOLO-V3 model which have lower resolution. DenseNet greatly improves the utilization of features in the neural network and enhances the detection result of the YOLO-V3 model. It is verified in experiments that the improved model exceeds Faster R-CNN with VGG16 NET, the original YOLO-V3 model, and other three state-of-the-art networks in detection performance, and it can realize real-time detection. The proposed method can be well applied to the detection of anthracnose lesions on apple surfaces in orchards.	187.9277734315063
1379.	Purpose: The purpose of this study was to examine the effect of vocabulary exposure intensity on vocabulary learning in preschool-age children with and without SLI and to reveal an adequate amount of vocabulary exposure intensity in book reading for vocabulary learning of children with SLI. Methods: Three four- to five-year-old children with SLI and four age-matched TD children participated in this study. The intervention program was conducted three times a week for 40 minutes per session. The session consisted of a thirty-minute book reading program followed by a ten-minute test. During the storybook reading session, the subjects were exposed 48 times repeatedly to 24 target words each. Vocabulary learning was assessed at four different points during intervention through a receptive, expressive vocabulary task and pre-test and post-test assessed the children's verbal definition ability. Results: A Mann-Whitney U Test revealed that the SLI group had significantly lower performance in the expressive vocabulary task and verbal definition task, However, the number of expressive vocabulary acquisition increased and the performance of children with SLI peformed as well as TD children at the 48th exposure intensity. Wilcoxon Signed-Rank Test revealed that pre-test and post-test examined large effect sizes for language tasks (receptive, expressive vocabulary, verbal definition) for both SLI and TD groups. Conclusions: Forty-eight times proved to be an adequate amount of vocabulary exposure intensity for vocabulary acquisition of children with SLI. The result showed that the SLI group has more difficultly acquiring deeper vocabulary knowledge than TD children. Also, the repeated vocabulary exposures were highly effective on the vocabulary learning in children with and without SLI and the effect-size supports these results.	187.92765373539072
1380.	Traditionally, abnormal heart sound classification is framed as a three-stage process. The first stage involves segmenting the phonocardiogram to detect fundamental heart sounds; after which features are extracted and classification is performed. Some researchers in the field argue the segmentation step is an unwanted computational burden, whereas others embrace it as a prior step to feature extraction. When comparing accuracies achieved by studies that have segmented heart sounds before analysis with those who have overlooked that step, the question of\textit{ whether to segment heart sounds before feature extraction} is still open. In this study, we explicitly examine the importance of heart sound segmentation as a prior step for heart sound classification and then seek to apply the obtained insights to propose a robust classifier for abnormal heart sound detection. Furthermore, recognizing the pressing need for explainable Artificial Intelligence (AI) models in the medical domain, we also unveil hidden representations learned by the classifier using model interpretation techniques. Experimental results demonstrate that the segmentation which can be learned by the model plays an essential role in abnormal heart sound classification. Our new classifier is also shown to be robust, stable, and most importantly, explainable, with an accuracy of almost 100% on the widely used PhysioNet dataset.	187.92764477046018
1381.	Arrhythmia is a group of conditions in which the heartbeat is irregular. There are many types of arrhythmia. Some can be life-threatening. Electrocardiogram (ECG) is an effective clinical tool used to diagnosis arrhythmia. Automatic recognition of different arrhythmia types in ECG signals has become an important and challenging issue. In this article, we proposed an algorithm to detect arrhythmia in 12-lead ECG signals and classify signals into 9 categories. Two 19-layer deep neural networks combining convolutional neural network and gated recurrent unit were proposed to realize this work. The first one was trained directly with the raw 12-lead ECG data while the other one was trained with an 18-lead" ECG data, where the six extra leads containing morphology information in fractional time-frequency domain were generated utilizing fractional Fourier transform (FRFT). Overall detection results were obtained by fusing the output of these two networks and the final classification results on the testing dataset reports our proposed algorithm obtained a F1 score of 0.855. Furthermore, with our proposed algorithm, a better F1 score 0.81 was attained using training dataset provided by the China Physiological Signal Challenge held in 2018.	187.927571139699
1382.	In this paper, a deep learning approach, Restricted Boltzmann Machine (RBM), is used to perform automatic hand sign language recognition from visual data. We evaluate how RBM, as a deep generative model, is capable of generating the distribution of the input data for an enhanced recognition of unseen data. Two modalities, RGB and Depth, are considered in the model input in three forms: original image, cropped image, and noisy cropped image. Five crops of the input image are used and the hand of these cropped images are detected using Convolutional Neural Network (CNN). After that, three types of the detected hand images are generated for each modality and input to RBMs. The outputs of the RBMs for two modalities are fused in another RBM in order to recognize the output sign label of the input image. The proposed multi-modal model is trained on all and part of the American alphabet and digits of four publicly available datasets. We also evaluate the robustness of the proposal against noise. Experimental results show that the proposed multi-modal model, using crops and the RBM fusing methodology, achieves state-of-the-art results on Massey University Gesture Dataset 2012, American Sign Language (ASL). and Fingerspelling Dataset from the University of Surrey's Center for Vision, Speech and Signal Processing, NYU, and ASL Fingerspelling A datasets.	187.92747505152678
1383.	This paper presents a new technique for hyperspectral image (HSI) classification by using superpixel guided deep-sparse-representation learning. The proposed technique constructs a hierarchical architecture by exploiting the sparse coding to learn the HSI representation. Specifically, a multiple-layer architecture using different superpixel maps is designed, where each superpixel map is generated by downsampling the superpixels gradually along with enlarged spatial regions for labeled samples. In each layer, sparse representation of pixels within every spatial region is computed to construct a histogram via the sum-pooling with l(1) normalization. Finally, the representations (features) learned from the multiple-layer network are aggregated and trained by a support vector machine classifier. The proposed technique has been evaluated over three public HSI data sets, including the Indian Pines image set, the Salinas image set, and the University of Pavia image set. Experiments show superior performance compared with the state-of-the-art methods.	187.92747155681013
1384.	We introduce a neural method that is able to fuse concepts from a knowledge base with the context information for the task of grouping of aspect terms. Rather than only using context information, we use the corresponding concepts of aspect terms as additional information for aspect terms representation. We also introduce a location-based attention mechanism for accurately representing context features. As both the concept and the aspect term are same level features, i.e. aspect level features, we develop a model with gating mechanism to fuse them together. All of the above features are fed into a parallel metric learning network which has the ability to learn an easier grouping representation of samples. Experimental results demonstrate that our approach outperforms different baselines and model variants on five datasets.	187.92742942615854
1385.	Due to the urgent demand for remote sensing big data analysis, large-scale remote sensing image retrieval (LSRSIR) attracts increasing attention from researchers. Generally, LSRSIR can he divided into two categories as follows: uni-source LSRSIR (US-LSRSIR) and cross-source LSRSIR (CS-LSRSIR). More specifically, US-LSRSIR means the inquiry remote sensing image and images in the searching data set come from the same remote sensing data source, whereas CS-LSRSIR is designed to retrieve remote sensing images with a similar content to the inquiry remote sensing image that are from a different remote sensing data source. In the literature, US-LSRSIR has been widely exploited, but CS-LSRSIR is rarely discussed. In practical situations, remote sensing images from different kinds of remote sensing data sources are continually increasing, so there is a great motivation to exploit CS-LSRSIR. Therefore, this paper focuses on CS-LSRSIR. To cope with CS-LSRSIR, this paper proposes source-invariant deep hashing convolutional neural networks (SIDHCNNs), which can be optimized in an end-to-end manner using a series of well-designed optimization constraints. To quantitatively evaluate the proposed SIDHCNNs, we construct a dual-source remote sensing image data set that contains eight typical land-cover categories and 10000 dual samples in each category. Extensive experiments show that the proposed SIDHCNNs can yield substantial improvements over several baselines involving the most recent techniques.	187.927381065237
1386.	In recent years, convolutional neural networks (CNNs) have been widely used for visual object tracking, especially in combination with correlation filters (CFs). However, the increasing complex CNN models introduce more useless information, which may decrease the tracking performance. This study proposes an online feature map selection method to remove noisy and irrelevant feature maps from different convolutional layers of CNN, which can reduce computation redundancy and improve tracking accuracy. Furthermore, a novel appearance model update strategy, which exploits the feedback from the peak value of response maps, is developed to avoid model corruption. Finally, an extensive evaluation of the proposed method was conducted over OTB-2013 and OTB-2015 datasets, and compared with different kinds of trackers, including deep learning-based trackers and CF-based trackers. The results demonstrate that the proposed method achieves a highly satisfactory performance.	187.927352095054
1387.	Due to the non-linear characteristics of the processing parameters, predicting the desired properties of nanocomposites using the conventional regression approach is often unsatisfactory. Thus, it is essential to use a machine learning approach to determine the optimum processing parameters. In this study, a backpropagation deep neural network (DNN) with nanoclay and compatibilizer content, and processing parameters as input, was developed to predict the mechanical properties, including tensile modulus and tensile strength, of clay-reinforced polyethylene nanocomposites. The high accuracy of the developed model proves that DNN can be used as an efficient tool for predicting mechanical properties of the nanocomposites in terms of four independent parameters.	187.92729339216623
1388.	In this paper, we propose a Convolutional Support Vector Machine (CSVM) network for the analysis of Ground Penetrating Radar B Scan (GPR B Scan) images. Similar to a Convolutional Neural Network (CNN) architecture, a CSVM is also a cascade of convolution and pooling layers. However, the main difference is that it utilizes linear Support Vector Machine (SVM) based filters to generate feature maps and follows a forward learning strategy. We applied proposed method for the classification of buried objects, shape type and soil type. We used simulated GPR B scan images to train the networks. Proposed method was tested on both simulated and real GPR B scan images. In addition, we conducted a comparative study of the CSVM method with the classical machine learning approaches and pre-trained CNN models. Experimental results show that the proposed method provides an improved classification performance while the computational complexity is low. (C) 2020 Elsevier Ltd. All rights reserved.	187.92724840048356
1389.	This work presents a vision based navigation system for an autonomous drone that is capable of recognizing and locating wind mills. WindMillNet, a Deep Neural Network created for this purpose was specially trained to recognize wind mills on camera images using transfer learning techniques. The drone powered by WindMillNet scans the horizon to find wind mills, and after perceiving a wind mill, navigates towards it, with the goal of performing its inspection. A hierarchical control system, implemented in the drone provides stability and control of its movements. Our framework was designed using a cyber-physical systems approach using high-level abstractions in modeling, communication, control and computation. (C) 2019, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.	187.92723735078903
1390.	In this work we propose a new physical realization of optical neural network (ONN) based on a recently appeared technological platform of synthetic photonic lattices (SPL),(1,2) and demonstrate its capabilities for deep learning. The system operates with time series of optical pulses with ability to easily control their parameters and possesses the architecture that well suits the ONN paradigm. We have also shown that such an ONN can be potentially utilized for signal processing in optical communication lines for signal distortion compensation.	187.92693892804994
1391.	The multi-fold growth of the social media user-base fuelled a substantial increase in the amount of hate speech posts on social media platforms. The enormous data volume makes it hard to capture such cases and either moderate or delete them. This paper presents an approach to detect and visualize online aggression, a special case of hate speech, over social media. Aggression is categorized into overtly aggressive (OAG), covertly aggressive (CAG), and non-aggressive labels (NAG). We have designed a user interface based on a web browser plugin over Facebook and Twitter to visualize the aggressive comments posted on the Social media user's timelines. This plugin interface might help to the security agency to keep a tab on the social media stream. It also provides citizens with a tool that is typically only available for large enterprises. The availability of such a tool alleviates the technological imbalance between industry and citizens. Besides, the system might be helpful to the research community to create further tools and prepare weakly labeled training data in a few minutes using comments posted by users on celebrity's Facebook, Twitter timeline. We have reported the results on a newly created dataset of user comments posted on Facebook and Twitter using our proposed plugins and the standard Trolling Aggression Cyberbullying 2018 (TRAC) dataset in English and code-mixed Hindi. Various classifiers like Support Vector Machine (SVM), Logistic regression, deep learning model based on Convolution Neural Network (CNN), Attention-based model, and the recently proposed BERT pre-trained language model by Google AI, have been used for aggression classification. The weighted F1-score of around 0.64 and 0.62 is achieved on TRAC Facebook English and Hindi datasets while on Twitter English and Hindi datasets, the weighted F1-score is 0.58 and 0.50, respectively. (c) 2020 Elsevier Ltd. All rights reserved.	187.92687866986057
1392.	PurposeTo automatically detect and classify geographic atrophy (GA) in fundus autofluorescence (FAF) images using a deep learning algorithm.MethodsIn this study, FAF images of patients with GA, a healthy comparable group and a comparable group with other retinal diseases (ORDs) were used to train a multi-layer deep convolutional neural network (DCNN) (1) to detect GA and (2) to differentiate in GA between a diffuse-trickling pattern (dt-GA) and other GA FAF patterns (ndt-GA) in FAF images.For the automated detection of GA in FAF images, two classifiers were built (GA vs. healthy/GA vs. ORD). The DCNN was trained and validated with 400 FAF images in each case (GA 200, healthy 200, or ORD 200). For the subsequent testing, the built classifiers were then tested with 60 untrained FAF images in each case (AMD 30, healthy 30, or ORD 30). Hereby, both classifiers automatically determined a GA probability score and a normal FAF probability score or an ORD probability score.To automatically differentiate between dt-GA and ndt-GA, the DCNN was trained and validated with 200 FAF images (dt-GA 72; ndt-GA 138). Afterwards, the built classifier was tested with 20 untrained FAF images (dt-GA 10; ndt-GA 10) and a dt-GA probability score and an ndt-GA probability score was calculated.For both classifiers, the performance of the training and validation procedure after 500 training steps was measured by determining training accuracy, validation accuracy, and cross entropy.ResultsFor the GA classifiers (GA vs. healthy/GA vs. ORD), the achieved training accuracy was 99/98%, the validation accuracy 96/91%, and the cross entropy 0.062/0.100. For the dt-GA classifier, the training accuracy was 99%, the validation accuracy 77%, and the cross entropy 0.166.The mean GA probability score was 0.9810.048 (GA vs. healthy)/0.972 +/- 0.439 (GA vs. ORD) in the GA image group and 0.01 +/- 0.016 (healthy)/0.061 +/- 0.072 (ORD) in the comparison groups (p<0.001). The mean dt-GA probability score was 0.807 +/- 0.116 in the dt-GA image group and 0.180 +/- 0.100 in the ndt-GA image group (p<0.001).ConclusionFor the first time, this study describes the use of a deep learning-based algorithm to automatically detect and classify GA in FAF. Hereby, the created classifiers showed excellent results. With further developments, this model may be a tool to predict the individual progression risk of GA and give relevant information for future therapeutic approaches.	187.92674018361407
1393.	Oil palm plantation mapping is an important task in land planning and management in Malaysia. Most existing studies were based on satellite images using traditional machine learning or image segmentation methods. In order to obtain finer oil palm plantation maps from high spatial-resolution satellite images, we proposed a novel deep learning-based semantic segmentation approach, named Residual Channel Attention Network (RCANet). It consists of an encoder-decoder architecture and a post-processing component. The Residual Channel Attention Unit (RCAU) designed in our proposed approach reuses the low-level features extracted from the encoder part through upsampling, effectively enhancing the discriminative features and suppressing the indiscriminate features. We extended the fully connected Conditional Random Field (FC-CRF) in the post-processing to further refine the segmentation results. Experiment results were evaluated by our proposed Malaysian Oil Palm Plantation Dataset (MOPPD), which was collected from the Google Earth high spatial-resolution image and published in this article. Our proposed method achieves the overall accuracy (OA) of 96.88% and mean Intersection-over-Union (mean IoU) of 90.58%, improving the OA by 2.03%-3.96% and the mean IoU by 2.13%-5.44% compared with other semantic segmentation methods (i.e. Fully Connected Network, U-Net and Fully Connected DenseNet). In addition, we exhibited the results of the oil palm plantation mapping in large-scale areas (around 320 km(2)) and demonstrated the effectiveness of our method for large-scale mapping.	187.92671151998746
1394.	The COVID-19 outbreak in late December 2019 is still spreading rapidly in many countries and regions around the world. It is thus urgent to predict the development and spread of the epidemic. In this paper, we have developed a forecasting model of COVID-19 by using a deep learning method with rolling update mechanism based on the epidemical data provided by Johns Hopkins University. First, as traditional epidemical models use the accumulative confirmed cases for training, it can only predict a rising trend of the epidemic and cannot predict when the epidemic will decline or end, an improved model is built based on long short-term memory (LSTM) with daily confirmed cases training set. Second, considering the existing forecasting model based on LSTM can only predict the epidemic trend within the next 30 days accurately, the rolling update mechanism is embedded with LSTM for long-term projections. Third, by introducing Diffusion Index (DI), the effectiveness of preventive measures like social isolation and lockdown on the spread of COVID-19 is analyzed in our novel research. The trends of the epidemic in 150 days ahead are modeled for Russia, Peru and Iran, three countries on different continents. Under our estimation, the current epidemic in Peru is predicted to continue until November 2020. The number of positive cases per day in Iran is expected to fall below 1000 by mid-November, with a gradual downward trend expected after several smaller peaks from July to September, while there will still be more than 2000 increase by early December in Russia. Moreover, our study highlights the importance of preventive measures which have been taken by the government, which shows that the strict controlment can significantly reduce the spread of COVID-19.	187.92663385590575
1395.	Major advances in diagnostic technologies are offering unprecedented insight into the condition of the retina and beyond ocular disease. Digital images providing millions of morphological datasets can fast and non-invasively be analyzed in a comprehensive manner using artificial intelligence (AI). Methods based on machine learning (ML) and particularly deep learning (DL) are able to identify, localize and quantify pathological features in almost every macular and retinal disease. Convolutional neural networks thereby mimic the path of the human brain for object recognition through learning of pathological features from training sets, supervised ML, or even extrapolation from patterns recognized independently, unsupervised ML. The methods of AI-based retinal analyses are diverse and differ widely in their applicability, interpretability and reliability in different datasets and diseases. Fully automated AI-based systems have recently been approved for screening of diabetic retinopathy (DR). The overall potential of ML/DL includes screening, diagnostic grading as well as guidance of therapy with automated detection of disease activity, recurrences, quantification of therapeutic effects and identification of relevant targets for novel therapeutic approaches. Prediction and prognostic conclusions further expand the potential benefit of AI in retina which will enable personalized health care as well as large scale management and will empower the ophthalmologist to provide high quality diagnosis/therapy and successfully deal with the complexity of 21st century ophthalmology.	187.92655047291075
1396.	Research that focuses on teacher identity is gaining traction as researchers argue that teachers mediate more than mathematical knowledge and skills in the classroom. This research tends to be underpinned by a social constructionist orientation, which foregrounds epistemology over ontology. This orientation is limiting for research that wishes to understand the base conditions that enable or constrain the expression (i.e. both communication and action) of teacher identity in teaching primary mathematics. The paper suggests that this requires research that explores the interaction between structure, culture and agency in the expression of teacher identity in teaching mathematics in primary school. The study argues that a social realist orientation is of value to research on teacher identity. From this perspective, teacher identity is defined as the manner in which teachers express their roles as teachers. As the paper is primarily theoretical, the exemplification is limited to two primary school teachers' expression of only one role namely effective communicator of mathematics. It demonstrates what social realism enables, that is, not illuminated in research underpinned by a social constructionist orientation. The argument made in this paper elucidates how social realism supports a deep analysis of the structural and agential conditions that enable and constrain teacher identities.	187.92653391211005
1397.	Image-edge smoothing is a practical technique in many image-editing implementations such as Visual Aesthetic Enhancement, Action Movie Production, and Privacy Protection. In the literature, there have been many well-adapted smoothing techniques used for image edges such as Gaussian and Bilateral Blurred utilizing visual semantics perceived by the human visual system. However, it is observed that the previously employed image-edge smoothing techniques are not both content-aware and semantically aware. In other words, the image edges are not smoothsimple and efficient, its performance might be less satisfactory. We tend to smooth semantically non-important regions while smoothing semantically important regions slightly in practice. The motivation behind this is that we propose a deep architecture for semantically aware image-edge smoothing. Hence, provided massive image patches extracted from highly aesthetic images crawled from Flickr, we extract multimodal visual features to characterize each. Then, these multimodal features are optimally combined via a multi-view learning framework. Hence, we employ an active learning framework to extract the visually attractive image patches from each image. Thus, we train a deep CNN to find out the edge attributes of actively selected image patches. Utilizing the trained CNN feature of each image patch, we construct a Gaussian mixture model to conduct image-edge smoothing. To verify the proposed method, extensive experimental runs on images with different styles are employed to present the attractiveness of image edges processed by the proposed method. Besides, the efficiency of the proposed method is compared to the well-known edge smoothing algorithms. (c) 2020 Elsevier B.V. All rights reserved.	187.9264992582893
1398.	In the field of computer graphics, synthesizing a new view of 3D objects in images from a single perspective image is an important problem. A part of the object is unobservable, since 3D objects mapping to image space will result in partial occlusion or self-occlusion of objects. The synthesis needs to infer spatial structure and posture of the object. The uncertainty due to occlusion is a problem in the synthesis. In this paper, the problem is solved by establishing a convolutional neural network (CNN), which uses images including multiple chairs as dataset. First of all, we study related networks to propose a novel multi-parallel and multi-level encoding-decoding network, which implements the transformation from a single perspective image and angle semantic information to a new perspective synthetic image in an end-to-end way. Secondly, the network is trained by establishing a dataset. Finally, it is proved the neural network performs better edge smoothing effect and higher precision in image synthesis than state-of-the-art networks.	187.92643923512756
1399.	In this paper, we tackle the problem of crowd counting in indoor videos, where people often stay almost static for a long time. The label distribution, which covers a certain number of crowd counting labels, representing the degree to which each label describes the video frame, is previously adopted to model the label ambiguity of the crowd number. However, since the label ambiguity is significantly affected by the crowd number of the scene, we initialize the label distribution of each frame by the discretized Gaussian distribution with adaptive variance instead of the original single static Gaussian distribution. Moreover, considering the gradual change of crowd numbers in the adjacent frames, a mixture of Gaussian models is proposed to generate the final label distribution representation for each frame. The weights of the Gaussian models rely on the frame and feature distances between the current frame and the adjacent frames. The mixed l(2,1)-norm is adopted to restrict the weights of predicting the adjacent crowd numbers to he locally correlated. We collect three new indoor video datasets with frame number annotation for further research. The proposed approach achieves state-of-the-art performance on seven challenging indoor videos and cross-scene experiments.	187.92638338480202
1400.	In facial expression identification classification and lower processing times are key in choosing the algorithms to use in the facial detection, preprocessing, feature extraction or classification step. Facial expression recognition is based on deep learning, feature and holistic algorithms. Feature based algorithms like local binary patterns, local directional patterns (LDP) extract features from various facial components like nose, mouth or ears into a histogram. Deep learning involves using convolutional neural networks for image analysis with several hidden layers as opposed to artificial neural or shallow networks. The most popular models are AlexNet, VGG-Face and GoogleNet. The study evaluates computational accuracy and efficiency of deep learning algorithms and compares them to local feature based algorithms. The FER2013, Yale Faces, AT&T Database of Faces, JAFFE and CK+ datasets were used for analysis. Popular frameworks deep learning frameworks called Keras and Tensorflow backends are used to classify data and give better accuracy than a variant of local binary patterns. The processing time is shorter for feature based algorithms than the deep learning algorithms. To improve time on the deep learning approaches the study used pre-trained models to achieve greater accuracy with low execution times as well. A combination of preprocessed multi block binary patterns, PCA, multilayer perceptron, support vector machines and extra trees classifier gave competitive results to the superior established convolutional network for small datasets within a percentage range. Preprocessing used canny edge detection and histogram equalization.	187.92628393812515
1401.	Because the most dangerous type of skin cancer, melanoma, is very difficult for dermatologists to detect because of the low contrast between the lesion and the adjacent skin, the automatic application of skin lesion segmentation is regarded as very challenging. This paper proposes the implementation of a medical image segmentation that will accelerate a melanoma diagnosis by dermatologists. In the implementation, Fully Convolutional Network (FCN) architectures generated by modifying Convolutional Neural Network (CNN) architectures are used. The proposed algorithm for an automatic semantic segmentation of skin lesions utilizes four different FCN architectures, FCN-AlexNet, FCN-8s, FCN-16s, and FCN-32s. The experimental studies in this paper are constructed on the ISIC 2017 dataset, and the evaluations of these architectures on the dataset are carried out for the first time with this study. In the experimental studies, once the images in the dataset are preprocessed, the FCNs are first trained separately. Secondly, the accuracies and Dice coefficients on the validation dataset are calculated by using these trained FCN architectures. Thirdly, the obtained results are compared. Finally, the inferences of lesion segmentation are visualized in order to exhibit how exactly the FCN architectures can segment the lesions. The experimental results show that the FCNs in the proposed algorithm are suitable for skin lesion segmentation. In addition, it is thought that the experimental results will contribute to the scientific literature and assist the researchers who are working on medical image segmentation. (c) 2020 Elsevier Ltd. All rights reserved.	187.92623774861414
1402.	Videosomnography (VSG) is a group of video-based methods used to record and label sleep versus awake states in humans. Traditional behavioral-VSG (B-VSG) labeling requires visual inspection of the video by a trained technician to determine whether a subject is sleep or awake. B-VSG is not used to label sleep stages (e.g., slow wave or REM sleep), rather it solely labels whether a subject is asleep or awake at a particular time. In this paper we describe an automated VSG sleep detection system which uses deep learning approaches to label frames in a sleep video as "sleep" or "awake" in young children. We examine 3D Convolutional Networks (C3D) and Long Shortterm Memory (LSTM) relative to motion information from selected Groups of Pictures of a sleep video and test temporal window sizes for back propagation. We compared our proposed VSG methods to traditional B-VSG sleep-awake labels. C3D had an accuracy of approximately 90% and the proposed LSTM method improved the accuracy to more than 95%. The analyses revealed that estimates generated from the proposed LSTM-based method with long-term temporal dependency are suitable for automated sleep or awake labeling.	187.92615564450836
1403.	The semiconductor manufacturing roadmap which generally follows Moore's law requires smaller and smaller EPE (Edge Placement Error), and this places stricter requirements on OPC model accuracy, which is mainly limited by metrology errors, pattern coverage and model form. Current metrology errors are mainly related to SEM image noise and measurement difficulty in complex 2D patterns. And traditional model form improvement by adding empirical terms for PEB (Post Exposure Bake), NTD (Negative Tone Development) and PRS (Physical Resist Shrinkage) effects still cannot meet the accuracy spec because other physical and chemical effects are uncaptured. Fitting these effects also requires comprehensive pattern coverage during model calibration. Solely improving model form may overfit the metrology error, which is risky, while solely improving metrology ignores existing model errors: both factors are troublesome for OPC. In this paper, a new metrology (MXP, naming for Metrology of Extreme Performance) and deep learning (Newron, naming for a Deep Convolutional Neural Network model form) integrated solution is proposed, where MXP decreases the metrology errors and provides good pattern coverage with high-volume reliable CD and EP (Edge Placement) gauges, and Newron captures remaining complex physical and chemical effects embedded in high-volume gauges beyond the traditional model. This solution shows overall similar to 30% prediction accuracy improvement compared to baseline metrology and FEM+ (Focus Exposure Matrix) model flow in N14 NTD process, predicts SEM shape of critical weak points more accurately	187.92611801215725
1404.	Ship detection from remote sensing images can provide important information for maritime reconnaissance and surveillance and is also a challenging task. Although previous detection methods including some advanced ones based on deep convolutional neural network expertize in detecting horizontal or nearly horizontal targets, they cannot give satisfying detection results for arbitrary-oriented ship detection. In this letter, we introduce a novel ship detection system that can detect arbitrary-oriented ships. In this method, a rotated region proposal networks ((RPN)-P-2) is proposed to generate multiorientated proposals with ship orientation angle information. In (RPN)-P-2, the orientation angles of bounding boxes are also regressed to make the inclined ship region proposals generated more accurately. For ship discrimination, a rotated region of interest pooling layer is adopted in the following classification subnetwork to extract discriminative features from such inclined candidate regions. The proposed whole ship detection system can be trained end to end. Experimental results conducted on our rotated ship data set and HRSD2016 benchmark demonstrate that our proposed method outperforms state-of-the-art approaches for the arbitrary-oriented ship detection task.	187.92607552515585
1405.	We present a method for improving human design of chairs. The goal of the method is generating enormous chair candidates in order to facilitate human designer by creating sketches and 3d models accordingly based on the generated chair design. It consists of an image synthesis module, which learns the underlying distribution of training dataset, a super-resolution module, which improve quality of generated image and human involvements. Finally, we manually pick one of the generated candidates to create a real life chair for illustration.	187.9260636154769
1406.	Radiation dose level is of an important consideration for fluoroscopy imaging of interventional C-arm systems. Low-dose imaging is always expected in clinical practice. However, it also causes many image noises, making doctors difficultly perform correct judgments and treatments. In this paper, we propose a new method based on deep CNN (convolutional neural networks) for fluoroscopic image denoising to enable low-dose imaging but with high image quality. We integrate DenseNet [1] into DnCNN [2], called Dense DnCNN, to make use of the advantages of denoising and avoiding the gradient vanishing that preserves image features over all the CNN levels during noise reduction. DenseBlock-B [3] is used to speed up the computation and increase the algorithm robustness by discarding ineffective features. In addition, perceptual loss is applied further to prevent images from excessive smoothing. We evaluate the proposed method of Dense DnCNN with fluoroscopic images involving phantom and clinic patient datasets. Our results of noise reduction show that Dense DnCNN results in an average 46.32dB in PSNR (peak signal to noise ratio), higher than 45.46dB by the original DnCNN. Also in visual evaluation, Dense DnCNN with perceptual loss performs better in preserving image details excluding excessive smooth.	187.92602448955364
1407.	Background The purpose of the present study was to evaluate deep learning-based image-guided surgical planning for deep brain stimulation (DBS). We developed deep learning semantic segmentation-based DBS targeting and prospectively applied the method clinically. Methods T2* fast gradient-echo images from 102 patients were used for training and validation. Manually drawn ground truth information was prepared for the subthalamic and red nuclei with an axial cut similar to 4 mm below the anterior-posterior commissure line. A fully convolutional neural network (FCN-VGG-16) was used to ensure margin identification by semantic segmentation. Image contrast augmentation was performed nine times. Up to 102 original images and 918 augmented images were used for training and validation. The accuracy of semantic segmentation was measured in terms of mean accuracy and mean intersection over the union. Targets were calculated based on their relative distance from these segmented anatomical structures considering the Bejjani target. Results Mean accuracies and mean intersection over the union values were high: 0.904 and 0.813, respectively, for the 62 training images, and 0.911 and 0.821, respectively, for the 558 augmented training images when 360 augmented validation images were used. The Dice coefficient converted from the intersection over the union was 0.902 when 720 training and 198 validation images were used. Semantic segmentation was adaptive to high anatomical variations in size, shape, and asymmetry. For clinical application, two patients were assessed: one with essential tremor and another with bradykinesia and gait disturbance due to Parkinson's disease. Both improved without complications after surgery, and microelectrode recordings showed subthalamic nuclei signals in the latter patient. Conclusion The accuracy of deep learning-based semantic segmentation may surpass that of previous methods. DBS targeting and its clinical application were made possible using accurate deep learning-based semantic segmentation, which is adaptive to anatomical variations.	187.92597371479604
1408.	Automatic text classification is the task of organizing documents into pre-determined classes, generally using machine learning algorithms. Generally speaking, it is one of the most important methods to organize and make use of the gigantic amounts of information that exist in unstructured textual format. Text classification is a widely studied research area of language processing and text mining. In traditional text classification, a document is represented as a bag of words where the words in other words terms are cut from their finer context i.e. their location in a sentence or in a document. Only the broader context of document is used with some type of term frequency information in the vector space. Consequently, semantics of words that can be inferred from the finer context of its location in a sentence and its relations with neighboring words are usually ignored. However, meaning of words, semantic connections between words, documents and even classes are obviously important since methods that capture semantics generally reach better classification performances. Several surveys have been published to analyze diverse approaches for the traditional text classification methods. Most of these surveys cover application of different semantic term relatedness methods in text classification up to a certain degree. However, they do not specifically target semantic text classification algorithms and their advantages over the traditional text classification. In order to fill this gap, we undertake a comprehensive discussion of semantic text classification vs. traditional text classification. This survey explores the past and recent advancements in semantic text classification and attempts to organize existing approaches under five fundamental categories; domain knowledge-based approaches, corpus-based approaches, deep learning based approaches, word/character sequence enhanced approaches and linguistic enriched approaches. Furthermore, this survey highlights the advantages of semantic text classification algorithms over the traditional text classification algorithms.	187.92590707521651
1409.	One of the crucial problems of the signal processing, digital forensics and machine learning is the environmental sound classification (ESC). Several ESC methods have been presented to obtain highly accurate model. In this work, a novel multileveled ESC method is presented. The presented ESC method uses two novel algorithms namely Spiral Pattern and two dimensional maximum, minimum, median and mean (2D-M4) pooling. By using these methods (Spiral Pattern and 2D-M4 pooling), 9 level feature generation approach is presented. Since the proposed Spiral Pattern has nine arrows, it extracts 9 and 18 bits using signum and ternary functions respectively. As a result, 1536 features are extracted in each level and totally 15,360 features are generated using from 0th to 9th levels. In order to select the discriminative features, neighbourhood component analysis (NCA) is used and 700 most distinctive features are selected. In the classification phase, deep neural network is trained and tested with the ESC-10 and ESC-50 datasets. 98.75% and 85.75% average classification accuracies were achieved with 10-folds cross validation for ESC-10 and ESC-50 datasets respectively. The experimental results reveal that the proposed Spiral Pattern and 2D-M4 pooling based ESC method is superior than the human auditory system (HAS) for environmental sound classification. (C) 2020 Elsevier Ltd. All rights reserved.	187.925897604883
1410.	High-resolution wide-area images are required in the diverse field of research ranging from urban planning and disaster prediction to agriculture and geology. Sometimes the image is taken under harsh weather conditions or at night time. Current optical remote sensing technology does not have the capability to acquire images in such conditions. Synthetic aperture radar (SAR) uses microwave signal which has a long-range propagation characteristic that allows us to capture images in difficult weather conditions. In addition to this, some polarimetric SAR (PolSAR) systems are also capable of capturing images using multifrequency bands simultaneously resulting into a multitude of information in comparison to the optical images. In this letter, we propose a single-hidden layer optimized Wishart network (OWN) and extended OWN for classification of the single-frequency and multifrequancy PolSAR data, respectively. Performance evaluation is conducted on a single-frequency as well as multifrequency SAR data obtained by Airborne Synthetic Aperture Radar. We observed that for combining multiple hand information, proposed single-hidden layer network outperforms deep learning-based architecture involving multiple hidden layers.	187.9258835605699
1411.	The lack of anomaly detection methods during mechanized tunnelling can cause financial loss and deficits in drilling time. On-site excavation requires hard obstacles to be recognized prior to drilling in order to avoid damaging the tunnel boring machine and to adjust the propagation velocity. The efficiency of the structural anomaly detection can be increased with intelligent optimization techniques and machine learning. In this research, the anomaly in a simple structure is detected by comparing the experimental measurements of the structural vibrations with numerical simulations using parameter estimation methods. (C) 2019 Elsevier Ltd. All rights reserved.	187.92587318902304
1412.	Optical marker-based motion capture is a vital tool in applications such as motion and behavioural analysis, animation, and biomechanics. Labelling, that is, assigning optical markers to the pre-defined positions on the body, is a time consuming and labour intensive post-processing part of current motion capture pipelines. The problem can be considered as a ranking process in which markers shuffled by an unknown permutation matrix are sorted to recover the correct order. In this paper, we present a framework for automatic marker labelling which first estimates a permutation matrix for each individual frame using a differentiable permutation learning model and then utilizes temporal consistency to identify and correct remaining labelling errors. Experiments conducted on the test data show the effectiveness of our framework.	187.9257099777368
1413.	Person re-identification is a challenging problem in computer vision. Lots of research interest is observed in this area over the past few years. A model for complete person re-identification can prove useful in this direction. Use of convolutional neural networks for pedestrian detection can improve the accuracy of detection to a larger extent. Deriving a descriptor which is invariant to the changes in the illumination, background and the pose can make the difference in the re-identification process. The predominant part of our work focuses on building a robust descriptor which can tackle such challenges. We have concentrated on building a descriptor by employing appearance-based features extracted both at local and global levels. Further, the dimensionality of the descriptor is reduced using kernel PCA. Distance metric learning algorithms are used to evaluate the descriptor on three major benchmark datasets. We propose a complete person re-identification system which involves both pedestrian detection and person re-identification. Major contributions of this work are to detect pedestrians from surveillance videos using CNN-based learning and to generate a kernel-PCA-based spatial descriptor and evaluate the descriptor using known distance metric learning methods on benchmark datasets.	187.92557375919748
1414.	In this paper, a convolutional neural networks (CNN) and optical flow based method is proposed for prediction of visual attention in the videos. First, a deep-learning framework is employed to extract spatial features in frames to replace those commonly used handcrafted features. The optical flow is calculated to obtain the temporal feature of the moving objects in video frames, which always draw audiences' attentions. By integrating these two groups of features, a hybrid spatial temporal feature set is obtained and taken as the input of a support vector machine (SVM) to predict the degree of visual attention. Finally, two publicly available video datasets were used to test the performance of the proposed model, where the results have demonstrated the efficacy of the proposed approach.	187.92555438608485
1415.	Network selection is one of the important techniques in cognitive radio networks (CRNs). With the development of network convergence technology and the popularity of heterogeneous networks, multiple primary CRNs interacting with multiple authorized networks are becoming possible, which can provide secondary users with more spectrum resources by network selection. Network selection is the key to spectrum sharing between CRNs and multiple primary networks. However, the spectrum sensing results, highly complex system state, and unsystematic research framework make the research of network selection very challenging. Traditional network selection algorithms are offline selection methods that are based on prior knowledge of primary networks. However, in the complex network environment, it is impossible to get prior knowledge from multiple primary networks, because the offline network selection methods lack efficiency. In order to meet these challenges, this article aims at improving the quality of service of cognitive users, and based on reinforcement learning method and the achievements of dynamic spectrum access of cognitive radio in single primary network environment, proposed a deep reinforcement learning based online network selection method of CRNs with multiple primary networks.	187.92545111785464
1416.	In recent years, small and weak target detection technology is one of the hotspots in information processing technology. However, the detection precision and speed of weak targets still have yet to be improved. As a branch of machine learning, deep learning has become more and more widely used in various fields. Therefore, this paper improves the deep convolutional networks for the characteristics of weak target detection, including the following three aspects: Firstly, a dataset dedicated to small and weak target detection is established. The data is sufficient and representative, which is beneficial to improve the quality of the network model. Each image in the dataset has a corresponding label that indicates the name of the image, and the coordinates and width of the target circumscribed rectangle. Secondly, the image is dilated many times so that the target having only a few pixels is covered by a lot of pixels. The highlighted portion of the image is dilated, and the result image has a larger highlighted area than the original image. Thirdly, the Faster R CNN algorithm is improved. In this paper, by adjusting the learning rates, a suitable one is determined to get the best network model. The results show that the average precision on the dataset has improved. The method proposed in this paper is of great significance for the detection of small and weak targets. For the military field, the research on weak target detection has high military value for improving early warning capability and counterattack capability.	187.92528344041125
1417.	Time-frequency representations of the speech signals provide dynamic information about how the frequency component changes with time. In order to process this information, deep learning models with convolution layers can be used to obtain feature maps. In many speech processing applications, the time-frequency representations are obtained by applying the short-time Fourier transform and using single-channel input tensors to feed the models. However, this may limit the potential of convolutional networks to learn different representations of the audio signal. In this paper, we propose a methodology to combine three different time-frequency representations of the signals by computing continuous wavelet transform, Mel-spectrograms, and Gammatone spectrograms and combining then into 3D-channel spectrograms to analyze speech in two different applications: (1) automatic detection of speech deficits in cochlear implant users and (2) phoneme class recognition to extract phone-attribute features. For this, two different deep learning-based models are considered: convolutional neural networks and recurrent neural networks with convolution layers.	187.9251224063482
1418.	Diseases caused by alterations of ionic concentrations are frequently observed challenges and play an important role in clinical practice. The clinically established method for the diagnosis of electrolyte concentration imbalance is blood tests. A rapid and non-invasive point-of-care method is yet needed. The electrocardiogram (ECG) could meet this need and becomes an established diagnostic tool allowing home monitoring of the electrolyte concentration also by wearable devices. In this review, we present the current state of potassium and calcium concentration monitoring using the ECG and summarize results from previous work. Selected clinical studies are presented, supporting or questioning the use of the ECG for the monitoring of electrolyte concentration imbalances. Differences in the findings from automatic monitoring studies are discussed, and current studies utilizing machine learning are presented demonstrating the potential of the deep learning approach. Furthermore, we demonstrate the potential of computational modeling approaches to gain insight into the mechanisms of relevant clinical findings and as a tool to obtain synthetic data for methodical improvements in monitoring approaches.	187.92509153784704
1419.	Domain adaptation is a significant and popular issue of solving distribution discrepancy among different domains in computer vision. Generally, previous works proposed are mainly devoted to reducing domain shift between source domain with labeled data and target domain without labels. Adversarial learning in deep networks has already been widely applied to learn disentangled and transferable features between two different domains to minimize domains distribution discrepancy. However, these methods rarely consider class distributions among source data during adversarial learning, and they pay little attention to these transferable regions among source and target domains images. In this paper, we propose a Generative Attention Adversarial Classification Network (GAACN) model for unsupervised domain adaptation. To learn a joint feature distribution between source and target domains, we present an improved generative adversarial network (GAN) following the feature extractor. Firstly, the discriminator of GAN discriminates the distribution of domains and the classes distribution among source data during adversarial learning, so that our feature extractor can learn a joint feature distribution between source and target domains and maintain the classes consistent simultaneously. Secondly, we present an attention module embedded in GAN, which allows the discriminator to discriminate the transferable regions among the images of source and target domains. Lastly, we propose a simple and efficient method which allocates pseudo-labels for unlabeled target data, and it can improve the performance of our model GAACN while mitigating negative transfer. Extensive experiments demonstrate that our proposed model achieves perfect results on several standard domain adaptation datasets. (C) 2020 Elsevier Ltd. All rights reserved.	187.92502774484575
1420.	Annually, 48% of the global energy is used by buildings in their construction, operation, and maintenance, causing significant damage to the environment due to the resulting greenhouse gas emissions. During their life cycles, buildings use energy in the form of embodied energy (EE) and operating energy (OE). In a conventional building, EE accounts for 10-20% of a building's life cycle energy (LCE), while OE accounts for 80-90%. As a result, the building sector has taken several measures to reduce OE in buildings. These OE reducing measures fail to account for the subsequent increase in EE and might cause an increase in the building's overall LCE. A systematic review of the literature shows limited research that comprehensively evaluates the impact of design measures aimed at OE reduction on EE for different construction assemblies. In this study, we quantify and compare trade-offs on EE demand, caused by OE reduction measures for eight different building wall assemblies across four climatic zones within the United States. The EE and OE demands of the ASHRAE 90.1-2016 benchmark model and its variations were computed using Tally (TM) and Autodesk (R) Green Building Studio (R) (GBS), respectively. The results helped us determine the EE factor (EE spent per unit of OE savings) for different OE reduction measures. Although the calculated EE factors vary across different climatic zones and construction assemblies, these factors show significant EE costs for different OE reduction measures. This knowledge could help inform the design of evolutionary and deep/machine learning-based algorithms to assess and optimize building energy use. (C) 2020 Elsevier B.V. All rights reserved.	187.92501856357973
1421.	More and deeper reinforcement learning algorithms have been proposed and demonstrated on a series of decision-making domains. However, little research has been hammered at algorithm extraction. With duality in deep reinforcement learning substantially summarized, we propose a conceptually simple framework for deep reinforcement learning based on duality. Then, we propose the dual method of prioritized sampling: prioritized learning. Finally, we give the formula and analysis for the duality with priority. The algorithm implementation and experiment will be put on Part II-Implementation.	187.92493876383298
1422.	Ultrasound image assessment plays an important role in the diagnosis of carotid artery atherosclerosis. The segmentation of plaques from carotid artery ultrasound images is critical for the atherosclerotic diagnosis. In this paper, a novel automatic plaque segmentation method is presented based on U-Net deep learning network which allows to train the network end-to-end for pixel-wise classification. A large number of labeled examples are required for traditional supervised learning techniques as to obtain the global optimization. However, in this task, it is unavailable to obtain so many labeled examples since manually segmentation of plaques is a time-consuming task and its reliability relies to the experience of experts. In order to solve the problem of lack of labeled samples, an unsupervised learning technique, the deep convolutional encoder-decoder architecture, was proposed to pre-train the parameters of U-Net by amount of unlabeled data. Then the parameters learned from the deep convolutional encoder-decoder network were applied to initialize a U-Net from the labeled images for fine-tuning. Algorithm accuracy was examined on the common carotid artery part of 26 3D carotid ultrasound images (34 plaques) by comparing the results of our algorithm with manual segmentations and the Dice similarity coefficient (DSC) is 90.72 +/- 6.2% which was better than the previous level set method with the DSC of 88.2 +/- 8.3%. The automatic method provides a more convenient way to segment carotid plaques in 3D ultrasound images.	187.9249101355738
1423.	CONTEXT: Parkinson disease (PD) can be physically, emotionally, and financially burdensome. Understanding its impact from the patient's perspective is an important way to sensitize clinicians to the challenges of living with PD. OBJECTIVE: To evaluate whether a book-length graphic memoir (an illness story in comic form) can help clinicians appreciate PD from the patient's perspective. DESIGN: A convergent mixed-methods study of clinicians working in a multidisciplinary movement disorders clinic. Participants read My Degeneration and completed preintervention and post-intervention questionnaires. They also attended a book group discussion. Quantitative findings were compared before and after the intervention, and qualitative data were analyzed for themes. MAIN OUTCOME MEASURES: Clinicians': 1) confidence in understanding patients' experiences with PD, 2) knowledge about PD, and 3) empathy toward patients and families. RESULTS: After reading the book, participants' confidence in understanding patients' experiences with PD increased significantly in the areas of stigma and disease impact on patients and families. Clinical knowledge was unchanged. Qualitative analysis revealed 3 main themes: 1) the book provides a meaningful way for clinicians to learn about the experience of living with PD; 2) the medium of comics engages clinicians in ways different from other mediums; and 3) benefits of the book may extend beyond the clinical team. CONCLUSION: Clinicians who read My Degeneration gained insight into the psychosocial effects of PD on patients and their loved ones. The book helped facilitate deeper understanding of patients' experiences living with PD and fostered greater empathy and self-reflection.	187.92469237653927
1424.	With the advances of sensing technology and deep learning, deep learning based human activity recognition from sensor signal data has been actively studied. While deep neural networks can automatically extract features appropriate for the target task and focus on increasing the recognition performance, they cannot select important input sensor signals, which leads to the lack of interpretability. Since not all signals from wearable sensors are important for the target task, sensor signal importance will be insightful information for practitioners. In this article, we propose an interpretable and accurate convolutional neural network capable of select important sensor signals. This is enabled by spatially sparse convolutional filters whose sparsity is imposed by spatial group lasso. While there is a tradeoff between accuracy and interpretability in a model, experimental results on the opportunity activity recognition dataset show that the proposed model can help improve recognition performance and select important sensor signals, providing interpretability.	187.92468673519426
1425.	Motion scoring of cardiac myocardium is essential for early detection and diagnosis of various cardiac diseases. Existing work on the myocardium motion mainly focuses on binary abnormality detection, while the myocardium motion can be clinically classified into four types: normal, hypokinetic, akinetic and dyskinetic, which has greater significance and is more challenging to predict. The state-of-the-art demonstrated that the method for cardiac motion scoring from MR sequences based on deep convolution neural network (CNN) with non-local attention has great potential. However, due to the complex myocardium deformation and subtle inter-class difference of motion patterns, the performance is still not satisfactory. In this paper, we introduce two types of "attention mechanism" to enhance the ability of the CNN network by effectively extracting the dependency in time-wise, space-wise and cardiac segment-wise. Experiment on 1440 myocardium segments of 90 subjects from short-axis MR sequences of multiple lengths prove that our method's prediction is more precise and consistent which paves the way to the potential implementation in clinical routine.	187.92461562101482
1426.	Processing method plays an important role in accelerating imaging process in ghost imaging. In this study, we propose a processing method with the Hadamard matrix and a deep neural network called ghost imaging hadamard neural network (GIHNN). We focus on how to break through the bottleneck of image reconstruction time, and GIHNN can identify an object before the imaging process. Our research reveals that the light intensity value contains the feature information of the object and expands the possibility of further applications of artificial intellectual techniques in computational ghost imaging.	187.9245751224338
1427.	Advancing the sustainable use and conservation of marine environments is urgent. Tons of debris including macro- and microplastics generated on land are entering the oceans, marine resources are decreasing, and many species are facing extinction. Though satellite remote sensing techniques are commonly used for global environmental monitoring, it is still difficult to detect small objects such as floating debris on the vast ocean surface, and the ecosystems deep in the oceans where light does not reach are unobservable. An autonomous monitoring system consisting of optimally controlled robots is required for acquiring spatiotemporally rich marine data. However, object detection in marine environments, which is a necessary function the robots should have for underwater and aerial monitoring, has not been extensively studied. Here, we argue that state-of-the-art deep-learning-based object detection works well for monitoring underwater ecosystems and marine debris. We found that by using the deep-learning object-detection algorithm YOLO v3, underwater sea life and debris floating on the ocean surface can be detected with mean average precision of 69.6% and 77.2%, respectively. We anticipate our results to be a starting point for developing tools for enabling safe and precise acquisition of marine data to elucidate and utilize this last frontier. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.	187.9244756678004
1428.	Accurately simulating fractured systems requires treating the fracture's characteristics. Here we describe a novel framework that involves coupling the Hybrid Embedded Fracture (HEF) scheme with Machine Learning. In general, HEF is more accurate than continuum medium schemes and less reliable but more efficient than the Discrete Fracture Networks (DFN) schemes. In our work, the attributes used to estimate the HEF flux exchange parameters are extracted using image processing, Machine-Learning, and Artificial-Intelligence techniques. In addition, we formulate a pure Machine-Learning classifier and Deep-Learning topology design to deal with the extraction of hierarchical fracture features from low-level to high-level based on Neural-Network layers. Computations are visualized using velocity vectors that are controlled by fractures characteristics extracted automatically from the fractured systems images. Their results provide an understanding of the flow behavior and maps of pressure distributions.	187.9244332585937
1429.	Weak signal detection is a challenging yet significant problem in the field of radio communication. Although hand-crafted filters are widely used in signal processing, they are challenged by the weak signal detection task with unknown background noise especially in the range of 0-5dB. In this paper, we propose the learning modulation filter networks (LMFNs) to improve the detection performance. The approach is based on a two-stage optimization scheme which addresses filter learning, attention mechanism and classification in a unified framework. Modulation filters are built to enhance the capacity of the learned filters, and the attention mechanism further characterizes the saliency properties of the input signal. LMFNs reduce the storage size of the network while achieving the state-of-the-art performance by a significant margin compared to traditional cognitive radio approaches. We establish a weak signal dataset that contains unmanned aerial vehicle (UAV) communication signals in a real-terrain environment. The source code and dataset will be made publicly available soon. (C) 2020 Elsevier Ltd. All rights reserved.	187.92442035042268
1430.	A new program, ECEP2D, for simulating the one-dimensional (ID) and two-dimensional (2D) patterns of the gel electrophoresis of a protein after it has been digested by one or more enzymes is introduced. With ECEP2D, students can gain deeper insights into gel electrophoresis by performing hands-on simulations. For example, students can visualize how 2D gel electrophoresis can improve resolution over 1D by comparing them side-by-side. Students can watch how different enzymes cut a protein into different fragments, giving rise to different gel patterns; some patterns are less congested than the others. Students can recognize how enzyme digestion can enhance gel electrophoresis to distinguish proteins. For students not having the chance to take biochemistry laboratories, ECEP2D provides a useful simulated learning environment. Instructors can also complement wet-lab experiments with simulations by ECEP2D to introduce more concepts with fewer laboratory hours. ECEP2D is available for free at http://www.umsl.edu/similar to wongch/software.html.	187.92440944627157
1431.	The best learning outcomes are rarely achieved without motivating the learner, and in this regard, active teaching and learning methods have been proven useful. Here, we introduce the "learn and innovate" strategy to enhance the students' interest, conceptual understanding, and deep learning under full guiding instructions. Moreover, by this strategy, we encourage the students to conduct an independent research while acquiring high-level thinking skills. Designing appropriate instructional strategies and innovative research tasks and media, which leads to collaborative/cooperative learning, enhances the students' interaction with the course materials. The method supports the students to gain self-confidence, motivation, and scientific skills to address different research challenges at early stages while enhancing their learning level. In this context, the adopted strategy fosters a first semester master student to deeply understand the new "Leidenfrost Nanochemistry" phenomenon to synthesize Au nanoparticles. Acquiring such knowledge, the student can participate in solving an exploratory research problem and the related experimental challenges. The "learn and innovate" approach has been proven to be a pivotal and novel active teaching strategy to stimulate the active learning of students and the innovative education-based Aha! effect.	187.92434846137812
1432.	Audio tagging is the task of predicting the presence or absence of sound classes within an audio clip. Previous work in audio tagging focused on relatively small datasets limited to recognizing a small number of sound classes. We investigate audio tagging on AudioSet, which is a dataset consisting of over 2 million audio clips and 527 classes. AudioSet is weakly labelled, in that only the presence or absence of sound classes is known for each clip, whereas the onset and offset times are unknown. To address the weakly labelled audio tagging problem, we propose attention neural networks as a way to attend the most salient parts of an audio clip. We bridge the connection between attention neural networks and multiple instance learning (MIL) methods, and propose decision-level and feature-level attention neural networks for audio tagging. We investigate attention neural networks modeled by different functions, depths, and widths. Experiments on AudioSet show that the feature-level attention neural network achieves a state-of-the-art mean average precision of 0.369, outperforming the best MIL method of 0.317 and Google's deep neural network baseline of 0.314. In addition, we discover that the audio tagging performance on AudioSet-embedding features has a weak correlation with the number of training samples and the quality of labels of each sound class.	187.92416429372417
1433.	Collecting data from mechanical systems in abnormal conditions is expensive and time consuming. Consequently, fault detection approaches based on classical supervised learning working with both normal and abnormal data are not applicable in some condition-based maintenance tasks. To address this problem, this paper proposes Fusing Convolutional Generative Adversarial Encoders (fCGAE) method to create fault detection models from only normal data. Firstly, to obtain an adequate deep feature space, encoder models based on 1D convolutional neural networks are created. Then, these encoders are optimized in an unsupervised way through Bidirectional Generative Adversarial Networks. Finally, the multi-channel features collected from the system are merged with One-Class Support Vector Machine. fCGAE is applied to fault detection in 3D printers, where experimental results in two fault detection cases show excellent generalization capabilities and better performance compared to peer methods. (C) 2020 Elsevier Ltd. All rights reserved.	187.92403282755726
1434.	In-situ measurements of the viscosity and density of small volumes of liquids are required in several industrial applications. MEMS sensors deploying vibrating microstructures constitute an attractive alternative given the significant impact of the surrounding liquid on their dynamic behavior. In this work, we combine physics-based modeling approaches and deep learning techniques to simultaneously estimate the density and viscosity of liquids from the resonance frequencies and quality factors of immersed microcantilevers. The physics-based model is first validated by comparing the simulated resonance frequencies and quality factors of immersed microcantilevers to those obtained from experiments conducted on a large variety of liquids. Then, we use the simulations results to train deep neutral networks to learn the mapping from the data space to the parameter space. The deep learning method shows high prediction accuracy provided that there is enough independent input data, shows no bias in the predicted values, and provides the results instantaneously. The optimal accuracy in the estimation of the liquid viscosity and density is achieved when the first resonance frequency and corresponding quality factor are used as inputs. (C) 2020 Elsevier Inc. All rights reserved.	187.92393634254464
1435.	Small humps on the floor go beyond the detectable scope of laser scanners and are therefore not integrated into SLAM based maps of mobile robots. However, even such small irregularities can have a tremendous effect on the robot's stability and the path quality. As a basis to develop anomaly detection algorithms, kinematics data is collected exemplarily for an overrun of a cable channel and a bulb plate. A recurrent neuronal network (RNN), based on the autoencoder principle, could be trained successfully with this data. The described RNN architecture looks promising to be used for realtime anomaly detection and also to quantify path quality.	187.92389337892712
1436.	Computer vision-based fire detection is one of the crucial tasks in modern surveillance system. In recent years, the convolutional neural network (CNN) has become an active topic because of its high accuracy recognition rate in a wide range of applications. How to reliably and effectively solve the problems of flame detection, however, has still been a challenging problem in practice. In this paper, we proposed a novel flame detection algorithm based on CNN in real time by processing the video data generated by an ordinary camera monitoring a scene. Firstly, to improve the efficiency of recognition, a candidate target area extraction algorithm is proposed for dealing with the suspected flame area. Secondly, the extracted feature maps of candidate areas are classified by the designed deep neural network model based on CNN. Finally, the corresponding alarm signal is obtained by the classification results. The experimental results show that the proposed method can effectively identify fire and achieve higher alarm rate in the homemade database. The proposed method can effectively realize the real-time performance of fire warning in practice.	187.92378787163403
1437.	Computational analysis, modeling, and prediction of many phenomena in materials require a three-dimensional (3D) microstructure sample that embodies the salient features of the material system under study. Since acquiring 3D microstructural images is expensive and time-consuming, an alternative approach is to extrapolate a 2D image (aka exemplar) into a virtual 3D sample and thereafter use the 3D image in the analyses and design. In this paper, we introduce an efficient and novel approach based on transfer learning to accomplish this extrapolation-based reconstruction for a wide range of microstructures including alloys, porous media, and polycrystalline. We cast the reconstruction task as an optimization problem where a random 3D image is iteratively refined to match its microstructural features to those of the exemplar. VGG19, a pre-trained deep convolutional neural network, constitutes the backbone of this optimization where it is used to obtain the microstructural features and construct the objective function. By augmenting the architecture of VGG19 with a permutation operator, we enable it to take 3D images as inputs and generate a collection of 2D features that approximate an underlying 3D feature map. We demonstrate the applications of our approach with nine examples on various microstructure samples and image types (grayscale, binary, and RGB). As measured by independent statistical metrics, our approach ensures the statistical equivalency between the 3D reconstructed samples and the corresponding 2D exemplar quite well. (C) 2020 Elsevier Ltd. All rights reserved.	187.92376189838583
1438.	GAN-based image colorization techniques are capable of producing highly realistic color in real-time. Subjective assessment of these approaches has demonstrated that humans are unable to differentiate between a true RGB image and a colorized image. In this work, we evaluate the fidelity of such colorization and for the first time analyze the GAN-based image colorization scheme in the context of image compression. Our analysis shows that the palette (set of colors) recommended by the GAN-based framework is very limited even for highly realistic interactive colorization. We propose two novel methods of automatic palette generation that allows for the GAN-based framework to be useful for image compression. We demonstrate that provided true colors at a few pixel locations, GAN-based approach results in good spread of color to other image regions. Subjective analysis on a number of public datasets shows that the current system has low fidelity but performs better than JPEG at low data rate regimes.	187.92375238408403
1439.	The quantification of 3D shape aesthetics has so far focused on specific shape features and manually defined criteria such as the curvature and the rule of thirds respectively. In this paper, we build a model of 3D shape aesthetics directly from human aesthetics preference data and show it to be well aligned with human perception of aesthetics. To build this model, we first crowdsource a large number of human aesthetics preferences by showing shapes in pairs in an online study and then use the same to build a 3D shape multi-view based deep neural network architecture to allow us learn a measure of 3D shape aesthetics. In comparison to previous approaches, we do not use any pre-defined notions of aesthetics to build our model. Our algorithmically computed measure of shape aesthetics is beneficial to a range of applications in graphics such as search, visualization and scene composition.	187.92360343148
1440.	The increasing diverse demand for image feature recognition and complicated relationships among image pixels cannot be fully and effectively handled by traditional single image recognition methods. In order to effectively improve classification accuracy in image processing, a deep belief network (DBN) classification model based on probability measure rough set theory is proposed in our research. First, the incomplete and inaccurate fuzzy information in the original image is preprocessed by the rough set method based on probability measure. Second, the attribute features of the image information are extracted, the attribute feature set is reduced to generate the classification rules, and key components are extracted as the input of the DBN. Third, the network structure of the DBN is determined by the extracted classification rules, and the importance of the rough set attributes is integrated and the weights of the neuronal nodes are corrected by the backpropagation (BP) algorithm. Last, the DBN is trained to classify images. The experimental analysis of the proposed method for medical imagery shows that it is more effective than current single rough set approach or the taxonomy of deep learning.	187.92355037774402
1441.	Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g., object recognition, object detection, semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities, e.g., multispectral imagery (MSI), are not available due to the large cost and manpower required. In this paper, we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data, we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting and provide a state-of-the-art baseline for future work.	187.92349550414272
1442.	This survey presents a review of state-of-the-art deep neural network architectures, algorithms, and systems in vision and speech applications. Recent advances in deep artificial neural network algorithms and architectures have spurred rapid innovation and development of intelligent vision and speech systems. With availability of vast amounts of sensor data and cloud computing for processing and training of deep neural networks, and with increased sophistication in mobile and embedded technology, the next-generation intelligent systems are poised to revolutionize personal and commercial computing. This survey begins by providing background and evolution of some of the most successful deep learning models for intelligent vision and speech systems to date. An overview of large-scale industrial research and development efforts is provided to emphasize future trends and prospects of intelligent vision and speech systems. Robust and efficient intelligent systems demand low-latency and high fidelity in resource-constrained hardware platforms such as mobile devices, robots, and automobiles. Therefore, this survey also provides a summary of key challenges and recent successes in running deep neural networks on hardware-restricted platforms, i.e. within limited memory, battery life, and processing capabilities. Finally, emerging applications of vision and speech across disciplines such as affective computing, intelligent transportation, and precision medicine are discussed. To our knowledge, this paper provides one of the most comprehensive surveys on the latest developments in intelligent vision and speech applications from the perspectives of both software and hardware systems. Many of these emerging technologies using deep neural networks show tremendous promise to revolutionize research and development for future vision and speech systems.	187.92347425753493
1443.	Salient object detection is a fundamental problem and has been received a great deal of attention in computer vision. Recently, deep learning model became a powerful tool for image feature extraction. In this study, the authors propose a multi-scale deep neural network (MSDNN) for salient object detection. The proposed model first extracts global high-level features and context information over the whole source image with the recurrent convolutional neural network. Then several stacked deconvolutional layers are adopted to get the multi-scale feature representation and obtain a series of saliency maps. Finally, the authors investigate a fusion convolution module to build a final pixel level saliency map. The proposed model is extensively evaluated on six salient object detection benchmark datasets. Results show that the authors' deep model significantly outperforms other 12 state-of-the-art approaches.	187.9234300153338
1444.	The recent success of Deep Convolutional Neural Network (DCNN) for various computer vision tasks such as image recognition has already demonstrated its robust feature representation ability. However, the limitation of training database on small scale vein recognition tasks restricts its performance because the recognition result of DCNN depends heavily on the number of trainsets. This motivates the design of a Multi-Scale Deep Representation Aggregation (MSDRA) model based on a pre-trained DCNN for vein recognition. First, the multi-scale feature maps are extracted by a pre-trained DCNN model. Second, a local mean threshold approach is designed to preliminarily remove the noisy information of multi-scale feature maps and generate the selected feature maps. Third, we propose an Unsupervised Vein Information Mining (UVIM) method to localize vein information of selected feature maps for generating a binary vein information mask, and then the vein information mask is utilized to keep useful deep representation and discard the background information. Finally, the discriminative multi-scale deep representations, which are generated by using the vein information mask to aggregate multi-scale feature maps, are concatenated into the final compact feature vectors, and then a Support Vector Machine (SVM) is introduced for final recognition. Our proposed model outperforms the state-of-the-art methods on two benchmark vein databases. Moreover, an additional experiment using the subset of PolyU Palmprint database illustrates the system's generalization ability and robustness.	187.92341253536938
1445.	Background Chest radiograph interpretation is critical for the detection of thoracic diseases, including tuberculosis and lung cancer, which affect millions of people worldwide each year. This time-consuming task typically requires expert radiologists to read the images, leading to fatigue-based diagnostic error and lack of diagnostic expertise in areas of the world where radiologists are not available. Recently, deep learning approaches have been able to achieve expert-level performance in medical image interpretation tasks, powered by large network architectures and fueled by the emergence of large labeled datasets. The purpose of this study is to investigate the performance of a deep learning algorithm on the detection of pathologies in chest radiographs compared with practicing radiologists. Methods and findings We developed CheXNeXt, a convolutional neural network to concurrently detect the presence of 14 different pathologies, including pneumonia, pleural effusion, pulmonary masses, and nodules in frontal-view chest radiographs. CheXNeXt was trained and internally validated on the ChestX-ray8 dataset, with a held-out validation set consisting of 420 images, sampled to contain at least 50 cases of each of the original pathology labels. On this validation set, the majority vote of a panel of 3 board-certified cardiothoracic specialist radiologists served as reference standard. We compared CheXNeXt's discriminative performance on the validation set to the performance of 9 radiologists using the area under the receiver operating characteristic curve (AUC). The radiologists included 6 board-certified radiologists (average experience 12 years, range 4-28 years) and 3 senior radiology residents, from 3 academic institutions. We found that CheXNeXt achieved radiologist-level performance on 11 pathologies and did not achieve radiologist-level performance on 3 pathologies. The radiologists achieved statistically significantly higher AUC performance on cardiomegaly, emphysema, and hiatal hernia, with AUCs of 0.888 (95% confidence interval [CI] 0.863-0.910), 0.911 (95% CI 0.866-0.947), and 0.985 (95% CI 0.974-0.991), respectively, whereas CheXNeXt's AUCs were 0.831 (95% CI 0.790-0.870), 0.704 (95% CI 0.567-0.833), and 0.851 (95% CI 0.785-0.909), respectively. CheXNeXt performed better than radiologists in detecting atelectasis, with an AUC of 0.862 (95% CI 0.825-0.895), statistically significantly higher than radiologists' AUC of 0.808 (95% CI 0.777-0.838); there were no statistically significant differences in AUCs for the other 10 pathologies. The average time to interpret the 420 images in the validation set was substantially longer for the radiologists (240 minutes) than for CheXNeXt (1.5 minutes). The main limitations of our study are that neither CheXNeXt nor the radiologists were permitted to use patient history or review prior examinations and that evaluation was limited to a dataset from a single institution. Conclusions In this study, we developed and validated a deep learning algorithm that classified clinically important abnormalities in chest radiographs at a performance level comparable to practicing radiologists. Once tested prospectively in clinical settings, the algorithm could have the potential to expand patient access to chest radiograph diagnostics.	187.9232927555109
1446.	Accurate segmentation of bi-ventricle from cardiac magnetic resonance images can provide assistance in estimation of clinical parameters and disease diagnosis for doctors. In this paper, we propose an automated and concurrent bi-ventricle segmentation method. First, we obtain region of interest (ROI) extraction for original cardiac image from large size to small size. Then we employ the conditional convolution generative adversarial network (CCGAN), which takes the extracted ROI as input, to generate mask of segmentation. The discriminator competes with the generator on the condition of the mask source to optimize the segmentation result. Finally, we get the cardiac segmentation similar to the gold standard. The proposed method is trained and tested on the data from automated cardiac diagnosis challenge (ACDC 2017). Experiment result shows our method produce better evaluation metrics compared with other advanced researches and demonstrate the effectiveness.	187.9231540762784
1447.	Spectral unmixing is an important task for hyperspectral remote sensing image processing, which infers the pure spectral signatures (endmembers) in hyperspectral image (HSI) and their corresponding fractions (abundances). Recently, deep learning has become a powerful tool for HSI analysis, such as HSI classification and HSI super-resolution. In this paper, we propose a new unmixing algorithm that uses the convolutional neural network (CNN) for hyperspectral data incorporating spectral library, which can be applied for a series of HSIs after training. The proposed deep spectral convolution network extracts features and then executes the estimating process from these extracted spectral characteristics to acquire the fractional abundances on a fixed spectral library. Meanwhile, considering the incorporation of spectral library, a deeper convolutional network has been adopted to achieve better results. Moreover, we construct a new loss function, which includes pixel reconstruction error, abundance sparsity, and abundance cross-entropy to train the aforementioned network in an end-to-end manner. Experiments on both simulated and real HSIs indicate the advantage of the proposed method, which can obviously enhance the abundance estimation accuracy. (C) 2020 Elsevier B.V. All rights reserved.	187.92313601512234
1448.	We propose a new framework for image-based three-dimensional (3D) model retrieval. We first model the query image as a Euclidean point. Then we model all projected views of a 3D model as a symmetric positive definite (SPD) matrix, which is a point on a Riemannian manifold. Thus, the image-based 3D model retrieval is reduced to a problem of Euclid-to-Riemann metric learning. To solve this heterogeneous matching problem, we map the Euclidean space and SPD Riemannian manifold to the same high-dimensional Hilbert space, thus shrinking the great gap between them. Finally, we design an optimization algorithm to learn a metric in this Hilbert space using a kernel trick. Any new image descriptors, such as the features from deep learning, can be easily embedded in our framework. Experimental results show the advantages of our approach over the state-of-the-art methods for image-based 3D model retrieval.	187.92309836618014
1449.	Protein fold recognition is critical for studying the structures and functions of proteins. The existing protein fold recognition approaches failed to efficiently calculate the pairwise sequence similarity scores of the proteins in the same fold sharing low sequence similarities. Furthermore, the existing feature vectorization strategies are not able to measure the global relationships among proteins from different protein folds. In this article, we proposed a new computational predictor called DeepSVM-fold for protein fold recognition by introducing a new feature vector based on the pairwise sequence similarity scores calculated from the fold-specific features extracted by deep learning networks. The feature vectors are then fed into a support vector machine to construct the predictor. Experimental results on the benchmark dataset (LE) show that DeepSVM-fold obviously outperforms all the other competing methods.	187.92300843061315
1450.	We propose the Sparse Feature Convolutional Neural Network (SFCNN) to reduce the volume of convolutional neural networks (CNNs). Despite the superior classification performance of CNNs, their enormous network volume requires high computational cost and long processing time, making real-time applications such as online-training difficult. We propose an advanced network that reduces the volume of conventional CNNs by producing a region-based sparse feature map. To produce the sparse feature map, two complementary region-based value extraction methods, cluster max extraction and local value extraction, are proposed. Cluster max is selected as the main function based on experimental results. To evaluate SFCNN, we conduct an experiment with two conventional CNNs. The network trains 59 times faster and tests 81 times faster than the VGG network, with a 1.2% loss of accuracy in multi-class classification using the Caltech101 dataset. In vehicle classification using the GTI Vehicle Image Database, the network trains 88 times faster and tests 94 times faster than the conventional CNNs, with a 0.1% loss of accuracy.	187.92299025841396
1451.	Optical Coherence Tomography (OCT) of the human eye are used by optometrists to analyze and detect various age-related eye abnormalities like Choroidal Neovascularization, Drusen (CNV), Diabetic Macular Odeama (DME), Drusen. Detecting these diseases are quite challenging and requires hours of analysis by experts, as their symptoms are somewhat similar. We have used transfer learning with VGG16 and Inception V3 models which are state of the art CNN models. Our solution enables us to predict the disease by analyzing the image through a convolutional neural network (CNN) trained using transfer learning. Proposed approach achieves a commendable accuracy of 94% on the testing data and 99.94% on training dataset with just 4000 units of data, whereas to the best of our knowledge other researchers have achieved similar accuracies using a substantially larger (almost 10 times) dataset.	187.92295887631377
1452.	Attention deficit and hyperactivity disorder (ADHD) is a neurodevelopmental disorder, which is characterized by inattention, hyperactivity and impulsive behaviors. In particular, children have difficulty keeping still exhibiting increased fine and gross motor activity. This paper focuses on analyzing the data obtained from two tri-axial accelerometers (one on the wrist of the dominant arm and the other on the ankle of the dominant leg) worn during school hours by a group of 22 children (11 children with ADHD and 11 paired controls). Five of the 11 ADHD diagnosed children were not on medication during the study. The children were not explicitly instructed to perform any particular activity but followed a normal session at school alternating classes of little or moderate physical activity with intermediate breaks of more prominent physical activity. The tri-axial acceleration signals were converted into 2D acceleration images and a Convolutional Neural Network (CNN) was trained to recognize the differences between non-medicated ADHD children and their paired controls. The results show that there were statistically significant differences in the way the two groups moved for the wrist accelerometer (t-test p-value <0.05). For the ankle accelerometer statistical significance was only achieved between data from the non-medicated children in the experimental group and the control group. Using a Convolutional Neural Network (CNN) to automatically extract embedded acceleration patterns and provide an objective measure to help in the diagnosis of ADHD, an accuracy of 0.875 for the wrist sensor and an accuracy of 0.9375 for the ankle sensor was achieved.	187.92292119909115
1453.	This letter presents a new deep learning-based framework for robust nonlinear estimation and control using the concept of a Neural Contraction Metric (NCM). The NCM uses a deep long short-term memory recurrent neural network for a global approximation of an optimal contraction metric, the existence of which is a necessary and sufficient condition for exponential stability of nonlinear systems. The optimality stems from the fact that the contraction metrics sampled offline are the solutions of a convex optimization problem to minimize an upper bound of the steady-state Euclidean distance between perturbed and unperturbed system trajectories. We demonstrate how to exploit NCMs to design an online optimal estimator and controller for nonlinear systems with bounded disturbances utilizing their duality. The performance of our framework is illustrated through Lorenz oscillator state estimation and spacecraft optimal motion planning problems.	187.92290467173942
1454.	To date, deep learning technologies have provided powerful decision support systems to radiologists in human medicine. The aims of this retrospective, exploratory study were to develop and describe an artificial intelligence able to screen thoracic radiographs for primary thoracic lesions in feline and canine patients. Three deep learning networks using three different pretraining strategies to predict 15 types of primary thoracic lesions were created (including tracheal collapse, left atrial enlargement, alveolar pattern, pneumothorax, and pulmonary mass). Upon completion of pretraining, the algorithms were provided with over 22 000 thoracic veterinary radiographs for specific training. All radiographs had a report created by a board-certified veterinary radiologist used as the gold standard. The performances of all three networks were compared to one another. An additional 120 radiographs were then evaluated by three types of observers: the best performing network, veterinarians, and veterinarians aided by the network. The error rates for each of the observers was calculated as an overall and for the 15 labels and were compared using a McNemar's test. The overall error rate of the network was significantly better than the overall error rate of the veterinarians or the veterinarians aided by the network (10.7% vs 16.8% vs17.2%,P = .001). The network's error rate was significantly better to detect cardiac enlargement and for bronchial pattern. The current network only provides help in detecting various lesion types and does not provide a diagnosis. Based on its overall very good performance, this could be used as an aid to general practitioners while waiting for the radiologist's report.	187.9228445111014
1455.	In heterogeneous networks, different modalities are coexisting. For example, video sources with certain lengths usually have abundant time-varying audiovisual data. From the users' perspective, different video segments will trigger different kinds of emotions. In order to better interact with users in heterogeneous networks and improve their user experiences, affective video content analysis to predict users' emotions is essential. Academically, users' emotions can be evaluated by arousal and valence values, and fear degree, which provides an approach to quantize the prediction accuracy of the reaction of the audience and users towards videos. In this paper, we propose the multimodal data fusion method for integrating the visual and audio data in order to perform the affective video content analysis. Specifically, to align the visual and audio data, the temporal attention filters are proposed to obtain the time-span features of the entire video segments. Then, by using the two-branch network structure, matched visual and audio features are integrated in the common space. At last, the fused audiovisual feature is employed for the regression and classification subtasks in order to measure the emotional responses of users. Simulation results show that the proposed method can accurately predict the subjective feelings of users towards the video contents, which provides a way to predict users' preferences and recommend videos according to their own demand.	187.92277698771895
1456.	Background: The accurate identification of the exon/intron boundaries is critical for the correct annotation of genes with multiple exons. Donor and acceptor splice sites (SS) demarcate these boundaries. Therefore, deriving accurate computational models to predict the SS are useful for functional annotation of genes and genomes, and for finding alternative SS associated with different diseases. Although various models have been proposed for the in silico prediction of SS, improving their accuracy is required for reliable annotation. Moreover, models are often derived and tested using the same genome, providing no evidence of broad application, i.e. to other poorly studied genomes. Results: With this in mind, we developed the Splice2Deep models for SS detection. Each model is an ensemble of deep convolutional neural networks. We evaluated the performance of the models based on the ability to detect SS in Homo sapiens, Oryza sativa japonica, Arabidopsis thaliana, Drosophila melanogaster, and Caenorhabditis elegans. Results demonstrate that the models efficiently detect SS in other organisms not considered during the training of the models. Compared to the state-of-the-art tools, Splice2Deep models achieved significantly reduced average error rates of 41.97% and 28.51% for acceptor and donor SS, respectively. Moreover, the Splice2Deep cross-organism validation demonstrates that models correctly identify conserved genomic elements enabling annotation of SS in new genomes by choosing the taxonomically closest model. Conclusions: The results of our study demonstrated that Splice2Deep both achieved a considerably reduced error rate compared to other state-of-the-art models and the ability to accurately recognize SS in other organisms for which the model was not trained, enabling annotation of poorly studied or newly sequenced genomes. Splice2Deep models are implemented in Python using Keras API; the models and the data are available at https://github.com/SomayahAlbaradei/Splice_Deep.git.	187.92272438317144
1457.	An approach for recovering the phase information from the detected intensity was proposed in this work. Unlike the conventional approach based on the Gerchberg-Saxton algorithm, the proposed approach recovered the phase information via an alternative technique in the realm of deep learning, the residual neural network. The database we utilized to train the network was collected by a Michelson-based interferometer, where a spatial light modulator was implemented to provide the phase modulation as the phase object. As the result, the mean absolute error of each pixel was 0.0614 pi.	187.9227020985284
1458.	PURPOSE: To develop and evaluate a deep adversarial learning-based image reconstruction approach for rapid and efficient MR parameter mapping. METHODS: The proposed method provides an image reconstruction framework by combining the end-to-end convolutional neural network (CNN) mapping, adversarial learning, and MR physical models. The CNN performs direct image-to-parameter mapping by transforming a series of undersampled images directly into MR parameter maps. Adversarial learning is used to improve image sharpness and enable better texture restoration during the image-to-parameter conversion. An additional pathway concerning the MR signal model is added between the estimated parameter maps and undersampled k-space data to ensure the data consistency during network training. The proposed framework was evaluated on T2 mapping of the brain and the knee at an acceleration rate R=8 and was compared with other state-of-the-art reconstruction methods. Global and regional quantitative assessments were performed to demonstrate the reconstruction performance of the proposed method. RESULTS: The proposed adversarial learning approach achieved accurate T2 mapping up to R=8 in brain and knee joint image datasets. Compared to conventional reconstruction approaches that exploit image sparsity and low-rankness, the proposed method yielded lower errors and higher similarity to the reference and better image sharpness in the T2 estimation. The quantitative metrics were normalized root mean square error of 3.6% for brain and 7.3% for knee, structural similarity index of 85.1% for brain and 83.2% for knee, and tenengrad measures of 9.2% for brain and 10.1% for the knee. The adversarial approach also achieved better performance for maintaining greater image texture and sharpness in comparison to the CNN approach without adversarial learning. CONCLUSION: The proposed framework by incorporating the efficient end-to-end CNN mapping, adversarial learning, and physical model enforced data consistency is a promising approach for rapid and efficient reconstruction of quantitative MR parameters.	187.92258168456038
1459.	The coronavirus COVID-19 pandemic is causing a global health crisis. One of the effective protection methods is wearing a face mask in public areas according to the World Health Organization (WHO). In this paper, a hybrid model using deep and classical machine learning for face mask detection will be presented. The proposed model consists of two components. The first component is designed for feature extraction using Resnet50. While the second component is designed for the classification process of face masks using decision trees, Support Vector Machine (SVM), and ensemble algorithm. Three face masked datasets have been selected for investigation. The Three datasets are the Real-World Masked Face Dataset (RMFD), the Simulated Masked Face Dataset (SMFD), and the Labeled Faces in the Wild (LFW). The SVM classifier achieved 99.64% testing accuracy in RMFD. In SMFD, it achieved 99.49%, while in LFW, it achieved 100% testing accuracy.	187.9225138089057
1460.	Globally, groundwater heavy metal (HM) pollution is a serious concern, threatening drinking water safety as well as human and animal health. Therefore, evaluation of groundwater HM pollution is essential to prevent accompanying hazardous ecological impacts. In this aspect, the effectiveness of various groundwater HM pollution evaluation approaches should be examined for their level of trustworthiness. In this study, 226 groundwater samples from Arang of Chhattisgarh state, India, were collected and analyzed. Measured concentration for various HMs were further used to calculate six groundwater pollution indices, such as the HM pollution index (HPI), HM evaluation index (HEI), contamination index (CI), entropy-weight based HM contamination index (EHCI), Heavy metal index (HMI), and principal component analysis-based metal index (PMI). Groundwater in the study area was mainly contaminated by elevated Cd, Fe, and Pb concentrations due to natural and anthropogenic pollution. Moreover, this study explored the performance of deep learning (DL)-based predictive models via comparative study. Two hidden layers with 26 and 19 neurons in the first and second hidden layers, respectively, were optimised along with rectified linear unit activation function. A mini-batch gradient descent was also applied to ensure smooth convergence of the training dataset into the model. Results demonstrated that the DL-PMI scored lowest errors, 0.022 for mean square error (MSE), 0.140 for mean absolute error (MAE), and 0.148 for root mean square error (RMSE), in the model validation than the other DL-based groundwater HM pollution model. Prediction performances of all pollution indices were also verified using artificial neural network (ANN)-based models, which also highlighted the lowest validation error for ANN-PMI (MSE=3.93, MAE=1.38, and RMSE=1.98). Furthermore, the prediction accuracies of PMI using both ANN and DL models scored the highest R2 value of 0.95 and 0.99, respectively. Therefore it is suggested that groundwater HM pollution using PMI as the best indexing approach in the present study area. Moreover, compared to benchmark, ANN, the DL performed better; hence, it could be concluded that the proposed DL model may be suitable approach in the field of computational chemistry by handling overfitting problems.	187.92239311406883
1461.	Convolutional neural networks have been proposed as an approach for classifying data corresponding to labeled and unlabeled datasets. The fast-growing data empowers deep learning algorithms to achieve higher accuracy. Numerous trained models have been proposed, which involve complex algorithms and increasing network depth. The main challenges of implementing deep convolutional neural networks are high energy consumption, high on-chip and off-chip bandwidth requirements, and large memory footprint. Different types of on-chip communication networks and traffic distribution methods have been proposed to reduce memory access latency and energy consumption of data movement. This paper proposes a new traffic distribution mechanism on a mesh topology using distributer nodes by considering memory access mechanism in the AlexNet, VggNet, and GoogleNet trained models. We also propose a flow mapping method (FMM) based on dataflow stationary which reduces energy consumption by 8%.	187.92238998383925
1462.	Based on field experiments at Nanyue Mountain Meteorological Station and Huaihua National Reference Climatological Station in Hunan Province, the camera images of icing weather phenomena, such as glaze, rime and mixing rime, are collected minutely from January to March in 2018. The convolution neural network technology is employed for modelling and training using the camera images of the icing field experiment at Nanyue station, and the results of identification are examined by the camera images. Furthermore, based on deep learning, the environmental layout requirements of ice accretion image identification are discussed. The main conclusions are as follows. When identifying icing weather phenomena at Nanyue station, the probability of correction (PC) is 99.21%, the false acceptance rate (FAR) is 0.28%, and the probability of omission (PO) is 0.51%. The probability of icing identification increases significantly in the initial stage of ice accretion, while that in the sustained stage is stably around 99.0%, and in the dissipation stage it gradually decreases. False acceptance and omission occur occasionally during the initiation and dissipation stages, the transition period between daytime and night, and the nighttime when the pictures are not clear enough. The test results show that the artificial intelligence identification model established in this paper can extract the key features of icing in different stages of an icing lifetime, and the identification result is good. In addition, the false acceptance and omission can be further eliminated by using the meteorological conditions criteria and judging the consistency of identification. This method can provide important technical support for the automatic observation of icing weather phenomena.	187.9223718651546
1463.	Inverse synthetic aperture radar (ISAR) object detection is one of the most important and challenging problems in computer vision tasks. To provide a convenient and high-quality ISAR object detection method, a fast and efficient weakly semi-supervised method, called deep ISAR object detection (DIOD), is proposed, based on advanced region proposal networks (ARPNs) and weakly semi-supervised deep joint sparse learning: 1) to generate high-level region proposals and localize potential ISAR objects robustly and accurately in minimal time, ARPN is proposed based on a multiscale fully convolutional region proposal network and a region proposal classification and ranking strategy. ARPN shares common convolutional layers with the Inception-ResNet-based system and offers almost cost-free proposal computation with excellent performance; 2) to solve the difficult problem of the lack of sufficient annotated training data, especially in the ISAR field, a convenient and efficient weakly semi-supervised training method is proposed with the weakly annotated and unannotated ISAR images. Particularly, a pairwise-ranking loss handles the weakly annotated images, while a triplet-ranking loss is employed to harness the unannotated images; and 3) to further improve the accuracy and speed of the whole system, a novel sharable-individual mechanism and a relational-regularized joint sparse learning strategy are introduced to achieve more discriminative and comprehensive representations while learning the shared-and individual-features and their correlations. Extensive experiments are performed on two real-world ISAR datasets, showing that DIOD outperforms existing state-of-the-art methods and achieves higher accuracy with shorter execution time.	187.92230871413284
1464.	The popular understanding and practice of discipleship has often assumed a particular shape of the life of faith, one which is more ?heroic? and active. This paper explores how the understanding and experience of learning and growing as Christians in two Methodist congregations challenges and nuances this understanding of discipleship. Focusing on the themes of non-heroic faith and participative faith which arose in the data, it compares the understanding of the Christian life within these congregations with the discipleship material in the book Holy Habits, by Andrew Roberts. Through engaging with Vygotskii?s Zone of Proximal Development an alternative pedagogy from that presented in the discipleship material is suggested of the dual practice of deep conversation and risk-taking. Far from retreating from a participative faith, the paper shows how it can provide a theological basis for such faith to grow and mature.	187.92218771240914
1465.	A forecast interval is effective for handling the forecast uncertainty in solar photovoltaic systems. In estimating the forecast interval, most available approaches apply an identical policy to all the point forecasts. This results in an inefficient interval (e.g. an unnecessarily wide interval for an accurate forecast). They also adopt a complex model and even require modification of the available deterministic forecasting model, which may adversely affect their application. To overcome these limitations, the authors introduce a forecast uncertainty-aware forecast interval. They calculate a forecast accuracy-related uncertainty metric from an ensemble method based on the dropout technique. The dropout technique is widely used in deep learning models. This implies that the proposed approach can be applied to available deep learning forecasting models without modifying them. Using the uncertainty metric and relevant data of previous forecast results, they estimate the uncertainty-aware forecast interval. Through experiments using real-world data, they first demonstrate the close relation of their uncertainty metric to the forecasting accuracy. Then, they demonstrate that the uncertainty-aware forecast interval reduces the mean interval length by up to 25.7% and decreases the prediction interval coverage probability by 4.07%, compared to available approaches. This illustrates that their approach results in an effective interval.	187.92212853482647
1466.	Two experimental studies were carried out to investigate whether adding multimedia features in a concept mapping task would improve the quality of the map built by students and promote more effective learning with expository hypertexts. Ninety-Nine undergraduates built a concept map to learn about a topic (water cycle or nitrogen cycle) either with a text-based or with a multimedia presentation of concepts (i.e. concepts were presented as textual labels illustrated with relevant pictures). Multimedia presentation of concepts was expected to foster the construction of a more elaborate concept map, to increase information processing and to improve learning outcome. Results of the two experiments were consistent by showing that multimedia presentation led learners to spend more time building the concept map and to build more coherent maps (i.e. text-based inter-connected concepts). In addition, experiment 2 showed that the multimedia presentation of concepts in concept mapping could also foster deeper exploration of the hypertext. However, learning outcomes were not affected by the learning conditions.	187.9221197668728
1467.	In communities historically shaped by processes of de jure and de facto segregation; police repression; and lack of access to equitable housing, jobs, and labor-rights, young people find very little of this content reflected in their school-based learning. These societal "civics lessons" indicate the need to move beyond the aim of closing the "civic opportunity gap" and toward a more relevant, critical-even transgressive-approach to civic learning in school. In this article, the authors look across their individual studies to consider how young people of color experienced and interpreted current forms of racialized injustice, how their school-based civic instruction intersected with these experiences, and where they turned to explore these dilemmas. Findings reveal that youth engaged with various out-of-school resources, including family members and new media platforms, to investigate and interpret racialized injustice. Through these findings we developed a grounded theory of school-based civics education that we call critically relevant civics, an approach that embraces the out-of-school resources that young people tap into to navigate the civic world and grapple with the precarious nature of their citizenship status.	187.922104356883
1468.	Interior sound quality plays a vital role in vehicle quality assessment because it forms users' general impressions of vehicles and influences consumers' purchase intentions. Thus, evaluating vehicle interior sound quality is important. Many researchers have developed intelligent prediction models to precisely evaluate vehicle interior sound quality. Deep convolutional neural networks (CNNs) can automatically learn features and many studies have applied deep CNNs to address noise and vibration issues. However, those studies suffer from two problems: i) the time and frequency characteristics of noise that influence interior sound quality have not been considered simultaneously; ii) the noise features that deep CNNs have learned need to be explored. Therefore, in this paper, to overcome the first problem, we develop a regularized deep CNN model that takes a noise time-frequency image as input. In addition, we introduce a neuron visualization algorithm for deep CNNs to solve the second problem. To verify the proposed methods, we establish an interior noise dataset through vehicular road tests and subjective evaluations. The sound quality of this recorded interior noise is evaluated through the developed deep CNN model, which reveals that deep CNNs that use a noise time-frequency image as input perform better than do those using time vector and frequency vector data as input. By analyzing feature maps extracted from the convolutional layers and the fully connected layer of the CNNs, we found that the deep CNN feature learning process can be regarded as color filter and Gabor filter processes applied to the noise time- frequency image. These results provide a new approach for evaluating vehicle interior sound quality and help in understanding which noise features deep CNNs learn. (c) 2020 Elsevier Ltd. All rights reserved.	187.9216962560615
1469.	AIM: To enable a world-leading research dataset of routinely collected clinical images linked to other routinely collected data from the whole Scottish national population. This includes more than 30 million different radiological examinations from a population of 5.4 million and >2 PB of data collected since 2010. METHODS: Scotland has a central archive of radiological data used to directly provide clinical care to patients. We have developed an architecture and platform to securely extract a copy of those data, link it to other clinical or social datasets, remove personal data to protect privacy, and make the resulting data available to researchers in a controlled Safe Haven environment. RESULTS: An extensive software platform has been developed to host, extract, and link data from cohorts to answer research questions. The platform has been tested on 5 different test cases and is currently being further enhanced to support 3 exemplar research projects. CONCLUSIONS: The data available are from a range of radiological modalities and scanner types and were collected under different environmental conditions. These real-world, heterogenous data are valuable for training algorithms to support clinical decision making, especially for deep learning where large data volumes are required. The resource is now available for international research access. The platform and data can support new health research using artificial intelligence and machine learning technologies, as well as enabling discovery science.	187.92157499343077
1470.	Network embedding which aims to embed a given network into a low-dimensional vector space has been proved effective in various network analysis and mining tasks such as node classification, link prediction and network visualization. The emerging network embedding methods have shifted of emphasis in utilizing mature deep learning models. The neural-network based network embedding has become a mainstream solution because of its high efficiency and capability of preserving the nonlinear characteristics of the network. In this paper, we propose Adversarial Network Embedding using Structural Similarity (ANESS), a novel, versatile, low-complexity GAN-based network embedding model which utilizes the inherent vertex-to-vertex structural similarity attribute of the network. ANESS learns robustness and effective vertex embeddings via a adversarial training procedure. Specifically, our method aims to exploit the strengths of generative adversarial networks in generating high-quality samples and utilize the structural similarity identity of vertexes to learn the latent representations of a network. Meanwhile, ANESS can dynamically update the strategy of generating samples during each training iteration. The extensive experiments have been conducted on the several benchmark network datasets, and empirical results demonstrate that ANESS significantly outperforms other state-of-theart network embedding methods.	187.92146682040993
1471.	Remote sensing (RS) image classification plays an important role in the earth observation technology using RS data, having been widely exploited in both military and civil fields. However, due to the characteristics of RS data such as high dimensionality and relatively small amounts of labeled samples available, performing RS image classification faces great scientific and practical challenges. In recent years, as new deep learning (DL) techniques emerge, approaches to RS image classification with DL have achieved significant breakthroughs, offering novel opportunities for the research and development of RS image classification. In this paper, a brief overview of typical DL models is presented first. This is followed by a systematic review of pixel-wise and scene-wise RS image classification approaches that are based on the use of DL. A comparative analysis regarding the performances of typical DL-based RS methods is also provided. Finally, the challenges and potential directions for further research are discussed. This article is categorized under: Application Areas > Science and Technology Technologies > Classification	187.9211226673341
1472.	We explore a method for reconstructing visual stimuli from brain activity. Using large databases of natural images we trained a deep convolutional generative adversarial network capable of generating gray scale photos, similar to stimuli presented during two functional magnetic resonance imaging experiments. Using a linear model we learned to predict the generative model's latent space from measured brain activity. The objective was to create an image similar to the presented stimulus image through the previously trained generator. Using this approach we were able to reconstruct structural and some semantic features of a proportion of the natural images sets. A behavioural test showed that subjects were capable of identifying a reconstruction of the original stimulus in 67.2% and 66.4% of the cases in a pairwise comparison for the two natural image datasets respectively. Our approach does not require end-to-end training of a large generative model on limited neuroimaging data. Rapid advances in generative modeling promise further improvements in reconstruction performance.	187.92110515214992
1473.	Significance:We introduce and evaluate emerging devices and modalities for wound size imaging and also promising image processing tools for smart wound assessment and monitoring. Recent Advances:Some commercial devices are available for optical wound assessment but with limited possibilities compared to the power of multimodal imaging. With new low-cost devices and machine learning, wound assessment has become more robust and accurate. Wound size imaging not only provides area and volume but also the proportion of each tissue on the wound bed. Near-infrared and thermal spectral bands also enhance the classical visual assessment. Critical Issues:The ability to embed advanced imaging technology in portable devices such as smartphones and tablets with tissue analysis software tools will significantly improve wound care. As wound care and measurement are performed by nurses, the equipment needs to remain user-friendly, enable quick measurements, provide advanced monitoring, and be connected to the patient data management system. Future Directions:Combining several image modalities and machine learning, optical wound assessment will be smart enough to enable real wound monitoring, to provide clinicians with relevant indications to adapt the treatments and to improve healing rates and speed. Sharing the wound care histories of a number of patients on databases and through telemedicine practice could induce a better knowledge of the healing process and thus a better efficiency when the recorded clinical experience has been converted into knowledge through deep learning.	187.92107229821258
1474.	Deep learning has been widely used nowadays to achieve an automated fault diagnosis of rolling bearings. However, most of deep learning based bearing fault diagnosis methods are based on the assumption that the recorded samples are labeled data, though most of field data are recorded without label information. To address this issue, an effective semi-supervised learning method based on the principle of consistency regularization is proposed in this study. The principle of consistency regularization underlines that the model predictions should be less sensitive to the extra perturbation imposed on the input samples. In the proposed method, a data augmentation method is proposed to serve as the extra perturbation, which is imposed on both the labeled and unlabeled samples to enrich the data library. Meanwhile, a label predicting process is formulated to estimate the appreciable label distribution for the unlabeled sample. Correspondingly, two consistency loss terms are introduced to regularize the model predictions for both the labeled and unlabeled samples to be invariant to the extra perturbation, among which a supervised loss term is adopted to enforce the model predictions for augmented labeled samples to be consistent with its true label information and an unsupervised loss is proposed to minimize the discrepancy between label distributions for the original unlabeled samples and its appreciable label distributions. The analysis result on an experimental bearing fault dataset demonstrates that the proposed method can provide an excellent identification performance under limited labeled samples situation. (C) 2020 Elsevier Ltd. All rights reserved.	187.92104516740773
1475.	Text clustering is an important method for effectively organising, summarising, and navigating text information. However, in the absence of labels, the text data to be clustered cannot be used to train the text representation model based on deep learning. To address the problem, an algorithm of text clustering based on deep representation learning is proposed using the transfer learning domain adaptation and the parameters update during cluster iteration. First, source domain data is used to perform the pre-training of the deep learning classification model. This procedure acts as an initialisation of the model parameters. Then, the domain discriminator is added to the model, to domain-divide the input sample. If the discriminator cannot distinguish which domain the data belongs to, the common feature space of two domains is obtained, so the domain adaptation problem is solved. Finally, the text feature vectors obtained by the model are clustered with MCSKM++ algorithm. The algorithm not only resolves the model pre-training problem in unsupervised clustering, but also has a good clustering effect on the transfer problem caused by different numbers of domain labels. Experiments suggest that the clustering accuracy of the algorithm is superior to other similar algorithms.	187.92103897205948
1476.	Modern power systems depend on cyber-physical systems to link physical devices and control technologies. A major concern in the implementation of smart power networks is to minimize the risk of data privacy violation (e.g., by adversaries using data poisoning and inference attacks). In this article, we propose a privacy-preserving framework to achieve both privacy and security in smart power networks. The framework includes two main modules: a two-level privacy module and an anomaly detection module. In the two-level privacy module, an enhanced-proof-of-work-technique-based blockchain is designed to verify data integrity and mitigate data poisoning attacks, and a variational autoencoder is simultaneously applied for transforming data into an encoded format for preventing inference attacks. In the anomaly detection module, a long short-term memory deep learning technique is used for training and validating the outputs of the two-level privacy module using two public datasets. The results highlight that the proposed framework can efficiently protect data of smart power networks and discover abnormal behaviors, in comparison to several state-of-the-art techniques.	187.92080077137607
1477.	The use of postmortem computed tomography in forensic medicine, in addition to conventional autopsy, is now a standard procedure in several countries. However, the large number of cases, the large amount of data, and the lack of postmortem radiology experts have pushed researchers to develop solutions that are able to automate diagnosis by applying deep learning techniques to postmortem computed tomography images. While deep learning techniques require a good understanding of image analysis and mathematical optimization, the goal of this review was to provide to the community of postmortem radiology experts the key concepts needed to assess the potential of such techniques and how they could impact their work.	187.920701785819
1478.	Purpose Quantitative T2* mapping is promising due to its clinical applicability and has been employed for the assessment of cartilage repair procedures of the knee. Generally, the under-sampling k-space technique was applied to accelerate T2* mapping which is considerable time-consuming with traditional sequences. However, the under-sampling k-space technique may be impractical for acquiring reliable sampling of the T2* decay. In order to improve the corresponding accuracy of T2* mapping with under-sampled k-space technique, a new method has been proposed of deep learning (DL) based under-sampling MR images reconstruction. Methods In this work, we employed a residual network with 3 layers to explore latent functions between fully-sampled and under-sampled MR images and then applied these functions to regularize the MR images reconstruction from under-sampling k-space data. The proposed method includes three steps. Firstly, the regridding reconstruction and ESPIRiT reconstruction algorithm was used to reconstruct MR images from fully sampling and under-sampling k-space data, respectively. Then, 12 MR images at different echo time (TE=0.2/0.5/0.8/2/3.3/5.5/8/11/15/20/25/30ms) derived from under-sampling k-space data were fed into the proposed network. Ultimately, the optimized MR images were utilized to calculate T2* values. Results The T2* values derived from the proposed method were more accurate than that from the regridding reconstruction or ESPIRiT reconstruction in four tissues. For instance, when the acceleration ratio (ACC) was set at 4, the T2* values (mean +/- standard deviation) of posterior cruciate ligament (PCL) were 7.97 +/- 0.40ms in regridding constructed reference image, the T2* values derived from the regridding reconstruction of 7.34 +/- 1.04ms fluctuated wildly, while the T2* values from the proposed method were restored to 7.84 +/- 1.39ms which were closer to the reference T2* values. Additionally, the T2* values of PCL were 6.99 +/- 9.47ms in ESPIRiT reconstructed reference image, the T2* values derived from the ESPIRiT reconstruction of 5.32 +/- 8.44ms fluctuated wildly, while the T2* values from the proposed method were restored to 6.64 +/- 11.73ms.The similar phenomenon can be seen in other three ROIs with ACC = 4 or 2. Conclusion T2* mapping optimized by the proposed DL-based method resembles the reference qualitatively and quantitatively. In conclusion, the proposed method has great promise on improving the accuracy of T2* mapping based on under-sampling k-space technique for fast magnetic resonance imaging.	187.92068714554227
1479.	Brain tumor image segmentation is process of locating the interesting area in terms of objects, like tumor and extracting it for the further process of the image and getting the boundaries of the image for analysis. The bio-medical brain tumor image segmentation is a great challenging field for the today world active researchers with the standardized image datasets and various metrics used for evaluating and comparing the performance of the new algorithm with existing segmentation algorithms. In recent development, these problems are addressed using various image manipulation tools and rapid growth of computer hardware enhancement. Image segmentation was done in three ways: (1) Manual-based (2) Semi-automated-based (3) Fully automated-based. But still be a short of research in the field of brain tumor segmentation and accurate identification of tumor cells. To overcome all the above-mentioned challenges and complexity of the brain tumor segmentation, it need to understand the pre-processing of the image like, registering the image, correction of bias in image, and non-brain tissue removal. In this paper, we propose a new methodology for segmenting the brain tumor from the affected brain image in a significantly efficient way by using deep learning method.	187.92058548041553
1480.	Accurately detecting the presence and evolving boundaries of cracks on rock surfaces is critical for under-standing the behavior of crack evolutions and facture mechanism of rock and rock-like material, which could cause engineering disasters if proper operation were not taken to deal with the evolving cracks. In this paper, we investigate the problem of vision-based automatic detection of cracks on rock surface at pixel-level, which is a preliminary step of crack evolution analysis. We build a Split Hopkinson Pressure Bar (SHPB) system to simulate the crack evolution process and capture the process as video data using a high frame camera, where a dataset of evolving cracks is created consisting of rock crack images that are manually labeled in pixel-level granularity. We propose a two-stage method to detect cracks in video data: the first stage employs Convolution Neural Network (CNN) based deep learning method to obtain preliminary results for each image frame while the second stage relies on novel variant Bayesian Inference to further refine the detection results. Specifically, in the first stage, a variant of U-Net model (denoted as CrackUNet) is developed to obtain intermediate classifications (crack or non-crack) that can better combine with other processing techniques for further improvement. Then in the second stage, a novel Spatial-Temporal Bayesian Inference (STBI) method is developed to further improve detection accuracy by taking advantages of the spatial and temporal correlations of the evolving cracks in video data. Experimental results show that the proposed method outperforms all the baselines.	187.92053062509981
1481.	Background Cystoscopy plays an important role in the diagnosis of bladder tumours. As a typical representative of the deep learning algorithm, the convolutional neural network has shown great advantages in the field of image recognition and segmentation. Methods One thousand two photographs of normal bladder tissue and 734 photos of bladder tumours under cystoscopy were taken from 175 patients. Caffe deep learning framework and EasyDL platform were used to structure and train the model. The trained model from the EasyDL platform was deployed on a mobile phone. Results The accuracy rate of the neural network to recognise the bladder cancer based on Caffe framework was 82.9%, and the data on the EasyDL platform were 96.9%. The model from EasyDL platform could discern bladder cancer accurately on the phone and website. Conclusion The deep learning network could recognise the bladder cancer accurately. Deploying that model on the mobile phone was useful for clinical use.	187.92052882634863
1482.	Performing an auscultation of respiratory system normally requires the presence of an experienced doctor, but the most recent advances in artificial intelligence (AI) open up a possibility for the laymen to perform this procedure by himself in home environment. However, to make it feasible, the system needs to include two main components: an algorithm for fast and accurate detection of breath phenomena in stethoscope recordings and an AI agent that interactively guides the end user through the auscultation process. In this work we present a system that solves both of these problems using state-of-the-art machine learning algorithms. Our breath phenomena detection model was trained on 5000 stethoscope recordings of both sick (hospitalized) and healthy children. All recordings were labeled by a pulmonologist and acousticians. The agent is able to accurately assess patient's lung health status by auscultating only 3 out of 12 locations on average. The decision about each next auscultation location or end of examination is made dynamically, after each recording, based on breath phenomena detected so far. This allows the agent to make best prediction even if the auscultation is time-constrained.	187.9203458525569
1483.	BackgroundThe small number of samples and the curse of dimensionality hamper the better application of deep learning techniques for disease classification. Additionally, the performance of clustering-based feature selection algorithms is still far from being satisfactory due to their limitation in using unsupervised learning methods. To enhance interpretability and overcome this problem, we developed a novel feature selection algorithm. In the meantime, complex genomic data brought great challenges for the identification of biomarkers and therapeutic targets. The current some feature selection methods have the problem of low sensitivity and specificity in this field.ResultsIn this article, we designed a multi-scale clustering-based feature selection algorithm named MCBFS which simultaneously performs feature selection and model learning for genomic data analysis. The experimental results demonstrated that MCBFS is robust and effective by comparing it with seven benchmark and six state-of-the-art supervised methods on eight data sets. The visualization results and the statistical test showed that MCBFS can capture the informative genes and improve the interpretability and visualization of tumor gene expression and single-cell sequencing data. Additionally, we developed a general framework named McbfsNW using gene expression data and protein interaction data to identify robust biomarkers and therapeutic targets for diagnosis and therapy of diseases. The framework incorporates the MCBFS algorithm, network recognition ensemble algorithm and feature selection wrapper. McbfsNW has been applied to the lung adenocarcinoma (LUAD) data sets. The preliminary results demonstrated that higher prediction results can be attained by identified biomarkers on the independent LUAD data set, and we also structured a drug-target network which may be good for LUAD therapy.ConclusionsThe proposed novel feature selection method is robust and effective for gene selection, classification, and visualization. The framework McbfsNW is practical and helpful for the identification of biomarkers and targets on genomic data. It is believed that the same methods and principles are extensible and applicable to other different kinds of data sets.	187.9203304767995
1484.	This paper presents a robust deep in-memory machine learning classifier with a stochastic gradient descent (SGD)-based on-chip trainer using a standard 16-kB 6T SRAM array. The deep in-memory architecture (DIMA) enhances both energy efficiency and throughput over conventional digital architectures by reading multiple bits per bit line (BL) per read cycle and by employing mixed-signal processing in the periphery of the bit-cell array. Though these techniques improve the energy efficiency and latency, DIMA's analog nature makes it sensitive to process, voltage, and temperature (PVT) variations, especially under reduced BL swings. On-chip training enables DIMA to adapt to chip-specific variations in PVT as well as data statistics, thereby further enhancing its energy efficiency. The 65-nm CMOS prototype IC demonstrates this improvement by realizing an on-chip trainable support vector machine. By learning chip-specific weights, on-chip training enables robust operation under reduced BL swing leading to a 2.4 times reduction in energy over an off-chip trained DIMA. The prototype IC in 65-nm CMOS consumes 42 pJ/decision at 32 M decisions/s, corresponding to 3.12 TOPS/W (1 OP = one 8-b x 8-b MAC) during inference, thereby achieving a reduction of 21 times in energy and 100 times in energy-delay product as compared with a conventional digital architecture. The energy overhead of training is <26% per decision for SGD batch sizes of 128 and higher.	187.9198435935831
1485.	In this paper, a deep learning approach for Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) is proposed. The novelty of the proposed framework stems from the fact that it is based on a transfer learning scheme, where a pre-trained Convolutional Neural Network (CNN) is employed to extract learned features in combination with a classical Support Vector Machine (SVM) for classification. The efficiency of the presented approach is validated on the MSTAR dataset, where ten target classes are used. A classification accuracy of 99.27% is achieved	187.9197959471151
1486.	Brain-related disorders such as epilepsy can be diagnosed by analyzing electroencephalograms (EEG). However, manual analysis of EEG data requires highly trained clinicians, and is a procedure that is known to have relatively low inter-rater agreement (IRA). Moreover, the volume of the data and the rate at which new data becomes available make manual interpretation a time-consuming, resource-hungry, and expensive process. In contrast, automated analysis of EEG data offers the potential to improve the quality of patient care by shortening the time to diagnosis and reducing manual error. In this paper, we focus on one of the first steps in interpreting an EEG session - identifying whether the brain activity is abnormal or normal. To address this specific task, we propose a novel recurrent neural network (RNN) architecture termed ChronoNet which is inspired by recent developments from the field of image classification and designed to work efficiently with EEG data. ChronoNet is formed by stacking multiple 1D convolution layers followed by deep gated recurrent unit (GRU) layers where each 1D convolution layer uses multiple filters of exponentially varying lengths and the stacked GRU layers are densely connected in a feed-forward manner. We used the recently released TUH Abnormal EEG Corpus dataset for evaluating the performance of ChronoNet. Unlike previous studies using this dataset, ChronoNet directly takes time-series EEG as input and learns meaningful representations of brain activity patterns. ChronoNet outperforms previously reported results on this dataset thereby setting a new benchmark.	187.91973930433707
1487.	Grasping the future fluctuation characteristics and trend of oil prices form the basis for a deep understanding of the system mechanisms and development trends of related research fields. However, due to the complex features of the oil price, accurate prediction is very difficult to get. In order to improve the accuracy of international crude oil price predictions, a novel hybrid prediction model is proposed, that is improved on existing decomposition ensemble learning techniques by developing the Dynamic Time Warping Fuzzy Clustering method (FCM-DTW) as a new reconstruction rule. The hybrid model consists of four main steps. First, the West Texas Intermediate (WTI) crude oil spot price is decomposed into a series of relatively stable, different frequency eigenmode components (IMFs) using the adaptive noise complete integration empirical mode decomposition algorithm (CEEMDAN). FCM-DTW is then employed to reconstitute the IMFs into three sub-sequences. Subsequently, an Autoregressive Integrated Moving Average (ARIMA) model is selected according to the data characteristics of the reconstructed sequence and applied to predict the reconstructed components. Finally, a simple additive method is used to integrate the predicted results of each reconstructed component to generate the crude oil price prediction value. The results show that the prediction accuracy of the proposed hybrid model, based on dynamic time warping fuzzy clustering algorithm, is significantly better than the benchmarks considered in this paper. (C) 2019 Elsevier Ltd. All rights reserved.	187.9197242847991
1488.	Single-cell RNA-seq has inspired new discoveries and innovation in the field of developmental and cell biology for the past few years and is useful for studying cellular responses at individual cell resolution. But, due to the paucity of starting RNA, the data acquired have dropouts. To address this, we propose a deep matrix factorization-based method, deepMc, to impute missing values in gene expression data. For the deep architecture of our approach, we draw our motivation from great success of deep learning in solving various machine learning problems. In this study, we support our method with positive results on several evaluation metrics such as clustering of cell populations, differential expression analysis, and cell type separability.	187.9196607065112
1489.	Visual semantic information comprises two important parts: the meaning of each visual semantic unit and the coherent visual semantic relation conveyed by these visual semantic units. Essentially, the former one is a visual perception task while the latter one corresponds to visual context reasoning. Remarkable advances in visual perception have been achieved due to the success of deep learning. In contrast, visual semantic information pursuit, a visual scene semantic interpretation task combining visual perception and visual context reasoning, is still in its early stage. It is the core task of many different computer vision applications, such as object detection, visual semantic segmentation, visual relationship detection or scene graph generation. Since it helps to enhance the accuracy and the consistency of the resulting interpretation, visual context reasoning is often incorporated with visual perception in current deep end-to-end visual semantic information pursuit methods. Surprisingly, a comprehensive review for this exciting area is still lacking. In this survey, we present a unified theoretical paradigm for all these methods, followed by an overview of the major developments and the future trends in each potential direction. The common benchmark datasets, the evaluation metrics and the comparisons of the corresponding methods are also introduced.	187.9196522058352
1490.	As the environmental awareness of urban citizens increases, traditional air quality monitoring stations cannot satisfy the need for air quality data at high temporal and spatial resolution due to their high construction and maintenance costs. Low-cost air quality monitors are being increasingly used for this purpose because of their portability and affordable price. However, low-cost monitors are usually beset by data quality issues, and the number of mounted air pollutant sensors is limited by the restriction of the cost and size of monitors. Therefore, we propose to extend the use of air quality monitor data via a deep learning technique called long short-term memory (LSTM). The extension is embodied in two aspects: first, calibration of air pollutant concentration data; and second, provision of indicative information about air pollutants where no corresponding sensors are available. A low-cost air quality monitor called KOALA (Knowing Our Ambient Local Air Quality), which was deployed in Sydney (Australia), was used as an example to prove this method's feasibility. Data from a 90-day period were used for model training, and data from a 30-day period were used for model validation. Random forest models were used for selecting the most useful LSTM model input variables. Historical 24-h information was incorporated to improve the performance of the LSTM models. The results showed that: first, LSTM models can be used to calibrate KOALA carbon monoxide (CO) data with the optimum input being raw CO measurements and the corresponding standard deviation information; and second, LSTM models can be used to estimate ozone concentration with the optimum input being CO concentration and three meteorological parameters [i.e. top soil layer temperature, 10 m U wind (earth-relative), and net shortwave radiation flux at the ground] generated through a deterministic model known as WRF (Weather Research and Forecasting). In addition, the LSTM ozone estimation model showed good performance at both the training location and a location 11 km away, indicating that the proposed method can be used to provide indicative information about air pollutants around the training location. (c) 2020 Elsevier Ltd. All rights reserved.	187.91953379980134
1491.	Modern engineered systems generally work under complex operational conditions. However, most of the existing artificial intelligence (Aft-based prognostic methods still lack an effective model that can utilize operational conditions data for remaining useful life (RUL) prediction. This paper develops a novel prognostic method based on bidirectional long short-term memory (BLSTM) networks. The method can integrate multiple sensors data with operational conditions data for RUL prediction of engineered systems. The proposed architecture based on BLSTM networks includes three main parts: first, one BLSTM network is used to directly extract features hidden in the multiple raw sensors signals; second, another BLSTM network is employed to learn higher features from operational conditions signals and the learned features from the sensors signals; and, third, fully connected layers and a linear regression layer are stacked to generate the target output of the RUL prediction. Unlike other Al-based prognostic methods, the developed method can simultaneously model both sensors data and operational conditions data in a consolidated framework. The proposed approach is demonstrated through a case study on aircraft turbofan engines, and comparisons with other popular state-of-the-art methods are also presented.	187.9194869635084
1492.	Recently, there has been an incremental interest on Environmental Sound Classification (ESC), which is an important topic of the non-speech audio classification task. A novel approach, which is based on deep Convolutional Neural Networks (CNN), is proposed in this study. The proposed approach covers a bunch of stages such as pre-processing, deep learning based feature extraction, feature concatenation, feature reduction and classification, respectively. In the first stage, the input sound signals are denoised and are converted into sound images by using the Sort Time Fourier Transform (STFT) method. After sound images are formed, pre-trained CNN models are used for deep feature extraction. In this stage, VGG16, VGG19 and DenseNet201 models are considered. The feature extraction is performed in a pyramidal fashion which makes the dimension of the feature vector quite large. For both dimension reduction and the determination of the most efficient features, a feature selection mechanism is considered after feature concatenation stage. In the last stage of the proposed method, a Support Vector Machines (SVM) classifier is used. The efficiency of the proposed method is calculated on various ESC datasets such as ESC 10, ESC 50 and UrbanSound8K, respectively. The experimental works show that the proposed method produced 94.8%, 81.4% and 78.14% accuracy scores for ESC-10, ESC-50 and UrbanSound8K datasets. The obtained results are also compared with the state-of-the art methods achievements. (C) 2020 Elsevier Ltd. All rights reserved.	187.9194520025254
1493.	With the proliferation of video data, video summarization is an ideal tool for users to browse video content rapidly. In this paper, we propose a novel foveated convolutional neural networks for dynamic video summarization. We are the first to integrate gaze information into a deep learning network for video summarization. Foveated images are constructed based on subjects' eye movements to represent the spatial information of the input video. Multi-frame motion vectors are stacked across several adjacent frames to convey the motion clues. To evaluate the proposed method, experiments are conducted on two video summarization benchmark datasets. The experimental results validate the effectiveness of the gaze information for video summarization despite the fact that the eye movements are collected from different subjects from those who generated summaries. Empirical validations also demonstrate that our proposed foveated convolutional neural networks for video summarization can achieve state-of-the-art performances on these benchmark datasets.	187.91944399818678
1494.	BACKGROUND AND PURPOSE: The use of AI in the process of CT image reconstruction may improve image quality of resultant images and therefore facilitate low-dose CT examinations. METHODS: Articles in this review were gathered from multiple databases (Google Scholar, Ovid and Monash University Library Database). A total of 17 articles regarding AI use in CT image reconstruction was reviewed, including 1 white paper from GE Healthcare. RESULTS: DLR algorithms performed better in terms of noise reduction abilities, and image quality preservation at low doses when compared to other reconstruction techniques. CONCLUSION: Further research is required to discuss clinical application and diagnostic accuracy of DLR algorithms, but AI is a promising dose-reduction technique with future computational advances.	187.9194302559844
1495.	Analysis dictionary learning (ADL) has been successfully applied to a variety of learning systems. However, the ordinal locality of analysis dictionary has rarely been explored in constructing discriminative terms. In this paper, a discriminative low-rank analysis-synthesis dictionary learning (LR-ASDL) algorithm with the adaptively ordinal locality is proposed for object classification. Specifically, we first explicitly introduce the relations between the analysis atoms and profiles (i.e., row vectors of the coefficients matrix). That is, the similarity between two profiles depends on that between the corresponding analysis atoms. Moreover, an adaptively ordinal locality preserving(AOLP) term is constructed by simultaneously exploiting the profiles and analysis atoms, which can be learned in a supervised way. In this way, the neighborhood correlations between analysis atoms and the highorder ranking information of each analysis atom's neighbors can be simultaneously preserved in the learning process. Particularly, this helps to uncover the intrinsic underlying data factors and inherit the geometry structure information of training samples. Furthermore, the low-rank model is imposed on the synthesis atoms to further facilitate the learned dictionaries to be more discriminative. Extensive experimental results on eight databases demonstrate that the LR-ASDL algorithm clearly outperforms some analysis and synthesis dictionary learning algorithms using deep and hand-crafted features. (C) 2019 Elsevier Ltd. All rights reserved.	187.919383477026
1496.	The conventional image segmentation techniques have a lot of issues with highest computational cost and low level accuracy for medical image diagnosis and genome analysis. The deep learning based optimization models utilize to predict the liver cancer with RNA genome using CT images and the prediction of genome classification with NGS is a higher probable in recent medical disease classification. This paper proposes a hybrid deep learning technique constructs with SegNet, MultiResUNet, and Krill Herd optimization (KHO) algorithm to perform the extraction of the liver lesions and RNA sequencing that the optimization techniques used into the deep learning method. The proposed technique implements the SegNet for segregating the liver with genome from the CT scan; the MultiResUNet is constructed to perform the extractions of liver lesions. The KHO algorithm is combined with the deep learning approaches for tuning the hyper parameters to every Convolutional neural network model and enhances the segmentation process which may elaborately identifies the sequence that causes the liver classification disease. The proposed technique is compared with the related techniques on liver lesion classification (LL) for NGS in genome. The performance results show that the proposed technique is better to other algorithms on various performance metrics.	187.91938324784599
1497.	Graph convolutional neural networks have aroused more and more attentions on account of the ability to handle the graph-structured data defined on irregular or non-Euclidean domains. Different from the data defined on regular grids, each node in the graph-structured data has different number of neighbors, and the interactions and correlations between nodes vary at different locations, resulting in complex graph structure. However, the existing graph convolutional neural networks generally pay little attention to exploiting the graph structure information. Moreover, most existing graph convolutional neural networks employ the weight sharing strategy which lies on the statistical assumption of stationarity. This assumption is not always verified on the graph-structured data. To address these issues, we propose a method that learns Graph Structure via graph Convolutional Networks (GSCN), which introduces the graph structure parameters measuring the correlation degrees of adjacent nodes. The graph structure parameters are constantly modified the graph structure during the training phase and will help the filters of the proposed method to focus on the relevant nodes in each neighborhood. Meanwhile by combining the graph structure parameters and kernel weights, our method, which relaxes the restriction of weight sharing, is better to handle the graph-structured data of non-stationarity. In addition, the non-linear activation function ReLU and the sparse constraint are employed on the graph structure parameters to promote GSCN to focus on the important links and filter out the insignificant links in each neighborhood. Experiments on various tasks, including text categorization, molecular activity detection, traffic forecasting and skeleton-based action recognition, illustrate the validity of our method. (C) 2019 Elsevier Ltd. All rights reserved.	187.91935654347196
1498.	Electrical Capacitance Tomography (ECT) image reconstruction has developed for decades and made great achievements, but there is still a need to find a new theoretical framework to make it better and faster. In recent years, machine learning theory has been introduced in the ECT area to solve the image reconstruction problem. However, there is still no public benchmark dataset in the ECT field for the training and testing of machine learning-based image reconstruction algorithms. On the other hand, a public benchmark dataset can provide a standard framework to evaluate and compare the results of different image reconstruction methods. In this paper, a benchmark dataset for ECT image reconstruction is presented. Like the great contribution of ImageNet that transformed machine learning research, this benchmark dataset is hoped to be helpful for society to investigate new image reconstruction algorithms since the relationship between permittivity distribution and capacitance can be better mapped. In addition, different machine learning-based image reconstruction algorithms can be trained and tested by the unified dataset, and the results can be evaluated and compared under the same standard, thus, making the ECT image reconstruction study more open and causing a breakthrough.	187.91925888509883
1499.	We propose a novel fine-grained color sketch-based image retrieval (CSBIR) approach. The CSBIR problem is investigated for the first time using deep learning networks, in which deep features are used to represent color sketches and images. A novel ranking method considering both shape matching and color matching is also proposed. In addition, we build a CSBIR dataset with color sketches and images to train and test our method. The results show that our method has better retrieval performance.	187.91924396883894
1500.	360 degrees cameras offer the possibility to cover a large area, for example an entire room, without using multiple distributed vision sensors. However, geometric distortions introduced by their lenses make computer vision problems more challenging. In this paper we address face detection in 360 degrees fisheye images. We show how a face detector trained on regular images can be re-trained for this purpose, and we also provide a 360 degrees fisheye-like version of the popular FDDB face detection dataset, which we call FDDB-360.	187.91921211923975
1501.	Automatic classification of hard and soft exudates in color fundus images is very helpful for computer-aided diagnosis of retina related diseases, such as diabetic retinopathy (DR). In this study, we developed a novel method for this purpose based on the emerging deep learning technology known as convolutional neural networks (CNNs) by leveraging its strength of explicitly extracting the underlying image textures. We specifically investigate whether the emphasis of the image characteristic within an exudate spot could improve the classification performance. To verify this, we collected a database of fundus image that contains soft and hard exudates. The exudate regions were cropped from fundus images. There are a total of 550 cropped image patches (275 hard and 275 soft) with a fixed dimension of 128x128 pixels. These patches were further thresholded to exclude image background, resulting in another version of image patches merely containing exudate regions. Each version of image patches was randomly divided into 440 for training and 110 for testing, and then fed into the developed deep learning network in a separate or combinatorial way. Experimental results showed that the classification accuracy of this method was 93.41% when the thresholded version of the dataset was used as an augmented learning procedure, as compared to 90.80% and 87.41% when the original and background excluded datasets were used for training, respectively. This suggests that the augmented CNN can provide more accurate classification performance when the region-of-interest (ROI) and the original images were integrated.	187.91912665259926
1502.	The revolution and development of malwares over time necessitate an intensive researches on advanced techniques to secure user's personal and critical information, the most challenging task is to build a strong and robust classifier allows to detect different types of malwares and being able to defeat zero-day malware attacks. Machine learning algorithms as SVM (support vector machine), Random Forest and Naive Bayes are well-known choices for building the malware classifier, even though the deep learning which is a subfield of machine learning, has a portion in classifying android malwares with high precision. In this paper we present a modest study on difference between using both techniques and proposition of an approach based on deep learning technique applied on Apk of android applications belong to a heterogeneous data combined of benign and malware applications of different types.	187.91908825595573
1503.	Trams have increasingly deployed object detectors to perceive running conditions, and deep learning networks have been widely adopted by those detectors. Growing neural networks have incurred severe attacks such as adversarial example attacks, imposing threats to tram safety. Only if adversarial attacks are studied thoroughly, researchers can come up with better defence methods against them. However, most existing methods of generating adversarial examples have been devoted to classification, and none of them target tram environment perception systems. In this paper, we propose an improved projected gradient descent (PGD) algorithm and an improved Carlini and Wagner (C&W) algorithm to generate adversarial examples against Faster R-CNN object detectors. Experiments verify that both algorithms can successfully conduct nontargeted and targeted white-box digital attacks when trams are running. We also compare the performance of the two methods, including attack effects, similarity to clean images, and the generating time. The results show that both algorithms can generate adversarial examples within 220 seconds, a much shorter time, without decrease of the success rate.	187.91906197595733
1504.	In this paper, an intelligent and lightweight anomalous network traffic detection framework is proposed. The framework uses principal component analysis (PCA) with the main purpose of feature extraction and dimensionality reduction and bidirectional generative adversarial network (BiGAN) model is used to detect the anomalous network traffic. The proposed framework was evaluated using KDDCUP-99 dataset and was compared with recent deep learning models. Various visualization methods were also employed to understand the characteristics of the dataset and to visualize the KDDCUP-99 dataset features. Our work shows the importance of feature reduction in improving the overall performance of the BiGAN models. In addition, the proposed models are faster and efficient at test time.	187.919044352377
1505.	We propose a learning-based image processing method for particle size measurement based on digital holography in this paper. The proposed approach uses a modified U-net architecture with recorded holograms, hologram reconstructed to each longitudinal location, and minimum intensity projection in longitudinal direction as inputs to produce outputs consisting of in-focus particles at each longitudinal location and their 2D centroids. A soft generalized dice loss is used for the particle size channel and a total variation regularized mean squared error loss is employed for the 2D centroids channel. The proposed method has been assessed using synthetic, manually-labeled experimental, and real experimental holograms. The results demonstrate that our approach have better performance in comparison to the state-of-the-art non-machine-learning methods in terms of particle extraction rate and positioning accuracy. Our learning-based approach can be readily extended to other types of image-based particle size measurement tasks such as shadowgraph imaging and defocusing imaging. (C) 2020 Elsevier Ltd. All rights reserved.	187.91904252999774
1506.	Chatbot applications are increasingly adopted in various domains such as e-commerce or customer services as a direct communication channel between companies and end-users. Multiple frameworks have been developed to ease their definition and deployment. They typically rely on existing cloud infrastructures and artificial intelligence techniques to efficiently process user inputs and extract conversation information. While these frameworks are efficient to design simple chatbot applications, they still require advanced technical knowledge to define complex conversations and interactions. In addition, the deployment of a chatbot application usually requires a deep understanding of the targeted platforms, increasing the development and maintenance costs. In this paper we introduce the Jarvis framework, that tackles these issues by providing a Domain Specific Language (DSL) to define chatbots in a platform-independent way, and a runtime engine that automatically deploys the chatbot application and manages the defined conversation logic. Jarvis is open source and fully available online.	187.91904010014196
1507.	Surface defect detection is a critical task in industrial production process. Nowadays, there are lots of detection methods based on computer vision and have been successfully applied in industry, they also achieved good results. However, achieving full automation of surface defect detection remains a challenge, due to the complexity of surface defect, in intraclass. While the defects between interclass contain similar parts, there are large differences in appearance of the defects. To address these issues, this article proposes a pyramid feature fusion and global context attention network for pixel-wise detection of surface defect, called PGA-Net. In the framework, the multiscale features are extracted at first from backbone network. Then the pyramid feature fusion module is used to fuse these features into five resolutions through some efficient dense skip connections. Finally, the global context attention module is applied to the fusion feature maps of adjacent resolution, which allows effective information propagate from low-resolution fusion feature maps to high-resolution fusion ones. In addition, the boundary refinement block is added to the framework to refine the boundary of defect and improve the result of the prediction. The final prediction is the fusion of the five resolutions fusion feature maps. The results of evaluation on four real-world defect datasets demonstrate that the proposed method outperforms the state-of-the-art methods on mean intersection of union and mean pixel accuracy (NEU-Seg: 82.15%, DAGM 2007: 74.78%, MT_defect: 71.31%, Road_defect: 79.54%).	187.91891202977598
1508.	Objective: To compare the accuracy and computational efficiency of two of the latest deep-learning algorithms for automatic identification of cephalometric landmarks. Materials and Methods: A total of 1028 cephalometric radiographic images were selected as learning data that trained You-Only-Look-Once version 3 (YOLOv3) and Single Shot Multibox Detector (SSD) methods. The number of target labeling was 80 landmarks. After the deep-learning process, the algorithms were tested using a new test data set composed of 283 images. Accuracy was determined by measuring the point-to-point error and success detection rate and was visualized by drawing scattergrams. The computational time of both algorithms was also recorded. Results: The YOLOv3 algorithm outperformed SSD in accuracy for 38 of 80 landmarks. The other 42 of 80 landmarks did not show a statistically significant difference between YOLOv3 and SSD. Error plots of YOLOv3 showed not only a smaller error range but also a more isotropic tendency. The mean computational time spent per image was 0.05 seconds and 2.89 seconds for YOLOv3 and SSD, respectively. YOLOv3 showed approximately 5% higher accuracy compared with the top benchmarks in the literature. Conclusions: Between the two latest deep-learning methods applied, YOLOv3 seemed to be more promising as a fully automated cephalometric landmark identification system for use in clinical practice.	187.91889794752888
1509.	Using different sources of information to support automated extracting of relations between biomedical concepts contributes to the development of our understanding of biological systems. The primary comprehensive source of these relations is biomedical literature. Several relation extraction approaches have been proposed to identify relations between concepts in biomedical literature, namely, using neural networks algorithms. The use of multichannel architectures composed of multiple data representations, as in deep neural networks, is leading to state-of-the-art results. The right combination of data representations can eventually lead us to even higher evaluation scores in relation extraction tasks. Thus, biomedical ontologies play a fundamental role by providing semantic and ancestry information about an entity. The incorporation of biomedical ontologies has already been proved to enhance previous state-of-the-art results.	187.91862706237418
1510.	Convolutional Neural Networks (CNNs) have performed extremely well on data represented by regularly arranged grids such as images. However, directly leveraging the classic convolution kernels or parameter sharing mechanisms on sparse 3D point clouds is inefficient due to their irregular and unordered nature. We propose a point attention network that learns rich local shape features and their contextual correlations for 3D point cloud semantic segmentation. Since the geometric distribution of the neighboring points is invariant to the point ordering, we propose a Local Attention-Edge Convolution (LAE-Conv) to construct a local graph based on the neighborhood points searched in multi-directions. We assign attention coefficients to each edge and then aggregate the point features as a weighted sum of its neighbors. The learned LAE-Conv layer features are then given to a point-wise spatial attention module to generate an interdependency matrix of all points regardless of their distances, which captures long-range spatial contextual features contributing to more precise semantic information. The proposed point attention network consists of an encoder and decoder which, together with the LAE-Conv layers and the point-wise spatial attention modules, make it an end-to-end trainable network for predicting dense labels for 3D point cloud segmentation. Experiments on challenging benchmarks of 3D point clouds show that our algorithm can perform at par or better than the existing state of the art methods. (C) 2020 Elsevier Ltd. All rights reserved.	187.91848037553467
1511.	Measurement of a polyp size is an essential task in colon cancer screening, since the polyp-size information has critical roles for decision on colonoscopy. However, an estimation of a polyp size from a single view of colonoscope without a measurement device is quite difficult even for expert physicians. To overcome this difficulty, automated size estimation techniques would be desirable for clinical scenes. This paper presents polyp-size classification method with a single colonoscopic image for colonoscopy. Our proposed method estimates depth information from a single colonoscopic image with trained model and utilises the estimated information for the classification. In our method, the model for depth information is obtained by deep learning with colonoscopic videos. Experimental results show the achievement of binary and trinary polyp-size classification with 79% and 74% accuracy from a single still image of a colonoscopic movie.	187.9183431957436
1512.	Hyperspectral unmixing (HU) is a method used to estimate the fractional abundances corresponding to endmembers in each of the mixed pixels in the hyperspectral remote sensing image. In recent times, deep learning has been recognized as an effective technique for hyperspectral image classification. In this letter, an end-to-end HU method is proposed based on the convolutional neural network (CNN). The proposed method uses a CNN architecture that consists of two stages: the first stage extracts features and the second stage performs the mapping from the extracted features to obtain the abundance percentages. Furthermore, a pixel-based CNN and cube-based CNN, which can improve the accuracy of HU, are presented in this letter. More importantly, we also use dropout to avoid overfitting. The evaluation of the complete performance is carried out on two hyperspectral data sets: Jasper Ridge and Urban. Compared with that of the existing method, our results show significantly higher accuracy.	187.91830390555856
1513.	According to the World Health Organization, cardio-vascular diseases accounts for 31% of all deaths worldwide in 2016. Detecting the onset of heart irregularities can potentially save many lives. The ubiquity of wearable devices opens up the possibility of having a heart disease detection at everyone's disposal. To enable this, low energy ECG classification is needed. Unlike previous methods of using signal processing or even deep learning networks, this paper is the first to propose a low cost means to detect abnormal ECG beat signals by first synthesizing temporal logic formulas from training signals, and then checking if the synthesized formulas by the input signal at runtime. Our results show that the method has a high accuracy in detecting abnormal ECG beats while requiring significantly lower computation resource. Compared to It takes only a state-of-the-art convolutional neural network approach, our method achieves a comparable accuracy but with 0.3% of memory, and millions of computation operations, hence energy, saved.	187.91823959100657
1514.	Deep learning is a popular direction in computer vision and digital image processing. It is widely utilized in many fields, such as robot navigation, intelligent video surveillance, industrial inspection, and aerospace. With the extensive use of deep learning techniques, classification and object detection algorithms have been rapidly developed. In recent years, with the introduction of the concept of "unmanned retail," object detection, and image classification play a central role in unmanned retail applications. However, open-source datasets of traditional classification and object detection have not yet been optimized for application scenarios of unmanned retail. Currently, classification and object detection datasets do not exist that focus on unmanned retail solely. Therefore, in order to promote unmanned retail applications by using deep learning-based classification and object detection, in this article we collected more than 30 000 images of unmanned retail containers using a refrigerator affixed with different cameras under both static and dynamic recognition environments. These images were categorized into ten kinds of beverages. After manual labeling, images in our constructed dataset contained 155 153 instances, each of which was annotated with a bounding box. We performed extensive experiments on this dataset using ten state-of-the-art deep learning-based models. Experimental results indicate great potential of using these deep learning-based models for real-world smart unmanned vending machines.	187.91819634777067
1515.	Existing RGB and CNN-based methods in video action recognition mostly do not distinguish human body from the environment, thus easily overfit the scenes and objects of training sets. In this work, we present a conceptually simple, general and high-performance framework for action recognition in videos, aiming at person-centric modeling. The method, called Action Machine, is based on person bounding boxes for instance-level action analysis. It extends the Inflated 3D ConvNet (I3D) by adding a branch for human pose estimation and a 2D CNN for pose-based action recognition. Action Machine can benefit from the multi-task training of action recognition and pose estimation, the fusion of predictions from RGB images and poses. Experiments results are provided on trimmed video action datasets, NTU RGB+D, Northwestern UCLA Multiview Action3D, MSR Daily Activity3D. Action Machine achieves superior performance and generalizes well across datasets.	187.91816618277883
1516.	In Magnetic Resonance Imaging (MRI), the success of deep learning-based under-sampled MR image reconstruction depends on: (i) size of the training dataset (ii) generalization capabilities of the trained neural network. Whenever there is a mismatch between the training and testing data, there is a need to retrain the neural network from scratch with thousands of MR images obtained using the same protocol. This may not be possible in MRI as it is costly and time consuming to acquire data. In this research, a transfer learning approach i.e. end-to-end fine tuning is proposed for the U-Net to address the data scarcity and generalization problems of deep learning-based MR image reconstruction. First the generalization capabilities of a pre-trained U-Net (initially trained on the human brain images of 1.5T scanner) are assessed for: (a) MR images acquired from MRI scanners of different magnetic field strengths, (b) MR images of different anatomies and (c) MR images under-sampled by different acceleration factors. Later, end-to-end fine tuning of the pre-trained U-Net is proposed for the reconstruction of the above-mentioned MR images i.e. (a), (b) and (c). The results show successful reconstructions obtained from the proposed method as reflected by the Structural SIMilarity index, Root Mean Square Error, Peak Signal-to-Noise Ratio and central line profile of the reconstructed images.	187.91813525302084
1517.	Iris recognition has emerged as one of the most accurate and convenient biometric for person identification and has been increasingly employed in a wide range of e-security applications. The quality of iris images acquired at-a-distance or under less constrained imaging environments is known to degrade the iris recognition accuracy. The periocular information is inherently embedded in such iris images and can be exploited to assist in the iris recognition under such non-ideal scenarios. Our analysis of such iris templates also indicates significant degradation and reduction in the region of interest, where the iris recognition can benefit from a similarity distance that can consider importance of different binary bits, instead of the direct use of Hamming distance in the literature. Periocular information can be dynamically reinforced, by incorporating the differences in the effective area of available iris regions, for more accurate iris recognition. This article presents such a periocular-assisted dynamic framework for more accurate less-constrained iris recognition. The effectiveness of this framework is evaluated on three publicly available iris databases using within-dataset and cross-dataset performance evaluation, e.g., improvement in the recognition accuracy of 22.9%, 10.4% and 14.6% on three databases under both the verification and recognition scenarios.	187.9181179373095
1518.	Recent improvements in deep learning radiomics (DLR) extracting high-level features form medical imaging could promote the performance of computer aided diagnosis (CAD) for cancer. Breast cancer is the most frequent cancer among women and prospective achievements have been reported by CAD systems based on deep learning methods for breast imaging. In this paper, we aim to provide a comprehensive overview of the recent research efforts on DLR in breast cancer with different modalities and propose the future directions in this field. First, we respectively summarize and analyze the dataset, architecture, application and evaluation on DLR for breast cancer with three main imaging modalities, i.e., ultrasound, mammography, magnetic resonance imaging. Especially, we provide a survey on deep learning architectures exploited in breast cancer, including discriminative architectures and generative architectures. Then, we propose some potential challenges along with future research directions as ref-erences to the clinical treatment management and decision making utilizing such breast cancer CAD systems. (c) 2020 Elsevier Ltd. All rights reserved.	187.91810852964417
1519.	Recent years have seen a growing interest in conversational pedagogical agents. However, creating robust dialogue managers for conversational pedagogical agents poses significant challenges. Agents' misunderstandings and inappropriate responses may cause breakdowns in conversational flow, lead to breaches of trust in agent-student relationships, and negatively impact student learning. Dialogue breakdown detection (DBD) is the task of predicting whether an agent's utterance will cause a breakdown in an ongoing conversation. A robust DBD framework can support enhanced user experiences by choosing more appropriate responses, while also offering a method to conduct error analyses and improve dialogue managers. This paper presents a multimodal deep learning-based DBD framework to predict breakdowns in student-agent conversations. We investigate this framework with dialogues between middle school students and a conversational pedagogical agent in a game-based learning environment. Results from a study with 92 middle school students demonstrate that multimodal long short-term memory network (LSTM)-based dialogue breakdown detectors incorporating eye gaze features achieve high predictive accuracies and recall rates, suggesting that multimodal detectors can play an important role in designing conversational pedagogical agents that effectively engage students in dialogue.	187.91809322935535
1520.	Ausability studyof aVirtual RealitySterile Urinary Catheter Insertion Game (VR SUCIG) was conducted to understand user needs in regards to this game. Background: Learning and retention ofpsychomotor skillsin health care is essential tosafe clinical practice. Bauman suggests games are most useful when they are part of a layered-learning approach; in other words, they support various forms of learning and serve as cognitive aids (Bauman et al., 2014). Intervention: TheVR Sterile Urinary Catheter Insertion Game (VRSUCIG)was created by nurses and a computer gaming developer to provide nursing students with a cost-effective way to practice sterile catheter insertion skills in a systematic, evidence-based manner. A usability study and user reaction survey were conducted to gain a deep understanding of user's needs. Methods: Three hundred nursing students, from 9 US nursing schools participated. Participants played the VR SUCIG and completed theSystem Usability Scale (SUS)and aUser Reaction Survey(URS). Results: The SUS for the 2nd generation of the VR SUCIG was 57, or medium usability. The URS demonstrated the game motivated them to keep practicing. The VR SUCIG promotedrepetitive practiceof the skill and visually accentuated the concept of sterility. Conclusions. User reactions indicate that nursing students were eager and excited to utilize this technology. Usability scores indicate further refinement of technology is needed.	187.9180306245111
1521.	This article aims to examine Internet usage patterns by gender, highlighting differences that relate to intensity of usage and types of online activities. The particularity of the sociodemographic, cultural, and economic conditions in Montenegro places gender differences in a context that may differ from those explored in previous research. An online survey for data collection involved 1147 respondents from Montenegro, and the data analysis was performed using the deep-learning method of k-means clustering and employing a decision tree. The results show that gender differences exist for both observed criteria. This article contributes to a better understanding of how online behavior relates to gender differences and confirms that using deep-learning methods can efficiently identify these differences.	187.9177337111025
1522.	A deep learning based active contour framework is proposed for pancreas segmentation. Data extension and fractional differential operation are firstly applied for pre-processing. Second. deep learning method is designed to acquire the initial contour of pancreas. Subsequently, an intensity constrained term is designed to stop the contours at the edges. The intensity constrained term is integrated into a variational active contour model with three terms. The accurate pancreas segmentation is obtained by the evolution of the active contour model. Our approach reaches high detection dice similarity coefficient (DSC) of 83% and sensitivity of 85% in a dataset containing 40 abdominal CT scans. Comparisons with other level set models provide evidence that the proposed method offers desirable performances.	187.91771977706583
1523.	Multiobject Tracking (MOT) is one of the most important abilities of autonomous driving systems. However, most of the existing MOT methods only use a single sensor, such as a camera, which has the problem of insufficient reliability. In this paper, we propose a novel Multiobject Tracking method by fusing deep appearance features and motion information of objects. In this method, the locations of objects are first determined based on a 2D object detector and a 3D object detector. We use the Nonmaximum Suppression (NMS) algorithm to combine the detection results of the two detectors to ensure the detection accuracy in complex scenes. After that, we use Convolutional Neural Network (CNN) to learn the deep appearance features of objects and employ Kalman Filter to obtain the motion information of objects. Finally, the MOT task is achieved by associating the motion information and deep appearance features. A successful match indicates that the object was tracked successfully. A set of experiments on the KITTI Tracking Benchmark shows that the proposed MOT method can effectively perform the MOT task. The Multiobject Tracking Accuracy (MOTA) is up to 76.40% and the Multiobject Tracking Precision (MOTP) is up to 83.50%.	187.9176955236148
1524.	Given a function dictionary D and an approximation budget N is an element of N, nonlinear approximation seeks the linear combination of the best N terms {T-n}(1 <= n <= N) subset of D to approximate a given function f with the minimum approximation error epsilon(L,f) := min({gn}subset of R, {Tn}subset of D) parallel to f(x) - Sigma(N)(n=1)g(n)T(n)(x)parallel to. Motivated by recent success of deep learning, we propose dictionaries with functions in a form of compositions, i.e., T(x) = T-(L) circle T(L-1) circle . . . circle T-(1)(x) for all T is an element of D, and implement T using ReLU feed-forward neural networks (FNNs) with L hidden layers. We further quantify the improvement of the best N-term approximation rate in terms of N when L is increased from 1 to 2 or 3 to show the power of compositions. In the case when L > 3, our analysis shows that increasing L cannot improve the approximation rate in terms of N. In particular, for any function f on [0, 1], regardless of its smoothness and even the continuity, if f can be approximated using a dictionary when L = 1 with the best N-term approximation rate is an element of(L,f) = O(N-eta), we show that dictionaries with L = 2 can improve the best N-term approximation rate to is an element of(L,f) = O(N-2 eta). We also show that for Holder continuous functions of order alpha on [0, 1](d), the application of a dictionary with L = 3 in nonlinear approximation can achieve an essentially tight best N-term approximation rate is an element of(L,f) = O(N-2 alpha/d). Finally, we show that dictionaries consisting of wide FNNs with a few hidden layers are more attractive in terms of computational efficiency than dictionaries with narrow and very deep FNNs for approximating Holder continuous functions if the number of computer cores is larger than N in parallel computing. (C) 2019 Elsevier Ltd. All rights reserved.	187.91769258622247
1525.	Background and Context Overlaying Computer Science (CS) courses on top of inequitable schooling systems will not move us toward "CS for All." This paper prioritizes the perspectives of minoritized students enrolled in high school CS classrooms across a large, urban school district in the Western United States, to help inform how CS can truly be for all. Objective This paper explores what student agency looks like while answering the research question "From the perspective of minoritized students historically underrepresented in computing, what makes a critical difference in their sense of agency in introductory CS high school classes?" Method Our research-practice partnership used qualitative data (including classroom observations, interviews, student artifacts, and video/photos) and surveys to surface the perspectives and visions of minoritized youth. Findings The research describes what student agency looks like as youth - who have had no prior CS learning experiences - use CS as a tool to resist marginalization and dehumanizing school contexts, while declaring their own "rightful presence" in CS classrooms. Implications Findings demonstrate the importance for CS curricula and pedagogy to center the lives of students in ways that are consequential for minoritized youth. This would support deeper engagement with content learning and student agency with computing.	187.91764267254223
1526.	EEG motor imagery recognition based brain computer interface has been an import scheme to construct an alternative pathway of the brain to the outside world. EEG signal is usually buried in noise and has very low signal to noise ratio (SNR), which has presented great challenge for efficient motor imagery classification. In addition, the large intra-subject and inter-subject signal variance toward one specific motor imagery also brings difficulty for accurate classification. In recent years, some deep learning solutions based on AutoEncoder, Restricted Boltzmann Machine, CNN and RNN have been proposed for EEG motor imagery classification which have well improved the motor imagery classification accuracy. However, the multi-subject and multi-task motor imagery classification problem remains a challenge. The high computational cost of the existing deep learning solutions is another serious issue to be addressed. In this paper, a new motor imagery classification solution based on Temporal Convolutional Network (TCN) is developed. The dilated causal convolution within TCN could well incorporate the temporal information in a parallel way with much higher computational efficiency than the traditional RNNs. Time stacked spatial EEG signal has been employed as the input to the TCN. Based on which, both the spatial distribution information and temporal variation of the brain signal have been considered. Extensive experiments have shown that the proposed TCN solution has obtained state of the art performance on multi-subject and multi-task motor imagery classification. A high classification accuracy as 97.89% on 20 subjects and 5 tasks has been reached.	187.91743885006926
1527.	Recognizing addiction as a phenomenon with deep evolutionary roots grants valuable new perspectives into understanding its behavioral features, as well as its underlying neural mechanisms and genetic architecture. Although now generally misbranded as "human drugs of abuse," addictive plant alkaloids originally arose as potent chemical defenses against insect herbivory. The products of this evolutionary arms race, compounds such as nicotine, cathinone, or morphine, target essential biological mechanisms for motivation and learning and act as weaponized disruptors. Human vulnerabilities to these addictive drugs may thus represent little more than collateral damage arising from deep homology, i.e., shared biological implementation of behavioral functions with taxa that trace back to the early divergence of bilateral metazoans. Consistent with such a view, invertebrate preparations exhibit a rich spectrum of behavioral and neural consequences in response to drug exposure. Although there is certainly evidence for addiction-like phenomena in many invertebrate lineages, the present review focuses attention primarily on our recent work in crayfish. Using this decapod crustacean model, we have characterized a range of amphetamines, cathinones, and opioids for evidence of unconditioned intoxication, sympathomimetic properties, psychostimulant sensitization, conditioned cue learning, and operant self-administration. Overall, our findings on drug-sensitive reward in crayfish bear striking similarities to equivalent phenomena illustrated in mammals. Experimentally tractable invertebrate models may thus provide fundamental insights into the homo- and paralogous mechanisms mediating responses to addictive drugs, while illuminating the limits of such contrasts.	187.91732572289328
1528.	Speaker separation refers to the problem of separating speech signals from a mixture of simultaneous speakers. Previous studies are limited to addressing the speaker separation problem in anechoic conditions. This paper addresses the problem of talker-dependent speaker separation in reverberant conditions, which are characteristic of real-world environments. We employ recurrent neural networks with bidirectional long short-term memory (BLSTM) to separate and dereverberate the target speech signal. We propose two-stage networks to effectively deal with both speaker separation and speech dereverheration. In the two-stage model, the first stage separates and dereverberates two-talker mixtures and the second stage further enhances the separated target signal. We have extensively evaluated the two-stage architecture, and our empirical results demonstrate large improvements over unprocessed mixtures and clear performance gain over single-stage networks in a wide range of target-to-interferer ratios and reverberation times in simulated as well as recorded rooms. Moreover, we show that time-frequency masking yields better performance than spectral mapping for reverberant speaker separation.	187.91730368859015
1529.	Abnormal activity recognition is considered as the most challenging task in surveillance videos. Due to the traditional method depend on the computation of artificial features, and noise data has some influence on the extracted features. In this paper, a new hybrid deep learning structure was proposed to fuse the extracted features, which integrates convolutional neural network (CNN) and long short-term memory network (LSTM). Firstly, the video was preprocessed and extracted visual features by CNN. Next, LSTM was used to learn the temporal features of visual features and added attention mechanism to select important features. Finally, the video feature vector obtained layer by layer to judge abnormal activity. An experiment is used to test the ability of the model on the standard dataset UMN to recognize abnormal activity, the result shows that our experimental demonstrate high performance of recognition and outperform the state-of-art algorithms.	187.91726843250032
1530.	In low quality soils, as in the Indian state of Maharashtra, a sustainable land management practice is very important to enhance the soil quality and to maintain proper values for several nutrients that are relevant for an optimal crop yield. The evaluation of a soil fertility index for these nutrients and for each geographical place allows to create maps of village-wise fertility indices which are very useful for fertility management. An automatic prediction of such fertility indices would be very important to reduce the amount of chemical measurements of nutrients to be performed in different cultivation lands. The current study develops the prediction of fertility indices for soil organic carbon and four important soil nutrients (phosphorus pentoxide, iron, manganese and zinc) using almost all the available regression methods, specifically a collection of 76 regressors which belong to 20 families, including neural networks, deep learning, support vector regression, random forests, bagging and boosting, lasso and ridge regression, Bayesian models and more. The best results are achieved by the extremely randomized regression trees (extraTrees), with which achieve an acceptable prediction accuracy (average squared correlations between 0.57 and 0.70), being also relatively fast. Other regressors with high performance are random forests and regularized random forest, generalized boosting regression model and epsilon-support vector regression.	187.9172150106299
1531.	As deep learning models are applied to increasingly diverse problems, a key bottleneck is gathering enough high-quality training labels tailored to each task. Users therefore turn to weak supervision, relying on imperfect sources of labels like pattern matching and user-defined heuristics. Unfortunately, users have to design these sources for each task. This process can be time consuming and expensive: domain experts often perform repetitive steps like guessing optimal numerical thresholds and developing informative text patterns. To address these challenges, we present Snuba, a system to automatically generate heuristics using a small labeled dataset to assign training labels to a large, unlabeled dataset in the weak supervision setting. Snuba generates heuristics that each labels the subset of the data it is accurate for, and iteratively repeats this process until the heuristics together label a large portion of the unlabeled data. We develop a statistical measure that guarantees the iterative process will automatically terminate before it degrades training label quality. Snuba automatically generates heuristics in under five minutes and performs up to 9.74 F1 points better than the best known user-defined heuristics developed over many days. In collaborations with users at research labs, Stanford Hospital, and on open source datasets, Snuba outperforms other automated approaches like semi-supervised learning by up to 14.35 F1 points.	187.91720906490272
1532.	Recent advances in photoacoustic (PA) imaging have enabled detailed images of microvascular structure and quantitative measurement of blood oxygenation or perfusion. Standard reconstruction methods for PA imaging are based on solving an inverse problem using appropriate signal and system models. For handheld scanners, however, the ill-posed conditions of limited detection view and bandwidth yield low image contrast and severe structure loss in most instances. In this paper, we propose a practical reconstruction method based on a deep convolutional neural network (CNN) to overcome those problems. It is designed for real-time clinical applications and trained by large-scale synthetic data mimicking typical microvessel networks. Experimental results using synthetic and real datasets confirm that the deep-learning approach provides superior reconstructions compared to conventional methods.	187.91707994178654
1533.	Machine learning algorithms provide feasibility for crude oil price prediction. In this paper, a novel multi-hybrid predictive neural network model is proposed based on complex deep learning algorithm, which integrates empirical wavelet transform, random inheritance formula error correction algorithm, deep bidirectional LSTM neural network and Elman recurrent neural network with variational learning rate. The prediction model is selected according to the sequence frequency after EWT feature extraction, and the prediction results are obtained by separately predicting and reintegrating. On the basis of individual model, the structure of deep bidirectional training, random inheritance formula and variational learning rate are proposed, which further ameliorate the performance of the model and achieve more effective data information capture. Simultaneously, the examination of variational learning rate provides us with a feasible parameter selection. The proposed model achieves high-precision prediction of crude oil futures price, and stands out in the multi-model comparison analysis and q-DSCID synchronous evaluation, with superior prediction accuracy. (c) 2020 Elsevier Ltd. All rights reserved.	187.91705180437208
1534.	Unlike wired endoscopy, capsule endoscopy requires additional time for a clinical specialist to review the operation and examine the lesions. To reduce the tedious review time and increase the accuracy of medical examinations, various approaches have been reported based on artificial intelligence for computer-aided diagnosis. Recently, deep learning-based approaches have been applied to many possible areas, showing greatly improved performance, especially for image-based recognition and classification. By reviewing recent deep learning-based approaches for clinical applications, we present the current status and future direction of artificial intelligence for capsule endoscopy.	187.9169297996848
1535.	Human activity recognition (HAR) technology that analyzes data acquired from various types of sensing devices, including vision sensors and embedded sensors, has motivated the development of various context-aware applications in emerging domains, e.g., the Internet of Things (IoT) and healthcare. Even though a considerable number of HAR surveys and review articles have been conducted previously, the major/overall HAR subject has been ignored, and these studies only focus on particular HAR topics. Therefore, a comprehensive review paper that covers major subjects in HAR is imperative. This survey analyzes the latest state-of-the-art research in HAR in recent years, introduces a classification of HAR methodologies, and shows advantages and weaknesses for methods in each category. Specifically, HAR methods are classified into two main groups, which are sensor-based HAR and vision-based HAR, based on the generated data type. After that, each group is divided into subgroups that perform different procedures, including the data collection, pre-processing methods, feature engineering, and the training process. Moreover, an extensive review regarding the utilization of deep learning in HAR is also conducted. Finally, this paper discusses various challenges in the current HAR topic and offers suggestions for future research. (c) 2020 Elsevier Ltd. All rights reserved.	187.91685929649122
1536.	Cyber threat attribution identifies the source of a malicious cyber activity, which in turn informs cyber security mitigation responses and strategies. Such responses and strategies are crucial for deterring future attacks, particularly in the financial and critical infrastructure sectors. However, existing approaches generally rely on manual analysis of attack indicators obtained through approaches such as trace-back, firewalls, intrusion detection and honeypot deployments. These attack indicators, also known as low-level Indicators of Compromise (IOCs), are rarely re-used and can be easily modified and disguised resulting in a deceptive and biased cyber threat attribution. Cyber attackers, particularly financially-motivated actors, can use common high-level attack patterns that evolve less frequently as compared to the low-level IOCs. To attribute cyber threats effectively, it is necessary to identify them based on the high-level adversary's attack patterns (e.g. tactics, techniques and procedures - TTPs, software tools and malware) employed in different phases of the cyber kill chain. Identification of high-level attack patterns is time-consuming, requiring forensic investigation of the victim network(s) and other resources. In the rare case that attack patterns are reported in cyber threat intelligence (CTI) reports, the format is textual and unstructured typically taking the form of lengthy incident reports prepared for human consumption (e.g. prepared for C-level and senior management executives), which cannot be directly interpreted by machines. Thus, in this paper we propose a framework to automate cyber threat attribution. Specifically, we profile cyber threat actors (CTAs) based on their attack patterns extracted from CTI reports, using the distributional semantics technique of Natural Language Processing. Using these profiles, we train and test five machine learning classifiers on 327 CTI reports collected from publicly available incident reports that cover events from May 2012 to February 2018. It is observed that the CTA profiles obtained attribute cyber threats with a high precision (i.e. 83% as compared to other publicly available CTA profiles, where the precision is 33%). The Deep Learning Neural Network (DLNN) based classifier also attributes cyber threats with a higher accuracy (i.e. 94% as compared to other classifiers). (C) 2019 Elsevier B.V. All rights reserved.	187.91678563748758
1537.	Deformational plagiocephaly (DP) is a cranial deformity characterized by an asymmetrical distortion of an infant's skull. The diagnosis and evaluation of DP are performed using cranial asymmetry indexes obtained from cranial measurements, which can be estimated using anthropometric landmarks of the infant's head. However, manual labeling of these landmarks is a time-consuming and tedious task, being also prone to observer variability. In this paper, a novel framework to automatically detect anthropometric landmarks of 3D infant's head models is described. The proposed method is divided into two stages: (i) unfolding of the 3D head model surface; and (ii) landmarks' detection through a deep learning strategy. In the first stage, an unfolding strategy is used to transform the 3D mesh of the head model to a flattened 2D version of it. From the flattened mesh, three 2D informational maps are generated using specific head characteristics. In the second stage, a deep learning strategy is used to detect the anthropometric landmarks in a 3-channel image constructed using the combination of informational maps. The proposed framework was validated in fifteen 3D synthetic models of infant's head, being achieved, in average for all landmarks, a mean distance error of 3.5 mm between the automatic detection and a manually constructed ground-truth. Moreover, the estimated cranial measurements were comparable to the ones obtained manually, without statistically significant differences between them for most of the indexes. The obtained results demonstrated the good performance of the proposed method, showing the potential of this framework in clinical practice.	187.91661882047998
1538.	The automatic classification of cross-country (XC) skiing techniques using data from wearable sensors has the potential to provide insights for optimizing the performance of professional skiers. In this paper, we propose a unified deep learning model for classifying eight techniques used in classical and skating styles XC-skiing and optimize this model for the number of gyroscope sensors by analyzing the results for five different configurations of sensors. We collected data of four professional skiers on outdoor flat and natural courses. The model is first trained over the flat course data of two skiers and tested over the flat and natural course data of a third skier in a leave-one-out fashion, resulting in a mean accuracy of similar to 80% over three combinations. Secondly, the model is trained over the flat course data of three skiers and tested over flat course and natural course data of one new skier, resulting in a mean accuracy of 87.2% and 95.1% respectively, using the optimal sensor configuration (five gyroscope sensors: both hands, both feet, and the pelvis). High classification accuracy obtained using both approaches indicates that this deep learning model has the potential to be deployed for real-time classification of skiing techniques by professional skiers and coaches.	187.91655716056175
1539.	Manual segmentation is the gold standard method for radiation therapy planning; however, it is time-consuming and prone to inter- and intra-observer variation, giving rise to interests in auto-segmentation methods. We evaluated the feasibility of deep learning-based auto-segmentation (DLBAS) in comparison to commercially available atlas-based segmentation solutions (ABAS) for breast cancer radiation therapy. This study used contrast-enhanced planning computed tomography scans from 62 patients with breast cancer who underwent breast-conservation surgery. Contours of target volumes (CTVs), organs, and heart substructures were generated using two commercial ABAS solutions and DLBAS using fully convolutional DenseNet. The accuracy of the segmentation was assessed using 14 test patients using the Dice Similarity Coefficient and Hausdorff Distance referencing the expert contours. A sensitivity analysis was performed using non-contrast planning CT from 14 additional patients. Compared to ABAS, the proposed DLBAS model yielded more consistent results and the highest average Dice Similarity Coefficient values and lowest Hausdorff Distances, especially for CTVs and the substructures of the heart. ABAS showed limited performance in soft-tissue-based regions, such as the esophagus, cardiac arteries, and smaller CTVs. The results of sensitivity analysis between contrast and non-contrast CT test sets showed little difference in the performance of DLBAS and conversely, a large discrepancy for ABAS. The proposed DLBAS algorithm was more consistent and robust in its performance than ABAS across the majority of structures when examining both CTVs and normal organs. DLBAS has great potential to aid a key process in the radiation therapy workflow, helping optimise and reduce the clinical workload.	187.91645128897432
1540.	PurposeThe aim of this study was to develop an interactive deep learning-assisted identification of the hyperdense middle cerebral artery (MCA) sign (HMCAS) on non-contrast computed tomography (CT) among patients with acute ischemic stroke.Materials and methods35 HMCAS-positive and 39 HMCAS-negative samples extracted by 50-pixel-diameter circular regions of interest were obtained as training and validation datasets according to the consensus decisions of two experienced neuroradiologists. Data augmentation was performed to increase the number of training samples. A deep convolutional neural network (DCNN) (Xception) was used to classify input images as HMCAS-positive or -negative. Leave-one-case-out cross-validation was achieved to estimate sensitivity, specificity, and accuracy of the deep learning-based training model for identifying HMCAS.ResultsIn terms of diagnostic performance, DCNN for HMCAS offered 82.9% sensitivity, 89.7% specificity, and 86.5% accuracy in leave-one-case-out cross-validation. Area under the receiver operating characteristic curve for HMCAS was 0.947 (95% confidence interval 0.895-0.998; P<0.05).ConclusionThe deep learning method appears potentially beneficial for identifying HMCAS on non-contrast CT in patients with acute ischemic stroke.	187.91641423309187
1541.	This paper proposes an autoencoder-based one-class classification technique to predict a specific event such as the occurrence of a fire in a specific building. Basically, a binary classification system that uses machine learning to identify fire-risk buildings requires 'positive' fire data and 'negative' non-fire data. However, the fire-risk building data that can be actually obtained have a single class data that includes only the data of the occurrence of the fire and does not include the data of the 'non-occurrence'. In this situation, PU (Positive-Unlabeled) learning which uses 'unlabeled' data can be an effective way of generating the fire prediction model. The autoencoder generates new features from the unlabeled data, with which a predictive model for predicting the fire-risk buildings is built through PU learning.	187.91625558600805
1542.	This paper presents a deep learning approach for urban crime forecasting. A deep neural network architecture is designed so that it can be trained by using geo-referenced data of criminal activity and road intersections to capture relevant spatial patterns. Preliminary results suggest this model would be able to identify zones with criminal activity in square areas of 500 x 500 m(2) in a weekly scale.	187.91605039817443
1543.	We present some augmentations to literature Message Passing Neural Network (MPNN) architectures and benchmark their performances against a wide range of chemically and pharmaceutically relevant datasets. We analyse the effects of activation function for regularisation, we propose a new graph attention mechanism, and we implement a new edge-based memory system that should maximise the effectiveness of hidden state usage by directing and isolating information flow around the graph. We compare our results to the MolNet [14] benchmarking paper results on graph-based techniques, and also investigate the effect of method performance as a function of dataset preprocessing.	187.91580696240058
1544.	Accurate tracking and analysis of animal behavior is crucial for modern systems neuroscience. However, following freely moving animals in naturalistic, three-dimensional (3D) or nocturnal environments remains a major challenge. Here, we present EthoLoop, a framework for studying the neuroethology of freely roaming animals. Combining real-time optical tracking and behavioral analysis with remote-controlled stimulus-reward boxes, this system allows direct interactions with animals in their habitat. EthoLoop continuously provides close-up views of the tracked individuals and thus allows high-resolution behavioral analysis using deep-learning methods. The behaviors detected on the fly can be automatically reinforced either by classical conditioning or by optogenetic stimulation via wirelessly controlled portable devices. Finally, by combining 3D tracking with wireless neurophysiology we demonstrate the existence of place-cell-like activity in the hippocampus of freely moving primates. Taken together, we show that the EthoLoop framework enables interactive, well-controlled and reproducible neuroethological studies in large-field naturalistic settings. EthoLoop enables real-time tracking and behavioral analysis of animals in naturalistic environments and can be combined with behavioral conditioning, optogenetic stimulation or wireless recording of neural activity. The system is illustrated with freely behaving mice and mouse lemurs.	187.91568078714707
1545.	Uncertainty quantification for forward and inverse problems is a central challenge across physical and biomedical disciplines. We address this challenge for the problem of modeling subsurface flow at the Hanford Site by combining stochastic computational models with observational data using physics-informed GAN models. The geographic extent, spatial heterogeneity, and multiple correlation length scales of the Hanford Site require training a computationally intensive GAN model to thousands of dimensions. We develop a highly optimized implementation that scales to 27,500 NVIDIA Volta GPUs. We develop a hierarchical scheme based on a multi-player game-theoretic approach for exploiting domain parallelism, map discriminators and generators to multiple GPUs, and employ efficient communication schemes to ensure training stability and convergence. Our implementation scales to 4584 nodes on the Summit supercomputer with a 93.1% scaling efficiency, achieving peak and sustained half-precision rates of 1228 PF/s and 1207 PF/s.	187.91567286627355
1546.	This study addresses the problem of holistic road scene understanding based on the integration of visual and range data. To achieve the grand goal, the authors propose an approach that jointly tackles object-level image segmentation and semantic region labelling within a conditional random field (CRF) framework. Specifically, the authors first generate semantic object hypotheses by clustering 3D points, learning their prior appearance models, and using a deep learning method for reasoning their semantic categories. The learned priors, together with spatial and geometric contexts, are incorporated in CRF. With this formulation, visual and range data are fused thoroughly, and moreover, the coupled segmentation and semantic labelling problem can be inferred via graph cuts. The authors' approach is validated on the challenging KITTI dataset that contains diverse complicated road scenarios. Both quantitative and qualitative evaluations demonstrate its effectiveness.	187.91563148181586
1547.	Smart University (SU) system is significantly based on the deep integration of information technologies in the educationals process, indeed, the emergence of Smart University (SU) concept enable smart learning process by encompassing a range of smart components, which involve the implementation of an adaptive educational model using informational smart technologies. Through a process of interaction between academics and the organizational structure, it promotes modern methods of collaboration to increase the success and effectiveness of education. The service-oriented paradigm is crucial in ensuring a collaborative learning environment, which boosted by intelligent layers, additional treatment and data-powered. The paper concludes with "smart collaborative learning", as a relevant concept that adopts smart interactions to promotes modern methods of collaboration between teams of smart learners.	187.91557699437385
1548.	INTRODUCTION: Estimating PM2.5 concentrations and their prediction uncertainties at a high spatiotemporal resolution is important for air pollution health effect studies. This is particularly challenging for California, which has high variability in natural (e.g, wildfires, dust) and anthropogenic emissions, meteorology, topography (e.g. desert surfaces, mountains, snow cover) and land use. METHODS: Using ensemble-based deep learning with big data fused from multiple sources we developed a PM2.5 prediction model with uncertainty estimates at a high spatial (1km*1km) and temporal (weekly) resolution for a 10-year time span (2008-2017). We leveraged autoencoder-based full residual deep networks to model complex nonlinear interrelationships among PM2.5 emission, transport and dispersion factors and other influential features. These included remote sensing data (MAIAC aerosol optical depth (AOD), normalized difference vegetation index, impervious surface), MERRA-2 GMI Replay Simulation (M2GMI) output, wildfire smoke plume dispersion, meteorology, land cover, traffic, elevation, and spatiotemporal trends (geo-coordinates, temporal basis functions, time index). As one of the primary predictors of interest with substantial missing data in California related to bright surfaces, cloud cover and other known interferences, missing MAIAC AOD observations were imputed and adjusted for relative humidity and vertical distribution. Wildfire smoke contribution to PM2.5 was also calculated through HYSPLIT dispersion modeling of smoke emissions derived from MODIS fire radiative power using the Fire Energetics and Emissions Research version 1.0 model. RESULTS: Ensemble deep learning to predict PM2.5 achieved an overall mean training RMSE of 1.54mug/m3 (R2: 0.94) and test RMSE of 2.29mug/m3 (R2: 0.87). The top predictors included M2GMI carbon monoxide mixing ratio in the bottom layer, temporal basis functions, spatial location, air temperature, MAIAC AOD, and PM2.5 sea salt mass concentration. In an independent test using three long-term AQS sites and one short-term non-AQS site, our model achieved a high correlation (>0.8) and a low RMSE (<3 mug/m3). Statewide predictions indicated that our model can capture the spatial distribution and temporal peaks in wildfire-related PM2.5. The coefficient of variation indicated highest uncertainty over deciduous and mixed forests and open water land covers. CONCLUSION: Our method can be generalized to other regions, including those having a mix of major urban areas, deserts, intensive smoke events, snow cover and complex terrains, where PM2.5 has previously been challenging to predict. Prediction uncertainty estimates can also inform further model development and measurement error evaluations in exposure and health studies.	187.91552755893954
1549.	Deep learning has emerged as a leading machine learning tool in object detection and has attracted attention with its achievements in progressing medical image analysis. Convolutional Neural Networks (CNNs) are the most preferred method of deep learning algorithms for this purpose and they have an essential role in the detection and potential early diagnosis of colon cancer. In this article, we hope to bring a perspective to progress in this area by reviewing deep learning practices for colon cancer analysis. This study first presents an overview of popular deep learning architectures used in colon cancer analysis. After that, all studies related to colon cancer analysis are collected under the field of colon cancer and deep learning, then they are divided into five categories that are detection, classification, segmentation, survival prediction, and inflammatory bowel diseases. Then, the studies collected under each category are summarized in detail and listed. We conclude our work with a summary of recent deep learning practices for colon cancer analysis, a critical discussion of the challenges faced, and suggestions for future research. This study differs from other studies by including 135 recent academic papers, separating colon cancer into five different classes, and providing a comprehensive structure. We hope that this study is beneficial to researchers interested in using deep learning techniques for the diagnosis of colon cancer.	187.9155140514224
1550.	The explosive growth of text data requires effective methods to represent and classify these texts. Many text learning methods have been proposed, like statistics-based methods, semantic similarity methods, and deep learning methods. The statistics-based methods focus on comparing the substructure of text, which ignores the semantic similarity between different words. Semantic similarity methods learn a text representation by training word embedding and representing text as the average vector of all words. However, these methods cannot capture the topic diversity of words and texts clearly. Recently, deep learning methods such as CNNs and RNNs have been studied. However, the vanishing gradient problem and time complexity for parameter selection limit their applications. In this paper, we propose a novel and efficient text learning framework, named Latent Topic Text Representation Learning. Our method aims to provide an effective text representation and text measurement with latent topics. With the assumption that words on the same topic follow a Gaussian distribution, texts are represented as a mixture of topics, i.e., a Gaussian mixture model. Our framework is able to effectively measure text distance to perform text categorization tasks by leveraging statistical manifolds. Experimental results on text representation and classification, and topic coherence demonstrate the effectiveness of the proposed method.	187.91543613875223
1551.	In the past two decades, significant advances have been made on automated electroencephalogram (EEG)-based diagnosis of epilepsy and seizure detection. A number of innovative algorithms have been introduced that can aid in epilepsy diagnosis with a high degree of accuracy. In recent years, the frontiers of computational epilepsy research have moved to seizure prediction, a more challenging problem. While antiepileptic medication can result in complete seizure freedom in many patients with epilepsy, up to one-third of patients living with epilepsy will have medically intractable epilepsy, where medications reduce seizure frequency but do not completely control seizures. If a seizure can be predicted prior to its clinical manifestation, then there is potential for abortive treatment to be given, either self-administered or via an implanted device administering medication or electrical stimulation. This will have a far-reaching impact on the treatment of epilepsy and patient's quality of life. This paper presents a state-of-the-art review of recent efforts and journal articles on seizure prediction. The technologies developed for epilepsy diagnosis and seizure detection are being adapted and extended for seizure prediction. The paper ends with some novel ideas for seizure prediction using the increasingly ubiquitous machine learning technology, particularly deep neural network machine learning. (C) 2018 Elsevier Inc. All rights reserved.	187.91538787658067
1552.	Face recognition under the influence of complex illumination is a challenging problem to be solved. The common treatments for minimizing the affection of illumination variation are illumination preprocessing and illumination insensitive extraction techniques. However, the methods proposed previously present low performances. To realize high-accuracy recognition under varying illumination, this paper proposes a novel illumination processing algorithm called REC&SIG-SVD algorithm. Above all, singular value decomposition (SVD) is utilized to obtain preliminary high-frequency and low-frequency features of the face image in logarithm domain. This study proposes Sigmoid function which satisfies the principle of diminishing marginal utility to normalize singular values, aiming at calculating effective high-frequency features. Furthermore, this paper proposes a novel illumination normalization method to process low-frequency features, which is based on retina modeling cooperate with an advanced contrast limited adaptive histogram equalization (CLAHE). Meanwhile, enhancement on high-frequency features is realized by threshold-value filtering. Last but not least, the normalized high-frequency and enhanced low-frequency features are reassembled to form the normalized face image. The comparative trials based on Yale B and CMU PIE databases are conducted for our algorithm and other similar techniques as well as deep learning methods. The experimental results demonstrate that REC&SIG-SVD algorithm shows outstanding recognition performance.	187.91532479066694
1553.	As the need for wildfire detection increases, research on wildfire smoke detection combining low-cost cameras and deep learning technology is increasing. Camera-based wildfire smoke detection is inexpensive, allowing for a quick detection, and allows a smoke to be checked by the naked eye. However, because a surveillance system must rely only on visual characteristics, it often erroneously detects fog and clouds as smoke. In this study, a combination of a You-Only-Look-Once detector and a long short-term memory (LSTM) classifier is applied to improve the performance of wildfire smoke detection by reflecting on the spatial and temporal characteristics of wildfire smoke. However, because it is necessary to lighten the heavy LSTM model for real-time smoke detection, in this paper, we propose a new method for applying the teacher-student framework to deep LSTM. Through this method, a shallow student LSTM is designed to reduce the number of layers and cells constituting the LSTM model while maintaining the original deep LSTM performance. As the experimental results indicate, our proposed method achieves up to an 8.4-fold decrease in the number of parameters and a faster processing time than the teacher LSTM while maintaining a similar detection performance as deep LSTM using several state-of-the-art methods on a wildfire benchmark dataset.	187.91525766195673
1554.	This contribution aims at speech model-based speech enhancement by exploiting the source-filter model of human speech production. The proposed method enhances the excitation signal in the cepstral domain by making use of a deep neural network (DNN). We investigate two types of target representations along with the significant effects of their normalization. The new approach exceeds the performance of a formerly introduced classical signal processing-based cepstral excitation manipulation (CEM) method in terms of noise attenuation by about 1.5 dB. We show that this gain also holds true when comparing serial combinations of envelope and excitation enhancement. In the important low-SNR conditions, no significant trade-off for speech component quality or speech intelligibility is induced, while allowing for substantially higher noise attenuation. In total, a traditional purely statistical state-of-the-art speech enhancement system is outperformed by more than 3 dB noise attenuation.	187.91514795767182
1555.	Toxicity is an important factor in failed drug development, and its efficient identification and prediction is a major challenge in drug discovery. We have explored the potential of microscopy images of fluorescently labeled nuclei for the prediction of toxicity based on nucleus pattern recognition. Deep learning algorithms obtain abstract representations of images through an automated process, allowing them to efficiently classify complex patterns, and have become the state-of-the art in machine learning for computer vision. Here, deep convolutional neural networks (CNN) were trained to predict toxicity from images of DAPI-stained cells pre-treated with a set of drugs with differing toxicity mechanisms. Different cropping strategies were used for training CNN models, the nuclei-cropping-based Tox_CNN model outperformed other models classifying cells according to health status. Tox _CNN allowed automated extraction of feature maps that clustered compounds according to mechanism of action. Moreover, fully automated region-based CNNs (RCNN) were implemented to detect and classify nuclei, providing per-cell toxicity prediction from raw screening images. We validated both Tox _(R)CNN models for detection of pre-lethal toxicity from nuclei images, which proved to be more sensitive and have broader specificity than established toxicity readouts. These models predicted toxicity of drugs with mechanisms of action other than those they had been trained for and were successfully transferred to other cell assays. The Tax (R)CNN models thus provide robust, sensitive, and cost-effective tools for in vitro screening of drug-induced toxicity. These models can be adopted for compound prioritization in drug screening campaigns, and could thereby increase the efficiency of drug discovery.	187.91501137378765
1556.	Collision warning is essential in Advanced Driver Assistance Systems. However, all the studies focus on accurate assessment of risky situations without considering the driver's attention mechanism, which causes the proportion of valid warning triggers to be extremely low. In this paper, we present GazeFCW - a novel system that uses the driver's gaze direction to filter out unnecessary warning triggers. We verified the proposed system against several roads of different conditions. Our evaluation, across different crowded roads, shows a significant enhancement in warning trigger efficiency-compared to the standard system-reflected by an increase in the valid trigger proportion by 42%, a decrease in the invalid trigger proportion from 74.7% down to 32.7%, while adding only 50 ms run time execution overhead and causing negligible missing triggers.	187.91485665917614
1557.	The discovery of potential Drug-Target Interactions (DTIs) is a determining step in the drug discovery and repositioning process, as the effectiveness of the currently available antibiotic treatment is declining. Successful approaches have been presented to solve this problem but seldom protein sequences and structured data are used together. We present a deep learning architecture model, which exploits the particular ability of Convolutional Neural Networks (CNNs) to obtain 1D representations from protein amino acid sequences and SMILES (Simplified Molecular Input Line Entry System) strings. The results achieved demonstrate that using CNNs to obtain representations of the data, instead of the traditional descriptors, lead to improved performance.	187.91470266032155
1558.	Optimal engine operation during a transient driving cycle is the key to achieving greater fuel economy, engine efficiency, and reduced emissions. In order to achieve continuously optimal engine operation, engine calibration methods use a combination of static correlations obtained from dynamometer tests for steady-state operating points and road and/or track performance data. As the parameter space of control variables, design variable constraints, and objective functions increases, the cost and duration for optimal calibration become prohibitively large. In order to reduce the number of dynamometer tests required for calibrating modern engines, a large-scale simulation-driven machine learning approach is presented in this work. A parallel, fast, robust, physics-based reduced-order engine simulator is used to obtain performance and emission characteristics of engines over a wide range of control parameters under various transient driving conditions (drive cycles). We scale the simulation up to 3,906 nodes of the Theta supercomputer at the Argonne Leadership Computing Facility to generate data required to train a machine learning model. The trained model is then used to predict various engine parameters of interest, and the results are compared with those predicted by the engine simulator. Our results show that a deepneural-network-based surrogate model achieves high accuracy: Pearson product-moment correlation values larger than 0.99 and mean absolute percentage error within 1.07% for various engine parameters such as exhaust temperature, exhaust pressure, nitric oxide, and engine torque. Once trained, the deep-neural-network-based surrogate model is fast for inference: it requires about 16 mu s for predicting the engine performance and emissions for a single design configuration compared with about 0.5 s per configuration with the engine simulator. Moreover, we demonstrate that transfer learning and retraining can be leveraged to incrementally retrain the surrogate model to cope with new configurations that fall outside the training data space.	187.914700759846
1559.	Deep neural network (DNN) is a kind of intellectual property considering its usefulness and cost to develop. This paper proposes watermarking to a trained DNN models to protect its copyright. The proposed method has a remarkable feature for watermark detection process, which can decode the embedded pattern cumulatively and visually. In the experiment, we can embed a specific visual pattern using 5,000 or 60,000 images on the pretrained image classification DNN model. Then the embedded pattern is decoded using 20 images out of the 5,000 or 60,000 images, while a performance degradation to the original image classification task is small. At the conference site, real time and animated visual decoding demonstration is performed.	187.91470016178693
1560.	Data scarcity represents an important constraint for the training of deep neural networks in medical imaging. Medical image labeling, especially if pixel-level annotations are required, is an expensive task that needs expert intervention and usually results in a reduced number of annotated samples. In contrast, extensive amounts of unlabeled data are produced in the daily clinical practice, including paired multi-modal images from patients that were subjected to multiple imaging tests. This work proposes a novel self-supervised multimodal reconstruction task that takes advantage of this unlabeled multimodal data for learning about the domain without human supervision. Paired multimodal data is a rich source of clinical information that can be naturally exploited by trying to estimate one image modality from others. This multimodal reconstruction requires the recognition of domain-specific patterns that can be used to complement the training of image analysis tasks in the same domain for which annotated data is scarce. In this work, a set of experiments is performed using a multimodal setting of retinography and fluorescein angiography pairs that offer complementary information about the eye fundus. The evaluations performed on different public datasets, which include pathological and healthy data samples, demonstrate that a network trained for self-supervised multimodal reconstruction of angiography from retinography achieves unsupervised recognition of important retinal structures. These results indicate that the proposed self-supervised task provides relevant cues for image analysis tasks in the same domain. (c) 2020 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	187.9146926515392
1561.	Despite the vast increase of high-throughput molecular data, the prediction of important disease genes and the underlying molecular mechanisms of multi-factorial diseases remains a challenging task. In this work we use a powerful deep learning classifier, based on Graph Convolutional Networks (GCNs) to tackle the task of cancer gene prediction across different cancer types. Compared to previous cancer gene prediction methods, our GCN-based model is able to combine several heterogeneous omics data types with a graph representation of the data into a single predictive model and learn abstract features from both data types. The graph formalizes relations between genes which work together in regulatory cellular pathways. GCNs outperform other state-of-the-art methods, such as network propagation algorithms and graph attention networks in the prediction of cancer genes. Furthermore, they demonstrate that including the interaction network topology greatly helps to characterize novel cancer genes, as well as entire disease modules. In this work, we go one step forward and enable the interpretation of our deep learning model to answer the following question: what is the molecular cause underlying the prediction of a disease genes and are there differences across samples?	187.91462201109866
1562.	Detection and diagnosis of early and subclinical stages of Alzheimer's Disease (AD) play an essential role in the implementation of intervention and prevention strategies. Neuroimaging techniques predominantly provide insight into anatomic structure changes associated with AD. Deep learning methods have been extensively applied towards creating and evaluating models capable of differentiating between cognitively unimpaired, patients with Mild Cognitive Impairment (MCI) and AD dementia. Several published approaches apply information fusion techniques, providing ways of combining several input sources in the medical domain, which contributes to knowledge of broader and enriched quality. The aim of this paper is to fuse sociodemographic data such as age, marital status, education and gender, and genetic data (presence of an apolipoprotein E (APOE)-epsilon 4 allele) with Magnetic Resonance Imaging (MRI) scans. This enables enriched multi-modal features, that adequately represent the MRI scan visually and is adopted for creating and modeling classification systems capable of detecting amnestic MCI (aMCI). To fully utilize the potential of deep convolutional neural networks, two extra color layers denoting contrast intensified and blurred image adaptations are virtually augmented to each MRI scan, completing the Red-Green-Blue (RGB) color channels. Deep convolutional activation features (DeCAF) are extracted from the average pooling layer of the deep learning system Inception_v3. These features from the fused MRI scans are used as visual representation for the Long Short-Term Memory (LSTM) based Recurrent Neural Network (RNN) classification model. The proposed approach is evaluated on a sub-study containing 120 participants (aMCI = 61 and cognitively unimpaired = 59) of the Heinz Nixdorf Recall (HNR) Study with a baseline model accuracy of 76%. Further evaluation was conducted on the ADNI Phase 1 dataset with 624 participants (aMCI = 397 and cognitively unimpaired = 227) with a baseline model accuracy of 66.27%. Experimental results show that the proposed approach achieves 90% accuracy and 0.90F(1)-Score at classification of aMCI vs. cognitively unimpaired participants on the HNR Study dataset, and 77% accuracy and 0.83F(1)-Score on the ADNI dataset.	187.91456636786586
1563.	The analysis of longitudinal trajectories is a longstanding problem in medical imaging which is often tackled in the context of Riemannian geometry: the set of observations is assumed to lie on an a priori known Riemannian manifold. When dealing with high-dimensional or complex data, it is in general not possible to design a Riemannian geometry of relevance. In this paper, we perform Riemannian manifold learning in association with the statistical task of longitudinal trajectory analysis. After inference, we obtain both a submanifold of observations and a Riemannian metric so that the observed progressions are geodesics. This is achieved using a deep generative network, which maps trajectories in a low-dimensional Euclidean space to the observation space.	187.91444695736044
1564.	Annotated data availability has always been a major limiting f actor for the development of algorithms in the field of computer aided diagnosis. The purpose of this study is to investigate the feasibility of using a conditional generative adversarial network (GAN) to synthesize high resolution mammography images with semantic control. We feed a binary mammographic texture map to the generator to synthesize a full-field digital-mammogram (FFDM). Our results show the generator quickly learned to grow anatomical details around the edges within the texture mask. However, we found the training unstable and the quality of generated images unsatisfactory due to the inherent limitation of latent space and sample space mapping by the pix2pix framework. In order to synthesize high resolution mammography images with semantic control, we identified the critical challenge is to build the efficient mappings of binary textures with a great variety of pattern realizations with the image domain.	187.914435402123
1565.	A pioneering study is presented demonstrating that the presence of high glycated haemoglobin (HbA1c) levels in a patient's blood can be reliably predicted from routinely collected clinical data. This paves the way for performing early detection of Type-2 Diabetes Mellitus (T2DM). This will save healthcare providers a major cost associated with the administration and assessment of clinical tests for HbA1c. A novel collaborative denoising autoencoder framework is used to address this challenge. The framework builds an independent denoising autoencoder model for the high and low HbA1c level, which extracts feature representations in the latent space. A baseline model using just three features: patient age together with triglycerides and glucose level achieves 76% F1-score with an SVM classifier. The collaborative denoising autoencoder uses 78 features and can predict HbA1c level with 81% F1-score.	187.91440229717
1566.	The purpose of this study was to develop a lung segmentation based on a deep learning approach for dynamic chest radiography, and to assess the clinical utility for pulmonary function assessment. Maximum inhale and exhale images were selected in dynamic chest radiographs of 214 cases, comprising 150 images during respiration. In total, 534 images (2 to 4 images per case) with annotations were prepared for this study. Three hundred images were fed into a fully-convolutional neural network (FCNN) architecture to train a deep learning model for lung segmentation, and 234 images were used for testing. To reduce misrecognition of the lung, post processing methods on the basis of time-series information were applied to the resulting images. The change amount in the lung area was calculated throughout all frames and its clinical utility was assessed in patients with pulmonary diseases. The Sorenson-Dice coefficients between the segmentation results and the gold standard were 0.94 in inhale and 0.95 in exhale phases, respectively. There were some false recognitions (214/234), but 163 were eliminated by our post processing. The measurement of the lung area and its respiratory change were useful for the evaluation of lung conditions; prolonged expiration in obstructive pulmonary diseases could be detected as a reduced change amount in the lung area in the exhale phase. Semantic segmentation deep learning approach allows for the sequential lung segmentation of dynamic chest radiographs with high accuracy (94%) and is useful for the evaluation of pulmonary function.	187.91437423378477
1567.	With rapid advances in experimental instruments and protocols, imaging and sequencing data are being generated at an unprecedented rate contributing significantly to the current and coming big biomedical data. Meanwhile, unprecedented advances in computational infrastructure and analysis algorithms are realizing image-based digital diagnosis not only in radiology and cardiology but also oncology and other diseases. Machine learning methods, especially deep learning techniques, are already and broadly implemented in diverse technological and industrial sectors, but their applications in healthcare are just starting. Uniquely in biomedical research, a vast potential exists to integrate genomics data with histopathological imaging data. The integration has the potential to extend the pathologist's limits and boundaries, which may create breakthroughs in diagnosis, treatment, and monitoring at molecular and tissue levels. Moreover, the applications of genomics data are realizing the potential for personalized medicine, making diagnosis, treatment, monitoring, and prognosis more accurate. In this chapter, we discuss machine learning methods readily available for digital pathology applications, new prospects of integrating spatial genomics data on tissues with tissue morphology, and frontier approaches to combining genomics data with pathological imaging data. We present perspectives on how artificial intelligence can be synergized with molecular genomics and imaging to make breakthroughs in biomedical and translational research for computer-aided applications.	187.91413492586014
1568.	Framework-forming scleractinian (FFS) corals provide structurally complex habitats to support abundant and diverse benthic communities but are vulnerable to environmental changes and anthropogenic disturbances. Scientific modeling of suitable habitat provides important insights into the impact of the environmental conditions and fills the gap in the knowledge on habitat suitability. This study presents predictive habitat suitability modeling for deep-sea (depth > 50 in) FFS corals in the GoM. We first conducted a nonparametric estimate of the observed coral point process intensity as a function of each numeric environmental variable. Next, we performed species distribution modeling (SDM) using an assemble of four machine learning models - maximum entropy (ME), support vector machine (SVM), random forest (RF), and deep neural network (DNN). We found that most important variables controlling the coral distribution are super-dominant gravel and rock substrata. SW and SE aspects, slope steepness, salinity, depth, temperature, acidity, dissolved oxygen, and chlorophyll-a. Highly suitable habitats are predicted to be on the continental slope off Texas, Louisiana, and Mississippi and the shelf and slope of the West Florida Escarpment. All the four models have outstanding prediction performances with AUC values over 095. DNN model performs best (AUC - 0987). The study contributes to coral habitat modeling research by presenting unique methods induding nonparametric function of coral point process intensity. DNN and SVM models that have not been used in coral SDM, post-classification model assembling, and percentile approach to determine a threshold value for classifying a suitability score map into a binary map. Our findings would help support conservation prioritization, management and planning, and guide new field exploration. (C) 2020 Elsevier B.V. All rights reserved.	187.91412374240045
1569.	In recent 10 years, forest damage caused by forest fires in Korea has increased significantly compared to previous years. Therefore, interest and concern about damage caused by forest fires are very important in terms of environmental and ecosystem. According to various domestic and international research results, forests perform functions such as reporting of life resources, prevention of desertification, and adjustment of micro climate. There are many studies to extract the damage areas based on hyper spectral aerial image, high resolution satellite image, vegetation index and factors affecting the forest environment. However, there are limitations that the indexes have different threshold values depending on the region and season, and the threshold value must be continuously adjusted in order to detect the concentration of the damage areas. In this study, we detected forest disaster damaged areas through satellite image data and deep learning. We collected image data on Landsat satellite and applied to the detection of damaged area using U-net [1] and SegNet [2] models. We tried to verify the applicability of semantic segmentation for remote sensing, compare and evaluate each model, and build an optimal forest disaster detection model.	187.9140413503266
1570.	Quantitative structure-activity relationship (QSAR) analysis uses structural, quantum chemical, and physicochemical features calculated from molecular geometry as explanatory variables predicting physiological activity. Recently, deep learning based on advanced artificial neural networks has demonstrated excellent performance in the discipline of QSAR research. While it has properties of feature representation learning that directly calculate feature values from molecular structure, the use of this potential function is limited in QSAR modeling. The present study applied this function of feature representation learning to QSAR analysis by incorporating 360 degrees images of molecular conformations into deep learning. Accordingly, I successfully constructed a highly versatile identification model for chemical compounds that induce mitochondrial membrane potential disruption with the external validation area under the receiver operating characteristic curve of >= 0.9.	187.91378533032255
1571.	Doctoral forms of study are now diverse, although debate exists about whether ontological differences separate the research-based Doctor of Philosophy (PhD) from alternative doctoral forms that contribute to professional practice. The purpose and processes of doctoral study and prevailing market logics that suit the knowledge economy affect the doctoral experience. Solutions entail relationality between the ideas that members of society hold about the ontology and purpose of the PhD and alternative doctoral forms, individual existential desires, and the materialities of the contemporary workplace. The PhD discursively contributes to both academic and professional becoming, with deep disciplinary mastery of threshold concepts. Disciplinary learning groups offer a critical and sometimes transforming experience. In addition to preparing the next generation of academics, the traditional PhD offers high-level generic skills that are rare outside academia. In geography, especially, these skills are increasingly valued in society, not least when combined with diverse content that is highly relevant to contemporary global challenges. Institutions might help staff and candidates resist neoliberal tendencies for timely completions and offer a more appropriate learning experience, alongside ethical and transparent promotion of the purpose and practices of the doctoral experience. In time, such changes might signal a transformation influencing how all actors from society, the institution of higher education, supervisory staff, and doctoral candidates imagine doctoral and post-doctoral work-"acknowledging" doctoral expertise and its societal value from both within and outside the academy.	187.9137360148103
1572.	Background: Type 2 diabetes mellitus (T2DM) is a major public health burden. Self-management of diabetes including maintaining a healthy lifestyle is essential for glycemic control and to prevent diabetes complications. Mobile-based health data can play an important role in the forecasting of blood glucose levels for lifestyle management and control of T2DM. Objective: The objective of this work was to dynamically forecast daily glucose levels in patients with T2DM based on their daily mobile health lifestyle data including diet, physical activity, weight, and glucose level from the day before. Methods: We used data from 10 T2DM patients who were overweight or obese in a behavioral lifestyle intervention using mobile tools for daily monitoring of diet, physical activity, weight, and blood glucose over 6 months. We developed a deep learning model based on long short-term memory-based recurrent neural networks to forecast the next-day glucose levels in individual patients. The neural network used several layers of computational nodes to model how mobile health data (food intake including consumed calories, fat, and carbohydrates; exercise; and weight) were progressing from one day to another from noisy data. Results: The model was validated based on a data set of 10 patients who had been monitored daily for over 6 months. The proposed deep learning model demonstrated considerable accuracy in predicting the next day glucose level based on Clark Error Grid and +/- 10% range of the actual values. Conclusions: Using machine learning methodologies may leverage mobile health lifestyle data to develop effective individualized prediction plans for T2DM management. However, predicting future glucose levels is challenging as glucose level is determined by multiple factors. Future study with more rigorous study design is warranted to better predict future glucose levels for T2DM management.	187.91372893302784
1573.	In this work, we propose a novel deep Hierarchical Guidance and Regularization (HGR) learning framework for end-to-end monocular depth estimation, which well integrates a hierarchical depth guidance network and a hierarchical regularization learning method for fine-grained depth prediction. The two properties in our proposed HGR framework can be summarized as: (1) the hierarchical depth guidance network automatically learns hierarchical depth representations by supervision guidance and multiple side cony-operations from the basic CNN, leveraging the learned hierarchical depth representations to progressively guide the upsampling and prediction process of upper deconv-layers; (2) the hierarchical regularization learning method integrates various-level information of depth maps, optimizing the network to predict depth maps with similar structure to ground truth. Comprehensive evaluations over three public benchmark datasets (including NYU Depth V2, KITTI and Make3D datasets) well demonstrate the state-of-the-art performance of our proposed depth estimation framework. (C) 2018 Elsevier Ltd. All rights reserved.	187.91366358926302
1574.	OBJECTIVE: To improve hypospadias classification system, we hereby, show the use of machine learning/image recognition to increase objectivity of hypospadias recognition and classification. Hypospadias anatomical variables such as meatal location, quality of urethral plate, glans size, and ventral curvature have been identified as predictors for postoperative outcomes but there is still significant subjectivity between evaluators. MATERIALS AND METHODS: A hypospadias image database with 1169 anonymized images (837 distal and 332 proximal) was used. Images were standardized (ventral aspect of the penis including the glans, shaft, and scrotum) and classified into distal or proximal and uploaded for training with TensorFlow. Data from the training were outputted to TensorBoard, to assess for the loss function. The model was then run on a set of 29 "Test" images randomly selected. Same set of images were distributed among expert clinicians in pediatric urology. Inter- and intrarater analyses were performed using Fleiss Kappa statistical analysis using the same 29 images shown to the algorithm. RESULTS: After training with 627 images, detection accuracy was 60%. With1169 images, accuracy increased to 90%. Inter-rater analysis among expert pediatric urologists was k= 0.86 and intrarater 0.74. Image recognition model emulates the almost perfect inter-rater agreement between experts. CONCLUSION: Our model emulates expert human classification of patients with distal/proximal hypospadias. Future applicability will be on standardizing the use of these technologies and their clinical applicability. The ability of using variables different than only anatomical will feed deep learning algorithms and possibly better assessments and predictions for surgical outcomes.	187.91364087040992
1575.	Deep Learning techniques have achieved remarkable results in many domains. Often, training deep learning models requires large datasets, which may require sensitive information to be uploaded to the cloud to accelerate training. To adequately protect sensitive information, we propose distributed layer-partitioned training with step-wise activation functions for privacy-preserving deep learning. Experimental results attest our method to be simple and effective.	187.91354535767772
1576.	Background One of the significant attacks targeting the application layer is the distributed denial-of-service (DDoS) attack. It degrades the performance of the server by usurping its resources completely, thereby denying access to legitimate users and causing losses to businesses and organizations. Aim This study aims to investigate existing methodologies for application-layer DDoS (APDDoS) attack defense by using specific measures: detection methods/techniques, attack strategy, and feature exploration of existing APDDoS mechanisms. Methodology The review is carried out on a database search of relevant literature in IEEE Xplore, ACM, Science Direct, Springer, Wiley, and Google Search. The search dates to capture journals and conferences are from 2000 to 2019. Review papers that are not in English and not addressing the APDDoS attack are excluded. Three thousand seven hundred eighty-nine studies are identified and streamlined to a total of 75 studies. A quantifiable assessment is performed on the selected articles using six search procedures, namely: source, methods/technique, attack strategy, datasets/corpus, status, detection metric, and feature exploration. Results Based on existing methods/techniques for detection, the results show that machine learning gave the highest proportion with 36%. However, assessment based on attack strategy shows that several studies do not consider an attack form for deploying their solution. Result based on existing features for the APDDoS detection technique shows request stream during a user session and packet pattern gave the highest result with 47%. Unlike packet header information with 33%, request stream during absolute time interval with 12% and web user features 8%. Conclusion Research findings show that a large proportion of the solutions for APDDoS attack detection utilized features based on request stream during user session and packet pattern. The optimization of features will improve detection accuracy. Our study concludes that researchers need to exploit all attack strategies using deep learning algorithms, thus enhancing effective detection of APDDoS attack launch from different botnets.	187.91348298610473
1577.	Distributed and pervasive web services have become a major platform for sharing information. However, the hypertext transfer protocol secure (HTTPS), which is a crucial web encryption technology for protecting the information security of users, creates a supervisory burden for network management (e.g., quality-of-service guarantees and traffic engineering). Identifying various types of encrypted traffic is crucial for cyber security and network management. In this paper, we propose a novel deep learning model called BGRUA to identify the web services running on HTTPS connections accurately. BGRUA utilizes a bidirectional gated recurrent unit (GRU) and attention mechanism to improve the accuracy of HTTPS traffic classification. The bidirectional GRU is used to extract the forward and backward features of the byte sequences in a session. The attention mechanism is adopted to assign weights to features according to their contributions to classification. Additionally, we investigate the effects of different hyperparameters on the performance of BGRUA and present a set of optimal values that can serve as a basis for future relevant studies. Comparisons to existing methods based on three typical datasets demonstrate that BGRUA outperforms state-of-the-art encrypted traffic classification approaches in terms of accuracy, precision, recall, and F1-score. (C) 2020 Elsevier Inc. All rights reserved.	187.91344253093143
1578.	Augmented-reality (AR) devices allow physicians to incorporate data visualization into diagnostic and treatment procedures to improve work efficiency and safety and reduce cost. They are also used to enhance surgical training. In this study, we implemented an AR application for Botox injections using a face recognition algorithm based on deep learning, and we evaluated the recognition accuracy of this application using 27 participants. The accuracy was around 3 mm for all parts of the facial region. The method of increasing surgical efficiency with AR is accurate enough to be used for surgery and provides great potential for further development.	187.9134120488043
1579.	Conebeam CT using a circular trajectory is quite often used for various applications due to its relative simple geometry. For conebeam geometry, Feldkamp, Davis and Kress algorithm is regarded as the standard reconstruction method, but this algorithm suffers from so-called conebeam artifacts as the cone angle increases. Various model-based iterative reconstruction methods have been developed to reduce the cone-beam artifacts, but these algorithms usually require multiple applications of computational expensive forward and backprojections. In this paper, we develop a novel deep learning approach for accurate conebeam artifact removal. In particular, our deep network, designed on the differentiated backprojection domain, performs a data-driven inversion of an ill-posed deconvolution problem associated with the Hilbert transform. The reconstruction results along the coronal and sagittal directions are then combined using a spectral blending technique to minimize the spectral leakage. Experimental results under various conditions confirmed that our method generalizes well and outperforms the existing iterative methods despite significantly reduced runtime complexity.	187.91336989301584
1580.	BACKGROUND: Preliminary experience suggests that deep learning algorithms are nearly as good as humans in detecting common, displaced, and relatively obvious fractures (such as, distal radius or hip fractures). However, it is not known whether this also is true for subtle or relatively nondisplaced fractures that are often difficult to see on radiographs, such as scaphoid fractures. QUESTIONS/PURPOSES: (1) What is the diagnostic accuracy, sensitivity, and specificity of a deep learning algorithm in detecting radiographically visible and occult scaphoid fractures using four radiographic imaging views? (2) Does adding patient demographic (age and sex) information improve the diagnostic performance of the deep learning algorithm? (3) Are orthopaedic surgeons better at diagnostic accuracy, sensitivity, and specificity compared with deep learning? (4) What is the interobserver reliability among five human observers and between human consensus and deep learning algorithm? METHODS: We retrospectively searched the picture archiving and communication system (PACS) to identify 300 patients with a radiographic scaphoid series, until we had 150 fractures (127 visible on radiographs and 23 only visible on MRI) and 150 non-fractures with a corresponding CT or MRI as the reference standard for fracture diagnosis. At our institution, MRIs are usually ordered for patients with scaphoid tenderness and normal radiographs, and a CT with radiographically visible scaphoid fracture. We used a deep learning algorithm (a convolutional neural network [CNN]) for automated fracture detection on radiographs. Deep learning, an advanced subset of artificial intelligence, combines artificial neuronal layers to resemble a neuron cell. CNNs-essentially deep learning algorithms resembling interconnected neurons in the human brain-are most commonly used for image analysis. Area under the receiver operating characteristic curve (AUC) was used to evaluate the algorithm's diagnostic performance. An AUC of 1.0 would indicate perfect prediction, whereas 0.5 would indicate that a prediction is no better than a flip of a coin. The probability of a scaphoid fracture generated by the CNN, sex, and age were included in a multivariable logistic regression to determine whether this would improve the algorithm's diagnostic performance. Diagnostic performance characteristics (accuracy, sensitivity, and specificity) and reliability (kappa statistic) were calculated for the CNN and for the five orthopaedic surgeon observers in our study. RESULTS: The algorithm had an AUC of 0.77 (95% CI 0.66 to 0.85), 72% accuracy (95% CI 60% to 84%), 84% sensitivity (95% CI 0.74 to 0.94), and 60% specificity (95% CI 0.46 to 0.74). Adding age and sex did not improve diagnostic performance (AUC 0.81 [95% CI 0.73 to 0.89]). Orthopaedic surgeons had better specificity (0.93 [95% CI 0.93 to 0.99]; p < 0.01), while accuracy (84% [95% CI 81% to 88%]) and sensitivity (0.76 [95% CI 0.70 to 0.82]; p = 0.29) did not differ between the algorithm and human observers. Although the CNN was less specific in diagnosing relatively obvious fractures, it detected five of six occult scaphoid fractures that were missed by all human observers. The interobserver reliability among the five surgeons was substantial (Fleiss' kappa = 0.74 [95% CI 0.66 to 0.83]), but the reliability between the algorithm and human observers was only fair (Cohen's kappa = 0.34 [95% CI 0.17 to 0.50]). CONCLUSIONS: Initial experience with our deep learning algorithm suggests that it has trouble identifying scaphoid fractures that are obvious to human observers. Thirteen false positive suggestions were made by the CNN, which were correctly detected by the five surgeons. Research with larger datasets-preferably also including information from physical examination-or further algorithm refinement is merited. LEVEL OF EVIDENCE: Level III, diagnostic study.	187.91310507141768
1581.	Environmental and growth factors are important variables that affect the transpiration rate of crops, but due to their complex nature, it is difficult to systematically use all these factors to estimate transpiration rates. Application of artificial neural networks (ANNs) can be an efficient way of deriving meaningful results from complex nonlinear data. The objectives of this study were to estimate transpiration rates using an ANN, to compare these estimations with the Penman-Monteith (P-M) equation, and to analyze the estimation accuracy according to cultivation period. Paprika (Capsicum annuum L. cv. Scirocco) was cultivated for two cropping periods in a year. Environmental factors were collected every minute and leaf area index (LAI) as a growth factor was measured every 2 weeks. An ANN consisting of an input layer using eight environmental and growth factors, five hidden layers, and an output layer for transpiration rate was constructed. The estimation accuracy in the ANN was higher than the P-M when using aerial environmental factors, but it was further increased by adding root-zone factors. Using daily average data, ANN accuracy was higher for longer cultivation periods and accompanying data. R-2 values were 0.88 and 0.73 in the ANN and P-M for one year, whereas they were 0.84-0.93 and 0.79-0.83 for the individual seasons, respectively. The accuracy of the ANN tended to increase when the time step (data-averaging time unit) decreased to 10 min and there was no significant difference over 10 min. Using 10-min average data, the ANN showed high accuracies with R-2 = 0.95-0.96 and root mean square error = 0.07-0.10 g m(-2) min(-1), regardless of cultivation period and season. Therefore, it was confirmed that the ANN could accurately estimate transpiration rates at specific times using the data collected from the entire cultivation period. This approach may be useful for developing irrigation strategies by estimating the transpiration rates of crops grown in soilless cultures.	187.9130776410981
1582.	The development of chromatin immunoprecipitation (ChIP) with massively parallel DNA sequencing (ChIP-seq) technologies has promoted generation of large-scale epigenomics data, providing us unprecedented opportunities to explore the landscape of epigenomic profiles at scales across both histone marks and tissue types. In addition to many tools directly for data analysis, advanced computational approaches, such as deep learning, have recently become promising to deeply mine the data structures and identify important regulators from complex functional genomics data. We implemented a neural network framework, a Variational Auto-Encoder (VAE) model, to explore the epigenomic data from the Roadmap Epigenomics Project and the Encyclopedia of DNA Elements (ENCODE) project. Our model is applied to 935 reference samples, covering 28 tissues and 12 histone marks. We used the enhancer and promoter regions as the annotation features and ChIP-seq signal values in these regions as the feature values. Through a parameter sweep process, we identified the suitable hyperparameter values and built a VAE model to represent the epigenomics data and to further explore the biological regulation. The resultant Roadmap-ENCODE VAE (RE-VAE) model contained data compression and feature representation. Using the compressed data in the latent space, we found that the majority of histone marks were well clustered but not for tissues or cell types. Tissue or cell specificity was observed only in some histone marks (e.g., H3K4me3 and H3K27ac) and could be characterized when the number of tissue samples is large (e.g., blood and brain). In blood, the contributive regions and genes identified by RE-VAE model were confirmed by tissue-specificity enrichment analysis with an independent tissue expression panel. Finally, we demonstrated that RE-VAE model could detect cancer cell lines with similar epigenomics profiles. In conclusion, we introduced and implemented a VAE model to represent large-scale epigenomics data. The model could be used to explore classifications of histone modifications and tissue/cell specificity and to classify new data with unknown sources.	187.9130252219773
1583.	Steganography is the art of embedding a confidential message within a host message. Modern steganography is focused on widely used multimedia file formats, such as images, video files, and Internet protocols. Recently, cyber attackers have begun to include steganography (for communication purposes) in their arsenal of tools for evading detection. Steganalysis is the counter-steganography domain which aims at detecting the existence of steganography within a host file. The presence of steganography in files raises suspicion regarding the file itself, as well as its origin and receiver, and might be an indication of a sophisticated attack. The JPEG file format is one of the most popular image file formats and thus is an attractive and commonly used carrier for steganography embedding. State-of-the-art JPEG steganalysis methods, which are mainly based on neural networks, are limited in their ability to detect sophisticated steganography use cases. In this paper, we propose ASSAF, a novel deep neural network architecture composed of a convolutional denoising autoencoder and a Siamese neural network, specially designed to detect steganography in JPEG images. We focus on detecting the J-UNIWARD method, which is one of the most sophisticated adaptive steganography methods used today. We evaluated our novel architecture using the BOSSBase dataset, which contains 10,000 JPEG images, in eight different use cases which combine different JPEG's quality factors and embedding rates (bpnzAC). Our results show that ASSAF can detect stenography with high accuracy rates, outperforming, in all eight use cases, the state-of-the-art steganalysis methods by 6% to 40%.	187.91300897717394
1584.	Background: Recently, studies have demonstrated that machine learning techniques, particularly cutting-edge deep learning technology, have achieved significant progression on the classification of Alzheimer's disease (AD) and its prodromal phase, mild cognitive impairment (MCI). Moreover, accurate prediction of the progress and the conversion risk from MCI to probable AD has been of great importance in clinical application. Methods: In this study, the baseline MR images and follow-up information during 3 years of 150 normal controls (NC), 150 patients with stable MCI (sMCI) and 157 converted MCI (cMCI) were collected from the Alzheimer's Disease Neuroimaging Initiative (ADNI). The deep convolutional neural networks (CNNs) were adopted to distinguish different stages of MCI from the NC group, and predict the conversion time from MCI to AD. Two CNN architectures including GoogleNet and CaffeNet were explored and evaluated in multiple classifications and estimations of conversion risk using transfer learning from pre-trained ImageNet (via fine-tuning) and five-fold crass-validation. A novel data augmentation approach using random views aggregation was applied to generate abundant image patches from the original MR scans. Results: The GoogleNet acquired accuracies with 97.58%, 67.33% and 84.71% in three-way discrimination among the NC, sMCI and cMCI groups respectively, whereas the CaffeNet obtained promising accuracies of 98.71%, 72.04% and 92.35% in the NC, sMCI and cMCI classifications. Furthermore, the accuracy measures of conversion risk of patients with cMCI ranged from 71.25% to 83.25% in different time points using GoogleNet, whereas the CaffeNet achieved remarkable accuracy measures from 95.42% to 97.01% in conversion risk prediction. Conclusions: The experimental results demonstrated that the proposed methods had prominent capability in classification among the 3 groups such as sMCI, cMCI and NC, and exhibited significant ability in conversion risk prediction of patients with MCI.	187.9129292075762
1585.	Sanitary sewer systems are designed to collect and transport sanitary wastewater and stormwater. Pipe inspection is important in identifying both the type and location of pipe defects to maintain the normal sewer operations. Closed-circuit television (CCTV) has been commonly utilized for sewer pipe inspection. Currently, interpretation of the CCTV images is mostly conducted manually to identify the defect type and location, which is time-consuming, labor-intensive and inaccurate. Conventional computer vision techniques are explored for automated interpretation of CCTV images, but such process requires large amount of image pre-processing and the design of complex feature extractor for certain cases. In this study, an automated approach is developed for detecting sewer pipe defects based on a deep learning technique namely faster region-based convolutional neural network (faster R-CNN). The detection model is trained using 3000 images collected from CCTV inspection videos of sewer pipes. After training, the model is evaluated in terms of detection accuracy and computation cost using mean average precision (mAP), missing rate, detection speed and training time. The proposed approach is demonstrated to be applicable for detecting sewer pipe defects accurately with high accuracy and fast speed. In addition, a new model is constructed and several hyper-parameters are adjusted to study the influential factors of the proposed approach. The experiment results demonstrate that dataset size, initialization network type and training mode, and network hyper-parameters have influence on model performance. Specifically, the increase of dataset size and convolutional layers can improve the model accuracy. The adjustment of hyper-parameters such as filter dimensions or stride values contributes to higher detection accuracy, achieving an mAP of 83%. The study lays the foundation for applying deep learning techniques in sewer pipe defect detection as well as addressing similar issues for construction and facility management.	187.91291568030059
1586.	In this paper, we present a deep learning based underwater acoustic (UWA) orthogonal frequency-division multiplexing (OFDM) communication system. Unlike the traditional receiver for UWA OFDM communication system that performs explicitly channel estimation and equalization for the detection of transmitted symbols, the deep learning based UWA OFDM communication receiver interpreted as a deep neural network (DNN) can recover the transmitted symbols directly after sufficient training. The estimation of transmitted symbols in the DNN based receiver is achieved in two stages: (1) training stage, when labeled data such as known transmitted data and signal received in the unknown channel are used to train the DNN, and (2) test stage, where the DNN receiver recovers transmitted symbols given the received signal. To demonstrate the performance of the deep learning based UWA OFDM communications, we generate a large number of labeled and unlabeled data by using an acoustic propagation model with a measured sound speed profile to train and test the DNN receiver. The performance of the deep learning based UWA OFDM communications is evaluated under various system parameters, such as the cyclic prefix length, number of pilot symbols, and others. Simulation results demonstrate that the deep leaning based receiver offers consistent improvement in performance compared to the traditional UWA OFDM receiver. (C) 2019 Elsevier Ltd. All rights reserved.	187.91291318083867
1587.	BackgroundImmuno-oncology requires objective and standardized methods for measuring immune cell infiltrates for therapy selection and clinical trials.MethodsCurrent approaches in applying digital pathology in immuno-oncology and developments in computational image analysis were analyzed.ResultsSince 2008, digital pathology has had an ever increasing importance in immuno-oncology. It is currently the only technology allowing the systematic and cost-effective quantitative spatial immune-profiling of patients. The analysis of immunological biomarkers requires integrated staining and image analysis strategies from single- to multistain on slide stacks. Statistical limits of the hypothesis to be tested have to be taken into account. Digital image analysis opens anew technological role for pathology in immuno-oncology and thereby serves as akey technological driver.ConclusionDigital pathology delivers objective and quantitative data on the tumor microenvironment. But currently, afully automatic, high-throughput analytics capability is still missing. Deep learning is the remedy for this, as it improves image analysis with increasing data availability. This requires the creation of systematic data collections but will in the end deliver standardized and automatic immunological analyses.	187.9126221639847
1588.	Exemplified by the Ediacara biota, Precambrian strata yielded some most enigmatic fossils in the history of life. They exhibited unique body plans that perished on the eve of the Cambrian explosion. The phylogenetic affinity of the Ediacara biota has long been a matter of debate. Their affinities wandered across various phyla of life, including algae, ctenophores, cnidarians, annelids, molluscs, protists, terrestrial lichens and even an independent kingdom, Vendobionta. Finding the roots of modern phyla back in the Precambrian is frustratingly difficult, due to the relatively scarce fossil records back in time. Fortunately, biomarkers derived from biomolecules can be preserved as fossils too. These taxon-specific molecules served as windows into the primaeval world. They provide precious information about life perished in deep time from a unique perspective. In 2018, cholesteroids, a group of sterols characteristic of metazoans was detected from the iconic Ediacaran fossil Dickinsonia, provided another line of evidence for its animal affinity, along with existing morphological and ontogenic evidence, we can arguably confirm that Dickinsonia, as a member of metazoa, is more closely related to us than we thought. Hopanes extracted from disc-like fossils Beltanelliformis, illustrating that they may represent colonies of cyanobacteria. Two types of sponge biomarkers, 24-isopropylcholestane and 26-methylstigmastane, were found in 660-635 million years old rocks, potentially the sign of the earliest animals. However, learned from previous applications of biomarkers in the research of early life, two major hurdles must be overcome: contaminations and the possibility that the same biomarker produced by different taxonomic groups. Modern contaminations may come from various sources but can be minimised by adopting biomarker-clean protocols of sampling, e.g. the hydrocarbon-clean drilling method has been implemented on acquiring biomarkers from Archean rocks which are typically deficient of organic matter, hence prone to contamination. The latter hurdle is more serious and could significantly undermine the reliability of biomarkers. It is unlikely to fully investigate the triadic relationships between biomarkers, possible precursors and producers for all the groups of organisms. 24-isopropylcholestane and 26-methylstigmastane, once considered to be biomarkers exclusively for sponges. Their occurrences in the Neoproterozoic rocks were viewed as the first appearance of sponges. However, this evidence is probably no longer valid, because, for both biomarkers, their precursors were recently found common among Rhizaria, a supergroup of mostly unicellular protists. Even more cautions should be exercised while dealing with extinct groups, since we may never know what precursors they were capable to produce. As a result, biomarkers alone would not be enough, there have to be other lines of evidence to be convincing. When biomarkers contradict existing body fossil records, trust latter seems to be more promising at this moment.	187.9125065797812
1589.	Many distributed deep learning systems have been published over the past few years, often accompanied by impressive performance claims. In practice these figures are often achieved in high performance computing (HPC) environments with fast InfiniBand network connections. For average deep learning practitioners this is usually an unrealistic scenario, since they cannot afford access to these facilities. Simple re-implementations of algorithms such as EASGD [1] for standard Ethernet environments often fail to replicate the scalability and performance of the original works [2]. In this paper, we explore this particular problem domain and present MPCA SGD, a method for distributed training of deep neural networks that is specifically designed to run in low-budget environments. MPCA SGD tries to make the best possible use of available resources, and can operate well if network bandwidth is constrained. Furthermore, MPCA SGD runs on top of the popular Apache Spark [3] framework. Thus, it can easily be deployed in existing data centers and office environments where Spark is already used. When training large deep learning models in a gigabit Ethernet cluster, MPCA SGD achieves significantly faster convergence rates than many popular alternatives. For example, MPCA SGD can train ResNet-152 [4] up to 5.3x faster than state-of-the-art systems like MXNet [5], up to 5.3x faster than bulk-synchronous systems like SparkNet [6] and up to 5.3x faster than decentral asynchronous systems like EASGD [1].	187.91246244281132
1590.	Many well-known line spectral estimators may experience significant performance loss with noisy measurements. To address the problem, we propose a deep learning denoising based approach for line spectral estimation. The proposed approach utilizes a residual learning assisted denoising convolutional neural network (DnCNN) trained to recover the unstructured noise component, which is used to denoise the original measurements. Following the denoising step, we employ a popular model order selection method and a subspace line spectral estimator to the denoised measurements for line spectral estimation. Numerical results show that the proposed approach outperforms a recently introduced atomic norm minimization based denoising method and offers a substantial improvement compared with the line spectral estimation results obtained by directly applying the subspace estimator without denoising.	187.9124578441613
1591.	This study describes a group model building exercise that aims to develop a deeper understanding of the dynamic complexity of chronic disease care delivery within a primary care setting in Singapore, leveraging on the insights of stakeholders with personal and institutional knowledge of the health care system. A group model building exercise, which included 50 stakeholders, was used to develop the qualitative model. The qualitative model helped to bring a feedback perspective to understanding the dynamic complexity of chronic disease care delivery. The feedback perspective helped in identifying the systemic issues within chronic disease care delivery, which has the potential to inform system-wide interventions and policies to improve health. Enhancing chronic care in Singapore will require an enhancement of both the capacity and capability of the primary care sector. (c) 2018 John Wiley & Sons, Ltd.	187.91220135444223
1592.	Recent studies show that pulmonary vascular diseases may specifically affect arteries or veins through different physiologic mechanisms. To detect changes in the two vascular trees, physicians manually analyze the chest computed tomography (CT) image of the patients in search of abnormalities. This process is time consuming, difficult to standardize, and thus not feasible for large clinical studies or useful in real-world clinical decision making. Therefore, automatic separation of arteries and veins in CT images is becoming of great interest, as it may help physicians to accurately diagnose pathological conditions. In this paper, we present a novel, fully automatic approach to classify vessels from chest CT images into arteries and veins. The algorithm follows three main steps: first, a scale-space particles segmentation to isolate vessels; then a 3-D convolutional neural network (CNN) to obtain a first classification of vessels; finally, graph-cuts' optimization to refine the results. To justify the usage of the proposed CNN architecture, we compared different 2-D and 3-D CNNs that may use local information from bronchus-and vessel-enhanced images provided to the network with different strategies. We also compared the proposed CNN approach with a randomforests (RFs) classifier. The methodology was trained and evaluated on the superior and inferior lobes of the right lung of 18 clinical cases with noncontrast chest CT scans, in comparison with manual classification. The proposed algorithm achieves an overall accuracy of 94%, which is higher than the accuracy obtained using other CNN architectures and RF. Our method was also validated with contrast-enhanced CT scans of patients with chronic thromboembolic pulmonary hypertension to demonstrate that our model generalizes well to contrast-enhanced modalities. The proposed method outperforms state-of-the-art methods, paving the way for future use of 3-D CNN for artery/vein classification in CT images.	187.9119798317572
1593.	We demonstrate how image recognition and reinforcement learning combined may be used to determine the atomistic structure of reconstructed crystalline surfaces. A deep neural network represents a reinforcement learning agent that obtains training rewards by interacting with an environment. The environment contains a quantum mechanical potential energy evaluator in the form of a density functional theory program. The agent handles the 3D atomistic structure as a series of stacked 2D images and outputs the next atom type to place and the atomic site to occupy. Agents are seen to require 1000-10 000 single point density functional theory evaluations, to learn by themselves how to build the optimal surface reconstructions of anatase TiO2(001)-(1 x 4) and rutile SnO2(110)-(4 x 1).	187.911668860435
1594.	At present, technologies based on deep learning methods for automated detection of sewer defects have been developing rapidly. In this study, a novel semantic segmentation network called PipeUNet is proposed for sewer defect segmentation. In order to enhance the feature extraction capability and resolve semantic differences between high level and low level features, a new module named feature reuse and attention mechanism block is added between the original skip connections of U-Net. Focal loss is adopted to solve the class imbalance problem. PipeUNet was trained using the CCTV images with typical defects including crack, infiltration, joint offset and intruding lateral. It was tested by the defects images and normal images to evaluate the network's defect segmentation and detection performance respectively. It achieved the highest Mean Intersection over Union of 76.37% which proved the proposed approach's efficiency. It can process CCTV images at a high speed of 32 images per second.	187.91153590519997
1595.	Eccentric infrared photorefraction is an attractive vision screening method which is widely used for uncooperative subjects, such as infants and toddlers. Unlike conventional slope-based photorefraction, a deep neural network is used to predict refractive error in this study. Total 1216 ocular image were collected by a homemade photorefraction device, whose corresponding refractive error was measured by a commercial autorefractor device, to create a series of dataset for our deep neural network. The mean squared error of the preliminary result is +/- 0.9 diopter, which indicates its feasibility and can be improved with bigger database.	187.91139943016987
1596.	Stock market trading is relatively difficult due to the relatively complicated investment in financial markets. In order to solve this problem, an industry configuration model based on deep learning network sentiment mining and fundamental research is proposed innovatively in this paper. Firstly, by crawling the network information, the network public opinion data is used to conduct industry classification and sentiment analysis on the data, thereby obtaining the industry sentiment index and the industry income forecast. Then combined with the fundamental data and market data and the technical indicators generated by it, multi-factor analysis is carried out, and the income forecast is obtained. Through three sets of comparative experiments, the results show that the investment returns obtained are the best with the industry configuration model based on deep learning-based network sentiment mining and fundamental research.	187.9113213527598
1597.	Steganography algorithms recognition is a sub-section of steganalysis. Analysis shows when a steganalysis detector trained on one cover source is applied to images from an unseen source, generally the detection performance decreases. To tackle with this problem, this paper proposes a steganalytic scheme for steganography algorithms recognition. For a given testing image, a match image of the testing image is achieved. The match image is generated by performing a Gaussian filtering on the testing image to remove the possible stego signal. Then the match image is embedded in with recognized steganography algorithms. A CNN model trained on a training set is used to extract deep features from testing image and match images. Computing similarity between features with inner product operation or weighted-chi (2), the final decision is made according to similarity between testing feature and each class of match feature. The proposed scheme can also detect steganography algorithms unknown in training set. Experiments show that, comparing with directly used CNN model, the proposed scheme achieves considerable improvement on testing accuracy when detecting images come from unseen source.	187.91127093908534
1598.	In this paper, we propose an implicit gradient descent algorithm for the classic k-means problem. The implicit gradient step or backward Euler is solved via stochastic fixed-point iteration, in which we randomly sample a mini-batch gradient in every iteration. It is the average of the fixed-point trajectory that is carried over to the next gradient step. We draw connections between the proposed stochastic backward Euler and the recent entropy stochastic gradient descent for improving the training of deep neural networks. Numerical experiments on various synthetic and real datasets show that the proposed algorithm provides better clustering results compared to k-means algorithms in the sense that it decreased the objective function (the cluster) and is much more robust to initialization.	187.91125795019752
1599.	People have become busier in the modern world with both work and housework. In addition to the different types of robotic cleaner, it would be quite helpful to have a smart robotic trash collection and dumping system that provides on-call services so that a user does not need to physically get up and put trash into a trash can. As the bin reaches its maximum capacity, it also dumps the trash automatically without the user's instructions. Available smart trash cans are usually focused on determining if the trash is recyclable. Most trash cans also do not have the capability to move autonomously. In this research, we utilize fingerprint mapping for wireless indoor positioning towards the implementation of an autonomous vehicle with a mounted trash can. The user may make an indoor call to the trash-can-mounted vehicle via a mobile application under an IoT and cloud computing environment. The vehicle can position itself in front of the user for trash collection through automatic obstacle avoidance navigation with smart path planning from deep learning. The system can also monitor the amount of accumulated trash and dump trash at a fixed location before returning to the start point. This research on a smart trash-collecting robot can provide significant assistance to people who are busy, those with impaired or limited movements, and the elderly.	187.91122683631576
1600.	Pavement friction and texture characteristics are important to road surface safety. Despite extensive studies conducted in the last decades, the relationship between pavement texture and surface friction has not been fully understood. This paper implements deep learning (DL) techniques to investigate the application of pavement texture data for pavement skid resistance and safety analysis. High speed texture profiles and grip tester friction data are collected in parallel on high friction surface treatment (HFST) sites including various types of lead-in and lead-out pavement sections distributed in 12 states of the United States. FrictionNet, a convolutional neural network (CNN)-based DL architecture, was developed to predict pavement friction levels directly using texture profiles. This architecture is composed of six artificial neuron layers: two convolution layers, three fully connected layers, and one output layer, with 606,409 tuned hyperparameters. There were 50,400 pairs of texture and friction data sets gathered for training, whereas another 12,600 pairs were gathered for validation and testing. The input of FrictionNet is the spectrogram of original texture profile for 1m segments, and the output is the corresponding friction level ranging from 0.2 to 1.0. FrictionNet achieves 96.85% accuracy for training, 88.92% for validation, and 88.37% for testing in friction prediction. The result demonstrates the potential of using DL methods for highway speed noncontact texture measurements for pavement friction evaluation at the network level.	187.91099502067962
1601.	Precision herbicide application can substantially reduce herbicide input and weed control cost in turfgrass management systems. Intelligent spot-spraying system predominantly relies on machine vision-based detectors for autonomous weed control. In this work, several deep convolutional neural networks (DCNN) were constructed for detection of dandelion (Taraxacum officinale Web.), ground ivy (Glechoma hederacea L.), and spotted spurge (Euphorbia maculata L.) growing in perennial ryegrass. When the networks were trained using a dataset containing a total of 15,486 negative (images contained perennial ryegrass with no target weeds) and 17,600 positive images (images contained target weeds), VGGNet achieved high F-1 scores (>= 0.9278), with high recall values (>= 0.9952) for detection of E. maculata, G. hederacea, and T. officinale growing in perennial ryegrass. The F-1 scores of AlexNet ranged from 0.8437 to 0.9418 and were generally lower than VGGNet at detecting E. maculata, G. hederacea, and T. officinale. GoogleNet is not an effective DCNN at detecting these weed species mainly due to the low precision values. DetectNet is an effective DCNN and achieved high F-1 scores (>= 0.9843) in the testing datasets for detection of T. officinale growing in perennial ryegrass. Moreover, VGGNet had the highest Matthews correlation coefficient (MCC) values, while GoogleNet had the lowest MCC values. Overall, the approach of training DCNN, particularly VGGNet and DetectNet, presents a clear path toward developing a machine vision-based decision system in smart sprayers for precision weed control in perennial ryegrass.	187.91091493457162
1602.	Information about clouds is important for observing and predicting weather and climate as well as for generating and distributing solar power. Most existing approaches extract cloud information from satellite data by classifying individual pixels instead of using closely integrated spatial information, ignoring the fact that clouds are highly dynamic, spatially continuous entities. This paper proposes a novel cloud classification method based on deep learning. Relying on a Convolutional Neural Network (CNN) architecture for image segmentation, the presented Cloud Segmentation CNN (CS-CNN), classifies all pixels of a scene simultaneously rather than individually. We show that CS-CNN can successfully process multispectral satellite data to classify continuous phenomena such as highly dynamic clouds. The proposed approach produces excellent results on Meteosat Second Generation (MSG) satellite data in terms of quality, robustness, and runtime compared to other machine learning methods such as random forests. In particular, comparing CS-CNN with the CLAAS-2 cloud mask derived from MSG data shows high accuracy (0.94) and Heidke Skill Score (0.90) values. In contrast to a random forest, CS-CNN produces robust results and is insensitive to challenges created by coast lines and bright (sand) surface areas. Using GPU acceleration, CS-CNN requires only 25 ms of computation time for classification of images of Europe with 508 x 508 pixels.	187.9106199804366
1603.	Background Gastric cancer is a common kind of malignancies, with yearly occurrences exceeding one million worldwide in 2017. Typically, ulcerous and cancerous tissues develop abnormal morphologies through courses of progression. Endoscopy is a routinely adopted means for examination of gastrointestinal tract for malignancy. Early and timely detection of malignancy closely correlate with good prognosis. Repeated presentation of similar frames from gastrointestinal tract endoscopy often weakens attention for practitioners to result in true patients missed out to incur higher medical cost and unnecessary morbidity. Highly needed is an automatic means for spotting visual abnormality and prompts for attention for medical staff for more thorough examination. Methods We conduct classification of benign ulcer and cancer for gastrointestinal endoscopic color images using deep neural network and transfer-learning approach. Using clinical data gathered from Gil Hospital, we built a dataset comprised of 200 normal, 367 cancer, and 220 ulcer cases, and applied the inception, ResNet, and VGGNet models pretrained on ImageNet. Three classes were defined-normal, benign ulcer, and cancer, and three separate binary classifiers were built-those for normal vs cancer, normal vs ulcer, and cancer vs ulcer for the corresponding classification tasks. For each task, considering inherent randomness entailed in the deep learning process, we performed data partitioning and model building experiments 100 times and averaged the performance values. Results Areas under curves of respective receiver operating characteristics were 0.95, 0.97, and 0.85 for the three classifiers. The ResNet showed the highest level of performance. The cases involving normal, i.e., normal vs ulcer and normal vs cancer resulted in accuracies above 90%. The case of ulcer vs cancer classification resulted in a lower accuracy of 77.1%, possibly due to smaller difference in appearance than those cases involving normal. Conclusions The overall level of performance of the proposed method was very promising to encourage applications in clinical environments. Automatic classification using deep learning technique as proposed can be used to complement manual inspection efforts for practitioners to minimize dangers of missed out positives resulting from repetitive sequence of endoscopic frames and weakening attentions.	187.91054729180138
1604.	Accurate cell conductance tuning is critical to realizing multilevel resistive random access memory (RRAM)-based compute-in-memory inference engines. To tighten the distribution of the cells of each state, we developed a two-step write-verify scheme within a limited number of iterations, which was tested on a test vehicle based on HfO(2)RRAM array to realize 2 bits per cell. The conductance of the cells is gathered in the targeted range within 10 loops of set and reset processes for each step. Moreover, the read noise of the RRAM cells is statistically measured and its impact on the upper bound of analog-to-digital converter (ADC) resolution is predicted. The result shows that the intermediate state cells under relatively high read voltage (e.g. 0.2 V) are vulnerable to the read noise. Fortunately, the aggregated read noise along the column will not disturb the output of a 5 bit ADC that is required for a 128 x 128 array with 2 bits per cell.	187.91051320932604
1605.	The visualization community hosts a number of exciting workshops each year that focus on a diverse range of topics, including the use of virtual reality (VR) in visualization applications, design, and development of data systems for interactive data exploration, consideration of cognitive biases in decision making, integration of deep learning techniques, visualization for digital humanities, strategies for teaching visualization, hands-on approach to scientific discovery, and activities to improve diversity in the visualization community. These workshops represent late-breaking work and research in cutting-edge domains that could lead to new frontiers in visualization research and application.	187.9103988856676
1606.	In recent years, deep learning algorithm based on cyclic neural network and semantic segmentation has performed well in the field of image segmentation. The purpose of this paper is to realize the quality analysis of English text through recurrent neural network and semantic segmentation. This paper proposes an attention based English text quality analysis model based on recurrent neural network. Through the introduction of attention mechanism, the influence of semantics in the text is considered in the analysis of English text quality. The target relies on the quality of English text to determine the text quality of the sentence for a given target object. At present, most English text quality analysis methods are aimed at the traditional semantic analysis tasks. Based on rnn-attention model, a rnnattention-t model is proposed, which introduces the information of the target object while modeling the text. In addition, considering that the influence of the top and bottom of the target object on the semantic trend is usually different, this paper proposes an rnn-attention-c model, which models the top and bottom of the target object respectively. The experimental data have shown that the quality analysis of English text based on recurrent neural network and semantic segmentation is faster than the traditional method. The experimental results have demonstrated that our method can effectively and quickly confirm the quality of English text, which is about 7% faster than the conventional method. (c) 2020 Elsevier B.V. All rights reserved.	187.91010592355312
1607.	This paper reports on a unique practice based learning model to prepare undergraduate nursing students for clinical placement. The learning and teaching model described in this paper outlines the establishment of an entire on-campus simulated hospital and health service (SHHS) at the University of South Australia, School of Nursing and Midwifery. The model is pedagogically structured to immerse students in an authentic clinical environment to achieve deep learning in preparation for safe practice. A quality improvement cycle was used to evaluate the outcomes of the model in two phases: Phase 1: Purposive sampling of first and second year Bachelor of Nursing students from 2012 to 2015 who were surveyed about their satisfaction with the model of learning. Bachelor of Nursing students were invited to complete a survey about their experience with the teaching and learning model employed in the SHHS in response to the question, 'What aspects of the SHHS are the most important to your success?' Phase 2: External clinical stakeholders working with nursing students in clinical placements were asked to respond to questions about the preparedness of students educated in this model to transition to employment. The evaluation showed that the SHHS model positively influenced students satisfaction and confidence and increased the perception of clinicians of the work readiness of students.	187.9099765716695
1608.	A large number of studies that use artificial intelligence (AI) methodologies to analyze medical imaging and support computer-aided diagnosis have been conducted in the biomedical engineering domain. Owing to the advances in dental diagnostic X-ray systems such as panoramic radiographs, periapical radiographs, and dental computed tomography (CT), especially, dual-energy cone beam CT (CBCT), dental image analysis now presents more opportunities to discover new results and findings. Recent researches on dental image analysis have been increasingly incorporating analytics that utilize AI methodologies that can be divided into conventional machine learning and deep learning approaches. This review first covers the theory on dual-energy CBCT and its applications in dentistry. Then, analytical methods for dental image analysis using conventional machine learning and deep learning methods are described. We conclude by discussing the issues and suggesting directions for research in future.	187.909919392558
1609.	To identify topology features of different complex network topology is essential in network science researches. Apart from traditional tools in doing such jobs such as power-law, a proved method of convolutional neural network (CNN) is introduced into this research field after we re-format the complex network topology adjacent matrix into an image. We design a CNN of overall 10 layers comprising convolutional layers, pooling layers and a softmax dense layer at last to extract relevant features and classify such features. Experiments show that the CNN models can effectively extract target features and result in an average accuracy rate of 95.65% in feature classification.	187.9096313175497
1610.	Cheminformatics aims to assist in chemistry applications that depend on molecular interactions, structural characteristics, and functional properties. The arrival of deep learning and the abundance of easily accessible chemical data from repositories like PubChem have enabled advancements in computer-aided drug discovery. Virtual high-throughput screening (vHTS) is one such technique that integrates chemical domain knowledge to perform in silico biomolecular simulations, but prediction of binding affinity is restricted due to limited availability of ground-truth binding assay results. Here, text representations of 83 000 000 molecules are leveraged to perform single-target binding affinity prediction directly on the outcome of screening assays. The embedding of an end-to-end transformer neural network, trained to encode the structural characteristics of a molecule via a text-based translation task, is repurposed through transfer learning to classify binding affinity to single targets with few known binding compounds. We quantify the observed increase in AUC on binding prediction tasks between classifiers trained on the translation embedding versus those using an untrained embedding. Visualization of the embedding space reveals organization of structural and functional properties that aid binding prediction. The pretrained transformer, data, and associated software to extract embeddings are made publicly available at https://github.com/mpcrlab/MolecularTransformerEmbeddings.	187.90947806414192
1611.	Objectives To develop and evaluate a deep learning algorithm for fully automated detection of primary sclerosing cholangitis (PSC)-compatible cholangiographic changes on three-dimensional magnetic resonance cholangiopancreatography (3D-MRCP) images. Methods The datasets of 428 patients (n = 205 with confirmed diagnosis of PSC;n = 223 non-PSC patients) referred for MRI including MRCP were included in this retrospective IRB-approved study. Datasets were randomly assigned to a training (n = 386) and a validation group (n = 42). For each case, 20 uniformly distributed axial MRCP rotations and a subsequent maximum intensity projection (MIP) were calculated, resulting in a training database of 7720 images and a validation database of 840 images. Then, a pre-trained Inception ResNet was implemented which was conclusively fine-tuned (learning rate 10(-3)). Results Applying an ensemble strategy (by binning of the 20 axial projections), the mean absolute error (MAE) of the developed deep learning algorithm for detection of PSC-compatible cholangiographic changes was lowered from 21 to 7.1%. Sensitivity, specificity, positive predictive (PPV), and negative predictive value (NPV) for detection of these changes were 95.0%, 90.9%, 90.5%, and 95.2% respectively. Conclusions The results of this study demonstrate the feasibility of transfer learning in combination with extensive image augmentation to detect PSC-compatible cholangiographic changes on 3D-MRCP images with a high sensitivity and a low MAE. Further validation with more and multicentric data is now desirable, as it is known that neural networks tend to overfit the characteristics of the dataset.	187.90908518301868
1612.	The detection of mathematical expression from PDF documents has been studied and advanced for recent years. In the process, the detection of variables of inline expressions that are represented by alphabetical characters is a challenge. Compared to other components of inline expressions, there are many factors that cause the ambiguities for the detection of variables. In this paper, the error in detecting variables in PDF scientific documents is analytically presented. Novel rules are proposed to improve the accuracy in the detection process. The experimental results on benchmark datasets containing English and Vietnamese documents show the effectiveness of the proposed method. The comparison with existing methods demonstrates the out-performance of the proposed method. Furthermore, pre-trained deep Convolutional Neural Networks are employed and optimized to automatically extract visual features of extracted components from PDF and machine learning algorithms are used to improve the accuracy of the detection.	187.90885926704783
1613.	Code commenting is a common programming practice of practical importance to help developers review and comprehend source code. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of deep learning techniques in the NLP field, many studies focus on using the machine translation model to automatically generate comment for the source code. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for program comprehension due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032 open source projects in our previous study. In this paper, we propose a reinforcement learning-based method, RL-BlockCom, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the abstract syntax tree (i.e., AST) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of reinforcement learning with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the BLEU-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation.	187.9088508029157
1614.	The COVID-19 diagnostic approach is mainly divided into two broad categories, a laboratory-based and chest radiography approach. The last few months have witnessed a rapid increase in the number of studies use artificial intelligence (AI) techniques to diagnose COVID-19 with chest computed tomography (CT). In this study, we review the diagnosis of COVID-19 by using chest CT toward AI. We searched ArXiv, MedRxiv, and Google Scholar using the terms "deep learning", "neural networks", "COVID-19", and "chest CT". At the time of writing (August 24, 2020), there have been nearly 100 studies and 30 studies among them were selected for this review. We categorized the studies based on the classification tasks: COVID-19/normal, COVID-19/non-COVID-19, COVID-19/non-COVID-19 pneumonia, and severity. The sensitivity, specificity, precision, accuracy, area under the curve, and F1 score results were reported as high as 100%, 100%, 99.62, 99.87%, 100%, and 99.5%, respectively. However, the presented results should be carefully compared due to the different degrees of difficulty of different classification tasks.	187.90877220155747
1615.	In this paper we introduce a methodology for the simple integration of almost-independence information on the visible (input) variables of the restricted Boltzmann machines (RBM) into the weight decay regularization of the contrastive divergence and stochastic gradient descent algorithm. After identifying almost independent clusters of the input coordinates by Chow-Liu tree and forest estimation, the RBM regularization strategy is constructed. We show an example of a sparse two hidden layer Deep Belief Net (DBN) applied on the MNIST data classification problem. The performance is quantified by estimating mis-classification rate and measure of manifold disentanglement. Approach is benchmarked to the full model.	187.9087563300148
1616.	Exploring the spatial patterns and temporal dynamics of human brain activities has long been a great topic, yet development of a unified spatial-temporal model for such purpose is still challenging. To better understand brain networks based on fMRI data and inspired by the success in applying deep learning for brain encoding/decoding, we propose a novel deep sparse recurrent auto-encoder (DSRAE) in an unsupervised spatial-temporal way to learn spatial and temporal patterns of brain networks jointly. The proposed DSRAE has been validated on the publicly available human connectome project (HCP) fMRI datasets with promising results. To our best knowledge, the proposed DSRAE is among the early unified models that can extract connectome-scale spatial-temporal networks from 4D fMRI data simultaneously.	187.90871737951716
1617.	Ship classification in remote sensing images has been rarely studied because of relative scarcity of publicly available datasets. It is well known that datasets have played an important role in object classification research, especially for CNN-based algorithms which have been proved to perform well. In this paper, we introduce a public Dataset for Ship Classification in Remote sensing images (DSCR). We collect 1,951 remote sensing images from DOTA, HRSC2016, NWPU VHR-10 and Google Earth, containing warships and civilian ships of various scales. For object classification, we cut out ships of different categories from the collected images. The whole dataset contains about 20,675 instances which are divided into seven categories, i.e. aircraft carrier, destroyer, assault ship, combat ship, cruiser, other military ship and civilian ship. Each image contains ships of the same category, which is labeled by the category name. Since our dataset contains most models of major warships, it is relatively comprehensive for ship classification. To build a benchmark for ship classification, we evaluated six popular CNN-based object classification algorithms on our dataset, including ResNet, ResNext, VGG, GoogLeNet, DenseNet, and AlexNet. Experiments demonstrates that our dataset can be used for verifying ship classification algorithms and may advance the development of ship classification in remote sensing images. DSCR dataset is publicly available at https://github.com/DYH666/DSCR.	187.90864789951968
1618.	In this work, we propose an algorithm for training deep neural networks for classification of breast cancer in histopathological images affected by data unbalance with support of active learning. The output of the neural network on unlabeled samples is used to calculate weighted information entropy. It is utilized as uncertainty score for automatic selecting both samples with high and low confidence. A number of low confidence samples that are selected in each iteration is manually labeled by pathologist. A threshold that decays over iteration number is used to decide which high confidence samples should be concatenated with manually labeled samples and then used in fine-tuning of convolutional neural network. The neural network can optionally be trained using weighted cross-entropy loss to better cope with bias towards the majority class.	187.90856980312864
1619.	Sensitivity of screening mammography is reduced by increased mammographic density (MD). MD can obscure or "mask" developing lesions making them harder to detect. Predicting masking risk may be an effective tool for a stratified screening program where selected women can receive alternative screening modalities that are less susceptible to masking. Here, we investigate whether the use of artificial intelligence can accurately predict the masking risk and compare its performance to that of conventional BI-RADS density classification. The analysis was based on mammograms of 214 subjects comprised of 147 women with a screen-detected (SD) or "non-masked" cancer and 67 that developed a non-screen detected (NSD) or presumably masked cancer within 2 years following a negative screen. Prior to analysis, mammograms were pre-processed into quantitative MD maps using an in-house algorithm. A transfer learning approach was used to train a convolutional neural network (CNN) based on VGG-16 in a seven cross-fold approach to classify masking status. A two-step transfer learning method was also used where the pre-trained CNN was initially trained on 5,865 mammograms to classify by BI-RADS density category and then trained for masking status. Using BI-RADS density as a masking risk predictor has an AUC of 0.64 [0.57 - 0.71 95CI]. The CNN-mask yielded an AUC of 0.76 [0.68 - 0.81]. Combining the CNN-mask with our previous hand-crafted masking risk predictor, the AUC improved to 0.78 [0.70 - 0.83]. The combined AUC improved to 0.81 [0.72 - 0.90] when analysis was restricted to NSD cancers surfacing clinically within one year after a negative screen. The two-step transfer learning yielded similar performance. This work suggests that a CNN masking risk predictor can be used to guide a stratified screening program to overcome the limitations of screening mammography in dense breasts.	187.90856658329426
1620.	Interaction between grain boundaries and impurities usually leads to significant altering of material properties. Understanding the composition-structure-property relationship of grain boundaries is a key avenue for tailoring and designing high performance materials. In this work, we studied segregation of W into ZrB2 grain boundaries by a hybrid method combining Monte Carlo (MC) and molecular dynamics (MD), and examined the effects of segregation on grain boundary strengths by MD tensile testing with a fitted machine learning potential. It is found that W prefers grain boundary sites with local compression strains due to its smaller size compared to Zr. Rich segregation patterns (including monolayer, off-center bilayer, and other complex patterns); segregation induced grain boundary structure reconstruction; and order-disorder like segregation pattern transformation are discovered. Strong segregation tendency of W into ZrB2 grain boundaries and significant improvements on grain boundary strengths are certified, which guarantees outstanding high temperature performance of ZrB2-based UHTCs.	187.90856235541952
1621.	Background Each year in the United States, over 80 million people are affected by acne, atopic dermatitis, rosacea, psoriasis, and impetigo. Artificial intelligence and machine learning could prove to be a good tool for assisting in the diagnosis of dermatological conditions. The objective of this study was to evaluate the use of data augmentation in machine learning image recognition of five dermatological disease manifestations-acne, atopic dermatitis, impetigo, psoriasis, and rosacea. Materials and Methods Open-source dermatological images were gathered and used to retrain TensorFlow Inception version-3. Retraining was done twice-once with and once without data augmentation. Both models were tested with the same images, and R software was used to perform statistical analysis. Results The average of each of the statistical measures (sensitivity, specificity, PPV, NPN, MCC, and F1 Score) increased when data augmentation was added to the model. In particular, the average Matthews correlation coefficient increased by 7.7%. Each of the five dermatological manifestations had an increase in area under the curve (AUC) after data augmentation with the average increase in AUC of 0.132 and a standard deviation of 0.033. Atopic dermatitis had the highest increase in AUC of 0.18. With data augmentation, the lowest AUC was 0.87 for psoriasis and the highest was 0.97 for acne, indicating that the model performs well. Conclusion With a deep learning-based approach, it is possible to differentiate dermatological images with appreciable MCC, F1 score, and AUC. Further, data augmentation can be used to increase the model's accuracy by a significant amount.	187.9084547794953
1622.	Breast cancer risk assessment relies on accurate classification of breast density, which is a key component of the ACR breast cancer screening recommendations for clinical decisions. The 5th edition of the BIRADS standard divides breast density into four categories, ranging from almost entirely fatty to extremely dense. High breast density (classes C and D) reduces the sensitivity of mammography, since the dense fibroglandular tissue can hide lesions, masses and other findings. Therefore, although the benefit of supplementary imaging in such cases has not been conclusively demonstrated, the ACR guidelines suggest additional screening for patients with high breast density. This creates an important treatment decision boundary between class B (scattered areas of fibroglandular density) and class C (heterogeneously dense). Unfortunately, the slightly abstract, qualitative nature of the class descriptions leads to significant inter- and intra-rater variation in breast density assessment. This is exacerbated by updates to the BIRADS standard that can cause recent breast density assessments to be incompatible with prior assessments for the same patient. Additionally, images from similar patients can vary significantly when taken with different devices or at sites with different acquisition protocols. To address these issues, we present a new deep learning algorithm combining three models that achieves accurate and objective breast density classification. The first model performs the normal four-class breast density classification, the second model performs a two-class low (A or B) vs. high (C or D) classification, and the third patch-based model focuses on improving the accuracy of the B and C categories. We present initial results from 9989 studies from a three-site dataset with BIRADS 4th and 5th edition ground truth.	187.9083721020181
1623.	It is a reliable way to judge gastric cancer by pathological section. Using deep learning method to detect medical images, as an auxiliary diagnosis method, it can improve the speed and accuracy of doctors to diagnose gastric cancer, and reduce misdiagnosis and missed diagnosis. Mask R-CNN is the latest method in the related field at the beginning of the research. It is mainly used to segment the objects in daily life and achieve good results. The medical image is very different from the scene in life, and the detection effect is also weakened. We use the Mask R-CNN method to detect the pathological sections of gastric cancer, and segment the cancer nest, and then optimize it by adjusting parameters. The method finally allows it to obtain a test result with an AP value of 61.2 when detecting medical images.	187.9083640841585
1624.	Natural language processing (NLP) is an interdisciplinary field, combining linguistics, computer science, and artificial intelligence to enable machines to read and understand human language for meaningful purposes. Recent advancements in deep learning have begun to offer significant improvements in NLP task performance. These techniques have the potential to create new automated tools that could improve clinical workflows and unlock unstructured textual information contained in radiology and clinical reports for the development of radiology and clinical artificial intelligence applications. These applications will combine the appropriate application of classic linguistic and NLP preprocessing techniques, modern NLP techniques, and modern deep learning techniques.	187.90826899251198
1625.	Purpose In engineering practice many structures are assembled by several linear components through nonlinear joints. A novel hybrid modeling method based on finite element model reduction and deep learning techniques is proposed to meet the ever-increasing requirements of efficient and accurate modeling for nonlinear jointed structures. Methods The main idea of the hybrid modeling method for nonlinear jointed structures is summarized as follows: Firstly, finite element models of linear components are reduced to improve the computing efficiency using the free-interface mode synthesis method, as numerical integration of governing equations of nonlinear structures with large numbers of degrees-of-freedom is always time-consuming. Secondly, deep neural networks are used to equivalently represent the nonlinear joints which are difficult to describe by accurate and physically-motivated models, so as to avoid the errors caused by traditional mechanism modeling or system identification. Nonlinear joints are finally replaced with their equivalent neural networks and connected with the substructure models of linear components through the compatibility of displacements and equilibrium of forces at the interfaces. Results and Conclusions The performance of the proposed hybrid modeling method is tested and assessed via a case study focused on a cantilever plate with nonlinear joints. Comparative results demonstrate the capability of the proposed method for efficient and accurate modeling of nonlinear jointed structures and predicting their intrinsic nonlinear behavior.	187.90798067397628
1626.	Rationale and Objectives: Breast segmentation using the U-net architecture was implemented and tested in independent validation datasets to quantify fibroglandular tissue volume in breast MRI. Materials and Methods: Two datasets were used. The training set was MRI of 286 patients with unilateral breast cancer. The segmentation was done on the contralateral normal breasts. The ground truth for the breast and fibroglandular tissue (FGT) was obtained by using a template-based segmentation method. The U-net deep learning algorithm was implemented to analyze the training set, and the final model was obtained using 10-fold cross-validation. The independent validation set was MRI of 28 normal volunteers acquired using four different MR scanners. Dice Similarity Coefficient (DSC), voxel-based accuracy, and Pearson's correlation were used to evaluate the performance. Results: For the 10-fold cross-validation in the initial training set of 286 patients, the DSC range was 0.83-0.08 (mean 0.95 +/- 0.02) for breast and 0.73-0.97 (mean 0.91 +/- 0.03) for FGT; and the accuracy range was 0.92-0.99 (mean 0.98 +/- 0.01) for breast and 0.87-0.99 (mean 0.97 +/- 0.01) for FGT. For the entire 224 testing breasts of the 28 normal volunteers in the validation datasets, the mean DSC was 0.86 +/- 0.05 for breast, 0.83 +/- 0.06 for FGT; and the mean accuracy was 0.94 +/- 0.03 for breast and 0.93 +/- 0.04 for FGT. The testing results for MRI acquired using four different scanners were comparable. Conclusion: Deep learning based on the U-net algorithm can achieve accurate segmentation results for the breast and FGT on MRI. It may provide a reliable and efficient method to process large number of MR images for quantitative analysis of breast density.	187.90795931729468
1627.	This study developed three types of deep belief network (DBN)-based models to estimate NOx emission in coal-fired power plants by a new data acquisition method. Based on the experimental data obtained by field experiments, the validated Fluent-based simulation results and the historical operating data from a database are used in the model calculations. Using mutual information, the model input set is optimized by the feature selection method. With the optimal inputs, three types of DBN-based NOx prediction models are constructed, in which the extreme learning machine, back propagation network, and radial basis function network are below the top layer of the DBN to serve as the regression model. The results indicate that the DBN-based models have a greater prediction accuracy with 0.93,0.9, and 0.89 coefficients of determination and greater robustness compared to the three other NOx prediction models.	187.90789858229766
1628.	In the near future, the fifth-generation wireless technology is expected to be rolled out, offering low latency, high bandwidth and multiple antennas deployed in a single access point. This ecosystem will help further enhance various location-based scenarios such as assets tracking in smart factories, precise smart management of hydroponic indoor vertical farms and indoor way-finding in smart hospitals. Such a system will also integrate existing technologies like the Internet of Things (IoT), WiFi and other network infrastructures. In this respect, 5G precise indoor localization using heterogeneous IoT technologies (Zigbee, Raspberry Pi, Arduino, BLE, etc.) is a challenging research area. In this work, an experimental 5G testbed has been designed integrating C-RAN and IoT networks. This testbed is used to improve both vertical and horizontal localization (3D Localization) in a 5G IoT environment. To achieve this, we propose the DEep Learning-based co-operaTive Architecture (DELTA) machine learning model implemented on a 3D multi-layered fingerprint radiomap. The DELTA begins by estimating the 2D location. Then, the output is recursively used to predict the 3D location of a mobile station. This approach is going to benefit use cases such as 3D indoor navigation in multi-floor smart factories or in large complex buildings. Finally, we have observed that the proposed model has outperformed traditional algorithms such as Support Vector Machine (SVM) and K-Nearest Neighbor (KNN).	187.90778574674096
1629.	Super resolution (SR) reconstruction and pixel interpolation are profitable technologies to acquire high resolution (HR) images from low resolution images. However, implementing the same interpolation or SR algorithms in different color spaces may still produce diverse results. Therefore, this study aimed to systematically investigate how the selection of color spaces take effect in the process of increasing image resolution. The resolution enhancement means involved an SR algorithm based on classified dictionary learning proposed by us and an SR algorithm based on deep learning with convolutional neural networks, as well as three typical pixel interpolation algorithms of bicubic, bilinear, and nearest. The evaluated color spaces involved RGB, YCbCr, YIQ, HSV, HSI, and CIELAB, which produced corresponding color coordinate systems. Based on the numerical measures of the peak signal to noise ratio (PSNR) and the color difference formula CIEDE2000 calculated between the original HR images and the processed versions, the results indicate that, YCbCr, YIQ, and CIELAB are suitable mapping spaces for resolution enhancement operations, and only the coordinate of bright and dark information is the dimension that need to be reconstructed by SR methods. Besides, color spaces with perceptual parameters of hue, brightness/lightness, and colorfulness/chroman/saturation are not suitable neither for SR reconstruction nor for pixel interpolation, which would cause severe color distortions. Thus, for preferable image effect, the recommended strategies are implementing SR algorithms for merely L* coordinate of CIELAB space or merely Y coordinate of YCbCr and YIQ systems, while the other two coordinates use the bicubic interpolation algorithm.	187.9077123194378
1630.	Deep Learning is expanding in the detection and diagnosis of abnormalities, including coronary artery calcification (CAC), in CT. CACs can also be visualized on low-dose thoracic screening CTs (LDCT), and thus, in this study, deep learning is investigated for the detection of CACs and assessment of their severity on LDCT images. The study dataset included 863 LDCT cases, each assigned a case severity score, which is related to the Agatston score, ranging between 0 and 12 (0 = no CAC present, 12 = severe CACs). Within the cardiac region, 224 x 224 pixel ROIs were extracted from each CT slice and input to a convolutional neural network (CNN). CNN-based features were extracted using a pre-trained VGG19 and merged with a support vector machine (SVM) yielding a slice likelihood score of the presence of CACs. Case prediction scores were obtained by using the maximum and mean scores of all slices belonging to that case. Area under the ROC curve (AUC) was used as a metric to assess the discrimination performance level. Using a randomly selected subset of images containing similar amounts of each severity subtype, the SVM performed better using the max slice score per case (AUC = 0.79, standard error = 0.03). While this AUC value does not reach those found in similar studies for diagnostic CT and cardiac CT angiography, this study demonstrates potential for deep learning use in LDCT screening programs.	187.9077013856284
1631.	How to use high-resolution remote sensing images to quickly and accurately obtain high-value target information such as aircraft and ships has become a hot topic in the research of automatic target detection. This paper uses Google Earth image to make aircraft data set, then detect the aircraft targets respectively based on the two deep learning models YOLOv3 and Faster_R_CNN. At the same time, in order to significantly improve the aircraft detection accuracy, this paper proposes a shadow processing algorithm with double threshold random sampling to conduct data preprocessing for aircraft targets in remote sensing images. The experimental results show that both deep learning models can effectively detect aircraft targets and have great application potential in automatic detection of remote sensing image targets. The shadow processing algorithm can effectively eliminate the projected shadow of the aircraft, restore the texture characteristics of the shaded area, greatly improve the overall quality of the remote sensing image, and lay a good data foundation for subsequent aircraft detection.	187.90769213706872
1632.	Lameness has a considerable influence on the welfare and health of dairy cows. Many attempts have been made to develop automatic lameness detection systems using computer vision technology. However, these detection methods are easily affected by the characteristics of individual cows, resulting in inaccurate detection of lameness. Therefore, this study explores an individualized lameness detection method for dairy cattle based on the supporting phase using computer vision. This approach is applied to eliminate the influence of the characteristics of individual cows and to detect lame cows and lame hooves. In this paper, the correlation coefficient between lameness and the supporting phase is calculated, a lameness detection algorithm based on the supporting phase is proposed, and the accuracy of the algorithm is verified. Additionally, the reliability of this method using computer vision technology is verified based on deep learning. One hundred naturally walking cows are selected from video data for analysis. The results show that the correlation between lameness and the supporting phase was 0.864; 96% of cows were correctly classified, and 93% of lame hooves were correctly detected using the supporting phase-based lameness detection algorithm. The mean average precision is 87.0%, and the number of frames per second is 83.3 when the Receptive Field Block Net Single Shot Detector deep learning network was used to detect the locations of cow hooves in the video. The results show that the supporting phase-based lameness detection method proposed in this paper can be used for the detection and classification of cow lameness and the detection of lame hooves with high accuracy. This approach eliminates the influence of individual cow characteristics and could be integrated into an automatic detection system and widely applied for the detection of cow lameness.	187.90745501910573
1633.	A new goal for medical informatics is to develop robust tools that integrate clinical data on a patient in order to estimate the risk of imminent adverse events. This new field of predictive analytics monitoring is growing very quickly. Its claims, however, can be vulnerable when clinicians fail to use the best mathematical and statistical tools, when quantitative scientists fail to grasp the nuances of clinical medicine, and when either fails to incorporate knowledge of physiology. Its potential, though is clear: we can provide more effective clinical decision support and make better predictive analytics monitoring tools if we apply principles learned from physiology and mathematics to the right problems in clinical medicine. (C) 2018 Elsevier Inc. All rights reserved.	187.90745249091364
1634.	Dense registration of fingerprints is a challenging task due to elastic skin distortion, low image quality, and self-similarity of ridge pattern. To overcome the limitation of handcraft features, we propose to train an end-to-end network to directly output pixel-wise displacement field between two fingerprints. The proposed network includes a siamese network for feature embedding, and a following encoder-decoder network for regressing displacement field. By applying displacement fields reliably estimated by tracing high quality fingerprint videos to challenging fingerprints, we synthesize a large number of training fingerprint pairs with ground truth displacement fields. In addition, based on the proposed registration algorithm, we propose a fingerprint mosaicking method based on optimal seam selection. Registration and matching experiments on FVC2004 databases, Tsinghua Distorted Fingerprint (TDF) database, and NIST SD27 latent fingerprint database show that our registration method outperforms previous dense registration methods in accuracy. Mosaicking experiments on FVC2004 DB1_A and a small fingerprint database demonstrate that the proposed algorithm produced higher quality fingerprints and led to higher matching accuracy, which also validates the performance of our registration algorithm.	187.90744858079802
1635.	Background and Objectives: Detection and classification of pulmonary nodules are critical tasks in medical image analysis. The Lung Image Database Consortium (LIDC) database is a widely used resource for small pulmonary nodule classification research. This dataset is comprised of nodule characteristic evaluations and CT scans of patients. Although these characteristics are utilized in several studies, they can be used to improve classification performance. Methods: Numerous methods have been proposed to classify malignancy, but there are not many studies that facilitate nodule characteristics in classification steps. In this study, we use information on nodule characteristics and propose cascaded classification schemes. A group of hand-crafted features and deep features are used to define the nodules. In the first step of the classifier, the nodule characteristics are classified based on individual base classifiers. In the second step, the results of the first level classifier are combined for use in malignancy classification. In addition, stacking methods are applied to improve the performance of the cascaded classifiers. Results: The results confirmed that combining deep and hand-crafted features contribute to classification performance with an 8% improvement in average classification accuracy, 9% improvement in sensitivity, and 3% in specificity. Deep features from a nodule bounding area are more descriptive than the exact nodule region. The best performing cascaded classifier featured a classification accuracy of 84.70%, sensitivity of 67.37%, and specificity of 95.46%. First level stacking demonstrated similar results on classification accuracy and specificity but sensitivity was measured at 75.59%. Stacking on both levels provided the best classification accuracy and specificity with scores of 86.98% and 96.06%, respectively. When the malignancy ratings were grouped, stacking on both levels demonstrated better performance than other methods with a classification accuracy of 88.80%, sensitivity of 88.41%, and specificity of 94.12%. Conclusions: Information on cascading characteristics with image features is beneficial for the classification of the malignancy ratings. Stacking approaches on both levels demonstrate better classification accuracy, but in the context of sensitivity, first level stacking performs better. Grouping the malignancy ratings results in better classification outcomes as in the case of similar studies in the literature. (C) 2018 Elsevier B.V. All rights reserved.	187.90741173909709
1636.	Result relevance scoring is critical to e-commerce search user experience. Traditional information retrieval methods focus on keyword matching and hand-crafted or counting-based numeric features, with limited understanding of item semantic relevance. We describe a highly-scalable feed-forward neural model to provide relevance score for (query, item) pairs, using only user query and item title as features, and both user click feedback as well as limited human ratings as labels. Several general enhancements were applied to further optimize eval/test metrics, including Siamese pairwise architecture, random batch negative co-training, and point-wise fine-tuning. We found significant improvement over GBDT baseline as well as several off-the-shelf deep-learning baselines on an independently constructed ratings dataset. The GBDT model relies on 10 times more features. We also present metrics for select subset combinations of techniques mentioned above.	187.90739917029228
1637.	Outdoor ultrafine particles (UFPs) (<0.1m) may have an important impact on public health but exposure assessment remains a challenge in epidemiological studies. We developed a novel method of estimating spatiotemporal variations in outdoor UFP number concentrations and particle diameters using street-level images and audio data in Montreal, Canada. As a secondary aim, we also developed models for noise. Convolutional neural networks were first trained to predict 10-second average UFP/noise parameters using a large database of images and audio spectrogram data paired with measurements collected between April 2019 and February 2020. Final multivariable linear regression and generalized additive models were developed to predict 5-minute average UFP/noise parameters including covariates from deep learning models based on image and audio data along with outdoor temperature and wind speed. The best performing final models had mean cross-validation R2 values of 0.677 and 0.523 for UFP number concentrations and 0.825 and 0.735 for UFP size using two different test sets. Audio predictions from deep learning models were stronger predictors of spatiotemporal variations in UFP parameters than predictions based on street-level images; this was not explained only by noise levels captured in the audio signal. All final noise models had R2 values above 0.90. Collectively, our findings suggest that street-level images and audio data can be used to estimate spatiotemporal variations in outdoor UFPs and noise. This approach may be useful in developing exposure models over broad spatial scales and such models can be regularly updated to expand generalizability as more measurements become available.	187.90729610580172
1638.	The problem of recognition of emotions in humans is still open from a few aspects. In our study, we used a deep learning method named stacked autoencoder to classify regions of four emotional states in valencearousal plane (high valence-low arousal, high valence-high arousal, low valence-low arousal, and low valence-high arousal). We used a number of physiological signals, including electroencephalogram (EEG), electromyogram (EMG), and other peripheral signals from the DEAP database and extracted spectral and time features from these signals. Also, nonlinear features were extracted from EEG. Then these features were imported to multiple stacked autoencoders in a parallel form (PSAE) to primarily classify four emotional regions in a valence-arousal plane. The final decision about classification was performed using the majority voting method. The average accuracy for classifying four emotional regions from the valence arousal plane, i.e., low arousal and low valence (LALV), low arousal and high valence (LAHV), high arousal and high valence (HAHV), and high arousal and low valence (HALV), reached 93.6%. This result shows that our proposed method demonstrates certain advantages in solving the classification problem; probably, it can also be used for other classification problems.	187.90722222081425
1639.	Companies market their services and products on social media platforms with today's easy access to the internet. As result, they receive feedback and reviews from their users directly on their social media sites. Reading every text is time-consuming and resource-demanding. With access to technology-based solutions, analyzing the sentiment of all these texts gives companies an overview of how positive or negative users are on specific subjects will minimize losses. In this paper, we propose a deep learning approach to perform sentiment analysis on reviews using a convolutional neural network model, because that they have proven remarkable results for text classification. We validate our convolutional neural network model using large-scale data sets: IMDB movie reviews and Reuters data sets with a final accuracy score of similar to 86% for both data sets.	187.90715332392418
1640.	Heart failure with preserved ejection fraction (HFpEF) is a complex, heterogeneous syndrome in need of improved classification given its high morbidity and mortality and few effective treatment options. HFpEF represents an ideal setting to examine the utility and feasibility of a precision medicine approach. This article (based on the 20th annual Feigenbaum Lecture, presented at the 2019 American Society of Echocardiography Scientific Sessions) describes the utility of echocardiography as a "digital biopsy'' and how deep quantitative echocardiographic phenotyping, coupled with machine learning, can be used to identify novel HFpEF phenotypes. The cellular and ultrastructural basis of abnormal speckle-tracking echocardiography-(STE-) based measurements of cardiac mechanics can provide a window into cardiomyocyte calcium homeostasis. STE-based measurements of longitudinal strain can thus inform the extent of myocardial involvement in patients with HFpEF, which may help to determine responsiveness to cardiac-specific HF medications. However, classifying the complex, systemic, multiorgan nature of HFpEF appropriately likely requires more advanced methods. Using unsupervised machine learning, HFpEF can be classified into three distinct phenogroups with differing clinical and echocardiographic characteristics and outcomes: (1) natriuretic peptide deficiency syndrome; (2) extreme cardiometabolic syndrome; and (3) right ventricle-cardio-abdomino-renal syndrome. Each can be probed to determine their biological basis. The goal of improved classification of HFpEF is to match the right patient with the right treatment, with the hope of improving the track record of HFpEF clinical trials. This article emphasizes the central role of echocardiography in advancing precision medicine and illustrates the integration of basic, translational, clinical, and population research in echocardiography with the goal of better understanding the pathobiology of a complex cardiovascular syndrome.	187.90706615014145
1641.	Weather prediction task remains a challenging problem in computer vision field although some solutions have been used for many applications such as air/sea transportation. The increasing requirement toward safer human transportation that requires a robust weather prediction model has motivated the development of a vast number of weather prediction models. In the past decade, the advent of deep learning methods has opened up a new approach to weather prediction, mainly in two areas: automated learning hierarchical representation of weather data and robust weather prediction models. This paper presents a method for automatic feature extraction from weather time series data using Autoencoder model. The learned weather representation was used to train Long Short-term Memory model as a prediction model or regressor. Although it can be used to predict many other weather variables, in this study, the proposed model was tested to predict temperature, dew point, and humidity. The results show that the model performance measured by training and testing RMSE values are as follows. Predicting temperature: AE90-LSTM model (0.00003, 0.00010) and predicting dew point: AE199-LSTM model (0.00005, 0.00010). Interestingly, for predicting humidity 100LSTM model (0.00004, 0.00001) and AE100-LSTM model (0.00001, 0.00008) achieved almost similar performance.	187.9069330186362
1642.	In this paper, we aim to provide a survey on the applications of deep learning for cancer detection and diagnosis and hope to provide an overview of the progress in this field. In the survey, we firstly provide an overview on deep learning and the popular architectures used for cancer detection and diagnosis. Especially we present four popular deep learning architectures, including convolutional neural networks, fully convolutional networks, auto-encoders, and deep belief networks in the survey. Secondly, we provide a survey on the studies exploiting deep learning for cancer detection and diagnosis. The surveys in this part are organized based on the types of cancers. Thirdly, we provide a summary and comments on the recent work on the applications of deep learning to cancer detection and diagnosis and propose some future research directions. (C) 2018 Published by Elsevier Ltd.	187.90685189845954
1643.	The interaction between the gird and wind farms has significant impact on the power grid, therefore prediction of the interaction between gird and wind farms is of great significance. In this paper, a wind turbine-gird interaction prediction model based on long short term memory (LSTM) network under the TensorFlow framework is presented. First, the multivariate time series was screened by principal component analysis (PCA) to reduce the data dimensionality. Secondly, the LSTM network is used to model the nonlinear relationship between the selected sequence of wind turbine network interactions and the actual output sequence of the wind farms, it is proved that it has higher accuracy and applicability by comparison with single LSTM model, Autoregressive Integrated Moving Average (ARIMA) model and Back Propagation Neural Network (BPNN) model, the Mean Absolute Percentage Error (MAPE) is 0.617%, 0.703%, 1.397% and 3.127%, respectively. Finally, the Prony algorithm was used to analyze the predicted data of the wind turbine-grid interactions. Based on the actual data, it is found that the oscillation frequencies of the predicted data from PCA-LSTM model are basically the same as the oscillation frequencies of the actual data, thus the feasibility of the model proposed for analyzing interaction between grid and wind turbines is verified.	187.9066531932047
1644.	A novel method based on a double branch deep fusion convolution neural network (DDFnet) is developed to classify dried jujubes. First, the structure of the network is designed as double branches. In one branch, the dataset of the jujubes is pre-trained with a model trained by a Squeezenet network on a large-scale ImageNet dataset. The other branch is founded on the structure of Squeezenet, which is composed of fire modules. The feature maps that are output by squeeze and expand convolution layers are fused into fusion modules. Next, a model trained on the dataset with DDFnet is used to achieve the multi-classification of jujubes. Finally, the dataset is classified by the model; it shows good performance with high accuracy rates of 99.6 %, 99.8 %, 98.5 %, and 99.2 % for the classification of plump, wizened, cracked, and defective jujubes, respectively. This research demonstrates the feasibility of DDFnet for sorting dried jujubes and enhancing product quality.	187.90648878786877
1645.	Conventional bioaerosol sensing requires the sampled aerosols in the field to be transferred to a laboratory for manual inspection, which can be rather costly and slow, also requiring a professional for labeling and microscopic examination of the samples. Here we demonstrate label-free bioaerosol sensing using a field-portable and cost-effective device based on holographic microscopy and deep-learning, which screens bioaerosols at a throughput of 13 L/min. Two different deep neural networks are designed to rapidly reconstruct the amplitude and phase images of the captured bioaerosols, and to classify the type of each bioaerosol that is imaged. As a proof-of-concept, we studied label-free sensing of common bioaerosol types, for example, Bermuda grass pollen, oak tree pollen, ragweed pollen, Aspergillus spore, and Alternaria spore and achieved >94% classification accuracy. The presented label-free bioaerosol measurement device, with its mobility and cost-effectiveness, will find several applications in indoor and outdoor air quality monitoring.	187.90644807079522
1646.	Ice accretion on wind turbine blades is one of the major faults affecting the operational safety and power generation efficiency of wind turbines. Current icing detection methods are based on either meteorological observing system or extra condition monitoring system. Compared with current methods, icing detection using the intrinsic supervisory control and data acquisition (SCADA) data of wind turbines has plenty of potential advantages, such as low cost, high stability, and early icing detection ability. However, there have not been deep investigations in this field at present. In this paper, a novel intelligent wind turbine blade icing detection method based on the wind turbine SCADA data is proposed. This method consists of three processes: SCADA data preprocessing, automatic feature extraction, and ensemble icing detection model construction. Specifically, deep autoencoders network is employed to learn multilevel fault features from the complex SCADA data adaptively. And the ensemble technique is utilized to make full use of all the extracted features from different hidden layers of the deep autoencoders network to build the ensemble icing detection model. The effectiveness of the proposed method is validated using the data collected from actual wind farms. The experimental results reveal that the proposed method is able to not only adaptively extract valuable fault features from the complex SCADA data, but also obtains higher detection accuracy and generalization capability compared with conventional machine learning models and individual deep learning model.	187.90640149643508
1647.	The frequent hazy weather in North China has drawn people's attention. The anthropogenic emission by fossil fuel power plants is one of the main pollution resource, so the environmental protection administration need to monitor power plants. Thus, a power plant detection system is needed to locate power plants and judge their working status. In this paper, we propose a power plant monitoring framework based on Feature Pyramid Network (FPN) to automatically detect the chimneys and condensing towers of the power plants and judge their working status in high resolution remote sensing images (RSIs). We improve the original FPN by changing the number of layers and scales of feature pyramid to get better performance. Experimental results show that our improved FPN framework can effectively detect the chimneys and condensing towers of fossil-fuel power plants and judge their working status with mean average precision up-to 0.8591, showing good potential for power plant monitoring.	187.9063943510056
1648.	The detection of programming language for a source code file has achieved high accuracy using the machine learning techniques. On the other hand, for a piece of software (called snippet), the detection of programming language is required to append tags automatically in a question and answer site such as Stack Overflow. However, the detection of programming language for a snippet is still a challenge since snippets is not a complete source code. Usually, experienced developers can detect the language of such snippet at a glance. It is considered that such a task that a human being easily solves can be solved by the image classification method using deep learning technique. Therefore, we propose a programming language detection method using a deep learning based image classification method. By using the data from actual Q&A site, we evaluate our proposed model. The results of experiment demonstrate that we can successfully detect the correct programming language for snippets with over 90% accuracy.	187.90629528182876
1649.	Reconstructing 3D ventricular surfaces from 2D cardiac MR data is challenging due to the sparsity of the input data and the presence of interslice misalignment. It is usually formulated as a 3D mesh fitting problem often incorporating shape priors and smoothness regularization, which might affect accuracy when handling pathological cases. We propose to formulate the 3D reconstruction as a volumetric mapping problem followed by isosurfacing from dense volumetric data. Taking advantage of deep learning algorithms, which learn to predict each voxel label without explicitly defining the shapes, our method is capable of generating anatomically meaningful surfaces with great flexibility. The sparse 3D volumetric input can process contours with any orientations and thus can utilize information from multiple short- and long-axis views. In addition, our method can provide correction of motion artifacts. We have validated our method using a statistical shape model on reconstructing 3D shapes from both spatially consistent and misaligned input data.	187.90619571022035
1650.	Artificial intelligence (AI) advancements have significant implications for medical imaging. Stroke is the leading cause of disability and the fifth leading cause of death in the United States. AI applications for stroke imaging are a topic of intense research. AI techniques are well-suited for dealing with vast amounts of stroke imaging data and a large number of multidisciplinary approaches used in classification, risk assessment, segmentation tasks, diagnosis, prognosis, and even prediction of therapy responses. This article addresses this topic and seeks to present an overview of machine learning and/or deep learning applied to stroke imaging.	187.90607632404988
1651.	Stroke is a leading cause of mortality and disability worldwide, expected to result in 61 million disability-adjusted life-years in 2020. Rapid diagnostics is the core of stroke management for early prevention and medical treatment. Serum metabolic fingerprints (SMFs) reflect underlying disease progression, predictive of patient phenotypes. Deep learning (DL) encoding SMFs with clinical indexes outperforms single biomarkers, while posing challenges with poor prediction to interpret by feature selection. Herein, rapid computer-aided diagnosis of stroke is performed using SMF based multi-modal recognition by DL, to combine adaptive machine learning with a novel feature selection approach. SMFs are extracted by nano-assisted laser desorption/ionization mass spectrometry (LDI MS), consuming 100 nL of serum in seconds. A multi-modal recognition is constructed by integrating SMFs and clinical indexes with an enhanced area under curve (AUC) up to 0.845 for stroke screening, compared to single-modal diagnosis by only SMFs or clinical indexes. The prediction of DL is addressed by selecting 20 key metabolite features with differential regulation through a saliency map approach, shedding light on the molecular mechanisms in stroke. The approach highlights the emerging role of DL in precision medicine and suggests an expanding utility for computational analysis of SMFs in stroke screening.	187.90596928510638
1652.	Cardiac magnetic resonance imaging (CMRI) provides high resolution images ideal for assessing cardiac function and diagnosis of cardiovascular diseases. To assess cardiac function, estimation of ejection fraction, ventricular volume, mass and stroke volume are crucial, and the segmentation of left ventricle from CMRI is the first critical step. Fully convolutional neural network architectures have proved to be very efficient for medical image segmentation, with U-Net inspired architecture as the current state-of-the-art. Generative adversarial networks (GAN) inspired architectures have recently gained popularity in medical image segmentation with one of them being SegAN, a novel end-to-end adversarial neural network architecture. In this paper, we investigate SegAN with three different types of U-Net inspired architectures for left ventricle segmentation from cardiac MRI data. We performed our experiments on the 2017 ACDC segmentation challenge dataset. Our results show that the performance of U-Net architectures is better when trained in the SegAN framework than when trained stand-alone. The mean Dice scores achieved for three different U-Net architectures trained in the SegAN framework was on the order of 93.62%, 92.49% and 94.57%, showing a significant improvement over their Dice scores following stand-alone training - 92.58%, 91.46% and 93.81%, respectively.	187.90595297788397
1653.	The research paper purports to assess the antecedents that affect users' behavioral intention to use wearable payment. Specifically, this empirical research examines the roles of perceived aesthetics, technology readiness, mobile usefulness, and mobile ease of use on behavioral intention. Differing from past mobile payment studies, a newly proposed methodology that involves a dual-stage analysis and an emerging Artificial Intelligence analysis named deep learning was performed on 307 usable responses. Findings revealed that all relationships were supported except for the linkage between mobile ease of use and behavioral intention. The results of this study provide valuable insights to payment companies and smart wearable device manufacturers to come up with plans and marketing strategies to convince the potential adopters to adopt wearable payment, guiding marketers to design a more successful wearable payment solution. Theoretically, the newly integrated theoretical model that incorporates Mobile Technology Acceptance Model, Fashion Theory, and Technology Readiness Theory could help ascertain the relative significance of certain determinants, providing a clearer insight on the acceptance of wearable payment among consumers. (C) 2020 Elsevier Ltd. All rights reserved.	187.90591803687067
1654.	Influencers are non-celebrity individuals who gain popularity on social media by posting visually attractive content (e.g., photos and videos) and by interacting with other users (i.e., Followers) to create a sense of authenticity and friendship. Brands partner with Influencers to garner engagement from their target consumers in a new marketing strategy known as "Influencer marketing." Nonetheless, the theoretical underpinnings of such remains unknown. We suggest a new conceptual framework of "Visual-Congruence-induced Social Influence (VCSI)," which contextualizes the Similarity-Attraction Model in the Social Influence literature. Using VCSI, we delineate how Influencers use visual congruence as representations of shared interests in a specific area to build strong bonds with Followers. This intimate affiliation catalyzes (i.e., mediates) the positive effects of visual congruence on Followers' brand engagement. To test these hypotheses, we conducted in vivo observations of Influencer marketing on Instagram. We collected 45,000 images and social media usage behaviors over 26 months. We then applied deep-learning algorithms to automatically classify each image and used social media analytics to disclose hidden associations between visual elements and brand engagement. Our hypothesis testing results provide empirical support for VCSI, advancing theories into the rapidly growing fields of multimodal content and Influencer marketing.	187.90583716922626
1655.	A healthy sleep structure is clinically very important for overall health. The sleep structure can be represented by the percentage of different sleep stages during the total sleep time. In this study, we proposed a method for automatic classification of sleep stages from an electrocardiogram (ECG) signal using a gated-recurrent unit (GRU). The proposed method performed multiclass classification for three-class sleep stages such as awake, light, and deep sleep. A deep structured GRU was used in the proposed method, which is a common recurrent neural network. The proposed deep learning (SleepGRU) model consists of a 5-layer GRU and is optimized by batch-normalization, dropout, and Adam update rules. The ECG signal was recorded during nocturnal polysomnography from 112 subjects, and was normalized and segmented into units of 30-second duration. To train and evaluate the proposed method, the training set consisted of 80,316 segments from 89 subjects, and the test set used 20,079 segments from 23 subjects. We achieved good performances with an overall accuracy of 80.43% and F1-score of 80.07% for the test set. The proposed method can be an alternative and useful tool for sleep monitoring and sleep screening, which have previously been manually evaluated by a sleep technician or sleep expert.	187.90582008408327
1656.	Ensembles of deep convolutional neural networks (CNNs), which integrate multiple deep CNN models to achieve better generalization for an artificial intelligence application, now play an important role in ensemble learning due to the dominant position of deep learning. However, the usage of ensembles of deep CNNs is still not adequate because the increasing complexity of deep CNN architectures and the emerging data with large dimensionality have made the training stage and testing stage of ensembles of deep CNNs inevitably expensive. To alleviate this situation, we propose a new approach that finds multiple models converging to local minima in subparameter space for ensembles of deep CNNs. The subparameter space here refers to the space constructed by a partial selection of parameters, instead of the entire set of parameters, of a deep CNN architecture. We show that local minima found in the subparameter space of a deep CNN architecture can in fact be effective for ensembles of deep CNNs to achieve better generalization. Moreover, finding local minima in the subparameter space of a deep CNN architecture is more affordable at the training stage, and the multiple models at the found local minima can also be selectively fused to achieve better ensemble generalization while limiting the expense to a single deep CNN model at the testing stage. Demonstrations of MobilenetV2, Resnet50 and InceptionV4 (deep CNN architectures from lightweight to complex) on ImageNet, CIFAR-10 and CIFAR-10 0, respectively, lead us to believe that finding local minima in the subparameter space of a deep CNN architecture could be leveraged to broaden the usage of ensembles of deep CNNs. (C) 2020 Elsevier Ltd. All rights reserved.	187.90570014980972
1657.	BACKGROUND: Hypertension (HPT) occurs when there is increase in blood pressure (BP) within the arteries, causing the heart to pump harder against a higher afterload to deliver oxygenated blood to other parts of the body. PURPOSE: Due to fluctuation in BP, 24-h ambulatory blood pressure monitoring has emerged as a useful tool for diagnosing HPT but is limited by its inconvenience. So, an automatic diagnostic tool using electrocardiogram (ECG) signals is used in this study to detect HPT automatically. METHOD: The pre-processed signals are fed to a convolutional neural network model. The model learns and identifies unique ECG signatures for classification of normal and hypertension ECG signals. The proposed model is evaluated by the 10-fold and leave one out patient based validation techniques. RESULTS: A high classification accuracy of 99.99% is achieved for both validation techniques. This is one of the first few studies to have employed deep learning algorithm coupled with ECG signals for the detection of HPT. Our results imply that the developed tool is useful in a hospital setting as an automated diagnostic tool, enabling the effortless detection of HPT using ECG signals.	187.90560022665113
1658.	To solve the problem of fabric defect detection under complex illumination conditions, the Recurrent Attention Model (RAM) which is insensitive to illumination and noise differences has been introduced. However, the policy gradient algorithm in the RAM has some problems, such as the difficulty of convergence and the inefficiency of the algorithm due to the shortcomings of round updating. In this paper, the Deep Deterministic Policy Gradient- Recurrent Attention Model (DDPG-RAM) algorithm is proposed to solve the problems of policy gradient algorithm. Although the decoupling of the reinforcement learning task and classification task will lead to the inconsistency of the data, the gradient variance will be smaller, and the convergence speed and stability will be accelerated. Experiment results show that fabric defects can be detected by the proposed DDPG-RAM algorithm under complex illumination conditions. Compared with RAM and the Convolutional Neural Network (CNN), the accuracy of the decoupled algorithm is 95.24%, and the convergence speed is 50% faster than that of the RAM.	187.90554483244108
1659.	Far field input utterance is one of the major causes of performance degradation of speaker verification systems. In this study, we used teacher student learning framework to compensate for the performance degradation caused by far field utterances. Teacher student learning refers to training the student deep neural network in possible performance degradation condition using the teacher deep neural network trained without such condition. In this study, we use the teacher network trained with near distance utterances to train the student network with far distance utterances. However, through experiments, it was found that performance of near distance utterances were deteriorated. To avoid such phenomenon, we proposed techniques that use trained teacher network as initialization of student network and training the student network using both near and far field utterances. Experiments were conducted using deep neural networks that input raw waveforms of 4-channel utterances recorded in both near and far distance. Results show the equal error rate of near and far-field utterances respectively, 2.55 % / 2.8 % without teacher student learning, 9.75 % / 1.8 % for conventional teacher student learning, and 2.5 % / 2.7 % with proposed techniques.	187.9053153762199
1660.	The identification of Hate Speech in Social Media is of great importance and receives much attention in the text classification community. There is a huge demand for research for languages other than English. The HASOC track intends to stimulate development in Hate Speech for Hindi, German and English. Three datasets were developed from Twitter and Facebook and made available. Binary classification and more fine-grained subclasses were offered in 3 subtasks. For all subtasks, 321 experiments were submitted. The approaches used most often were LSTM networks processing word embedding input. The performance of the best system for identification of Hate Speech for English, Hindi, and German was a Marco-F1 score of 0.78, 0.81 and 0.61, respectively.	187.9053066657911
1661.	Cervical cancer is the fourth leading cause of cancer-related deaths. It is very important to make the precise diagnosis for the early stage of cervical cancer. In recent years, transfer Learning makes a great breakthrough in the field of machine learning, and the use of transfer learning technology in cervical histopathology image classification becomes a new research domain. In this paper, we propose a transfer learning framework of Inception-V3 network to classify well, moderately and poorly differentiated cervical histopathology images, which are stained using immunohistochemistry methods. In this framework, an Inception-V3 based transfer learning structure is first built up. Then, a fine-tuning approach is applied to extract effective deep learning features from the structure. Finally, the extracted features are designed for the final classification. In the experiment, a practical images stained by AQP, HIF and VEGF approaches are applied to test the proposed transfer learning network, and an average accuracy of 77.3% is finally achieved.	187.90530284157472
1662.	Glaucoma is a leading cause of irreversible blindness. Accurate segmentation of the optic disc (OD) and optic cup (OC) from fundus images is beneficial to glaucoma screening and diagnosis. Recently, convolutional neural networks demonstrate promising progress in the joint OD and OC segmentation. However, affected by the domain shift among different datasets, deep networks are severely hindered in generalizing across different scanners and institutions. In this paper, we present a novel patch-based output space adversarial learning framework ( ${p}$ OSAL) to jointly and robustly segment the OD and OC from different fundus image datasets. We first devise a lightweight and efficient segmentation network as a backbone. Considering the specific morphology of OD and OC, a novel morphology-aware segmentation loss is proposed to guide the network to generate accurate and smooth segmentation. Our ${p}$ OSAL framework then exploits unsupervised domain adaptation to address the domain shift challenge by encouraging the segmentation in the target domain to be similar to the source ones. Since the whole-segmentation-based adversarial loss is insufficient to drive the network to capture segmentation details, we further design the ${p}$ OSAL in a patch-based fashion to enable fine-grained discrimination on local segmentation details. We extensively evaluate our ${p}$ OSAL framework and demonstrate its effectiveness in improving the segmentation performance on three public retinal fundus image datasets, i.e., Drishti-GS, RIM-ONE-r3, and REFUGE. Furthermore, our ${p}$ OSAL framework achieved the first place in the OD and OC segmentation tasks in the MICCAI 2018 Retinal Fundus Glaucoma Challenge.	187.90527884415462
1663.	Feature representations extracted from hippocampus in magnetic resonance (MR) images are widely used in computer-aided Alzheimer's disease (AD) diagnosis, and thus accurate segmentation for the hippocampus has been remaining an active research topic. Previous studies for hippocampus segmentation require either human annotation which is tedious and error-prone or pre-processing MR images via time-consuming non-linear registration. Although many automatic segmentation approaches have been proposed, their performance is often limited by the small size of hippocampus and complex confounding information around the hippocampus. In particular, human-engineered features extracted from segmented hippocampus regions (e.g., the volume of the hippocampus) are essential for brain disease diagnosis, while these features are independent of diagnosis models, leading to sub-optimal performance. To address these issues, we propose a multi-task deep learning (MDL) method for joint hippocampus segmentation and clinical score regression using MR images. The prominent advantages of our MDL method lie on that we don't need any time-consuming non-linear registration for pre-processing MR images, and features generated by MDL are consistent with subsequent diagnosis models. Specifically, we first align all MR images onto a standard template, followed by a patch extraction process to approximately locate hippocampus regions in the template space. Using image patches as input data, we develop a multi-task convolutional neural network (CNN) for joint hippocampus segmentation and clinical score regression. The proposed CNN network contains two subnetworks, including 1) a U-Net with a Dice-like loss function for hippocampus segmentation, and 2) a convolutional neural network with a mean squared loss function for clinical regression. Note that these two subnetworks share a part of network parameters, to exploit the inherent association between these two tasks. We evaluate the proposed method on 407 subjects with MRI data from baseline Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The experimental results suggest that our MDL method achieves promising results in both tasks of hippocampus segmentation and clinical score regression, compared with several state-of-the-art methods.	187.90522266593672
1664.	The most prevalent arrhythmia observed in clinical practice is atrial fibrillation (AF). AF is associated with an irregular heartbeat pattern and a lack of a distinct P-waves signal. A low-cost method for identifying this condition is the use of a single-lead electrocardiogram (ECG) as the gold standard for AF diagnosis, after annotation by experts. However, manual interpretation of these signals may be subjective and susceptible to inter-observer variabilities because many non-AF rhythms exhibit irregular RR-intervals and lack P-waves similar to AF. Furthermore, the acquired surface ECG signal is always contaminated by noise. Hence, highly accurate and robust detection of AF using short-term, single-lead ECG is valuable but challenging. To improve the existing model, this paper proposes a simple algorithm of a discrete wavelet transform (DWT) coupled with one-dimensional convolutional neural networks (1D-CNNs) to classify three classes: Normal Sinus Rhythm (NSR), AF and non-AF (NAF). The experiment was conducted with a combination of three public datasets and one dataset from an Indonesian hospital. The robustness of the proposed model was evaluated based on several validation data with an unseen pattern from 4 datasets. The results indicated that 1D-CNNs outperformed other approaches and achieved satisfactory performances with high generalization ability. The accuracy, sensitivity, specificity, precision, and F1-Score for two classes were 99.98%, 99.91%, 99.91%, 99.99%, and 99.95%, respectively. For the three classes, the accuracy, sensitivity, specificity, precision, and F1-Score was 99.17%, 98.90%, 99.17%, 96.74%, and 97.48%, respectively. Potentially, our approach can aid AF diagnosis in clinics and patient self-monitoring to improve early detection and effective treatment of AF. (C) 2020 The Authors. Published by Elsevier B.V.	187.90503322581623
1665.	Example A botnet is a group of compromised Internet-connected devices controlled remotely by cyber criminals to launch coordinated attacks and to perform various malicious activities. Since botnets continuously adapt themselves to the evolving countermeasures introduced by both network and host-based detection mechanism, the traditional approaches do not provide adequate protection to botnet threat. On the one hand, behavioral analysis of network traffic can play a key role to detect botnets. For instance, behavioral analysis can be applied to observe and discover communication patterns that botnets operate during their life cycle. On the other hand, deep learning has been successfully applied to various classification tasks, and it is also a promising solution for botnet discovery. In this paper, we apply deep neural network to detect botnet by modeling network traffic flow. The performance of the proposed method is evaluated with publicly available large-scale communication traces. The experimental results illustrate that deep learning is an efficient and effective method for identifying botnet traffic with a high true positive rate (attack detection rate) and low false positive alarm rate.	187.90490049231317
1666.	In this research, a novel snoring sound classification (SSC) method is presented by proposing a new feature generation function to yield a high classification rate. The proposed feature extractor is named as Local Dual Octal Pattern (LDOP). A novel LDOP based SSC method is presented to solve the low success rate problems for Munich-Passau Snore Sound Corpus (MPSSC) dataset. Multilevel discrete wavelet transform (DWT) decomposition and the LDOP based feature generation, informative features selection with ReliefF and iterative neighborhood component analysis (RFINCA), and classification using k nearest neighbors (kNN) are fundamental phases of the proposed SSC method. Seven leveled DWT transform, and LDOP are used together to generate low, medium, and high levels features. This feature generation network extracts 4096 features in total. RFINCA selects 95 the most discriminative and informative ones of these 4096 features. In the classification phase, kNN with leave one out cross-validation (LOOCV) is used. 95.53% classification accuracy and 94.65% unweighted average recall (UAR) have been achieved using this method. The proposed LDOP based SSC method reaches 22% better result than the best of the other state-of-the-art machine learning and deep learning-based methods. These results clearly denote the success of the proposed SSC method.	187.90483004702082
1667.	Although China is vigorously developing clean energy and nuclear power, the thermal power generation (mainly coal power) is still the most important power generation method at present. Economic load dispatch (ELD) is a typical optimization problem in power systems which lots of researchers are trying to explore. The purpose of ELD is to increase the efficiency of thermal power generation under the conditions of load and operational constraints. When it comes to power generation scheduling, manual operation is still the main form, which is inefficient. In order to use a large amount of historical power generation data to improve the efficiency of power generation scheduling and achieve the effect of energy conservation, we propose an intelligent power generation scheduling system based on Deep neural networks (DNN) and Ant colony optimization (ACO). Experiments show that our DNN algorithm can predict the unit coal consumption precisely. Compared with the dynamic programming algorithm and equal differential increment rate algorithm, ACO can complete power generation scheduling tasks more quickly and efficiently.	187.90478655047116
1668.	Computational approaches for predicting protein ligand interactions can facilitate drug lead discovery and drug target determination. We have previously developed a threading/structural-based approach, FINDSITEcomb, for the virtual ligand screening of proteins that has been extensively experimentally validated. Even when low resolution predicted protein structures are employed, FINDSITEcomb has the advantage of being faster and more accurate than traditional high-resolution structure-based docking methods. It also overcomes the limitations of traditional QSAR methods that require a known set of seed ligands that bind to the given protein target. Here, we further improve FINDSITEcomb by enhancing its template ligand selection from the PDB/DrugBank/ChEMBL libraries of known protein ligand interactions by (1) parsing the template proteins and their corresponding binding ligands in the DrugBank and ChEMBL libraries into domains so that the ligands with falsely matched domains to the targets will not be selected as template ligands; (2) applying various thresholds to filter out falsely matched template structures in the structure comparison process and thus their corresponding ligands for template ligand selection. With a sequence identity cutoff of 30% of target to templates and modeled target structures, FINDSITEcomb is shown to significantly improve upon FINDSITEcomb on the DUD-E benchmark set by increasing the 1% enrichment factor from 16.7 to 22.1, with a p-value of 4.3 X 10(-3) by the Student t-test. With an 80% sequence identity cutoff of target to templates for the DUD-E set and modeled target structures, FINDSITEcomb2.0, having a 1% ROC enrichment factor of 52.39, also outperforms state-of-the-art methods that employ machine learning such as a deep convolutional neural network, CNN, with an enrichment of 29.65. Thus, FINDSITEcomb2.0 represents a significant improvement in the state-of-the-art.	187.90472735638568
1669.	Pre-trained deep convolutional neural networks (CNNs) have shown promise in the training of deep CNNs for medical imaging applications. The purpose of this study was to investigate the use of partially pre-trained deep CNNs for the segmentation of malignant pleural mesothelioma tumor on CT scans. Four network configurations were investigated: (1) VGG16/U-Net network with pre-trained layers fixed during training, (2) VGG16/U-Net network with pre-trained layers fine-tuned during training, (3) VGG16/U-Net network with all except the first two pre-trained layers fine-tuned during training, and (4) a standard U-Net architecture trained from scratch. Deep CNNs were trained separately for tumor segmentation in left and right hemithoraces using 4259 and 6441 contoured axial CT sections, respectively. A test set of 61 CT sections from 16 patients excluded from training was used to evaluate segmentation performance; the Dice similarity coefficient (DSC) was calculated between computer-generated and reference segmentations provided by two radiologists and one radiology resident. Median DSC on the test set was 0.739 (range 0.328-0.920), 0.772 (range 0.342-0.949), 0.777 (range 0.216-0.946), and 0.758 (range 0.099-0.943) across all observers for network configurations (1), (2), (3) and (4) above, respectively. The median DSC achieved with configuration (3) when compared with the standard U-Net trained from scratch was found to be significantly higher for two out of three observers. A fine-tuned VGG16/U-Net deep CNN showed significantly higher overlap with two out of three observers when compared with a standard U-Net trained from scratch for the segmentation of malignant pleural mesothelioma tumor.	187.90443955636624
1670.	Deep learning-based fault diagnosis has been acclaimed for its superiority in adaptively mining salient features. The monitoring data used as the input of deep learning typically includes only structured data (e.g. vibration signals, voltage signals, and acoustic emission signals), not unstructured data (e.g. infrared images), which provides another perspective on the mechanical health condition. To apply multi-sourced heterogeneous monitoring data fully, this paper presents a novel fusion diagnosis method integrating structured and unstructured data for rotor system faults. A novel multi-mode convolutional neural network (M-CNN) is first proposed to automatically learn fault-sensitive features from raw multisensory data composed of vibration signals and infrared images. M-CNN equipped with adjustable filter banks can identify data types and adaptively adopt the appropriate convolution mode. Then, t-distributed stochastic neighbor embedding (t-SNE) is introduced to fuse the deep features to further improve the quality of the learned features. Finally, the fused features are employed to conduct fault classification tasks. The effectiveness of the scheme is verified by fault diagnosis experiments in a rotor system, where it achieves a remarkable classification rate of 98.97%. Compared with similar methods, the proposed method exhibits outstanding performance, indicating the feasibility of using multi-sourced heterogeneous data for rotor system fault-diagnosis.	187.9042159930074
1671.	Recently, click-through rate (CTR) prediction models have evolved from shallow methods to deep neural networks. Most deep CTR models follow an Embedding&MLP paradigm, that is, first mapping discrete id features, e.g. user visited items, into low dimensional vectors with an embedding module, then learn a multi-layer perception (MLP) to fit the target. In this way, embedding module performs as the representative learning and plays a key role in the model performance. However, in many real-world applications, deep CTR model often suffers from poor generalization performance, which is mostly due to the learning of embedding parameters. In this paper, we model user behavior using an interest delay model, study carefully the embedding mechanism, and obtain two important results: (i) We theoretically prove that small aggregation radius of embedding vectors of items which belongs to a same user interest domain will result in good generalization performance of deep CTR model. (ii) Following our theoretical analysis, we design a new embedding structure named res-embedding. In res-embedding module, embedding vector of each item is the sum of two components: (i) a central embedding vector calculated from an item-based interest graph (ii) a residual embedding vector with its scale to be relatively small. Empirical evaluation on several public datasets demonstrates the effectiveness of the proposed res-embedding structure, which brings significant improvement on the model performance.	187.90406897782466
1672.	Noisy situations cause huge problems for the hearing-impaired, as hearing aids often make speech more audible but do not always restore intelligibility. In noisy settings, humans routinely exploit the audio-visual (AV) nature of speech to selectively suppress background noise and focus on the target speaker. In this paper, we present a novel language-, noise- and speaker-independent AV deep neural network (DNN) architecture, termed CochleaNet, for causal or real-time speech enhancement (SE). The model jointly exploits noisy acoustic cues and noise robust visual cues to focus on the desired speaker and improve speech intelligibility. The proposed SE framework is evaluated using a first of its kind AV binaural speech corpus, ASPIRE, recorded in real noisy environments, including cafeteria and restaurant settings. We demonstrate superior performance of our approach in terms of both objective measures and subjective listening tests, over state-of-the-art SE approaches, including recent DNN based SE models. In addition, our work challenges a popular belief that scarcity of a mull-lingual, large vocabulary AV corpus and a wide variety of noises is a major bottleneck to build robust language, speaker and noise-independent SE systems. We show that a model trained on a synthetic mixture of the benchmark GRID corpus (with 33 speakers and a small English vocabulary) and CHiME 3 noises (comprising bus, pedestrian, cafeteria, and street noises) can generalise well, not only on large vocabulary corpora with a wide variety of speakers and noises, but also on completely unrelated languages such as Mandarin.	187.90372694459825
1673.	In order to more accurately locate and segment the varistor image to achieve the varistor image data set necessary for automatic construction of deep learning. This paper proposes a method for locating and stitching the body and stitch of varistor based on Hough transform and mathematical morphology. In order to obtain an image that eliminates surface reflection, the method first acquires a varistor image through a coaxial light source. Secondly, performing preprocessing on the image based on denoising, graying, and binarization; then, using the Hough transform based on circle detection to locate the body of the resistor; further separating the body and the stitches, firstly performing edge searching on the positioned body portion, and then performing background filling on the inside of the body, and finally using a mathematical morphology etching operation to eliminate the edge marks of the body to obtain the positioning of the stitches. The experiment aimed to locate and segment 91 varistor samples, and use the effective and correct data indicators to evaluate the segmentation results. The experimental results show that the actual results of the proposed method are ideal and have a good target segmentation effect, which is beneficial to provide reliable varistor image data sets necessary for deep learning.	187.90334012252936
1674.	Sentiment lexicon is a very important resource for opinion mining. Recently, many state-of-the-art works employ deep learning techniques to construct sentiment lexicons. In general, they firstly learn sentiment-aware word embeddings, and then use it as word features to construct sentiment lexicons. However, these methods do not consider the importance of each word to the distinguish of documents' sentiment polarities. As we know, most words among a document do not contribute to understand documents' semantic or sentiment. For example, in the tweet It's a good day, but i can't feel it. I'm really unhappy. The words 'unhappy', 'feel' and 'can't' are much more important than the words 'good', 'day' in predicting the sentiment polarity of this twitter. Meanwhile, many words, such as 'the', 'in', 'it' and 'I'm' are uninformative. In this paper, we propose a novel sparse self-attention LSTM (SSALSTM) to efficiently capture the above intuitive facts, and then construct a large scale sentiment lexicons in twitter. In SSALSTM, we use a novel self-attention mechanism to capture the importance of each words to the distinguish of documents' sentiment polarities. In addition, a L-1 regularize is applied in the attentions which can ensure the sparsity characters that most words in a document are semantic and sentiment indistinguishable. Once we learn an efficient sentiment-aware word embedding, we train a classifier which uses sentiment-aware word embedding as features to predict the sentiment polarities of words. Extensive experiments on four publicly available datasets, SemEval 2013-2016, indicate that the sentiment lexicon generated by our proposed model achieves state-of-the-art performance on both supervised and unsupervised sentiment classification tasks.	187.90333569905246
1675.	The existing intelligent fault diagnosis techniques of bevel gear focus on single-sensor signal analysis under the steady operation condition. In this study, a new method is proposed based on ensemble deep transfer learning and multisensor signals to enhance the fault diagnosis adaptability and reliability of bevel gear under various operation conditions. First, a novel stacked autoencoder (NSAE) is constructed using a denoising autoencoder, batch normalization, and the Swish activation function. Second, a series of source-domain NSAEs with multisensor vibration signals is pretrained. Third, the good model parameters provided by the source-domain NSAEs are transferred to initialize the corresponding target-domain NSAEs. Finally, a modified voting fusion strategy is designed to obtain a comprehensive result. The multisensor signals collected under the different operation conditions of bevel gear are used to verify the proposed method. The comparison results show that the proposed method can diagnose different faults in an accurate and stable manner using only one target-domain sample, thereby outperforming the existing methods.	187.90322808338766
1676.	A panoramic surveillance system is designed to achieve continuous monitoring of the surrounding environment. The image acquisition module of the system is composed of five fixed-focal-length cameras and one variable-focal-length camera, which realizes 360 degree environmental surveillance. An adaptive threshold is used to dynamically update the background template in order to better accommodate various weather changes. Further, a pixel-level video moving target detection algorithm is applied to effectively detect whether an intruding target exists and determine the direction of the target. It shows the advantages of less computation and preferable detection accuracy. Once an intrusive target is found, the deep convolution neural network SSD is employed to recognize the specific target quickly. As common sense, visual object tracking is one of the most attractive issue in computer vision. Recently, deep neural network has been widely developed in object tracking and shown great achievement. Here, we propose an end-to-end lightweight siamese convolution neural network to achieve fast and robust target tracking. The experiment result shows panoramic surveillance system can effectively and robustly perform security tasks such as panoramic imaging, target recognition and fast target tracking. At the same time, the deep convolution neural network can recognize and track the target accurately and quickly, which meets the real-time and accuracy requirements of practical task.	187.9031500124192
1677.	Deep learning applications introduce heavy I/O loads on computer systems. The inherently long-running, highly concurrent, and random file accesses can easily saturate traditional shared file systems and negatively impact other users. We investigate here a solution to these problems based on leveraging local storage and the interconnect to serve training datasets at scale. We present FanStore, a user-level transient object store that provides low-latency and scalable POSIX file access by integrating the function interception technique and various metadata/data placement strategies. On a single node, FanStore provides performance similar to that of the XFS journaling file system. On many nodes, our experiments with real applications show that FanStore achieves over 90% scaling efficiency.	187.9031287363343
1678.	Agent-based modeling is a rule-based, discrete-event, and spatially explicit computational modeling method that employs computational objects that instantiate the rules and interactions among the individual components ("agents") of system. Agent-based modeling is well suited to translating into a computational model the knowledge generated from basic science research, particularly with respect to translating across scales the mechanisms of cellular behavior into aggregated cell population dynamics manifesting at the tissue and organ level. This capacity has made agent-based modeling an integral method in translational systems biology (TSB), an approach that uses multiscale dynamic computational modeling to explicitly represent disease processes in a clinically relevant fashion. The initial work in the early 2000s using agent-based models (ABMs) in TSB focused on examining acute inflammation and its intersection with wound healing; the decade since has seen vast growth in both the application of agent-based modeling to a wide array of disease processes as well as methodological advancements in the use and analysis of ABM. This report presents an update on an earlier review of ABMs in TSB and presents examples of exciting progress in the modeling of various organs and diseases that involve inflammation. This review also describes developments that integrate the use of ABMs with cutting-edge technologies such as high-performance computing, machine learning, and artificial intelligence, with a view toward the future integration of these methodologies. This article is categorized under: Translational, Genomic, and Systems Medicine > Translational Medicine Models of Systems Properties and Processes > Mechanistic Models Models of Systems Properties and Processes > Organ, Tissue, and Physiological Models Models of Systems Properties and Processes > Organismal Models	187.90288758499418
1679.	For the first time, technical data protection plays a major role in privacy law with the enactment of the General Data Protection Regulation (GDPR). A number of obligations for controllers and the rights of data subjects in the GDPR refer to technical aspects. From a data protection authority's technical perspective, in this article, the challenges and open questions that persist one year after the application of the GDPR are discussed.	187.9027949488918
1680.	Traditional visual relationship detection methods only use RGB information to train the semantic network, which do not match human habits that we combine RGB information with Depth information to perceive the world, thus, there is not enough generalization ability (zero-shot performance) to extract the visual relationships in practical scenes. To solve this problem, a novel visual relationship detection framework based on RGB-D images is proposed in this paper. Since it is difficult to get accurate depth maps from complex scenes, we propose a fuzzy strategy based method to represent Depth features of inaccurate depth maps which are independent of manual depth annotations. In particular, we formulate the RGB-Depth-Balanced-Network (RDBN) which can simultaneously process RGB features and the corresponding estimated depth maps to counter the inaccuracy of depth maps and extract semantic information by the only input of monocular RGB images. In experiments, we conduct ablation experiments to analyze functions of different visual components to demonstrate the effectiveness of our RDBN. Furthermore, we show that RDBN outperforms state-of-the-art visual relationship detection methods on Visual Relationship Dataset (VRD) and UnRel Dataset when tackling the visual relationship detection task of zero-shot learning in specific depth conditions, and the task of image retrieval among unusual relationships. (C) 2020 Elsevier B.V. All rights reserved.	187.9027235736511
1681.	Recommender system has recently attracted a lot of attention in the information service community. Currently, most recommendation models use deep neural networks to learn user preferences for items and make the final recommendations. However, these current models have not effectively captured the deep semantic features of users and items and have not fully used the auxiliary information of the items. This may result in unsatisfactory recommendations for users' projects. In order to solve the above problem, in this paper, a novel recommendation model called RM-DRL (Recommendation Model based on Deep Representation Learning) was proposed. It mainly consists of two modules: Information Preprocessing and Feature Representation. The former generates the user's primitive feature vectors and the items used in the latter. The latter consists of two phases: Representation Learning for Item Features (RL-IF) and Representation Learning for User Features (RL-UF). The RL-IF takes the primitive feature vectors of the item as input and uses a multi-layer Convolutional Neural Network (CNN) to learn to accurately produce the semantic feature vector of the item through multi-task learning. In RL-UF, the user primitive feature vectors and semantic feature vectors of the user preference history, and the positive and negative items were taken as input, and a novel Attention-Integrated Gated Recurrent Unit (AIGRU) neural network was proposed to learn to accurately produce user semantic feature vector. After the Feature Representation module converges, the semantic feature vectors of the users and the items can be used to calculate the users' preferences on the items via vector dot product. Extensive experiments on five real-world datasets show that RM-DRL remarkably outperforms state-of-the-art baselines in solving the recommendation problem. (C) 2020 Elsevier Inc. All rights reserved.	187.90260787997755
1682.	Video-based person re-identification is an important task with the challenges of lighting variation, low-resolution images, background clutter, occlusion, and human appearance similarity in the multi-camera visual sensor networks. In this paper, we propose a video-based person re-identification method called the end-to-end learning architecture with hybrid deep appearance-temporal feature. It can learn the appearance features of pivotal frames, the temporal features, and the independent distance metric of different features. This architecture consists of two-stream deep feature structure and two Siamese networks. For the first-stream structure, we propose the Two-branch Appearance Feature (TAF) sub-structure to obtain the appearance information of persons, and used one of the two Siamese networks to learn the similarity of appearance features of a pairwise person. To utilize the temporal information, we designed the second-stream structure that consisting of the Optical flow Temporal Feature (OTF) sub-structure and another Siamese network, to learn the person's temporal features and the distances of pairwise features. In addition, we select the pivotal frames of video as inputs to the Inception-V3 network on the Two-branch Appearance Feature sub-structure, and employ the salience-learning fusion layer to fuse the learned global and local appearance features. Extensive experimental results on the PRID2011, iLIDS-VID, and Motion Analysis and Re-identification Set (MARS) datasets showed that the respective proposed architectures reached 79%, 59% and 72% at Rank-1 and had advantages over state-of-the-art algorithms. Meanwhile, it also improved the feature representation ability of persons.	187.90248010416536
1683.	Coronary extraction is a crucial step in the assessment of cardiovascular diseases during clinical diagnosis and surgical planning. Coronary artery structures in CTA (Computed Tomography Angiography) images are affected by other nearby tissues due to scattered distribution. Therefore, in this paper, we present a deep learning method for the Coronary ascending aorta segmentation on CTA images. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. In the process of convolution operation, in order to reduce the computation, a new decomposition convolution method of reducing number of parameters is introduced. The adoption of this approach is not only greatly reduces the compute largely, but also has little effect on the performance loss during convolution calculation. This approach greatly improves the degree of automated segmentation with less manual intervention.	187.90162975149147
1684.	In modern era, the graphical information is presented in the form of web images. As the dependency of human beings on web information is increasing day-by-day, so the spammers are injecting spam by adopting new spamming techniques. Image spam is a spamming technique that integrates spam text contents into graphical images in order to bypass conventional text-based spam filters. The spam images are of various categories, such as redirection spam, advertisement spam, fake review, and content spam. In order to detect image spam efficiently, it is important to analyze the features of the image data. However, the existing image spam detection techniques in literature focused on textual or graphic features of the image. Moreover, to extract the relevant features from the images is also a challenging task. So, to fill these gaps, in this paper, we propose a Spam Protector for Advertisement of Malicious Images (SPAMI) framework using features extraction by browsing different websites and webpages. SPAMI is a cognitive spam protector which labels the spam advertisement images by using deep learning models. Three deep learning models are used for the same, i.e., CNN, RNN, and LSTM. The regress analysis of output from these models is done in the proposed SPAMI framework. Finally, we analysed the labels (Advertisement, Suspicious, Normal) for all the 600 images collected. The accuracy obtained from these models is 95% with real-time collected images, which improved up to 97% when tested with "Image Spam Hunter" dataset. (C) 2020 Elsevier Inc. All rights reserved.	187.90160081044996
1685.	Football (soccer) is one of the most popular sports in the world. A huge number of people watch live football matches by TV or Internet. A football match takes 90 minutes, but viewers may only want to watch a few highlights to save their time. As far as we know, there is no such a product that can be put into use to achieve intelligent highlight extraction from live football matches. In this paper, we propose an intelligent editing system for live football matches. Our system can automatically extract a series of highlights, such as goal, shoot, corner kick, red yellow card and the appearance of star players, from the live stream of a football match. Our system has been integrated into live streaming platforms during the 2018 FIFA World Cup and performed fairly well.	187.90156158541322
1686.	This paper presents a novel approach based on the direct use of deep neural networks to approximate wavelet sub-bands for remote sensing (RS) image scene classification in the JPEG 2000 compressed domain. The proposed approach consists of two main steps. The first step aims to approximate the finer level wavelet sub-bands. To this end, we introduce a novel Deep Neural Network approach that utilizes the coarser level binary decoded wavelet sub-bands to approximate the finer level wavelet sub-bands (the image itself) through a series of deconvolutional layers. The second step aims to describe the high-level semantic content of the approximated wavelet sub-bands and to perform scene classification based on the learnt descriptors. This is achieved by: i) a series of convolutional layers for the extraction of descriptors which models the approximated sub-bands; and ii) fully connected layers for the RS image scene classification. Then, we introduce a loss function that allows to learn the parameters of both steps in an end-to-end trainable and unified neural network. The proposed approach requires only the coarser level wavelet sub-bands as input and thus minimizes the amount of decompression applied to the compressed RS images. Experimental results show the effectiveness of the proposed approach in terms of classification accuracy and reduced computational time when compared to the conventional use of Convolutional Neural Networks within the JPEG 2000 compressed domain.	187.90139618363455
1687.	Recent advances in machine-learning, especially in deep neural networks have significantly accelerated the development and deployment of transport-oriented intelligent designs with increasingly high efficiency. While these technologies are exceptionally promising toward revolutionizing our current mobility and reducing the number of road accidents, the way to safe Intelligent Transportation Systems (ITS) remains long. Since pedestrians are the most vulnerable road users, designing accurate pedestrian detection methods is a priority task. However, traditional monocular pedestrian detection methods are limited, especially in occlusion handling. Hence, a collaborative perception scheme in which vehicles no longer restrict their input data to their immediate embedded sensors and rather exploit data from remote sensors is necessary to achieve a more comprehensive environment perception. In this work, we propose a novel public dataset: Infrastructure to Vehicle Multi-View Pedestrian Detection Database (I2V-MVPD) that combines synchronized images from both a mobile camera embedded in a car and a static camera in the road infrastructure. We also propose a new multi-view pedestrian detection framework based on collaborative intelligence between vehicles and infrastructure. Our results show a significant improvement in detection performance over monocular detection. (c) 2020 Elsevier B.V. All rights reserved.	187.90138864698656
1688.	This letter proposes a perceptual metric for speech quality evaluation, which is suitable, as a loss function, for training deep learning methods. This metric, derived from the perceptual evaluation of the speech quality algorithm, is computed in a perframe basis and from the power spectra of the reference and processed speech signal. Thus, two disturbance terms, which account for distortion once auditory masking and threshold effects are factored in, amend the mean square error (MSE) loss function by introducing perceptual criteria based on human psychoacoustics. The proposed loss function is evaluated f o r noisy speech enhancement with deep neural networks. Experimental results show that our metric achieves significant gains in speech quality (evaluated using an objective metric and a listening test) when compared to using MSE, or other perceptual-based loss functions from the literature.	187.90122829659617
1689.	Diffusion-weighted MRI makes it possible to quantify subvoxel brain microstructure and to reconstruct white matter fiber trajectories with which structural connectomes can be created. However, at the border between cerebrospinal fluid and white matter, or in the presence of edema, the obtained MRI signal originates from both the cerebrospinal fluid as well as from the white matter partial volume. Diffusion tractography can be strongly influenced by these free water partial volume effects. Thus, including a free water model can improve diffusion tractography in glioma patients. Here, we analyze how including a free water model influences structural connectivity estimates in healthy subjects as well as in brain tumor patients. During a clinical study, we acquired diffusion MRI data of 35 glioma patients and 28 age- and sex-matched controls, on which we applied an open-source deep learning based free water model. We performed deterministic as well as probabilistic tractography before and after free water modeling, and utilized the tractograms to create structural connectomes. Finally, we performed a quantitative analysis of the connectivity matrices. In our experiments, the number of tracked diffusion streamlines increased by 13% for high grade glioma patients, 9.25% for low grade glioma, and 7.65% for healthy controls. Intra-subject similarity of hemispheres increased significantly for the patient as well as for the control group, with larger effects observed in the patient group. Furthermore, inter-subject differences in connectivity between brain tumor patients and healthy subjects were reduced when including free water modeling. Our results indicate that free water modeling increases the similarity of connectivity matrices in brain tumor patients, while the observed effects are less pronounced in healthy subjects. As the similarity between brain tumor patients and healthy controls also increased, connectivity changes in brain tumor patients may have been overestimated in studies that did not perform free water modeling.	187.9011650096523
1690.	Diabetic eye disease is a collection of ocular problems that affect patients with diabetes. Thus, timely screening enhances the chances of timely treatment and prevents permanent vision impairment. Retinal fundus images are a useful resource to diagnose retinal complications for ophthalmologists. However, manual detection can be laborious and time-consuming. Therefore, developing an automated diagnose system reduces the time and workload for ophthalmologists. Recently, the image classification using Deep Learning (DL) in between healthy or diseased retinal fundus image classification already achieved a state of the art performance. While the classification of mild and multi-class diseases remains an open challenge, therefore, this research aimed to build an automated classification system considering two scenarios: (i) mild multi-class diabetic eye disease (DED), and (ii) multi-class DED. Our model tested on various datasets, annotated by an opthalmologist. The experiment conducted employing the top two pretrained convolutional neural network (CNN) models on ImageNet. Furthermore, various performance improvement techniques were employed, i.e., fine-tune, optimization, and contrast enhancement. Maximum accuracy of 88.3% obtained on the VGG16 model for multi-class classification and 85.95% for mild multi-class classification.	187.90100785294413
1691.	PURPOSE: CT-image reconstruction using truncated or sparsely acquired projection data to reduce radiation dose, iodine volume, and patient motion artifacts has been widely investigated. To continue these efforts, we investigated the use of machine-learning based reconstruction techniques using deep convolutional generative adversarial networks (DCGANs) and evaluated its effect using standard imaging metrics. METHODS: Ten-thousand head CT scans were collected from the 2019 RSNA Intracranial Hemorrhage Detection and Classification Challenge dataset. Sinograms were simulated and then resampled in both a one-third truncated and one-third sparse manner. DCGANs were tasked with correcting the incomplete projection data, either in the sinogram domain where the full sinogram was recovered by the DCGAN and then reconstructed, or the reconstruction domain where the incomplete data were first reconstructed and the sparse or truncation artifacts were corrected by the DCGAN. Seventy-five hundred images were used for network training and 2500 were withheld for network assessment using mean absolute error (MAE), structural similarity index measure (SSIM), and peak signal-to-noise ratio (PSNR) between results of different correction techniques. Image data from a quality-assurance phantom were also re-sampled in the two manners and corrected and reconstructed for network performance assessment using line profiles across high-contrast features, the modulation transfer function (MTF), noise power spectrum (NPS), and Hounsfield Unit (HU) linearity analysis. RESULTS: Better agreement with the fully sampled reconstructions were achieved from sparse acquisition corrected in the sinogram domain and the truncated acquisition corrected in the reconstruction domain. MAE, SSIM, and PSNR showed quantitative improvement from the DCGAN correction techniques. HU linearity of the reconstructions was maintained by the correction techniques for the sparse and truncated acquisitions. MTF curves reached the 10% modulation cutoff frequency at 5.86 lp/cm for the truncated corrected reconstruction compared with 2.98 lp/cm for the truncated uncorrected reconstruction, and 5.36 lp/cm for the sparse corrected reconstruction compared with around 2.91 lp/cm for the sparse uncorrected reconstruction. NPS analyses yielded better agreement across a range of frequencies between the re-sampled corrected phantom and truth reconstructions. CONCLUSIONS: We demonstrated the use of DCGANs for CT-image correction from sparse and truncated simulated projection data, while preserving imaging quality of the fully sampled projection data.	187.9010058288286
1692.	Computer-aided diagnosis of early-stage lung adenocarcinoma based on deep learning is prospective for assisting the prevention and treatment of the deathly disease of lung cancer, however, relevant works face the problem of limited training data. The technique of data source fusion with the training of deep models on multiple relevant datasets is promising to resolve the lack of training data, while the bias of data distribution from different data sources exists as a universal issue to affect the learning performance. In this paper, we propose a deep learning framework based on bias-undoing data source fusion to classify early stages of lung adenocarcinoma in computed tomography (CT) images. The framework conducts learning on the integrated datasets for respectively natural image, lung nodule CT and lung adenocarcinoma CT, as designed with an organization of base parameters and bias parameters to adapt to the data distribution with bias. Experimental results demonstrate that the proposed bias-undoing framework is effective to improve the performance of deep learning for lung adenocarcinoma classification, and is with great superiority to those general fusion frameworks on alleviating the effect of dataset bias.	187.90077039569564
1693.	3D-2D medical image matching is a crucial task in image-guided surgery, image-guided radiation therapy and minimally invasive surgery. The task relies on identifying the correspondence between a 2D reference image and the 2D projection of the 3D target image. In this paper, we propose a novel image matching framework between 3D CT projection and 2D X-ray image, tailored for vertebra images. The main idea is to learn a vertebra detector by means of the deep neural network. The detected vertebra is represented by a bounding box in the 3D CT projection. Next, the bounding box annotated by the doctor on the X-ray image is matched to the corresponding box in the 3D projection. We evaluate our proposed method on our own-collected 3D-2D registration dataset. The experimental results show that our framework outperforms the state-of-the-art neural network-based keypoint matching methods.	187.90071515423813
1694.	Atrial fibrillation (AF) is one of the most common sustained chronic cardiac arrhythmia in elderly population, associated with a high mortality and morbidity in stroke, heart failure, coronary artery disease, systemic thromboembolism, etc. The early detection of AF is necessary for averting the possibility of disability or mortality. However, AF detection remains problematic due to its episodic pattern. In this paper, a multiscaled fusion of deep convolutional neural network (MS-CNN) is proposed to screen out AF recordings from single lead short electrocardiogram (ECG) recordings. The MS-CNN employs the architecture of two-stream convolutional networks with different filter sizes to capture features of different scales. The experimental results show that the proposed MS-CNN achieves 96.99% of classification accuracy on ECG recordings cropped/padded to 5 s. Especially, the best classification accuracy, 98.13%, is obtained on ECG recordings of 20 s. Compared with artificial neural network, shallow single-stream CNN, and Visual-Geometry group network, the MS-CNN can achieve the better classification performance. Meanwhile, visualization of the learned features from the MS-CNN demonstrates its superiority in extracting linear separable ECG features without hand-craft feature engineering. The excellent AF screening performance of the MS-CNN can satisfy the most elders for daily monitoring with wearable devices.	187.90037844325656
1695.	The lack of well-structured annotations in a growing amount of RNA expression data complicates data interoperability and reusability. Commonly used text mining methods extract annotations from existing unstructured data descriptions and often provide inaccurate output that requires manual curation. Automatic data-based augmentation (generation of annotations on the base of expression data) can considerably improve the annotation quality and has not been well-studied. We formulate an automatic augmentation of small RNA-seq expression data as a classification problem and investigate deep learning (DL) and random forest (RF) approaches to solve it. We generate tissue and sex annotations from small RNA-seq expression data for tissues and cell lines of homo sapiens. We validate our approach on 4243 annotated small RNA-seq samples from the Small RNA Expression Atlas (SEA) database. The average prediction accuracy for tissue groups is 98% (DL), for tissues - 96.5% (DL), and for sex - 77% (DL). The "one dataset out" average accuracy for tissue group prediction is 83% (DL) and 59% (RF). On average, DL provides better results as compared to RF, and considerably improves classification performance for 'unseen' datasets.	187.90010387885485
1696.	We propose smart liquid-liquid extraction columns of biopharmaceuticals using deep Q-learning algorithm. In this contribution, we demonstrated the application of the tool for design of liquid-liquid extraction process for concentration of API from fermentation broth. To this end, we present the following;1) development of property model to describe solubility of API in different solvents using the nonrandom two-liquid segment activity coefficient model, 2) design the liquid-liquid extraction process for different solvent candidates commonly used in pharma industries, 3) application of deep Q-learning algorithm to optimize liquid-liquid extraction control, and 4) perform sensitivity analysis to study effect of feed fraction of API on the performance. We have validated the developed property process modelling by comparing the existing experimental data and the characteristics of diverse solvents and using sensitivity analysis. We expect that the results from this study would contribute to further development the general framework of downstream separation for the future by extending to more downstream separation processes.	187.89998866236607
1697.	We present a novel speech enhancement method based on locally linear embedding (LLE). The proposed method works as a post-filter to further suppress the residual noises in the enhanced speech signals obtained by a speech enhancement system to attain improved speech quality and intelligibility. We design two types of LLE-based post-filters: the direct LLE-based post-filter (called the DL post-filter) and the LLE-based difference compensation post-filter (called the LDC post-filter). The key technique of the proposed post-filters is to apply the LLE-based feature prediction method, which integrates the LLE algorithm, a classical manifold learning method, with the exemplar-based feature prediction method, to predict either the spectral features of the clean speech from those of the enhanced speech (for DL) or the spectral difference of {clean speech; noisy speech} from that of {enhanced speech; noisy speech} (for LDC). As a result, for DL, the predicted clean speech signals can be directly reconstructed from the predicted clean spectral features. On the other hand, for LDC, the predicted clean spectral features are obtained by compensating the spectral features of the noisy speech with the predicted clean-noisy spectral difference, and then the predicted clean speech signals can be reconstructed accordingly. Experimental results demonstrate the effectiveness of the proposed post-filters for two representative speech enhancement methods, namely the deep denoising autoencoder (DDAE) and the minimum mean-square-error (MMSE) spectral estimation methods.	187.89996208220313
1698.	For the past several years there has been a push in the industry to drive innovation by pairing different types of metrology to keep up with the challenging requirements of overlay, focus and CD in multi-patterning processes. Holistic metrology is an example of this where instead of using a single metrology method we pair various available metrology methods to enrich the overall information content. With advancements in deep learning algorithms we can better utilize existing infrastructure to extract information from metrology parings for a cost-effective solution that has traditionally gone unused. In computational alignment metrology we pair leveling data with alignment and wafer quality to generate a dense alignment vector map. In the first step wafer leveling metrology from the lithographic apparatus is deconvolved into individual contributors. Selecting the deconvolved signatures with greatest influence on alignment metrology we train our dense input metrology to our targeted alignment metrology using a deep feedforward network. With the trained weights and biases of the deep feedforward network and input from a new lot of wafers we can now compute a dense alignment vector map. With a 3rd order HOWA model fit to the original 32 marks and then again to the same 32 marks paired with leveling, the model fit to the dense estimation from the 32 marks paired with leveling out performs HOWA fit to the original 32 marks. Finally, by fitting an advanced alignment model which optimizes spatial frequency between our enhanced alignment and corresponding overlay metrology, we can realize additional performance improvements in wafer to wafer overlay.	187.8999478249387
1699.	A multi-robot-based fault detection system for railway tracks is proposed to eliminate manual human visual inspection. A hardware prototype is designed to implement a master-slave robot mechanism capable of detecting rail surface defects, which include cracks, squats, corrugations, and rust. The system incorporates ultrasonic sensor inputs coupled with image processing using OpenCV and deep learning algorithms to classify the surface faults detected. The proposed Convolutional Neural Network (CNN) model fared better compared to the Artificial Neural Network (ANN), random forest, and Support Vector Machine (SVM) algorithms based on accuracy, R-squared value, F1 score, and Mean-Squared Error (MSE). To eliminate manual inspection, the location and status of the fault can be conveyed to a central location enabling immediate attention by utilizing GSM, GPS, and cloud storage-based technologies. The system is extended to a multi-robot framework designed to optimize energy utilization, increase the lifetime of individual robots, and improve the overall network throughput. Thus, the Low Energy Adaptive Clustering Hierarchy (LEACH) protocol is simulated using 100 robot nodes, and the corresponding performance metrics are obtained.	187.89985632760528
1700.	This paper proposes a supervised deep hashing approach for highly efficient and effective cover song detection. Our system consists of two identical sub-neural networks, each one having a hash layer to learn a binary representations of input audio in the form of spectral features. A loss function joins the two outputs of the sub-networks by minimizing the Hamming distance for a pair of audio files covering the same music work. We further enhance system performance by loudness embedding, beat synchronization, and early fusion of input audio features. The output of 128-bit hash reaches state-of-the-art performance with mean pairwise accuracy. This system demonstrates the possibility of memory-efficient and real-time efficient cover song detection with satisfiable accuracy in large scale.	187.8997785363603
1701.	Face presentation attack detection (PAD) is essential for securing the widely used face recognition systems. Most of the existing PAD methods do not generalize well to unseen scenarios because labeled training data of the new domain is usually not available. In light of this, we propose an unsupervised domain adaptation with disentangled representation (DR-UDA) approach to improve the generalization capability of PAD into new scenarios. DR-UDA consists of three modules, i.e., ML-Net, UDA-Net and DR-Net. ML-Net aims to learn a discriminative feature representation using the labeled source domain face images via metric learning. UDA-Net performs unsupervised adversarial domain adaptation in order to optimize the source domain and target domain encoders jointly, and obtain a common feature space shared by both domains. As a result, the source domain PAD model can be effectively transferred to the unlabeled target domain for PAD. DR-Net further disentangles the features irrelevant to specific domains by reconstructing the source and target domain face images from the common feature space. Therefore, DR-UDA can learn a disentangled representation space which is generative for face images in both domains and discriminative for live vs. spoof classification. The proposed approach shows promising generalization capability in several public-domain face PAD databases.	187.8996710892588
1702.	Chinese couplets, as one of the traditional Chinese culture, is the treasure of Chinese civilization and the inheritance of Chinese history. Given a sentence (namely an antecedent clause), people reply with another sentence (namely a subsequent clause) equal in length. Because of the complexity of the semantic and grammatical rules of couplet, it is not easy to create a suitable couplet that meets the requirements of sentence pattern, context, and flatness. In this paper, given the issued antecedent clause, we can automatically generate the subsequent clause by encoder-decoder model. Moreover, to satisfy special characteristics of couplets, we incorporate the attention mechanism into the encoding-decoding process, which greatly improves the accuracy of couplets generated automatically.	187.89962512906155
1703.	Alzheimer's Disease (AD) is an irreversible disease that gradually worsens with time. Therefore, early diagnosis of Alzheimer's disease is important to prevent brain tissue damage and treat the patient properly. Mild Cognitive Impairment (MCI) is a prodromal stage of AD, which has no harm to the patient's ability to have functional activities in daily life except a minor cognitive deficiency. Since MCI can be detected at the earliest stage of AD, it is critical to detect patients with MCI to delay the progression of AD. It is possible to distinguish patients with AD, MCI, and Normal Control (NC) from one another by the size of brain volume, hippocampus and patient's clinical information. The brain and hippocampus gradually shrink in size and shape as AD develops. In this study, we propose a deep learning-based technique to classify patients with AD, MCI and NC by brain Magnetic Resonance ( MR) images. Deep learning has shown human-level performance in a lot of studies including medical image analysis with constrained amount of training data. We propose a deep learning-based ensemble model which consists of 3 Convolutional Neural Networks (CNN) [1] with Network In Network (NIN) [2] architecture. The kernel size is 3x3 convolution followed by 1x1 convolution to reduce the number of trainable parameters and extract features for classification better. In addition, Global Averaging Pooling (GAP) is used instead of Fully-Connected (FC) layers to avoid overfitting by reducing the number of trainable parameters. By using the ensemble model, this shows the 81.66% in classifying 3 classes.	187.899467420184
1704.	Background Magnetic resonance imaging (MRI) of the knee is the preferred method for diagnosing knee injuries. However, interpretation of knee MRI is time-intensive and subject to diagnostic error and variability. An automated system for interpreting knee MRI could prioritize high-risk patients and assist clinicians in making diagnoses. Deep learning methods, in being able to automatically learn layers of features, are well suited for modeling the complex relationships between medical images and their interpretations. In this study we developed a deep learning model for detecting general abnormalities and specific diagnoses (anterior cruciate ligament [ACL] tears and meniscal tears) on knee MRI exams. We then measured the effect of providing the model's predictions to clinical experts during interpretation. Methods and findings Our dataset consisted of 1,370 knee MRI exams performed at Stanford University Medical Center between January 1, 2001, and December 31, 2012 (mean age 38.0 years; 569 [41.5%] female patients). The majority vote of 3 musculoskeletal radiologists established reference standard labels on an internal validation set of 120 exams. We developed MRNet, a convolutional neural network for classifying MRI series and combined predictions from 3 series per exam using logistic regression. In detecting abnormalities, ACL tears, and meniscal tears, this model achieved area under the receiver operating characteristic curve (AUC) values of 0.937 (95% CI 0.895, 0.980), 0.965 (95% CI 0.938, 0.993), and 0.847 (95% CI 0.780, 0.914), respectively, on the internal validation set. We also obtained a public dataset of 917 exams with sagittal T1 -weighted series and labels for ACL injury from Clinical Hospital Centre Rijeka, Croatia. On the external validation set of 183 exams, the MRNet trained on Stanford sagittal T2-weighted series achieved an AUC of 0.824 (95% CI 0.757, 0.892) in the detection of ACL injuries with no additional training, while an MRNet trained on the rest of the external data achieved an AUC of 0.911 (95% CI 0.864, 0.958). We additionally measured the specificity, sensitivity, and accuracy of 9 clinical experts (7 board-certified general radiologists and 2 orthopedic surgeons) on the internal validation set both with and without model assistance. Using a 2-sided Pearson's chi-squared test with adjustment for multiple comparisons, we found no significant differences between the performance of the model and that of unassisted general radiologists in detecting abnormalities. General radiologists achieved significantly higher sensitivity in detecting ACL tears (p-value = 0.002; q-value = 0.019) and significantly higher specificity in detecting meniscal tears (p-value = 0.003; q-value = 0.019). Using a 1-tailed ttest on the change in performance metrics, we found that providing model predictions significantly increased clinical experts' specificity in identifying ACL tears (p-value < 0.001; q-value = 0.006). The primary limitations of our study include lack of surgical ground truth and the small size of the panel of clinical experts. Conclusions Our deep learning model can rapidly generate accurate clinical pathology classifications of knee MRI exams from both internal and external datasets. Moreover, our results support the assertion that deep learning models can improve the performance of clinical experts during medical imaging interpretation. Further research is needed to validate the model prospectively and to determine its utility in the clinical setting.	187.89912738121885
1705.	Rice is one of the world's major staple foods, especially in China. Highly accurate monitoring on rice-producing land is, therefore, crucial for assessing food supplies and productivity. Recently, the deep-learning convolutional neural network (CNN) has achieved considerable success in remote-sensing data analysis. A CNN-based paddy-rice mapping method using the multitemporal Landsat 8, phenology data, and land-surface temperature (LST) was developed during this study. First, the spatial-temporal adaptive reflectance fusion model (STARFM) was used to blend the moderate-resolution imaging spectroradiometer (MODIS) and Landsat data for obtaining multitemporal Landsat-like data. Subsequently, the threshold method is applied to derive the phenological variables from the Landsat-like (Normalized difference vegetation index) NDVI time series. Then, a generalized single-channel algorithm was employed to derive LST from the Landsat 8. Finally, multitemporal Landsat 8 spectral images, combined with phenology and LST data, were employed to extract paddy-rice information using a patch-based deep-learning CNN algorithm. The results show that the proposed method achieved an overall accuracy of 97.06% and a Kappa coefficient of 0.91, which are 6.43% and 0.07 higher than that of the support vector machine method, and 7.68% and 0.09 higher than that of the random forest method, respectively. Moreover, the Landsat-derived rice area is strongly correlated (R-2 = 0.9945) with government statistical data, demonstrating that the proposed method has potential in large-scale paddy-rice mapping using moderate spatial resolution images.	187.8989763838553
1706.	OBJECTIVE Gross-total resection (GTR) is often the primary surgical goal in transsphenoidal surgery for pituitary adenoma. Existing classifications are effective at predicting GTR but are often hampered by limited discriminatory ability in moderate cases and by poor interrater agreement. Deep learning, a subset of machine learning, has recently established itself as highly effective in forecasting medical outcomes. In this pilot study, the authors aimed to evaluate the utility of using deep learning to predict GTR after transsphenoidal surgery for pituitary adenoma. METHODS Data from a prospective registry were used. The authors trained a deep neural network to predict GTR from 16 preoperatively available radiological and procedural variables. Class imbalance adjustment, cross-validation, and random dropout were applied to prevent overfitting and ensure robustness of the predictive model. The authors subsequently compared the deep learning model to a conventional logistic regression model and to the Knosp classification as a gold standard. RESULTS Overall, 140 patients who underwent endoscopic transsphenoidal surgery were included. GTR was achieved in 95 patients (68%), with a mean extent of resection of 96.8% +/- 10.6%. Intraoperative high-field MRI was used in 116 (83%) procedures. The deep learning model achieved excellent area under the curve (AUC; 0.96), accuracy (91%), sensitivity (94%), and specificity (89%). This represents an improvement in comparison with the Knosp classification (AUC: 0.87, accuracy: 81%, sensitivity: 92%, specificity: 70%) and a statistically significant improvement in comparison with logistic regression (AUC: 0.86, accuracy: 82%, sensitivity: 81%, specificity: 83%) (all p < 0.001). CONCLUSIONS In this pilot study, the authors demonstrated the utility of applying deep learning to preoperatively predict the likelihood of GTR with excellent performance. Further training and validation in a prospective multicentric cohort will enable the development of an easy-to-use interface for use in clinical practice.	187.8988683140858
1707.	We propose a deep learning tool to localize fish objects in benthic underwater videos on a frame by frame basis. The deep network predicts fish object spatial coordinates and simultaneously segments the corresponding pixels of each fish object. The network follows a state of the art inception resnet v2 architecture that automatically generates informative features for object localization and mask segmentation tasks. Predicted masks are passed to dense Conditional Random Field (CRF) post-processing for contour and shape refinement. Unlike prior methods that rely on motion information to segment fish objects, our proposed method only requires RGB video frames to predict both box coordinates and object pixel masks. Independence from motion information makes our proposed model more robust to camera movements or jitters, and makes it more applicable to process underwater videos taken from unmanned water vehicles. We test the model in actual benthic underwater video frames taken from ten different sites. The proposed tool can segment fish objects despite wide camera movements, blurred underwater resolutions, and is robust to a wide variety of environments and fish species shapes.	187.89871720887362
1708.	In order to obtain a discriminative, compact and robust data representation, a discriminative and robust nonnegative matrix factorization method with soft label constraint (DRNMF_SLC) is proposed. By minimizing the objective function, the data representation after learning soft label constraint is obtained. To further acquire a more hierarchical and discriminative data representation, a deep discriminative and robust nonnegative matrix factorization network method with soft label constraint (Deep DRNMFN_SLC) is constructed. In order to improve the feature expression ability of deep neural network (DNN), a deep discriminative and robust nonnegative matrix factorization network method with soft label constraint based on DNN (Deep DRNMFN_SLC_DNN) is proposed, which could obtain a more discriminative, robust and generalized feature representation, and meanwhile greatly reduce the dimension of data features. Furthermore, the objective function of DRNMF_SLC is constructed by introducing both the global loss function and the central loss function of soft label constraint matrix, and the optimization solution and convergence proof of objective function are given simultaneously. When the proposed DRNMF_SLC method and Deep DRNMFN_SLC_DNN method are, respectively, applied to the face recognition under occlusions and illumination variations, the frameworks, Algorithm 1 and Algorithm 2 are given. The extensive and adequate experiments demonstrate the effectiveness of the proposed method.	187.8984900652908
1709.	This paper presents ADMSv2, an end-to-end data-driven system that enables real-time and historical data analytics and machine learning tasks over big, streaming, spatiotemporal data. ADMSv2 employs a unified multi-layered architecture that integrates several open-source frameworks to collect, store, manage, and analyze a variety of data sources, including massive traffic sensor data, bus trajectory data, transportation network data, and traffic incidents data. ADMSv2 enables numerous applications in intelligent transportation, urban planning, public policy, and emergency response, all of which are critical for city resilience. Here, we demonstrate three application scenarios running on top of ADMSv2 to showcase the efficiency of its capabilities of query processing on real-world streaming and historical data as well as real-time data analysis using deep learning for traffic forecasting.	187.89830826238827
1710.	In this paper, we propose a two-stream transformer networks (TSTN) approach for video-based face alignment. Unlike conventional image-based face alignment approaches which cannot explicitly model the temporal dependency in videos and motivated by the fact that consistent movements of facial landmarks usually occur across consecutive frames, our TSTN aims to capture the complementary information of both the spatial appearance on still frames and the temporal consistency information across frames. To achieve this, we develop a two-stream architecture, which decomposes the video-based face alignment into spatial and temporal streams accordingly. Specifically, the spatial stream aims to transform the facial image to the landmark positions by preserving the holistic facial shape structure. Accordingly, the temporal stream encodes the video input as active appearance codes, where the temporal consistency information across frames is captured to help shape refinements. Experimental results on the benchmarking video-based face alignment datasets show very competitive performance of our method in comparisons to the state-of-the-arts.	187.89810475437528
1711.	The advance of new hearing technologies has generated high expectations regarding the development and learning of deaf children, but little research has been done on the language levels of this generation of deaf learners who receive education at the same pace as their hearing peers. The aim of this study was to examine the relationships between academic competence (AC) in Spanish Literacy and Mathematics and linguistic comprehension of deaf Spanish students who are attending Primary Education in general classrooms. Scores on lexical and grammatical comprehension showed that most of them were below their chronological age, and the age gap was greatest for grammatical comprehension. Results showed significant differences both in lexical and grammatical levels when comparing deaf students with different levels of AC. Probing deeper into the relation between grammatical comprehension and AC, certain types of complex grammatical structures have been found related with a better Spanish Literacy. The intervention in linguistic competence should be included in a general programme of intervention in oral and written language.	187.89807387715877
1712.	Existing deep neural network (DNN) frameworks optimize the computation graph of a DNN by applying graph transformations manually designed by human experts. This approach misses possible graph optimizations and is difficult to scale, as new DNN operators are introduced on a regular basis. We propose TASO, the first DNN computation graph optimizer that automatically generates graph substitutions. TASO takes as input a list of operator specifications and generates candidate substitutions using the given operators as basic building blocks. All generated substitutions are formally verified against the operator specifications using an automated theorem prover. To optimize a given DNN computation graph, TASO performs a cost-based backtracking search, applying the substitutions to find an optimized graph, which can be directly used by existing DNN frameworks. Our evaluation on five real-world DNN architectures shows that TASO outperforms existing DNN frameworks by up to 2.8x, while requiring significantly less human effort. For example, TensorFlow currently contains approximately 53,000 lines of manual optimization rules, while the operator specifications needed by TASO are only 1,400 lines of code.	187.8980408603973
1713.	This study develops a three-dimensional (3D) Laser Railway Detection System for automated railway fastener defect detection on 3D ballastless track. The 3D laser imaging system overcomes the shortcomings of shadows and illumination variations, thereby providing 3D information of the ballastless track with high reproducibility and accuracy. RailNet, an efficient architecture based on a Convolutional Neural Network (CNN), is proposed in this paper for detecting high-speed railway fastener defects on 3D ballastless track. RailNet consists of 10 layers and includes more than 120,000 parameters. RailNet is trained using 80,000 3D fastener images with 1-mm resolution and is then demonstrated to be successful at identifying damaged and missing fasteners. The testing results show that the system described in this paper can inspect the defective hook-shaped fasteners notably well. The proposed RailNet significantly outperforms the other approaches with a prediction accuracy of 100%, and the number of testing samples is 16,000.	187.898010024738
1714.	Background and Aims: Few artificial intelligence-based technologies have been developed to improve the efficiency of screening for esophageal squamous cell carcinoma (ESCC). Here, we developed and validated a novel system of computer-aided detection (CAD) using a deep neural network (DNN) to localize and identify early ESCC under conventional endoscopic white-light imaging. Methods: We collected 2428 (1332 abnormal, 1096 normal) esophagoscopic images from 746 patients to set up a novel DNN-CAD system in 2 centers and prepared a validation dataset containing 187 images from 52 patients. Sixteen endoscopists (senior, mid-level, and junior) were asked to review the images of the validation set. The diagnostic results, including accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), were compared between the DNN-CAD system and endoscopists. Results: The receiver operating characteristic curve for DNN-CAD showed that the area under the curve was >96%. For the validation dataset, DNN-CAD had a sensitivity, specificity, accuracy, PPV, and NPV of 97.8%, 85.4%, 91.4%, 86.4%, and 97.6%, respectively. The senior group achieved an average diagnostic accuracy of 88.8%, whereas the junior group had a lower value of 77.2%. After referring to the results of DNN-CAD, the average diagnostic ability of the endoscopists improved, especially in terms of sensitivity (74.2% vs 89.2%), accuracy (81.7% vs 91.1%), and NPV (79.3% vs 90.4%). Conclusions: The novel DNN-CAD system used for screening of early ESCC has high accuracy and sensitivity, and can help endoscopists to detect lesions previously ignored under white-light imaging.	187.8977372275176
1715.	The objective of this study was to build a machine learning model that can predict healing of diabetes-related foot ulcers, using both clinical attributes extracted from electronic health records (EHR) and image features extracted from photographs. The clinical information and photographs were collected at an academic podiatry wound clinic over a three-year period. Both hand-crafted color and texture features and deep learning-based features from the global average pooling layer of ResNet-50 were extracted from the wound photographs. Random Forest (RF) and Support Vector Machine (SVM) models were then trained for prediction. For prediction of eventual wound healing, the models built with hand-crafted imaging features alone outperformed models built with clinical or deep-learning features alone. Models trained with all features performed comparatively against models trained with hand-crafted imaging features. Utilization of smartphone and tablet photographs taken outside of research settings hold promise for predicting prognosis of diabetes-related foot ulcers.	187.8973431346831
1716.	Background Secondary schools that implement smoke-free policies are confronted with students who start smoking outside their premises. One solution is to complement smoke-free policies with prohibitions for all students to leave the school area during school hours, technically making school hours a smoke-free period. However, there are strikingly few Dutch secondary schools that implement this approach. This study explores why staff members in the Netherlands decide not to implement smoke-free school hours for all students. Method We interviewed 13 staff members, with different functions, from four secondary schools. The analysis was informed by the Advocacy Coalition Framework (ACF) to delve into the values, rationales, and assumptions of staff with the aim to identify deep core, policy core, and secondary beliefs. Results We identified six beliefs. Two deep core beliefs are that schools should provide adolescents the freedom to learn how to responsibly use their personal autonomy and that schools should only interfere if adolescents endanger or bother others. Three policy core beliefs identified included the following: that smoking is not a pressing issue for schools to deal with; that schools should demarcate their jurisdiction to intervene in adolescents' lives in time, space, and precise risk behavior; and that implementing smoke-free school hours would interfere with maintaining positive student-staff relationships. One secondary belief identified was that smoke-free school hours would be impossible to enforce consistently. Conclusion This paper was the first to demonstrate the many beliefs explaining why schools refrain from voluntary implementing far-reaching smoke-free policies.	187.897073441357
1717.	BACKGROUND/AIMS: Accurate isolation and quantification of intraocular dimensions in the anterior segment (AS) of the eye using optical coherence tomography (OCT) images is important in the diagnosis and treatment of many eye diseases, especially angle-closure glaucoma. METHOD: In this study, we developed a deep convolutional neural network (DCNN) for the localisation of the scleral spur; moreover, we introduced an information-rich segmentation approach for this localisation problem. An ensemble of DCNNs for the segmentation of AS structures (iris, corneosclera shell adn anterior chamber) was developed. Based on the results of two previous processes, an algorithm to automatically quantify clinically important measurements were created. 200 images from 58 patients (100 eyes) were used for testing. RESULTS: With limited training data, the DCNN was able to detect the scleral spur on unseen anterior segment optical coherence tomography (ASOCT) images as accurately as an experienced ophthalmologist on the given test dataset and simultaneously isolated the AS structures with a Dice coefficient of 95.7%. We then automatically extracted eight clinically relevant ASOCT measurements and proposed an automated quality check process that asserts the reliability of these measurements. When combined with an OCT machine capable of imaging multiple radial sections, the algorithms can provide a more complete objective assessment. The total segmentation and measurement time for a single scan is less than 2s. CONCLUSION: This is an essential step towards providing a robust automated framework for reliable quantification of ASOCT scans, for applications in the diagnosis and management of angle-closure glaucoma.	187.8968612009895
1718.	Human perception of an object's skeletal structure is particularly robust to diverse perturbations of shape. This skeleton representation possesses substantial advantages for parts-based and invariant shape encoding, which is essential for object recognition. Multiple deep learning-based skeleton detection models have been proposed, while their robustness to adversarial attacks remains unclear. (1)This paper is the first work to study the robustness of deep learning-based skeleton detection against adversarial attacks, which are only slightly unlike the original data but still imperceptible to humans. We systematically analyze the robustness of skeleton detection models through exhaustive adversarial attacking experiments. (2)We propose a novel Frequency attack, which can directly exploit the regular and interpretable perturbations to sharply disrupt skeleton detection models. Frequency attack consists of an excitatory-inhibition waveform with high frequency attribution, which confuses edge-sensitive convolutional filters due to the sudden contrast between crests and troughs. Our comprehensive results verify that skeleton detection models are also vulnerable to adversarial attacks. The meaningful findings will inspire researchers to explore more potential robust models by involving explicit skeleton features.	187.89672588451316
1719.	Background: Self-harm is preventable if the risk can be identified early. The co-occurrence of multiple diseases is related to self-harm risk. This study develops a comorbidity network-based deep learning framework to improve the prediction of individual self-harm. Methods: Between 01/01/2007-12/31/2010, we obtained 2,323 patients with self-harm records and 46,460 randomly sampled controls from 1,764,094 inpatients across 44 public hospitals in Hong Kong. 80% of the samples were randomly selected for model training, and the remaining 20% were set aside for model testing. We propose a novel patient embedding method, namely Dx2Vec (Diagnoses to Vector), based on the comorbidity network constructed by all historical diagnoses. Dx2Vec represents the comorbidity patterns among diseases and temporal patterns of historical admissions for each patient. Results: Experiments demonstrate that the Dx2Vec-based model outperforms the baseline deep learning model in identifying patients who would self-harm within 12 months (C-statistic: 0.89). The precision is 0.54 for positive cases and 0.98 for negative cases, whilst the recall is 0.72 for positive cases and 0.96 for negative cases. The model extracted the most predictive diagnoses, and pairwise comorbid diagnoses to help medical professionals identify patients with risk. Limitations: The inpatient data does not contain lab test information. Conclusions: Incorporation of a disease comorbidity network can significantly improve self-harm prediction performance, indicating that it is critical to consider comorbidity patterns in self-harm screening and prevention programs. The findings have the potential to be translated into effective self-harm screening systems.	187.8966670595573
1720.	In real-world situation, speech signals reaching our ears are usually degraded by the background noise. These distortions are detrimental to the speech quality and intelligibility and also cause a serious problem to many speech-related applications, such as automatic speech recognition and speaker identification. In order to deal with the background noise distortions, we propose a strategy to enhance the degraded speech in this paper, where speech enhancement is conducted using supervised deep neural network models. The models are trained to learn a mapping from the features of noisy speech to estimate the ideal-ratio mask (IRM). The estimated IRM is then applied to the noisy speech in order to obtain an enhanced version of the degraded speech. The mean square error (MSE) is used as an objective cost function. Additionally, Global Variance Equalization is performed as a post-processing step to equalize variances of the features. Systematic evaluations and comparisons show that the proposed supervised method improves objective metrics of speech quality and intelligibility substantially and significantly outperforms the competing and baseline speech enhancement methods. Finally, the proposed method is examined in speaker identification task in noisy situations. The proposed method leads to the highest speaker identification rates when compare to the competing and baseline speech enhancement methods.	187.89645951643038
1721.	OBJECTIVE: This study aims to develop and test a new computer-aided diagnosis (CAD) scheme of chest X-ray images to detect coronavirus (COVID-19) infected pneumonia. METHOD: CAD scheme first applies two image preprocessing steps to remove the majority of diaphragm regions, process the original image using a histogram equalization algorithm, and a bilateral low-pass filter. Then, the original image and two filtered images are used to form a pseudo color image. This image is fed into three input channels of a transfer learning-based convolutional neural network (CNN) model to classify chest X-ray images into 3 classes of COVID-19 infected pneumonia, other community-acquired no-COVID-19 infected pneumonia, and normal (non-pneumonia) cases. To build and test the CNN model, a publicly available dataset involving 8474 chest X-ray images is used, which includes 415, 5179 and 2,880 cases in three classes, respectively. Dataset is randomly divided into 3 subsets namely, training, validation, and testing with respect to the same frequency of cases in each class to train and test the CNN model. RESULTS: The CNN-based CAD scheme yields an overall accuracy of 94.5 % (2404/2544) with a 95 % confidence interval of [0.93,0.96] in classifying 3 classes. CAD also yields 98.4 % sensitivity (124/126) and 98.0 % specificity (2371/2418) in classifying cases with and without COVID-19 infection. However, without using two preprocessing steps, CAD yields a lower classification accuracy of 88.0 % (2239/2544). CONCLUSION: This study demonstrates that adding two image preprocessing steps and generating a pseudo color image plays an important role in developing a deep learning CAD scheme of chest X-ray images to improve accuracy in detecting COVID-19 infected pneumonia.	187.8960925449045
1722.	We compared the performance of different Deep Learning - Convolutional Neural Network (DL-CNN) models for bladder cancer treatment response assessment based on transfer learning by freezing different DL-CNN layers and variation of the DL-CNN structure. Pre- and post-treatment CT scans of 123 patients (129 cancers, 158 pre- and post-treatment cancer pairs) undergoing chemotherapy were collected. 33% of patients had T0 stage cancer (complete response) after chemotherapy. Regions of interest (ROIs) of pre- and post-treatment scans were extracted from the segmented lesions and combined into hybrid pre-post image pairs. The dataset was split into training (94 pairs and 6209 hybrid ROIs), validation (10 pairs) and test sets (54 pairs). The DL-CNN consists of 2 convolution (C1, C2), 2 locally connected (L1, L2), and 1 fully connected layers, implemented in TensorFlow. The DL-CNN was trained to classify the bladder cancers as fully responding (stage T0) or not fully responding to chemotherapy based on the hybrid ROIs. Two blinded radiologists provided an estimate of the likelihood of the lesion being stage T0 post-treatment by reading the pairs of pre- and post-treatment CT volumes. The test AUC was 0.73 for T0 prediction by the base DL-CNN structure with randomly initialized weights. The base DL-CNN structure with transfer learning pre-trained weights (no frozen layers) achieved a test AUC of 0.79. The test AUCs for 3 modified DL-CNN structures (different C1, C2 max pooling filter sizes, strides, and padding, with transfer learning) were 0.72, 0.86, and 0.69, respectively. For the base DL-CNN with (C1) frozen, (C1, C2) frozen, and (C1, C2, L3) frozen during transfer learning, the test AUCs were 0.81, 0.78, and 0.71, respectively. The radiologists' AUCs were 0.76 and 0.77. The DL-CNN performed better with pre-trained than randomly initialized weights.	187.8960689846955
1723.	A multi-rotor Unmanned Aerial Vehicle (UAV) system is developed to solve the manhole cover detection problem for the infrastructure maintenance in the suburbs of big city. The visible light sensor is employed to collect the ground image data and a series of image processing and machine learning methods are used to detect the manhole cover. First, the image enhancement technique is employed to improve the imaging effect of visible light camera. An imaging environment perception method is used to increase the computation robustness: the blind Image Quality Evaluation Metrics (IQEMs) are used to percept the imaging environment and select the images which have a high imaging definition for the following computation. Because of its excellent processing effect the adaptive Multiple Scale Retinex (MSR) is used to enhance the imaging quality. Second, the Single Shot multi-box Detector (SSD) method is utilized to identify the manhole cover for its stable processing effect. Third, the spatial coordinate of manhole cover is also estimated from the ground image. The practical applications have verified the outdoor environment adaptability of proposed algorithm and the target detection correctness of proposed system. The detection accuracy can reach 99% and the positioning accuracy is about 0.7 meters.	187.89581284115917
1724.	Automatic identification of a meaning of a word in a context is termed as Word Sense Disambiguation (WSD). It is a vital and hard artificial intelligence problem used in several natural language processing applications like machine translation, question answering, information retrieval, etc. In this paper, an explicit WSD system for Punjabi language using supervised techniques has been analysed. The sense tagged corpus of 150 ambiguous Punjabi noun words has been manually prepared. The six supervised machine learning techniques Decision List, Decision Tree, Naive Bayes, K-Nearest Neighbour (K-NN), Random Forest and Support Vector Machines (SVM) have been investigated in this proposed work. Every classifier has used same feature space encompassing lexical (unigram, bigram, collocations, and co-occurrence) and syntactic (part of speech) count based features. The semantic features of Punjabi language have been devised from the unlabelled Punjabi Wikipedia text using word2vec continuous bag of word and skip gram shallow neural network models. Two deep learning neural network classifiers multilayer perceptron and long short term memory have also been applied for WSD of Punjabi words. The word embedding features have experimented on six classifiers for the Punjabi WSD task. It has been observed that the performance of the supervised classifiers applied for the WSD task of Punjabi language has been enhanced with the application of word embedding features. In this work, an accuracy of 84% has been achieved by LSTM classifier using word embedding feature.	187.89569190863278
1725.	The domain adaptation uses labeled source domain data to train a classifier to be used in the target domain with no or small amount of labeled data. Usually there exists discrepancy in terms of marginal and conditional distributions for both source and target domains, which is of critical importance to minimize the distribution discrepancy between domains. As a classical model in deep learning, the autoencoder is capable of realizing distribution matching and enhancing classification accuracy by extracting more abstract and effective features from data. A Domain adaptation network based on autoencoder (DANA) is proposed. The DANA structure consists of a couple of encoding layers: a feature extraction layer and a classification layer. For the feature extraction layer, the marginal distributions of source and target domains are matched by using the nonparametric maximum mean discrepancy measurement. For the classification layer, the softmax regression model is applied to encode the label information of source domains meanwhile to match the conditional distribution. Experimental results on ImageNet, Corel and Leaves datasets have shown the enhanced classification accuracy by our proposed algorithm compared with the classical methods.	187.89561926172695
1726.	Overlapped fingerprints can be potentially present in several civil applications and criminal investigations. Segmentation of overlapped fingerprints is a required step in the process of fingerprint separation and subsequent verification. Overlapped fingerprint segmentation is performed manually (and the resulting manually drawn masks are a required additional input) in all of the overlapped latent fingerprints separation approaches in the literature, which make them only semi-automatic. This study proposes a novel overlapped fingerprint mask segmentation approach, thereby filling that gap in the development of fully automated fingerprint separation solutions. The proposed method uses convolutional neural networks to classify image blocks into three classes - background, single region, and overlapped region. The proposed approach shows satisfactory performance on three different datasets and opens the door for full automation of fingerprint separation algorithms, which is a very promising research area.	187.89548332621524
1727.	Compounds with the ability to interact with multiple targets, also called promiscuous compounds, provide the basis for polypharmacological drug discovery. In recent years, a plethora of structural analogs with different promiscuity has been identified. Nevertheless, the molecular origins of promiscuity remain to be elucidated. In this study, we systematically extracted different structural analogs with varying promiscuity using the matched molecular pair (MMP) formalism from public biological screening and medicinal chemistry data. Care was taken to eliminate all compounds with potential false-positive activity annotations from the analysis. Promiscuity predictions were then attempted at the level of compound pairs representing promiscuity cliffs (PCs; formed by analogs with large promiscuity differences) and corresponding non-PC MMPs (analog pairs without significant promiscuity differences). To address this prediction task, different machine learning models were generated and the results were compared with single compound predictions. PCs encoding promiscuity differences were found to contain more structure-promiscuity relationship information than sets of individual promiscuous compounds. In addition, feature analysis was carried out revealing key contributions to the correct prediction of PCs and non-PC MMPs via machine learning.	187.89545637052802
1728.	Heavy metal contamination in soil disturbs the chemical, biological, and physical soil conditions and adversely affects the health of living organisms. Visible and near-infrared spectroscopy (VNIRS) shows a potential feasibility for estimating heavy metal elements in soil. Moreover, deep learning models have been shown to successfully deal with complex multi-dimensional and multivariate nonlinear data. Thus, this study implemented a deep learning method on reflectance spectra of soil samples to estimate heavy metal concentrations. A convolutional neural network (CNN) was adopted to estimate arsenic (As), copper (Cu), and lead (Pb) concentrations using measured soil reflectance. In addition, a convolutional autoencoder was utilized as a joint method with the CNN for dimensionality reduction of the reflectance spectra. Furthermore, artificial neural network (ANN) and random forest regression (RFR) models were built for heavy metal estimation. Principal component analysis was utilized for dimensionality reduction of the ANN and RFR models. Among these models, the CNN model with convolutional autoencoder showed the highest accuracies for As, Cu, and Pb estimates, having R-2 values of 0.86, 0.74, and 0.82, respectively. The convolutional autoencoder disentangled the relevant features of multiple heavy metal elements and delivered robust features to the CNN model, thereby generating relatively accurate estimates. (c) 2020 Elsevier B.V. All rights reserved.	187.89545483643963
1729.	We present a style-transfer based wrapper, called Universal Material Generator (UMG), to improve the generalization performance of any fingerprint spoof (presentation attack) detector against spoofs made from materials not seen during training. Specifically, we transfer the style (texture) characteristics between fingerprint images of known materials with the goal of synthesizing fingerprint images corresponding to unknown materials, that may occupy the space between the known materials in the deep feature space. Synthetic live fingerprint images are also added to the training dataset to supervise the CNN to learn generative-noise invariant features which discriminate between lives and spoofs. The proposed approach is shown to improve the generalization performance of two state-of-the-art spoof detectors, namely Fingerprint Spoof Buster and Slim-ResCNN, winner of the LivDet 2017 spoof detection competition. Specifically, the performance is improved from TDR of 75.24% and 73.09% to TDR of 91.78% and 90.63% @ FDR = 0.2% for Spoof Buster and Slim-ResCNN, respectively. These results are based on a large-scale dataset of 5,743 live and 4,912 spoof images fabricated using 12 different materials. In addition to generalization across different spoof materials, the proposed approach is also shown to improve the average cross-sensor spoof detection performance from 67.60% and 64.62% to 80.63% and 77.59%, for Fingerprint Spoof Buster and Slim-ResCNN, respectively, when tested on the LivDet 2017 dataset.	187.89533703722032
1730.	By 2040, similar to 100 million people will have glaucoma. To date, there are a lack of high-efficiency glaucoma diagnostic tools based on visual fields (VFs). Herein, we develop and evaluate the performance of 'iGlaucoma', a smartphone application-based deep learning system (DLS) in detecting glaucomatous VF changes. A total of 1,614,808 data points of 10,784 VFs (5542 patients) from seven centers in China were included in this study, divided over two phases. In Phase I, 1,581,060 data points from 10,135 VFs of 5105 patients were included to train (8424 VFs), validate (598 VFs) and test (3 independent test sets-200, 406, 507 samples) the diagnostic performance of the DLS. In Phase II, using the same DLS, iGlaucoma cloud-based application further tested on 33,748 data points from 649 VFs of 437 patients from three glaucoma clinics. With reference to three experienced expert glaucomatologists, the diagnostic performance (area under curve [AUC], sensitivity and specificity) of the DLS and six ophthalmologists were evaluated in detecting glaucoma. In Phase I, the DLS outperformed all six ophthalmologists in the three test sets (AUC of 0.834-0.877, with a sensitivity of 0.831-0.922 and a specificity of 0.676-0.709). In Phase II, iGlaucoma had 0.99 accuracy in recognizing different patterns in pattern deviation probability plots region, with corresponding AUC, sensitivity and specificity of 0.966 (0.953-0.979), 0.954 (0.930-0.977), and 0.873 (0.838-0.908), respectively. The 'iGlaucoma' is a clinically effective glaucoma diagnostic tool to detect glaucoma from humphrey VFs, although the target population will need to be carefully identified with glaucoma expertise input.	187.89518578109454
1731.	Long-term blood pressure (BP) monitoring is a widely used approach in a homecare intelligent system. However, BP is usually measured using cuff-based devices with tedious operation in practice, which may not be cost effective for continuous BP tracking. In this article, we propose a novel attention-based multitask network with a weighting scheme for BP estimation by analyzing and modeling single lead electrocardiogram (ECG) signals. Experimental results demonstrate that the proposed method could achieve mean error of systolic blood pressure, diastolic blood pressure, and mean arterial pressure estimation in levels of 0.18 +/- 10.83, 1.24 +/- 5.90, and 0.84 +/- 6.47 mmHg, respectively. In comparison to other cutting-edge methods using ECG signals, the proposed method shows superior BP estimation performance. By integrating with a wearable/portable ECG monitoring device, the proposed model can be deployed to an embedded system or remote healthcare intelligent system to provide long-term BP monitoring service, which would help to reduce the incidence of malignant events happened in hypertensive population.	187.8951172899377
1732.	Accurate clinical target volume (CTV) delineation is essential to ensure proper tumor coverage in radiation therapy. This is a particularly difficult task for head-and-neck cancer patients where detailed knowledge of the pathways of microscopic tumor spread is necessary. This paper proposes a solution to auto-segment these volumes in oropharyngeal cancer patients using a two-channel 3D U-Net architecture. The first channel feeds the network with the patient's CT image providing anatomical context, whereas the second channel provides the network with tumor location and morphological information. Radiation therapy simulation computer tomography scans and their corresponding manually delineated CTV and gross tumor volume (GTV) delineations from 285 oropharyngeal patients previously treated at MD Anderson Cancer Center were used in this study. CTV and GTV delineations underwent rigorous group peer-review prior to the start of treatment delivery. The convolutional network's parameters were fine-tuned using a training set of 210 patients using 3-fold cross-validation. During hyper-parameter selection, we use a score based on the overlap (dice similarity coefficient (DSC)) and missed volumes (false negative dice (FND)) to minimize any possible under-treatment. Three auto-delineated models were created to estimate tight, moderate, and wide CTV margin delineations. Predictions on our test set (75 patients) resulted in auto-delineations with high overlap and close surface distance agreement (DSC > 0.75 on 96% of cases for tight and moderate auto-delineation models and 97% of cases having mean surface distance <= 5.0 mm) to the ground-truth. We found that applying a 5 mm uniform margin expansion to the auto-delineated CTVs would cover at least 90% of the physician CTV volumes for a large majority of patients; however, determination of appropriate margin expansions for auto-delineated CTVs merits further investigation.	187.89509771460737
1733.	A numerical study aiming at the enhancement of the operating range of supersonic cascade via boundary layer suction is presented. The purpose of this paper is to improve the maximum backpressure ratio of the flowfield by suction control and to learn the flowfield behavior and characteristics with different suction control parameters. An S-shaped supersonic cascade developed and tested at DLR (DLR-PAV-1.5) that operates with a relative entrance Mach number of 1.5 is selected in this paper. A two-dimensional multiblock N-S solver has been successfully applied to the cascade flow which is validated using the data of the experiment of Schreiber. An in-deep numerical study has been carried out to investigate the effects of suction locations, widths and angles by comparing the operating range and aerodynamic performance parameters of the supersonic cascade. The results indicate that the maximum backpressure ratio can be enhanced by 17.4% with a loss of 3% mainstream mass flow by suction slot in 60% or 70% length of the axial chord. As the width of the suction slot increases to 7 mm, the maximum backpressure ratio is enhanced by 24%, and the total pressure recovery coefficient is improved to 95.3%. The range of suction slot angle that can effectively improve the maximum backpressure ratio is 60-90 degrees and -90 degrees to -60 degrees. This paper provides guidance for the supersonic cascade to improve its performance parameters through suction control.	187.89502085910243
1734.	The rapid growth and wide applicability of Deep Learning (DL) frameworks poses challenges to computing centers which need to deploy and support the software, and also to domain scientists who have to keep up with the system environment and scale up scientific exploration through DL. We offer recommendations for deploying and scaling DL frameworks on the Summit supercomputer, currently atop the Top500 list, at the Oak Ridge National Laboratory Leadership Computing Facility (OLCF). We discuss DL software deployment in the form of containers, and compare performance of native-built frameworks and containerized deployment. Software containers show no noticeable negative performance impact and exhibit faster Python loading times and promise easier maintenance. To explore strategies for scaling up DL model training campaigns, we assess DL compute kernel performance, discuss and recommend I/O data formats and staging, and identify communication needs for scalable message exchange for DL runs at scale. We recommend that users take a step-wise tuning approach beginning with algorithmic kernel choice, node I/O configuration, and communications tuning as best-practice. We present baseline examples of scaling efficiency 87% for a DL run of ResNet50 running on 1024 nodes (6144 V100 GPUs).	187.89484563893518
1735.	This article uses the Model of Domain Learning as a framework to better understand the developmental nature of students' second language acquisition and teaching and learning of foreign languages. This examination includes the development of knowledge, strategies, and interest through the stages of expertise in the MDL - namely acclimation, competence, and proficiency/expertise. What encapsulates knowledge, strategies, and interest in the second language acquisition and previous empirical research that supports these developmental notions are overviewed. Finally, directions for future research and practical implications are discussed in light of the developmental nature of expertise development in second language acquisition and foreign language teaching and learning. (c) 2019 Elsevier Ltd. All rights reserved.	187.8945385408176
1736.	BACKGROUND AND OBJECTIVE: Currently, it is challenging to detect acute ischemic stroke (AIS)-related changes on computed tomography (CT) images. Therefore, we aimed to develop and evaluate an automatic AIS detection system involving a two-stage deep learning model. METHODS: We included 238 cases from two different institutions. AIS-related findings were annotated on each of the 238 sets of head CT images by referring to head magnetic resonance imaging (MRI) images in which an MRI examination was performed within 24h following the CT scan. These 238 annotated cases were divided into a training set including 189 cases and test set including 49 cases. Subsequently, a two-stage deep learning detection model was constructed from the training set using the You Only Look Once v3 model and Visual Geometry Group 16 classification model. Then, the two-stage model performed the AIS detection process in the test set. To assess the detection model's results, a board-certified radiologist also evaluated the test set head CT images with and without the aid of the detection model. The sensitivity of AIS detection and number of false positives were calculated for the evaluation of the test set detection results. The sensitivity of the radiologist with and without the software detection results was compared using the McNemar test. A p-value of less than 0.05 was considered statistically significant. RESULTS: For the two-stage model and radiologist without and with the use of the software results, the sensitivity was 37.3%, 33.3%, and 41.3%, respectively, and the number of false positives per one case was 1.265, 0.327, and 0.388, respectively. On using the two-stage detection model's results, the board-certified radiologist's detection sensitivity significantly improved (p-value=0.0313). CONCLUSIONS: Our detection system involving the two-stage deep learning model significantly improved the radiologist's sensitivity in AIS detection.	187.89447623093383
1737.	Motivation: Protein-protein interactions are important for many biological processes. Theoretical understanding of the structurally determining factors of interaction sites will help to understand the underlying mechanism of protein-protein interactions. Taking advantage of advanced mathematical methods to correctly predict interaction sites will be useful. Although some previous studies have been devoted to the interaction interface of protein monomer and the interface residues between chains of protein dimers, very few studies about the interface residues prediction of protein multimers, including trimers, tetramer and even more monomers in a large protein complex. As we all know, a large number of proteins function with the form of multibody protein complexes. And the complexity of the protein multimers structure causes the difficulty of interface residues prediction on them. So, we hope to build a method for the prediction of protein tetramer interface residue pairs. Results: Here, we developed a new deep network based on LSTM network combining with graph to predict protein tetramers interaction interface residue pairs. On account of the protein structure data is not the same as the image or video data which is well-arranged matrices, namely the Euclidean Structure mentioned in many researches. Because the Non-Euclidean Structure data can't keep the translation invariance, and we hope to extract some spatial features from this kind of data applying on deep learning, an algorithm combining with graph was developed to predict the interface residue pairs of protein interactions based on a topological graph building a relationship between vertexes and edges in graph theory combining multilayer Long Short-Term Memory network. First, selecting the training and test samples from the Protein Data Bank, and then extracting the physicochemical property features and the geometric features of surface residue associated with interfacial properties. Subsequently, we transform the protein multimers data to topological graphs and predict protein interaction interface residue pairs using the model. In addition, different types of evaluation indicators verified its validity.	187.89445222046575
1738.	Phase Measuring Deflectometry (PMD) is an effective metrology technique for specular surfaces, but it is hard to achieve rapid measurement precisely with prevenient fringe analysis methods. Inspired by recent successes of deep learning techniques for fringe analysis, we demonstrate for the first time that deep learning can be used to achieve high-precision three-dimensional (3D) measurement of specular surfaces with a single frame. In this research, it is proposed to use depthwise separable convolution to optimize measured results. Experimental results proved that this proposed method has better performance than the existing fringe analysis method employing deep learning.	187.89441997153105
1739.	The actual geographic learning resources are found in the field, that the field takes an important role in Geography studies with its function as a laboratory. In the field, students can understand the true conditions about Geography studies directly. Galunggung volcano was located in Tasikmalaya, West Java, Indonesia. It has potential aspect to be developed into a laboratory for Geography studies. The purpose of this study is to identify the potential possessed by the Galunggung mountain area as a Geography education laboratory. The step carried out in the Galunggung area analysis are: Delineation of the Galunggung volcano area using Satellite Maps and Images, data obtained by field surveys which are identified descriptively. Utilization of the Mount Galunggung Area as a field laboratory can help students to gain deeper understanding about the study in a more realistic situation. Mount Galunggung has the potential to be developed into a Geography Education Laboratory based on studies; hydrosphere, lithosphere, biosphere, anthroposphere, and atmosphere. Evaluation of environment-based learning is carried out thoroughly during the learning process and after learning is completed.	187.8943693725598
1740.	Human tissues are known to exhibit interindividual variability, but a deeper understanding of the different factors affecting protein expression is necessary to further apply this knowledge. Our goal was to explore the proteomic variability between individuals as well as between healthy and diseased samples, and to test the efficacy of machine learning classifiers. In order to investigate whether disparate proteomics data sets may be combined, we performed a retrospective analysis of proteomics data from 9 different human tissues. These data sets represent several different sample prep methods, mass spectrometry instruments, and tissue health. Using these data, we examined interindividual and intertissue variability in peptide expression, and analyzed the methods required to build accurate tissue classifiers. We also evaluated the limits of tissue classification by downsampling the peptide data to simulate situations where less data is available, such as clinical biopsies, laser capture microdissection or potentially single-cell proteomics. Our findings reveal the strong potential for utilizing proteomics data to build robust tissue classifiers, which has many prospective clinical applications for evaluating the applicability of model clinical systems.	187.89430520525872
1741.	Glaucoma is a chronic eye disease that leads to irreversible vision loss. Most of the existing automatic screening methods first segment the main structure and subsequently calculate the clinical measurement for the detection and screening of glaucoma. However, these measurement-based methods rely heavily on the segmentation accuracy and ignore various visual features. In this paper, we introduce a deep learning technique to gain additional image-relevant information and screen glaucoma from the fundus image directly. Specifically, a novel discaware ensemble network for automatic glaucoma screening is proposed, which integrates the deep hierarchical context of the global fundus image and the local optic disc region. Four deep streams on different levels and modules are, respectively, considered as global image stream, segmentation-guided network, local disc region stream, and disc polar transformation stream. Finally, the output probabilities of different streams are fused as the final screening result. The experiments on two glaucoma data sets (SCES and new SINDI data sets) show that our method outperforms other state-of-the-art algorithms.	187.8942015299367
1742.	Hierarchical local nonlinear dynamic feature learning is of great importance for soft sensor modeling in process industry. Convolutional neural network (CNN) is an excellent local feature extractor that is suitable for process data representation. In this paper, a dynamic CNN (DCNN) strategy is designed to learn hierarchical local nonlinear dynamic features for soft sensor modeling. In DCNN, each 1D process sample is dynamically augmented into 2D data sample with lagged unlabeled process variables, which contains both spatial cross -correlations and temporal auto-correlations. Then, the convolutional and pooling layers are alternately utilized to extract the local nonlinear spatial-temporal feature from the 2D sample data matrix. Moreover, the principle is analyzed for DCNN on how it can learn the local nonlinear spatial-temporal feature from the network. The effectiveness of proposed DCNN is verified on an industrial hydrocracking process.	187.89419713538913
1743.	This article proposes a parallel algorithm for computing the arithmetic reduction of n numbers as a set of matrix-multiply accumulate (MMA) operations that are executed simultaneously by GPU tensor cores. The analysis, assuming tensors of size m x m, shows that the proposed algorithm has a parallel running time of T(n) = 5log(m2n) and a speedup of S = 4/5 log(2) m(2) over a canonical parallel reduction. Experimental performance results on a Tesla V100 GPU show that the tensor-core based approach is energy efficient and runs up to similar to 3.2x and 2x faster than a standard GPU-based reduction and Nvidia's CUB library, respectively, while keeping the numerical error below 1 percent with respect to a double precision CPU reduction. The chained design of the algorithm allows a flexible configuration of GPU thread-blocks and the optimal values found through experimentation agree with the theoretical ones. The results obtained in this work show that GPU tensor cores are relevant not only for Deep Learning or Linear Algebra computations, but also for applications that require the acceleration of large summations.	187.89412255394032
1744.	Unmanned Aerial Vehicles (UAVs) have been widely applied for pesticide spraying as they have high efficiency and operational flexibility. However, the pesticide droplet drift caused by wind may decrease the pesticide spraying efficiency and pollute the environment. A precision spraying system based on an airborne meteorological monitoring platform on manned agricultural aircrafts is not adaptable for. So far, there is no better solution for controlling droplet drift outside the target area caused by wind, especially by wind gusts. In this regard, a UAV trajectory adjustment system based on Wireless Sensor Network (WSN) for pesticide drift control was proposed in this research. By collecting data from ground WSN, the UAV utilizes the wind speed and wind direction as inputs to autonomously adjust its trajectory for keeping droplet deposition in the target spraying area. Two optimized algorithms, namely deep reinforcement learning and particle swarm optimization, were applied to generate the newly modified flight route. At the same time, a simplified pesticide droplet drift model that includes wind speed and wind direction as parameters was developed and adopted to simulate and compute the drift distance of pesticide droplets. Moreover, an LSTM-based wind speed prediction model and a RNN-based wind direction prediction model were established, so as to address the problem of missing the latest wind data caused by communication latency or a lack of connection with the ground nodes. Finally, experiments were carried out to test the communication latency between UAV and ground WSN, and to evaluate the proposed scheme with embedded Raspberry Pi boards in UAV for feasibility verification. Results show that the WSN-assisted UAV trajectory adjustment system is capable of providing a better performance of on-target droplet deposition for real time pesticide spraying with UAV.	187.8940088983128
1745.	In this study, we propose and validate an end-to-end pipeline based on deep learning for differential diagnosis of emphysema in thoracic CT images. The five lung tissue patterns involved in most differential restrictive and obstructive lung disease diagnoses include: emphysema, ground glass, fibrosis, micronodule, and normal. Four established network architectures have been trained and evaluated. To the best of our knowledge, this is the first comprehensive end-to-end deep CNN pipeline for differential diagnosis of emphysema. A comparative analysis shows the performance of the proposed models on two publicly available datasets.	187.893952861549
1746.	We previously introduced the Radon Cumulative Distribution Transform (RCDT) as a novel image transformation to highlight the subtle difference between left and right mammograms to detect mammographically-occult (MO) cancer from women with dense breasts and negative screening mammograms. This study developed deep convolutional neural networks (CNN) as classifiers for estimating the probability of having MO cancer. We acquired screening mammograms of 333 women (97 unilateral MO cancer) with dense breasts and at least two consecutive mammograms and used the immediate prior mammograms, which radiologists interpreted as negative. We divided our dataset into a training, a validation, and a test set with ratios of 0.72:0.08:0.2. We applied RCDT on the left and right mammograms of each view. We applied inverse radon transform to represent the resulting RCDT images in the image domain. We then fine-tuned a VGG16 network pretrained on ImageNet using the resulting images per each view. Using the same images, we also developed a traditional classifier using handcrafted features per each view. The CNNs achieved areas under the receiver operating characteristic (AUC) curve of 0.74 and 0.69 for CC view and MLO view, respectively. The traditional classifiers from handcrafted features achieved AUCs of 0.5 and 0.64 for CC view and MLO view, respectively. We averaged the scores from the top three classifiers and achieved an AUC of 0.81 on the test set. In conclusion, we showed that inverse radon transformed RCDT images hold information to detect MO cancer and deep CNNs could learn such information.	187.8939448719148
1747.	Traffic problems have seriously affected people's life quality and urban development, and forecasting short-term traffic congestion is of great importance to both individuals and governments. However, understanding and modeling the traffic conditions can be extremely difficult, and our observations from real traffic data reveal that: 1) similar traffic congestion patterns exist in the neighboring time slots and on consecutive workdays and 2) the levels of traffic congestion have clear multiscale properties. To capture these characteristics, we propose a novel method named PCNN, which is based on a deep convolutional neural network, modeling periodic traffic data for short-term traffic congestion prediction. PCNN has two pivotal procedures: time series folding and multi-grained learning. It first temporally folds the time series and constructs a 2-D matrix as the network input, such that both the real-time traffic conditions and past traffic patterns are well considered; then, with a series of convolutions over the input matrix, it is able to model the local temporal dependency and multiscale traffic patterns. In particular, the global trend of congestion can be addressed at the macroscale, whereas more details and variations of the congestion can be captured at the microscale. Experimental results on a realworld urban traffic data set confirm that folding time series data into a 2-D matrix is effective and PCNN outperforms the baselines significantly for the task of short-term congestion prediction.	187.8939151238687
1748.	Lung cancer is a serious illness affects people all over the globe. To increase the survival rate of patients affected by lung cancer, in advance recognition of lung cancer with effective treatments is important. This study introduces a new deep learning (DL) based feature extraction and classification technique for CT lung images. A DL model using Coding Network (CN) is presented for the extraction of high-level features and classical features. Initially, the convolution neural network is trained as a coding network and the actual pixels are coded into feature vectors for representing the high-level concepts for classification. Next, an extraction of chosen classical features takes place depending upon background knowledge of lung CT images. In addition, an automatic feature fusion takes place to avoid annoying parameter choice. Besides, support vector machine (SVM) model is employed for classify CT lung images in an effective way. For experimentation, a benchmark dataset is utilized to appraise the outcome of the presented CN-SVM model and is validated under several dimensions.	187.8938798472493
1749.	Using electron beam manipulation, we enable deterministic motion of individual Si atoms in graphene along predefined trajectories. Structural evolution during the dopant motion was explored, providing information on changes of the Si atom neighborhood during atomic motion and providing statistical information of possible defect configurations. The combination of a Gaussian mixture model and principal component analysis applied to the deep learning-processed experimental data allowed disentangling of the atomic distortions for two different graphene sublattices. This approach demonstrates the potential of e-beam manipulation to create defect libraries of multiple realizations of the same defect and explore the potential of symmetry breaking physics. The rapid image analytics enabled via a deep learning network further empowers instrumentation for e-beam controlled atom-by-atom fabrication. The analysis described in the paper can be reproduced via an interactive Jupyter notebook at https://git.io/JJ3Bx.	187.8938443152639
1750.	Domain adaptation, which transfers the knowledge from label-rich source domain to unlabeled target domains, is a challenging task in machine learning. The prior domain adaptation methods focus on pairwise adaptation assumption with a single source and a single target domain, while little work concerns the scenario of one source domain and multiple target domains. Applying pairwise adaptation methods to this setting may be suboptimal, as they fail to consider the semantic association among multiple target domains. In this work we propose a deep semantic information propagation approach in the novel context of multiple unlabeled target domains and one labeled source domain. Our model aims to learn a unified subspace common for all domains with a heterogeneous graph attention network, where the transductive ability of the graph attention network can conduct semantic propagation of the related samples among multiple domains. In particular, the attention mechanism is applied to optimize the relationships of multiple domain samples for better semantic transfer. Then, the pseudo labels of the target domains predicted by the graph attention network are utilized to learn domain-invariant representations by aligning labeled source centroid and pseudo-labeled target centroid. We test our approach on four challenging public datasets, and it outperforms several popular domain adaptation methods.	187.8935684845652
1751.	Automatic Image Annotation (AIA) aims to provide a semantic description for the content of image by assigning a set of textual labels. The recent approaches mainly focus on the improvement of single model and neglect the potential advantages of different models. In order to make full use of the advantages of different annotation models, Dual Model based on Multi-Label Selection Algorithm(DM-SA) is proposed in this research which combines a discriminative model with a nearest-neighbor-based model. The algorithm takes consideration of the advantages of each model, thus provides better annotation performance. A deep Convolutional Neural Network (CNN) is used to obtain visual representation of images first, then a discriminative model, CNN with Label Smoothing (CNN-LS), and a nearest-neighbor-based model, 2PKNN with Canonical Correlation Analysis (2PKNN-CCA) generate candidate label set respectively. Finally, a multi-label selection algorithm based on inverse document frequency is adopted to assign the final labels from two candidate label sets. Experimental results based on Corel5K and IAPRTC-12 datasets show that the proposed method can achieve state-of-the-art performance for average recall, 0.52 and 0.42 on Corel5K and IAPRTC-12 respectively.	187.8934925885237
1752.	Identifying bacterial species is essential to epidemiological surveillance. However, the determination of bacterial species is a tedious and labor-intensive process. Various machine learning methods have been used for identifying bacterial species with mass spectral fingerprints. Although machine learning methods achieve real-time identification without human experts, it still requires data preprocessing. To address this issue, we proposed a unified solution for the identification of bacterial species with a convolutional neural network. The neural network automatically determined species according to their mass spectra without the preprocessing steps. The convolutional and pooling layers in the neural network could replace the binning, baseline correction, and scaling procedures. Moreover, because of the explainable structure, the model could identify important regions of spectra to discriminate each bacterial species. We used spectral samples obtained from the fatty acid methyl esters of 10 samples from 16 bacterial species (a total of 16) to demonstrate the usefulness of the proposed method by comparing it with existing classification methods preceded by preprocessing. The comparison results confirmed that the proposed method outperformed the alternatives in terms of classification accuracy and robustness. Moreover, the classification results of the proposed method are interpretable.	187.89337265762902
1753.	Quantitative assessments of patient movement quality in osteoarthritis (OA), specifically spatiotemporal gait parameters (STGPs), can provide in-depth insight into gait patterns, activity types, and changes in mobility after total knee arthroplasty (TKA). A study was conducted to benchmark the ability of multiple deep neural network (DNN) architectures to predict 12 STGPs from inertial measurement unit (IMU) data and to identify an optimal sensor combination, which has yet to be studied for OA and TKA subjects. DNNs were trained using movement data from 29 subjects, walking at slow, normal, and fast paces and evaluated with cross-fold validation over the subjects. Optimal sensor locations were determined by comparing prediction accuracy with 15 IMU configurations (pelvis, thigh, shank, and feet). Percent error across the 12 STGPs ranged from 2.1% (stride time) to 73.7% (toe-out angle) and overall was more accurate in temporal parameters than spatial parameters. The most and least accurate sensor combinations were feet-thighs and singular pelvis, respectively. DNNs showed promising results in predicting STGPs for OA and TKA subjects based on signals from IMU sensors and overcomes the dependency on sensor locations that can hinder the design of patient monitoring systems for clinical application.	187.8933128093511
1754.	Spoken language identification (LID) or spoken language recognition (LR) is defined as the process of recognizing the language from speech utterance. In this paper, a new Fourier parameter (FP) model is proposed for the task of speaker-independent spoken language recognition. The performance of the proposed FP features is analyzed and compared with the legacy mel-frequency cepstral coefficient (MFCC) features. Two multilingual databases, namely Indian Institute of Technology Kharagpur Multilingual Indian Language Speech Corpus (IITKGP-MLILSC) and Oriental Language Recognition Speech Corpus (AP18-OLR), are used to extract FP and MFCC features. Spoken LID/LR models are developed with the extracted FP and MFCC features using three classifiers, namely support vector machines, feed-forward artificial neural networks, and deep neural networks. Experimental results show that the proposed FP features can effectively recognize different languages from speech signals. It can also be observed that the recognition performance is significantly improved when compared to MFCC features. Further, the recognition performance is enhanced when MFCC and FP features are combined.	187.89318424151867
1755.	BACKGROUND: Data augmentation (DA) has recently been demonstrated to achieve considerable performance gains for deep learning (DL)-increased accuracy and stability and reduced overfitting. Some electroencephalography (EEG) tasks suffer from low samples-to-features ratio, severely reducing DL effectiveness. DA with DL thus holds transformative promise for EEG processing, possibly like DL revolutionized computer vision, etc. NEW METHOD: We review trends and approaches to DA for DL in EEG to address: Which DA approaches exist and are common for which EEG tasks? What input features are used? And, what kind of accuracy gain can be expected? RESULTS: DA for DL on EEG begun 5 years ago and is steadily used more. We grouped DA techniques (noise addition, generative adversarial networks, sliding windows, sampling, Fourier transform, recombination of segmentation, and others) and EEG tasks (into seizure detection, sleep stages, motor imagery, mental workload, emotion recognition, motor tasks, and visual tasks). DA efficacy across techniques varied considerably. Noise addition and sliding windows provided the highest accuracy boost; mental workload most benefitted from DA. Sliding window, noise addition, and sampling methods most common for seizure detection, mental workload, and sleep stages, respectively. COMPARING WITH EXISTING METHODS: Percent of decoding accuracy explained by DA beyond unaugmented accuracy varied between 8 % for recombination of segmentation and 36 % for noise addition and from 14 % for motor imagery to 56 % for mental workload-29 % on average. CONCLUSIONS: DA increasingly used and considerably improved DL decoding accuracy on EEG. Additional publications-if adhering to our reporting guidelines-will facilitate more detailed analysis.	187.89315799494753
1756.	Orbital angular momentum (OAM) has demonstrated great success in the optical communication field, which theoretically allows an infinite increase of the transmitted capacity. The resolution of a receiver to precisely recognize OAM modes is crucial to expand the communication capacity. Here, we propose a deep learning (DL) method to precisely recognize OAM modes with fractional topological charges. The minimum interval recognized between adjacent modes decreases to 0.01, which as far as we know is the first time this superhigh resolution has been realized. To exhibit its efficiency in the optical communication process, we transfer an Einstein portrait by a superhigh-resolution OAM multiplexing system. As the convolutional neuron networks can be trained by data up to an infinitely large volume in theory, this work exhibits a huge potential of generalized suitability for next generation DL based ultrafine OAM optical communication, which might even be applied to microwave, millimeter wave, and terahertz OAM communication systems.	187.89311166164856
1757.	Rapid advances of big data and artificial intelligence (AI) techniques have pushed the envelope of traditional surgery to intelligent surgery, which revolutionizes the traditional medicine model dominated by the experiences of interveners and evidence-based medicine. Intelligent surgery requires to judiciously integrate the clinical experience of interveners and medical evidences with the new AI techniques, so as to achieve the best therapeutic effect for patients through effective disease risk control. This paper puts forward a new theory of prognostic control surgery in the long-term clinical practice of hepato-pancreato-biliary surgery. Our theory takes the optimal prognosis of patients as the goal, and pre-controls the disease risk through the best combination of the optimal intervener, intervention methods and intervention timing to achieve the maximum clinical benefits of patients with minimal medical trauma. This theory also takes full advantage of information technologies such as neural networks, deep learning, big data and imaging system, and uses high-dimensional network decision making to replace the traditional two-dimensional decision making tree model. A main technical challenge in the theory is how to effectively exploit the AI techniques in to improve the production efficiency of large hospitals, enhance the service level of primary medical care, and improve the diagnosis, prediction, treatment of diseases. Prognostic control surgery advocates the exploitation of emerging information technology methods, such as medical image recognition and prediction, 3D reconstruction based surgical planning, intraoperative navigation, and remote intelligent robotic surgical system, to promote the rapid and balanced surgical diagnosis and treatment. Guided by the theory of prognosis control surgery, our team successfully established minimally invasive anatomic hepatectomy, individualized pancreatic surgical approaches, modular hepatectomy, single-layer continuous suture of pancreaticojejunostomy, and end-to-end pancreatic anastomosis and advocated en-bloc resection of pancreatic cancer. This paper also provides the details of four core surgical strategies proposed in our prognosis control surgery, namely, blood control technique, surgical approach selection, resection technique and reconstruction technique, by which to achieve the minimally invasive surgery regularization and the complex surgery simplification.	187.8927801609239
1758.	Non-Small Cell Lung Cancer (NSCLC) is a major lung cancer type. Proper diagnosis depends mainly on tumor staging and grading. Pathological prognosis often faces problems because of the limited availability of tissue samples. Machine learning methods may play a vital role in such cases. 2D or 3D Deep Neural Networks (DNNs) has been the predominant technology in this domain. Contemporary studies tried to classify NSCLC tumors as benign or malignant. The application of 1D CNN in automated staging and grading of NSCLC is not very frequent. The aim of the present study is to develop a 1 D CNN model for automated staging and grading of NSCLC. The updated NSCLC Radiogenomics Collection from The Cancer Imaging Archive (TCIA) was used in the study. The segmented tumor images were fed into a hybrid feature detection and extraction model (MSER-SURF). The extracted features were clubbed with the clinical TNM stage and histopathological grade information and fed into the 1 D CNN model. The performance of the proposed CNN model was satisfactory. The accuracy and ROC-AUC score were higher than the other leading machine learning methods. The study also did well compared to state-of-the-art studies. The proposed model shows that 1D CNN is equally useful in NSCLC prediction like a conventional 2D/3D CNN model. The model may further be refined by carrying out experiments with varied hyper-parameters. Further studies may be conducted by considering semi-supervised or unsupervised learning techniques. (C) 2020 Elsevier Ltd. All rights reserved.	187.89243799999366
1759.	Purpose To accelerate T(2)mapping with highly sparse sampling by integrating deep learning image priors with low-rank and sparse modeling. Methods The proposed method achieves high-speed T(2)mapping by highly sparsely sampling (k, TE)-space. Image reconstruction from the undersampled data was done by exploiting the low-rank structure and sparsity in the T-2-weighted image sequence and image priors learned from training data. The image priors for a single TE were generated from the public Human Connectome Project data using a tissue-based deep learning method; the image priors were then transferred to other TEs using a generalized series-based method. With these image priors, the proposed reconstruction method used a low-rank model and a sparse model to capture subject-dependent novel features. Results The proposed method was evaluated using experimental data obtained from both healthy subjects and tumor patients using a turbo spin-echo sequence. High-quality T(2)maps at the resolution of 0.9 x 0.9 x 3.0 mm(3)were obtained successfully from highly undersampled data with an acceleration factor of 8. Compared with the existing compressed sensing-based methods, the proposed method produced significantly reduced reconstruction errors. Compared with the deep learning-based methods, the proposed method recovered novel features better. Conclusion This paper demonstrates the feasibility of learning T-2-weighted image priors for multiple TEs using tissue-based deep learning and generalized series-based learning. A new method was proposed to effectively integrate these image priors with low-rank and sparse modeling to reconstruct high-quality images from highly undersampled data. The proposed method will supplement other acquisition-based methods to achieve high-speed T(2)mapping.	187.8921701250884
1760.	BACKGROUND AND OBJECTIVE: Morphological diagnosis is a basic clinical task of the short-duration 12-lead electrocardiogram (ECG). Due to the scarcity of positive samples and other factors, there is currently no algorithm that is comparable to human experts in ECG morphological recognition. Our objective is to develop an ECG specialist-level deep learning method that can accurately identify ten ECG morphological abnormalities in real scene data. METHODS: We established a short-duration 12-lead ECG image dataset that consists of approximately 200,000 samples. To address the problems with small positive samples, a data augmentation method was proposed. We solved it by interpolating in the latent space of the vector quantized variational autoencoder (VQ-VAE) and generating new samples via sampling. The trained final classifier, general doctors, and ECG specialists evaluated the diagnostic performance on a test set that consisted of 1000 samples. RESULTS: Relative to that of unaugmented data, the F1 score was improved by 0-6%. Compared with ECG specialists, the deep neural network achieved higher F1 scores and sensitivity in most categories. CONCLUSIONS: Our method can improve the classification performance of ECG data with insufficient positive samples and reach the level of ECG specialists. This approach can provide specialized reference opinions for ordinary clinicians and reduce the errors of ECG specialists.	187.8920830872937
1761.	We propose a method that estimates 6-DoF camera pose from a partially visible large object, by exploiting information of its subparts that are detected using a state-of-the-art convolutional neural network (CNN). The trained CNN outputs two-dimensional bounding boxes around subparts and associated classes. Information from detection is then fed to a deep neural network that regresses to camera's 6-DoF poses. Experimental results show that the proposed method is more robust to occlusions than conventional learning-based methods.	187.89201615357058
1762.	Spine curvature disorders have been found relevant as the nervous system diseases and may produce serious disturbances of the whole body. The ability to automatically segment and locate the spinal vertebrae is, therefore, an important task for modern studies of the spinal curvature disorders detection. In this work, we devise a modern, simple and automated human spinal vertebrae segmentation and localization method using transfer learning, that works on CT and MRI acquisitions. We exploit pre-trained models to spinal vertebrae segmentation and localization problem. We first explore and evaluate different medical imaging architectures and choose the deep dilated convolutions as the initialization for our spinal vertebrae segmentation and localization task. Then we conduct the pre-trained model from spinal cord gray matter dataset to our spinal vertebrae segmentation task with supervised fine-tuning. The vertebral centroid coordinate can be computed from the segmented result, and the centroid localization error is used as the feedback for fine-tuning. We evaluate our method against traditional method on medical image segmentation and localization task and report the comparison of evaluation metrics. We show the qualitative and quantitative evaluation on spine CT images which are from spine CT volumes on the publicity platform SpineWeb. The evaluation results show that our approach was able to capture many properties of the spinal vertebrae, and provided good segmentation and localization performance. From our research we show that the deep dilated convolutions pre-trained on MRI spinal cord gray matter images can be transfer to process CT spinal vertebrae images.	187.89153823136323
1763.	A comprehensive and comprehensible summary of existing deep neural networks (DNNs) helps practitioners understand the behaviour and evolution of DNNs, offers insights for architecture optimization, and sheds light on the working mechanisms of DNNs. However, this summary is hard to obtain because of the complexity and diversity of DNN architectures. To address this issue, we develop DNN Genealogy, an interactive visualization tool, to offer a visual summary of representative DNNs and their evolutionary relationships. DNN Genealogy enables users to learn DNNs from multiple aspects, including architecture, performance, and evolutionary relationships. Central to this tool is a systematic analysis and visualization of 66 representative DNNs based on our analysis of 140 papers. A directed acyclic graph is used to illustrate the evolutionary relationships among these DNNs and highlight the representative DNNs. A focus + context visualization is developed to orient users during their exploration. A set of network glyphs is used in the graph to facilitate the understanding and comparing of DNNs in the context of the evolution. Case studies demonstrate that DNN Genealogy provides helpful guidance in understanding, applying, and optimizing DNNs. DNN Genealogy is extensible and will continue to be updated to reflect future advances in DNNs.	187.89153028713565
1764.	Principled computational approaches for tumor phylogeny reconstruction via single-cell sequencing typically aim to build the most likely perfect phylogeny tree from the noisy genotype matrix - which represents genotype calls of single cells. This problem is NP-hard, and as a result, existing approaches aim to solve relatively small instances of it through combinatorial optimization techniques or Bayesian inference. As expected, even when the goal is to infer basic topological features of the tumor phylogeny, rather than reconstructing the topology entirely, these approaches could be prohibitively slow. In this paper, we introduce fast deep learning solutions to the problems of inferring whether the most likely tree has a linear (chain) or branching topology and whether a perfect phylogeny is feasible from a given genotype matrix. We also present a reinforcement learning approach for reconstructing the most likely tumor phylogeny. This preliminary work demonstrates that data-driven approaches can reconstruct key features of tumor evolution.	187.89148694555468
1765.	In this Viewpoint, we discuss the current progress in applications of machine learning (ML) and artificial intelligence (AI) to meet the challenges of computational drug discovery. We identify several areas where existing methods have the potential to accelerate pharmaceutical research and disrupt more traditional approaches.	187.8914867954238
1766.	While breast cancer screening recommendations vary by agency, all agencies recommend mammographic screening with some frequency over some portion of a woman's lifetime. Temporal evaluation of these images may inform personalized risk of breast cancer. However, due to the highly deformable nature of breast tissue, the positioning of breast tissue may vary widely between exams. Therefore, registration of physical regions in the breast over time points is a critical first step in computerized analysis of changes in breast parenchyma over time. While a post-registration image is altered and therefore not appropriate for radiomic texture analysis, the registration process produces a mapping of points which may aid in aligning similar image regions across multiple time points. In this study, a total of 633 mammograms from 87 patients were retrospectively collected. These images were sorted into 1144 temporal pairs, where each combination of images of a given women of a given laterality was used to form a temporal pair. B-splines registration and multi-resolution registration were performed on each mammogram pair. While the B-splines took an average of 552.8 CPU seconds per registration, multi-resolution registration took only an average of 346.2 CPU seconds per registration. Multi-resolution registration had a 15% lower mean square error, which was significantly different than that of B-splines (p< 0.001). While previous work aimed to allow radiologists to visually evaluate the registered images, this study identifies corresponding points on images for use in assessing interval change for risk assessment and early detection of cancer through deep learning and radiomics.	187.89144699870496
1767.	Deep neural networks have been successfully applied in many different fields like computational imaging, healthcare, signal processing, or autonomous driving. In a proof-of-principle study, we demonstrate that computational optical form measurement can also benefit from deep learning. A data-driven machine-learning approach is explored to solve an inverse problem in the accurate measurement of optical surfaces. The approach is developed and tested using virtual measurements with a known ground truth.	187.89121481988605
1768.	The use of orthogonal projections on high-dimensional input and target data in learning frameworks is studied. First, we investigate the relations between two standard objectives in dimension reduction, preservation of variance and of pairwise relative distances. Investigations of their asymptotic correlation as well as numerical experiments show that a projection does usually not satisfy both objectives at once. In a standard classification problem, we determine projections on the input data that balance the objectives and compare subsequent results. Next, we extend our application of orthogonal projections to deep learning tasks and introduce a general framework of augmented target loss functions. These loss functions integrate additional information via transformations and projections of the target data. In two supervised learning problems, clinical image segmentation and music information classification, the application of our proposed augmented target loss functions increases the accuracy.	187.89087050138582
1769.	Diagnosis and staging of liver fibrosis is a vital prognostic marker in chronic liver diseases. Due to the inaccuracies and risk of complications associated with liver core needle biopsy, the current standard for diagnosis, other less invasive methods are sought for diagnosis. One such method that has been shown to correlate well with liver fibrosis is shear wave velocity measured by ultrasound (US) shear wave elastography; however, this technique requires specific software, hardware, and training. A current perspective in the radiology community is that the texture pattern from an US image may be predictive of the stage of liver fibrosis. We propose the use of convolutional neural networks (CNNs), a framework shown to be well suited for real world image interpretation, to test whether the texture pattern in gray scale elastography images (B-mode US with fixed, subject-agnostic acquisition settings) is predictive of the shear wave velocity (SWV). In this study, gray scale elastography images from over 300 patients including 3,500 images with corresponding SWV measurements were preprocessed and used as input to 100 different CNN architectures that were trained to regress shear wave velocity. In this study, even the best performing CNN explained only negligible variation in the shear wave velocity measures. These extensive test results suggest that the gray scale elastography image texture provides little predictive information about shear wave velocity and liver fibrosis.	187.89052376335258
1770.	Bedside radiography has increasingly attracted attention because it allows for immediate image diagnosis after X-ray imaging. Currently, wireless flat-panel detectors (FPDs) are used for digital radiography. However, adjustment of the X-ray tube and FPD alignment are extremely difficult tasks. Furthermore, to prevent a poor image quality caused by scattered X-rays, scatter removal grids are commonly used. In this study, we proposed a scatter-correction processing method to reduce the radiation dose when compared with that required by the X-ray grid for the segmentation of a mass region using deep learning during bedside chest radiography. A chest phantom and an acrylic cylinder simulating the mass were utilized to verify the image quality of the scatter-corrected chest X-rays with a low radiation dose. In addition, we used the peak signal-to-noise ratio and structural similarity to quantitatively assess the quality of the low radiation dose images compared with normal grid images. Furthermore, U-net was used to segment the mass region during the scatter-corrected chest X-ray with a low radiation dose. Our results showed that when scatter correction is used, an image with a quality equivalent to that obtained by grid radiography is produced, even when the imaging dose is reduced by approximately 20%. In addition, image contrast was improved using scatter radiation correction as opposed to using scatter removal grids. Our results can be utilized to further develop bedside chest radiography systems with reduced radiation doses.	187.89043516492117
1771.	The abundance and/or location of tumor infiltrating lymphocytes (TILs), especially CD8(+)T cells, in solid tumors can serve as a prognostic indicator in various types of cancer. However, it is often difficult to select an appropriate threshold value in order to stratify patients into well-defined risk groups. It is also important to select appropriate tumor regions to quantify the abundance of TILs. On the other hand, machine-learning approaches can stratify patients in an unbiased and automatic fashion. Based on immunofluorescence (IF) images of CD8(+)T lymphocytes and cancer cells, we develop a machine-learning approach which can predict the risk of relapse for patients with Triple Negative Breast Cancer (TNBC). Tumor-section images from 9 patients with poor outcome and 15 patients with good outcome were used as a training set. Tumor-section images of 29 patients in an independent cohort were used to test the predictive power of our algorithm. In the test cohort, 6 (out of 29) patients who belong to the poor-outcome group were all correctly identified by our algorithm; for the 23 (out of 29) patients who belong to the good-outcome group, 17 were correctly predicted with some evidence that improvement is possible if other measures, such as the grade of tumors, are factored in. Our approach does not involve arbitrarily defined metrics and can be applied to other types of cancer in which the abundance/location of CD8(+)T lymphocytes/other types of cells is an indicator of prognosis.	187.89015140605855
1772.	OBJECTIVE: Particle radiobiology has contributed new understanding of radiation safety and underlying mechanisms of action to radiation oncology for the treatment of cancer, and to planning of radiation protection for space travel. This manuscript will highlight the significance of precise physical and biologically effective dosimetry to this translational research for the benefit of human health.This review provides a brief snapshot of the evolving scientific basis for, and the complex current global status, and remaining challenges of hadron therapy for the treatment of cancer. The need for particle radiobiology for risk planning in return missions to the Moon, and exploratory deep-space missions to Mars and beyond are also discussed. METHODS: Key lessons learned are summarized from an impressive collective literature published by an international cadre of multidisciplinary experts in particle physics, radiation chemistry, medical physics of imaging and treatment planning, molecular, cellular, tissue radiobiology, biology of microgravity and other stressors, theoretical modeling of biophysical data, and clinical results with accelerator-produced particle beams. RESULTS: Research pioneers, many of whom were Nobel laureates, led the world in the discovery of ionizing radiations originating from the Earth and the Cosmos. Six radiation pioneers led the way to hadron therapy and the study of charged particles encountered in outer space travel. Worldwide about 250,000 patients have been treated for cancer, or other lesions such as arteriovenous malformations in the brain between 1954 and 2019 with charged particle radiotherapy, also known as hadron therapy. The majority of these patients (213,000) were treated with proton beams, but approximately 32,000 were treated with carbon ion radiotherapy. There are 3500 patients who have been treated with helium, pions, neon or other ions. There are currently 82 facilities operating to provide ion beam clinical treatments. Of these, only 13 facilities located in Asia and Europe are providing carbon ion beams for preclinical, clinical, and space research. There are also numerous particle physics accelerators worldwide capable of producing ion beams for research, but not currently focused on treating patients with ion beam therapy but are potentially available for preclinical and space research. Approximately, more than 550 individuals have traveled into Lower Earth Orbit (LEO) and beyond and returned to Earth. CONCLUSION: Charged particle therapy with controlled beams of protons and carbon ions have significantly impacted targeted cancer therapy, eradicated tumors while sparing normal tissue toxicities, and reduced human suffering. These modalities still require further optimization and technical refinements to reduce cost but should be made available to everyone in need worldwide. The exploration of our Universe in space travel poses the potential risk of exposure to uncontrolled charged particles. However, approaches to shield and provide countermeasures to these potential radiation hazards in LEO have allowed an amazing number of discoveries currently without significant life-threatening medical consequences. More basic research with components of the Galactic Cosmic Radiation field are still required to assure safety involving space radiations and combined stressors with microgravity for exploratory deep space travel. ADVANCES IN KNOWLEDGE: The collective knowledge garnered from the wealth of available published evidence obtained prior to particle radiation therapy, or to space flight, and the additional data gleaned from implementing both endeavors has provided many opportunities for heavy ions to promote human health.	187.8899755749075
1773.	PURPOSE: To develop and evaluate an automatic measurement model for hip joints based on anteroposterior (AP) pelvic radiography and a deep learning algorithm. METHODS: A total of 1260 AP pelvic radiographs were included. 1060 radiographs were randomly sampled for training and validation and 200 radiographs were used as the test set. Landmarks for four commonly used parameters, such as the center-edge (CE) angle of Wiberg, Tonnis angle, sharp angle, and femoral head extrusion index (FHEI), were identified and labeled. An encoder-decoder convolutional neural network was developed to output a multi-channel heat map. Measurements were obtained through landmarks on the test set. Right and left hips were analyzed respectively. The mean of each parameter obtained by three radiologists was used as the reference standard. The Percentage of Correct Key points (PCK), intraclass correlation coefficient (ICC), Pearson correlation coefficient (r), root mean square error (RMSE), mean absolute error (MAE), and Bland-Altman plots were used to determine the performance of deep learning algorithm. RESULTS: PCK of the model at 3mm distance threshold range was from 87 % to 100 %. The CE angle, Tonnis angle, Sharp angle and FHEI of the left hip generated by the model were 29.86.1, 5.64.2, 39.03.5 and 19 %5 %, respectively. The parameters of the right hip were 30.46.1, 7.14.4, 38.93.7 and 18 %5 %. There were good correlation and consistency of the four parameters between the model and the reference standard (ICC 0.83-0.93, r 0.83-0.93, RMSE 0.02-3.27, MAE 0.02-1.79). CONCLUSIONS: The new developed model based on deep learning algorithm can accurately identify landmarks on AP pelvic radiography and automatically generate parameters of hip joint. It will provide convenience for clinical practice of measurement.	187.88997008286174
1774.	Stock prediction via market data analysis is an attractive research topic. Both stock prices and news articles have been employed in the prediction processes. However, how to combine technical indicators from stock prices and news sentiments from textual news articles, and make the prediction model be able to learn sequential information within time series in an intelligent way, is still an unsolved problem. In this paper, we build up a stock prediction system and propose an approach that 1) represents numerical price data by technical indicators via technical analysis, and represents textual news articles by sentiment vectors via sentiment analysis, 2) setup a layered deep learning model to learn the sequential information within market snapshot series which is constructed by the technical indicators and news sentiments, 3) setup a fully connected neural network to make stock predictions. Experiments have been conducted on more than five years of Hong Kong Stock Exchange data using four different sentiment dictionaries, and results show that 1) the proposed approach outperforms the baselines in both validation and test sets using two different evaluation metrics, 2) models incorporating prices and news sentiments outperform models that only use either technical indicators or news sentiments, in both individual stock level and sector level, 3) among the four sentiment dictionaries, finance domain-specific sentiment dictionary (Loughran-McDonald Financial Dictionary) models the news sentiments better, which brings more prediction performance improvements than the other three dictionaries.	187.88965637553406
1775.	Scholars pay more and more attention to the spoken dialogue system after the emergence of deep learning technology. The task-based dialogue system has become one of the most important branches in the field of spoken dialogue systems. Dialogue management is the core of the task-based dialogue system, and its research theory and technology have been gained extensive attention. This paper summarizes the research progress and current situation of task-based dialogue system and dialogue management strategy. Firstly, it summarizes the status of the task-based dialogue system models and compares their advantages and disadvantages. Then it focuses on the analysis of various dialogue management research strategies from the perspective of model theory and research methods. Finally, it looks forward to the future research direction of task-oriented dialogue system combined with dialogue management.	187.88964598837802
1776.	Colorectal cancer is the fourth leading cause of cancer deaths worldwide, the standard for detection and prevention is the identification and removal of premalignant lesions through optical colonoscopy. More than 60% of colorectal cancer cases are attributed to missed polyps. Current procedures for automated polyp detection are limited by the amount of data available for training, underrepresentation of non-polypoid lesions and lesions which are inherently difficult to label and do not incorporate information about the topography of the surface of the lumen. It has been shown that information related to depth and topography of the surface of the lumen can boost subjective lesion detection. In this work, we add predicted depth information as an additional mode of data when training deep networks for polyp detection, segmentation and classification. We use conditional GANs to predict depth from monocular endoscopy images and fuse these predicted depth maps with RGB white light images in feature space. Our empirical analysis demonstrates that we achieve state-of-the-art results with RGB-D polyp segmentation with a 98% accuracy on four different publicly available datasets. Moreover, we demonstrate a 87.24% accuracy on lesion classification. We also show that our networks can domain adapt to a variety of different kinds of data from different sources.	187.88953214603927
1777.	The high-background glucose metabolism of normal gray matter on [18F]-fluoro-2-D-deoxyglucose (FDG) positron emission tomography (PET) of the brain results in a low signal-to-background ratio, potentially increasing the possibility of missing important findings in patients with intracranial malignancies. To explore the strategy of using a deep learning classifier to aid in distinguishing normal versus abnormal findings on PET brain images, this study evaluated the performance of a two-dimensional convolutional neural network (2D-CNN) to classify FDG PET brain scans as normal (N) or abnormal (A). Methods: Two hundred eighty-nine brain FDG-PET scans (N; n = 150, A; n = 139) resulting in a total of 68,260 images were included. Nine individual 2D-CNN models with three different window settings for axial, coronal, and sagittal axes were trained and validated. The performance of these individual and ensemble models was evaluated and compared using a test dataset. Odds ratio, Akaike's information criterion (AIC), and area under curve (AUC) on receiver-operative-characteristic curve, accuracy, and standard deviation (SD) were calculated. Results: An optimal window setting to classify normal and abnormal scans was different for each axis of the individual models. An ensembled model using different axes with an optimized window setting (window-triad) showed better performance than ensembled models using the same axis and different windows settings (axis-triad). Increase in odds ratio and decrease in SD were observed in both axis-triad and window-triad models compared with individual models, whereas improvements of AUC and AIC were seen in window-triad models. An overall model averaging the probabilities of all individual models showed the best accuracy of 82.0%. Conclusions: Data ensemble using different window settings and axes was effective to improve 2D-CNN performance parameters for the classification of brain FDG-PET scans. If prospectively validated with a larger cohort of patients, similar models could provide decision support in a clinical setting.	187.88936474771648
1778.	Wind speed interval prediction plays an important role in wind power generation. In this article, a new interval construction model based on error prediction is proposed. The variational mode decomposition is used to decompose the complex wind speed time series into simplified modes. Two types of GRU models are built for wind speed prediction and error prediction. Prediction error for each mode is given a weight and accumulated to obtain the width of the prediction interval. The particle swarm optimization algorithm is applied to search for the optimal weights of the prediction errors. Experiments considering eight cases from two wind fields are conducted by using methods of interval construction in the literature for comparison with the proposed model. The result shows that the proposed model can obtain prediction intervals with higher quality.	187.88935556477526
1779.	We propose a deep learning denoising computational ghost imaging (CGI) method to obtain a clear object image with a sub-Nyquist sampling ratio. We develop an end-to-end deep neural network (DDANet) for CGI image reconstruction. DDANet uses a one-dimensional (1-D) bucket signals (BSs) and multiple tunable noise-level maps as input, and outputs a clear image. We train DDANet with simulated BSs and ground-truth pairs, and then retrieve the object image directly from an experimental obtained 1-D BSs. The effectiveness of the proposed method is experimentally investigated. The proposed method has practical applications in image denoising and enhancement of the CGI and single-pixel computational imaging.	187.8890694883582
1780.	Purpose of Review Surgical management of locally advanced oral cavity squamous cell carcinomas (OCSCC) has long been recognized as a primary treatment modality. Technological advances have led to significant improvements in our surgical approach, from improvement in the visualization of tumors to more efficient and precise reconstruction. Here, we review the latest technological advances in surgical extirpation and reconstruction of locally advanced OCSCCs. Recent Findings The focus of technological innovation in surgical extirpation has been on improving visualization, with the use of intraoperative ultrasound for margin delineation, intraoperative navigation, narrow-band imaging, and the use of fluorescence. Though early, these are promising steps to ensuring complete resection of the cancer. Advances in reconstruction have been centered on the incorporation of computer assisted design, manufacturing, and virtual surgical planning, allowing for more complex three-dimensional defects to be expeditiously reconstructed. As these technologies are still under development, their impact on oncologic outcomes are not yet robustly defined; however, as technology continues to advance and become more widely available, new technologies will undoubtedly become integrated into enhancing surgical precision and planning.	187.88892272027994
1781.	Protein-RNA interaction plays important roles in post-transcriptional regulation. However, the task of predicting these interactions given a protein structure is difficult. Here we show that, by leveraging a deep learning model NucleicNet, attributes such as binding preference of RNA backbone constituents and different bases can be predicted from local physicochemical characteristics of protein structure surface. On a diverse set of challenging RNA-binding proteins, including Fem-3-binding-factor 2, Argonaute 2 and Ribonuclease III, NucleicNet can accurately recover interaction modes discovered by structural biology experiments. Furthermore, we show that, without seeing any in vitro or in vivo assay data, NucleicNet can still achieve consistency with experiments, including RNA compete, Immunoprecipitation Assay, and siRNA Knockdown Benchmark. NucleicNet can thus serve to provide quantitative fitness of RNA sequences for given binding pockets or to predict potential binding pockets and binding RNAs for previously unknown RNA binding proteins.	187.8889202956697
1782.	Vision-based crack detection is of crucial importance in various industries, and it is very challenging due to weak signals in noisy backgrounds. In this paper, we propose a novel hybrid approach for crack detection in raw images, which combines deep learning models and Bayesian probabilistic analysis for robust crack detection. First, we re-train a state-of-the-art object detector (e.g. a Faster R-CNN) to detect crack patches of suitable SNR (signal-noise-ratio). We design a semi-automatic method to generate ground truths of crack patches along crack lines for training. To further improve the accuracy of crack detections over the whole image, we propose a Bayesian integration algorithm to suppress false detections. Specifically, we use a deep CNN to recognize the orientation of the crack segment in each detected patch. Then, a Bayesian probability is computed on the accumulated evidence from detected adjacent patches within a neighborhood based on spatial proximity, orientation consistency and alignment consistency. The patch which lacks local supports is suppressed as false detection. An algorithm to learn the parameters of Bayesian integration is also derived. Extensive experiments and evaluations are performed on a new comprehensive dataset of crack images. The results show that our approach outperforms the state-of-the-art baseline approach on deep CNN classifier. Ablation experiments are also conducted to show the effectiveness of proposed techniques. (C) 2020 Elsevier Ltd. All rights reserved.	187.88891663397231
1783.	Vocational training is one part of non-formal education that can be used to improve the quality of human resources. Learning orientation contributes to determining the learning outcomes of an educational process. This research paper aims to discover the learning orientation of adolescent dropouts in attending sewing skill training at BPRSR Yogyakarta. This study was a qualitative research using the phenomenological approach conducted at BPRS Yogyakarta. The subject of this study were adolescent dropouts who became participants in sewing skill training. Observation, deep interview, and documentation study were used to collect the data in this research. The result showed that there were three types of participants learning orientations: 1) Skill assignment goal 2) Certificate goal 3) spending time detention goal. Learning orientation affected participants learning outcomes, therefore not ideal orientation needs mental and motivation mentoring.	187.8886697890387
1784.	Background Clinically, doctors obtain the left ventricular posterior wall thickness (LVPWT) mainly by observing ultrasonic echocardiographic video stream to capture a single frame of images with diagnostic significance, and then mark two key points on both sides of the posterior wall of the left ventricle with their own experience for computer measurement. In the actual measurement, the doctor's selection point is subjective, and difficult to accurately locate the edge, which will bring errors to the measurement results. Methods In this paper, a convolutional neural network model of left ventricular posterior wall positioning was built under the TensorFlow framework, and the target region images were obtained after the positioning results were processed by non-local mean filtering and opening operation. Then the edge detection algorithm based on threshold segmentation is used. After the contour was extracted by adjusting the segmentation threshold through prior analysis and the OTSU algorithm, the design algorithm completed the computer selection point measurement of the thickness of the posterior wall of the left ventricle. Results The proposed method can effectively extract the left ventricular posterior wall contour and measure its thickness. The experimental results show that the relative error between the measurement result and the hospital measurement value is less than 15%, which is less than 20% of the acceptable repeatability error in clinical practice. Conclusions Therefore, the measurement method proposed in this paper has the advantages of less manual intervention, and the processing method is reasonable and has practical value.	187.8886286115684
1785.	High-performance ligand-based virtual screening (VS) models have been developed using various computational methods, including the deep neural network (DNN) method. There are high expectations for exploration of the advanced capabilities of DNN to improve VS performance, and this capability has been optimally achieved using large data training datasets. However, their ability to screen large compound libraries has not been evaluated. There is a need for developing and evaluating ligand-based large data DNN VS models for large compound libraries. In this study, we developed ligand-based large data DNN VS models for inhibitors of six anticancer targets using 0.5 M training compounds. The developed VS models were evaluated by 10-fold cross-validation, achieving 77.9-97.8 % sensitivity, 99.9-100 % specificity, 0.82-0.98 Matthews correlation coefficient and 0.98-0.99 area under the curve, outperforming random forest models. Moreover, DNN VS models developed by pre-2015 inhibitors identified 50 % of post-2015 inhibitors with a 0.01-0.09 % false positive rate in screening 89 M PubChem compounds, also outperforming previous models. Experimental assays of the selected virtual hits of the EGFR inhibitor model led to reasonable novel structures of EGFR inhibitors. Our results confirmed the usefulness of the large data DNN model as a ligand-based VS tool to screen large compound libraries.	187.88862001564377
1786.	A smart home provides a facilitated environment for the detection of human activity with appropriate Deep Learning algorithms to manipulate data collected from numerous sensors attached to various smart things in a smart home environment. Human activities comprise expected and unexpected behavior events; therefore, detecting these events consisting of mutual dependent activities poses a key challenge in the activities detection paradigm. Besides, the battery-powered sensor ubiquitously and extensively monitors activities, disputes, and sensor energy depletion. Therefore, to address these challenges, we propose an Energy and Event Aware-Sensor Duty Cycling scheme. The proposed model predicts the future expected event using the Bi-Directional Long-Short Term Memory model and allocates Predictive Sensors to the predicted event. To detect the unexpected events, the proposed model localizes a Monitor Sensor within a cluster of Hibernate Sensors using the Jaccard Similarity Index. Finally, we optimize the performance of our proposed scheme by employing the Q-Learning algorithm to track the missed or undetected events. The simulation is executed against the conventional Machine Learning algorithms for the sensor duty cycle, scheduling to reduce the sensor energy consumption and improve the activity detection accuracy. The experimental evaluation of our proposed scheme shows significant improvement in activity detection accuracy from 94.12% to 96.12%. Besides, the effective rotation of the Monitor Sensor significantly improves the energy consumption of each sensor with the entire network lifetime.	187.88860898539906
1787.	Cervical cancer is one of the fastest growing global health problems and leading cause of mortality among women of developing countries. Automated Pap smear cell recognition and classification in early stage of cell development is crucial for effective disease diagnosis and immediate treatment. Thus, in this article, we proposed a novel internet of health things (IoHT)-driven deep learning framework for detection and classification of cervical cancer in Pap smear images using concept of transfer learning. Following transfer learning, convolutional neural network (CNN) was combined with different conventional machine learning techniques like K nearest neighbor, naive Bayes, logistic regression, random forest and support vector machines. In the proposed framework, feature extraction from cervical images is performed using pre-trained CNN models like InceptionV3, VGG19, SqueezeNet and ResNet50, which are fed into dense and flattened layer for normal and abnormal cervical cells classification. The performance of the proposed IoHT frameworks is evaluated using standard Pap smear Herlev dataset. The proposed approach was validated by analyzing precision, recall, F1-score, training-testing time and support parameters. The obtained results concluded that CNN pre-trained model ResNet50 achieved the higher classification rate of 97.89% with the involvement of random forest classifier for effective and reliable disease detection and classification. The minimum training time and testing time required to train model were 0.032 s and 0.006 s, respectively.	187.8884573502663
1788.	For over a decade, standards bodies like the IETF and W3C have attempted to prevent the centralization of the Web via the use of open standards for 'permission-less innovation.' Yet today, these standards, from OAuth to RSS, seem to have failed to prevent the massive centralization of the Web at the hands of a few major corporations like Google and Facebook. We'll delve deep into the lessons of failed attempts to replace DNS like XRIs, identity systems like OpenID, and metadata formats like the Semantic Web, all of which were re-cuperated by centralized platforms like Facebook as Facebook Connect and the "Like" Button. Learning from the past, a new generation of blockchain standards and governance mechanisms may be our last, best chance to save the Web.	187.88807736723396
1789.	We present a deep architecture and learning framework for establishing correspondences across cross-spectral visible and infrared images in an unpaired setting. To overcome the unpaired cross-spectral data problem, we design the unified image translation and feature extraction modules to be learned in a joint and boosting manner. Concretely, the image translation module is learned only with the unpaired cross-spectral data, and the feature extraction module is learned with an input image and its translated image. By learning two modules simultaneously, the image translation module generates the translated image that preserves not only the domain-specific attributes with separate latent spaces but also the domain-agnostic contents with feature consistency constraint. In an inference phase, the cross-spectral feature similarity is augmented by intra-spectral similarities between the features extracted from the translated images. Experimental results show that this model outperforms the state-of-the-art unpaired image translation methods and cross-spectral feature descriptors on various visible and infrared benchmarks.	187.88775766086917
1790.	With the ever-growing diversity of devices and applications that will be connected to 5G networks, flexible and agile service orchestration with acknowledged quality of experience (QoE) that satisfies the end user's functional and quality-of-service (QoS) requirements is necessary. Software-defined networking (SDN) and network function virtualization (NFV) are considered key enabling technologies for 5G core networks. In this regard, this paper proposes a reinforcement learning-based QoS/QoE-aware service function chaining (SFC) scheme in SDN/NFV-enabled 5G slices. First, it implements a lightweight QoS information collector based on the Link Layer Discovery Protocol, which works in a piggyback fashion on the southbound interface of the SDN controller, to enable QoS-awareness. Then, a deep Q-network-based orchestration agent is designed to support SFC in the context of NFV. The agent takes into account the QoE and QoS as key aspects to formulate the reward so that it is expected to maximize QoE while respecting QoS constraints. The experiment results show that the proposed framework exhibits good performance in QoE provisioning and QoS requirements maintenance for SFC in dynamic network environments.	187.88762954470923
1791.	Intrusion detection is the identification of unauthorized access of a computer network. This paper proposes a novel algorithm for a network intrusion detection system (NIDS) using an improved feature subset selected directly by a genetic algorithm (GA)-based exhaustive search and fuzzy C-means clustering (FCM). The algorithm identifies the bagging (BG) classifier and the convolutional neural network (CNN) model as an effective extractor by implementing the GA in combination with 5-fold cross validation (CV) to select the CNN model structure. The deep feature subset extracted by the selected CNN model is put into the BG classifier to validate the performance with the 5-fold CV. The high quality feature set obtained by the three-layered feature construction using the GA, FCM, CNN extractor, and a hybrid CNN and BG learning method significantly improves the final detection performance. Moreover, the highly reliable validation performance results achieved by the 5-fold CV procedure for the proposed algorithm imply a well-fitted application in a practical computer network environment NIDS. (c) 2020 Published by Elsevier B.V.	187.88742749686807
1792.	Breast density is an important factor in breast cancer screening. Methods exist to measure the volume of dense breast tissue from 2D mammograms. However, these methods can only be applied to raw mammograms. Breast density classification methods that have been developed for processed mammograms are commonly based on radiologist Breast Imaging and Reporting Data System (BI-RADS) annotations. Unfortunately, such labels are subjective and may introduce personal bias and inter-reader discrepancy. In order to avoid such limitations, this paper presents a method for estimation of percent dense tissue volume (PDV) from processed full field digital mammograms (FFDM) using a deep learning approach. A convolutional neural network (CNN) was implemented to carry out a regression task of estimating PDV using density measurement on raw FFDM as a ground truth. The dataset used for training, validation, and testing (Set A) includes over 2000 clinical cases from 3 different vendors. Our results show a high correlation of the predicted PDV to raw measurements, with a Spearman's correlation coefficient of r=0.925. The CNN was also tested on an independent set of 97 clinical cases (Set B) for which PDV measurements from FFDM and MRI were available. CNN predictions on Set B showed a high correlation with both raw FFDM and MRI data (r=0.897 and r=0.903, respectively). Set B had radiologist annotated BI-RADS labels, which agreed with the estimated values to a high degree, showing the ability of our CNN to make a distinction between different BI-RADS categories comparable to methods applied to raw mammograms.	187.88730557055482
1793.	Purpose: This study aims to evaluate the impact of key parameters on the pseudo computed tomography (pCT) quality generated from magnetic resonance imaging (MRI) with a 3-dimensional (3D) convolutional neural network. Methods and Materials: Four hundred two brain tumor cases were retrieved, yielding associations between 182 computed tomography (CT) and T1-weighted MRI (T1) scans, 180 CT and contrast-enhanced T1-weighted MRI (T1-Gd) scans, and 40 CT, T1, and T1 -Gd scans. A 3D CNN was used to map T1 or T 1 -Gd onto CT scans and evaluate the importance of different components. First, the training set size's influence on testing set accuracy was assessed. Moreover, we evaluated the MRI sequence impact, using T1-only and Ti -Gd-only cohorts. We then investigated 4 MRI standardization approaches (histogram-based, zero-mean/unit-variance, white stripe, and no standardization) based on training, validation, and testing cohorts composed of 242, 81, and 79 patients cases, respectively, as well as a bias field correction influence. Finally, 2 networks, namely HighResNet and 3D UNet, were compared to evaluate the architecture's impact on the pCT quality. The mean absolute error, gamma indices, and dose-volume histograms were used as evaluation metrics. Results: Generating models using all the available cases for training led to higher pCT quality. The T1 and T1-Gd models had a maximum difference in gamma index means of 0.07 percentage point. The mean absolute error obtained with white stripe was 78 +/- 22 Hounsfield units, which slightly outperformed histogram-based, zero-mean/unit-variance, and no standardization (P < .0001). Regarding the network architectures, 3%/3 mm gamma indices of 99.83% +/- 0.19% and 99.74% +/- 0.24% were obtained for HighResNet and 3D UNet, respectively. Conclusions: Our best pCTs were generated using more than 200 samples in the training data set. Training with T1 only and T1-Gd only did not significantly affect performance. Regardless of the preprocessing applied, the dosimetry quality remained equivalent and relevant for potential use in clinical practice. (C) 2020 Elsevier Inc. All rights reserved.	187.88707714795908
1794.	Diabetic retinopathy, glaucoma, and age-related macular degeneration are leading causes of vision loss and blindness worldwide. They tend to be asymptomatic in the early phase of disease and therefore require active screening programs to identify the patients requiring referral and treatment. Deep learning-based artificial intelligence technology has recently become a major topic in the field of ophthalmology. This paper aimed to provide a general view of the major findings on the application of deep learning for the classification of eye diseases from common imaging modalities. In the future, it is expected that these technologies will be applied in real-world screening programs to improve their efficiency and affordability.	187.88703665096776
1795.	In the management of lung nodules, it is important to precisely assess nodule size on computed tomography (CT) images. Given that the malignancy of nodules varies according to their composition, component-wise assessment is useful for diagnosing lung cancer. To improve the accuracy of volumetric measurement of lung nodules, we propose a deep learning-based method for segmenting nodules into multiple components, namely, solid, ground glass opacity (GGO), and cavity. We train a 3D fully convolutional network (FCN) with component-wise dice loss and apply a conditional random field (CRF) to refine the segmentation boundaries. To further gain the accuracy, we artificially generate synthetic cavitary nodules based on clinical observations and then augment the dataset for training the network. In experiments using about 300 CT images of clinical nodules, we evaluated our method in terms of mean absolute percentage error of volumetric measurement. We confirmed that our method achieved 15.84% lower error (averaged over 2 components of solid and GGO) compared with a conventional method based on image processing, and the error for cavity was decreased by 2.87% with our data-synthesis method.	187.88687315307106
1796.	This paper concerns the problem of Loop Closure Detection (LCD) of visual Simultaneous Localization and Mapping (SLAM). The LCD is a crucial model to reduce the accumulative error in visual SLAM. The traditional LCD methods use hand-crafted features, which ignore useful information. We propose a LCD method based on Convolutional Neural Networks (CNNs) without any manual intervention for visual features. We compare and analyze several popular deep neural networks models for LCD. Two open datasets has been used to evaluate the performance of LCD in terms of mean-per-class accuracy. The results show that deep neural networks are feasible for LCD and the ResNet50 network outperforms the other deep neural networks.	187.88681161514376
1797.	Deep learning based human brain network classification has gained increasing attention in recent years. However, current methods remain limited in exploring the topological structure information of a brain network. In this paper, we propose a kind of new convolutional kernels with an element-wise weighting mechanism (CKEW) to extract hierarchical topological features of brain networks, in which each weight is assigned to an element with a unique neuroscientific meaning. In addition, a novel classification framework based on CKEW is presented to diagnose brain diseases and explore the most important original features by a tracing feature analysis method efficiently. Experimental results on two autism spectrum disorder (ASD) datasets and an attention deficit hyperactivity disorder (ADHD) dataset with functional magnetic resonance imaging (fMRI) data demonstrate that our method can more accurately distinguish subject groups compared to several state-of-the-art methods in cerebral disease classification, and abnormal connectivity patterns and brain regions identified are more likely to become biomarkers associated with a cerebral disease. (C) 2020 Elsevier Ltd. All rights reserved.	187.88681145356702
1798.	Manual approaches to recognize cucumber diseases are often time-consuming, laborious and subjective. A deep convolutional neural network (DCNN) was proposed to conduct symptom-wise recognition of four cucumber diseases, i.e., anthracnose, downy mildew, powdery mildew, and target leaf spots. The symptom images were segmented from cucumber leaf images captured under field conditions. In order to decrease the chance of overfitting, data augmentation methods were utilized to enlarge the datasets formed by the segmented symptom images. With the augmented datasets containing 14,208 symptom images, the DCNN achieved good recognition results, with an accuracy of 93.4%. In order to compare the results of the DCNN, comparative experiments were conducted using conventional classifiers (Random Forest and Support Vector Machines), as well as AlexNet. Results showed that the DCNN was a robust tool for recognizing the cucumber diseases in field conditions.	187.8867236359746
1799.	With the development of deep learning techniques, fusion of deep features has demonstrated the powerful capability to improve recognition performance. However, most researchers directly fuse different deep feature vectors without considering the complementary and consistent information among them. In this paper, from the view-point of metric learning, we propose a novel deep feature fusion method, called deep feature fusion through adaptive discriminative metric learning (DFF-ADML), to explore the complementary and consistent information for scene recognition. Concretely, we formulate an adaptive discriminative metric learning problem, which not only fully exploits discriminative information from each deep feature vector, but also adaptively fuses complementary information from different deep feature vectors. Besides, we map different deep feature vectors of the same image into a common space by different linear transformations, such that the consistent information can be preserved as much as possible. Moreover, DFF-ADML is extended to a kernelized version. Extensive experiments on both natural scene and remote sensing scene datasets demonstrate the superiorly and robustness of the proposed deep feature fusion method.	187.88651540129965
1800.	The Great Australian Bight is one of Australia's most valuable marine ecosystems supporting globally significant populations of marine mammals, seabirds, and diverse and highly endemic benthic assemblages, as well as important fishing, aquaculture and ecotourism industries. The region is also considered a significant frontier for potential offshore petroleum resources and is actively being explored for oil and gas. The Great Australian Bight Research Program (GABRP) was an innovative, multi-year, $20 million, inter-disciplinary research collaboration involving BP Developments Australia (BP), CSIRO, the South Australian Research and Development Institute (SARDI), the University of Adelaide and Flinders University, that was developed in response to exploration activities in the region. The Program was the first large-scale, integrated study of the Great Australian Bight that involved more than 100 of Australia's leading scientists to generate a whole-of-system understanding of the region's environmental, economic and social values. We outline the processes to establish this strategic research collaboration; identify the key areas for success, and critically the lessons learned in order to guide future initiatives in regions open to exploration and development. As a result of the GABRP, there is now a legacy of data, information and models to inform future sustainable development in the Great Australian Bight; leading to the region now being one of the better understood deep water Australian marine systems.	187.88644874570372
1801.	Laryngeal vestibule (LV) closure is a critical physiologic event during swallowing, since it is the first line of defense against food bolus entering the airway. Identifying the laryngeal vestibule status, including closure, reopening and closure duration, provides indispensable references for assessing the risk of dysphagia and neuromuscular function. However, commonly used radiographic examinations, known as videofluoroscopy swallowing studies, are highly constrained by their radiation exposure and cost. Here, we introduce a non-invasive sensor-based system, that acquires high-resolution cervical auscultation signals from neck and accommodates advanced deep learning techniques for the detection of LV behaviors. The deep learning algorithm, which combined convolutional and recurrent neural networks, was developed with a dataset of 588 swallows from 120 patients with suspected dysphagia and further clinically tested on 45 samples from 16 healthy participants. For classifying the LV closure and opening statuses, our method achieved 78.94% and 74.89% accuracies for these two datasets, suggesting the feasibility of implementing sensor signals for LV prediction without traditional videofluoroscopy screening methods. The sensor supported system offers a broadly applicable computational approach for clinical diagnosis and biofeedback purposes in patients with swallowing disorders without the use of radiographic examination.	187.8862561691096
1802.	We propose a method to automatically segment multiple organs at risk (OARs) from routinely-acquired thorax CT images using generative adversarial network (GAN). Multi-label U-Net was introduced in generator to enable end-to-end segmentation. Esophagus and spinal cord location information were used to train the GAN in specific regions of interest (ROI). The probability maps of new CT thorax multi-organ were generated by the well-trained network and fused to reconstruct the final contour. This proposed algorithm was evaluated using 20 patients' data with thorax CT images and manual contours. The mean Dice similarity coefficient (DSC) for esophagus, heart, left lung, right lung and spinal cord was 0.73 +/- 0.04, 0.85 +/- 0.02, 0.96 +/- 0.01, 0.97 +/- 0.02 and 0.88 +/- 0.03. This novel deep-learning-based approach with the GAN strategy can automatically and accurately segment multiple OARs in thorax CT images, which could be a useful tool to improve the efficiency of the lung radiotherapy treatment planning.	187.88577657430974
1803.	Background and purpose: To investigate a novel markerless prostate localization strategy using a pre-trained deep learning model to interpret routine projection kilovoltage (kV) X-ray images in image-guided radiation therapy (IGRT). Materials and methods: We developed a personalized region-based convolutional neural network to localize the prostate treatment target without implanted fiducials. To train the deep neural network (DNN), we used the patient's planning computed tomography (pCT) images with pre-delineated prostate target to generate a large amount of synthetic kV projection X-ray images in the geometry of onboard imager (OBI) system. The DNN model was evaluated by retrospectively studying 10 patients who underwent prostate IGRT. Three out of the ten patients who had implanted fiducials and the fiducials' positions in the OBI images acquired for treatment setup were examined to show the potential of the proposed method for prostate IGRT. Statistical analysis using Lin's concordance correlation coefficient was calculated to assess the results along with the difference between the digitally reconstructed radiographs (DRR) derived and DNN predicted locations of the prostate. Results: Differences between the predicted target positions using DNN and their actual positions are (mean +/- standard deviation) 1.58 +/- 0.43 mm, 1.64 +/- 0.43 mm, and 1.67 +/- 0.36 mm in anterior-posterior, lateral, and oblique directions, respectively. Prostate position identified on the OBI kV images is also found to be consistent with that derived from the implanted fiducials. Conclusions: Highly accurate, markerless prostate localization based on deep learning is achievable. The proposed method is useful for daily patient positioning and real-time target tracking during prostate radiotherapy. (C) 2019 Elsevier B.V. All rights reserved.	187.88575643891448
1804.	As a form of artificial intelligence, artificial neural networks (ANNs) have the advantages of adaptability, parallel processing capabilities, and non-linear processing. They have been widely used in the early detection and diagnosis of tumors. In this article, we introduce the development, working principle, and characteristics of ANNs and review the research progress on the application of ANNs in the detection and diagnosis of gastrointestinal and liver tumors.	187.88570478358332
1805.	Finding a reliable and cost-effective approach to monitor the activities of the New Austrian Tunneling Method (NATM) tunnel construction automatically is a challenging yet important task. This study presents an interpretable artificial intelligence (AI) framework that automatically identifies NATM construction works using low-cost site surveillance images. The framework adopts the Bayesian statistics to combine the prior NATM construction knowledge with the visual evidence extracted by deep learning (DL) based computer vision models. The analysis results of Site CCTV surveillance videos of four NATM tunneling projects are presented to demonstrate its ability (i) to label NATM work cycles from the work timeline, (ii) to identify NATM work categories inside each work cycle, and (iii) to estimate the degree of plan-work deviation at the construction cycle level. The proposed framework yields promising results on a real NATM tunneling project.	187.88563357765082
1806.	Deformation is a comprehensive reflection of the structural state of a concrete dam, and research on prediction models for concrete dam deformation provides the basis for safety monitoring and early warning strategies. This paper focuses on practical problems such as multicollinearity among factors; the subjectivity of factor selection; robustness, externality, generalization, and integrity deficiencies; and the unsoundness of evaluation systems for prediction models. Based on rough set (RS) theory and a long short-term memory (LSTM) network, single-point and multipoint concrete dam deformation prediction models for health monitoring based on RS-LSTM are studied. Moreover, a new prediction model evaluation system is proposed, and the model accuracy, robustness, externality, and generalization are defined as quantitative evaluation indexes. An engineering project shows that the concrete dam deformation prediction models based on RS-LSTM can quantitatively obtain the representative factors that affect dam deformation and the importance of each factor relative to the effect. The accuracy evaluation index (AVI), robustness evaluation index (RVI), externality evaluation index (EVI), and generalization evaluation index (GVI) of the model are superior to the evaluation indexes of existing shallow neural network models and statistical models according to the new evaluation system, which can estimate the comprehensive performance of prediction models. The prediction model for concrete dam deformation based on RS-LSTM optimizes the factors that influence the model, quantitatively determines the importance of each factor, and provides high-performance, synchronous, and dynamic predictions for concrete dam behaviours; therefore, the model has strong engineering practicality.	187.88531192091182
1807.	Large classes taught with didactic lectures and assessed with multiple-choice tests are commonly reported to promote lower order (LO) thinking and a surface approach (SA) to learning. Using a case study design, we hypothesized that incorporating instructional scaffolding of core physiology principles and assessing students exclusively with long-answer written tests would encourage higher order (HO) thinking and promote a deep approach (DA) to learning in a two-course physiology sequence (Phys I and II), despite their large size. Test questions were categorized as LO or HO according to the Blooming Biology Tool, and students' LO and HO performance was determined for each of six tests across the two courses. The validated Revised Two-Factor Study Process Questionnaire survey tool was administered at the beginning and end of each course to measure student approach to learning. HO performance was maintained across Phys I (72.919.4 vs. 74.820.7%, P = 0.37) and significantly improved across Phys II (69.918.4 vs. 79.414.8%, P < 0.001). Unexpectedly, students' LO performance declined from the beginning to end of Phys I (78.520.6 vs. 69.417.9%, P < 0.001) and Phys II (80.519.6 vs. 72.224.3%, P < 0.001). Students' approach to learning did not change throughout Phys I or II, but at each time point students preferred a DA over a SA. Taken together, these results indicate that an intentionally designed large lecture class can support a DA to learning and suggests that this teaching and assessment structure may be particularly well suited to promote HO thinking, albeit possibly at the expense of LO thinking.	187.8852996490358
1808.	Computer Aided Decision (CAD) systems, based on 3D tomosynthesis imaging, could support radiologists in classifying different kinds of breast lesions and then improve the diagnosis of breast cancer (BC) with a lower X-ray dose than in Computer Tomography (CT) systems. In previous work, several Convolutional Neural Network (CNN) architectures were evaluated to discriminate four different classes of lesions considering high-resolution images automatically segmented: (a) irregular opacity lesions, (b) regular opacity lesions, (c) stellar opacity lesions and (d) no-lesions. In this paper, instead, we use the same previously extracted relevant Regions of Interest (ROIs) containing the lesions, but we propose and evaluate two different approaches to better discriminate among the four classes. In this work, we evaluate and compare the performance of two different frameworks both considering supervised classifiers topologies. The first framework is feature-based, and consider morphological and textural hand-crafted features, extracted from each ROI, as input to optimised Artificial Neural Network (ANN) classifiers. The second framework, instead, considers non-neural classifiers based on automatically computed features evaluating the classification performance extracting several sets of features using different Convolutional Neural Network models. Final results show that the second framework, based on features computed automatically by CNN architectures performs better than the first approach, in terms of accuracy, specificity, and sensitivity. (C) 2018 Elsevier B.V. All rights reserved.	187.8851959838546
1809.	The identification of major histocompatibility complex (MHC)-binding peptides in mass spectrometry (MS)-based immunopeptideomics relies largely on database search engines developed for proteomics data analysis. However, because immunopeptidomics experiments do not involve enzymatic digestion at specific residues, an inflated search space leads to a high false positive rate and low sensitivity in peptide identification. In order to improve the sensitivity and reliability of peptide identification, a post-processing tool named DeepRescore is developed. DeepRescore combines peptide features derived from deep learning predictions, namely accurate retention timeand MS/MS spectra predictions, with previously used features to rescore peptide-spectrum matches. Using two public immunopeptidomics datasets, it is shown that rescoring by DeepRescore increases both the sensitivity and reliability of MHC-binding peptide and neoantigen identifications compared to existing methods. It is also shown that the performance improvement is, to a large extent, driven by the deep learning-derived features. DeepRescore is developed using NextFlow and Docker and is available at .	187.88518832539785
1810.	Skin segmentation plays an important role in a wide variety of biomedical image processing applications, such as skin cancer identification, skin lesion detection, and wound isolation. However, contemporary research has been mainly based on facial and hand skin datasets, with no other body regions considered for skin pixels sampling. Segmenting skin specifically in the abdominal region can aid in robotic abdominal surgeries and treatment procedures, such as robot-assisted laparoscopic surgeries and abdominal ultrasounds. A robust and highly accurate abdominal skin detection technique thus becomes imperative. To this end, we compiled a novel dataset of 1,400 segmented abdominal pictures and adapted and compared four abdominal skin segmentation techniques: one based on thresholding and three deep learning techniques, namely a fully connected neural network for pixellevel classification, and two convolution-based networks, U-Net and Mask-RCNN. We show that the U-Net model outperforms the other segmentation techniques, resulting in a pixel-to-pixel mean cross-validation accuracy of 95.51% on our Abdominal dataset. The incorporation of the Abdominal dataset in the training helped improve the abdominal skin segmentation accuracy by 10.19%. The U-Net model proved to be computationally the fastest, enabling real time skin segmentation with a processing rate of 37 frames per second.	187.88517214316968
1811.	Extracting event sentences with explicit and significant information is a basic work of semantic analysis based retrieval of text information. Current methods of event extraction normally lack evaluation of the quality of information embedded in a sentence, thus the extracted event sentences usually contain inexplicit or insignificant information that is unusable for real-world applications. In this paper, we introduce ES-ESens, a deep learning based methodology for detecting event sentences with high-quality information. To evaluate the explicitness and significance of the information embedded in a sentence, ES-ESens adopts Recurrent Neural Network with attention mechanism to perform deep semantic analysis on the context of the sentence and the article that explains the background of the event. Based on datasets of practical applications, experiments are presented to show the performance of our methodology.	187.884525069389
1812.	High-frequency oscillations (HFOs) are spontaneous magnetoencephalography (MEG) patterns that have been acknowledged as a putative biomarker to identify epileptic foci. Correct detection of HFOs in the MEG signals is crucial for the accurate and timely clinical evaluation. Since the visual examination of HFOs is time-consuming, error-prone, and with poor inter-reviewer reliability, an automatic HFOs detector is highly desirable in clinical practice. However, the existing approaches for HFOs detection may not be applicable for MEG signals with noisy background activity. Therefore, we employ the stacked sparse autoencoder (SSAE) and propose an SSAE-based MEG HFOs (SMO) detector to facilitate the clinical detection of HFOs. To the best of our knowledge, this is the first attempt to conduct HFOs detection in MEG using deep learning methods. After configuration optimization, our proposed SMO detector is outperformed other classic peermodels by achieving 89.9% in accuracy, 88.2% in sensitivity, and 91.6% in specificity. Furthermore, we have tested the performance consistency of ourmodel using various validation schemes. The distribution of performance metrics demonstrates that our model can achieve steady performance.	187.88436494442578
1813.	In the production process of laser welding products, visual inspection is usually employed to recognize welding spot locations and diagnose their quality faults. However, commonly used algorithms fail to succeed in both reliability and computational efficiency, especially when applied to assembly line. In this article, a method based on deep learning algorithm and traditional computer vision (TCV) algorithm is proposed, which achieves quality inspection of laser welding spots in the process of battery production. First, compressed U-shape network (CU-net) is proposed to extract welding pads and welding spots. Then, a template-based method is proposed to confirm the validity of each welding spot. Finally, TCV heuristic algorithms are proposed to achieve three error detections, i.e., welding pad placed obliquely, electrode tab placed over highly, and welding spot welded through. Moreover, we build a Welding Spot Quality Inspection Dataset taken from real assembly line. Compared with other pipelines, including U-net, MaskRCNN, and PSPNet, CU-net shows a significant superiority in both processing speed and detection accuracy. The results of template-based method and TCV heuristic algorithms have shown high computational efficiency and ensured inspection accuracy. The inference time of the whole method is less than 100 ms with the implementation on NVIDIA 1060 and Intel i7-6700.	187.8841451316622
1814.	This paper presents a deep learning approach to summarizing long soccer videos by leveraging the spatiotemporal learning capability of three-dimensional Convolutional Neural Network (3D-CNN) and Long Short-Term Memory (LSTM) - Recurrent Neural Network (RNN). Our proposed approach involves, 1) a step-by-step development of a Residual Network (ResNet) based 3D-CNN that recognizes soccer actions, 2) manually annotating 744 soccer clips from five soccer action classes for training, and 3) training an LSTM network on soccer features extracted by the proposed ResNet based 3D-CNN. We combine the 3D-CNN and LSTM models to detect soccer highlights. To summarize a soccer match video, we model the video input as a sequential concatenation of video segments whose inclusion in a summary video production is based on its validated relevance. To evaluate the proposed summarization system, 10 soccer videos were summarized and subsequently evaluated by 48 participants polled from 8 countries using the Mean Opinion Score (MOS) scale. Collectively, the summarized videos received a 4 of 5 MOS.	187.8836209718154
1815.	School districts in the United States are required to monitor the overrepresentation of students of color in special education, yet recent studies have challenged these trends and suggest students of color may be underrepresented for services guaranteed under federal law. Missing in many of these discussions on disproportionality are the needs of Asian Americans and Pacific Islanders (AAPIs), a group consistently underrepresented in special education. Previous studies, however, do not examine the vast heterogeneity in experiences among AAPIs and how special education trends may differ across AAPI ethnic subgroups. Using longitudinal data on 10 cohorts of 42,807 total kindergartners from a school district over a 10-year period, this study probes deeper into underrepresentation by disaggregating participation trends and the timing of services for 11 AAPI ethnic subgroups. Results indicate that most AAPI student groups are underrepresented in special education and first receive services later than White peers. These patterns remain even after accounting for student background, level of acculturation, and school fixed effects.	187.88343522803558
1816.	As urban population increases, research on urban environmental noise is getting more attention. In this study, we classify the abnormal noise occurring in traffic situation by using a deep learning algorithm which shows high performance in recent environmental noise classification studies. Specifically, we classify the four classes of tire skidding sounds, car crash sounds, car horn sounds, and normal sounds using convolutional neural networks. In addition, we add three environmental noises, including rain, wind and crowd noises, to our training data so that the classification model is more robust in real traffic situation with environmental noises. Experimental results show that the proposed traffic sound classification model achieves better performance than the existing algorithms, particularly under harsh conditions with environmental noises.	187.88337116781946
1817.	Classification of very high-resolution (VHR) satellite images has three major challenges: 1) inherent low intraclass and high interclass spectral similarities; 2) mismatching resolution of available bands; and 3) the need to regularize noisy classification maps. Conventional methods have addressed these challenges by adopting separate stages of image fusion, feature extraction, and postclassification map regularization. These processing stages, however, are not jointly optimizing the classification task at hand. In this paper, we propose a single-stage framework embedding the processing stages in a recurrent multiresolution convolutional network trained in an end-to-end manner. The feedforward version of the network, called FuseNet, aims to match the resolution of the panchromatic and multispectral bands in a VHR image using convolutional layers with corresponding downsampling and upsampling operations. Contextual label information is incorporated into FuseNet by means of a recurrent version called ReuseNet. We compared FuseNet and ReuseNet against the use of separate processing steps for both image fusions, e.g., pansharpening and resampling through interpolation and map regularization such as conditional random fields. We carried out our experiments on a land-cover classification task using a Worldview-03 image of Quezon City, Philippines, and the International Society for Photogrammetry and Remote Sensing 2-D semantic labeling benchmark data set of Vaihingen, Germany. FuseNet and ReuseNet surpass the baseline approaches in both the quantitative and qualitative results.	187.88302061201816
1818.	Detection and classification methods have a vital and important role in identifying brain diseases. Timely detection and classification of brain diseases enable an accurate identification and effective management of brain impairment. Brain disorders are commonly most spreadable diseases and the diagnosing process is time-consuming and highly expensive. There is an utmost need to develop effective and advantageous methods for brain diseases detection and characterization. Magnetic resonance imaging (MRI), computed tomography (CT), and other various brain imaging scans are used to identify different brain diseases and disorders. Brain imaging scans are the efficient tool to understand the anatomical changes in brain in fast and accurate manner. These different brain imaging scans used with segmentation techniques and along with machine learning and deep learning techniques give maximum accuracy and efficiency. This paper focuses on different conventional approaches, machine learning and deep learning techniques used for the detection, and classification of brain diseases and abnormalities. This paper also summarizes the research gap and problems in the existing techniques used for detection and classification of brain disorders. Comparison and evaluation of different machine learning and deep learning techniques in terms of efficiency and accuracy are also highlighted in this paper. Furthermore, different brain diseases like leukoariaosis, Alzheimer's, Parkinson's, and Wilson's disorder are studied in the scope of machine learning and deep learning techniques.	187.88295142468203
1819.	A novel method to determine the Grade Group (GG) in prostate cancer (PCa) using multi-parametric magnetic resonance imaging (mpMRI) biomarkers is investigated in this paper. In this method, highlevel features are extracted from hand-crafted texture features using a deep network of stacked sparse autoencoders (SSAE) and classified them using a softmax classifier (SMC). Transaxial T2 Weighted (T2W), Apparent Diffusion Coefficient (ADC) and high B-Value Diffusion-Weighted (BVAL) images obtained from PROSTATEx-2 2017 challenge dataset are used in this technique. The method was evaluated on the challenge dataset composed of a training set of 112 lesions and a test set of 70 lesions. It achieved a quadratic-weighted Kappa score of 0.2772 on evaluation using test dataset of the challenge. It also reached a Positive Predictive Value (PPV) of 80% in predicting PCa with GC > 1. The method achieved first place in the challenge, winning over 43 methods submitted by 21 groups. A 3-fold cross-validation using training data of the challenge was further performed and the method achieved a quadratic-weighted kappa score of 0.2326 and Positive Predictive Value (PPV) of 80.26% in predicting PCa with GG > 1. Even though the training dataset is a highly imbalanced one, the method was able to achieve a fair kappa score. Being one of the pioneer methods which attempted to classify prostate cancer into 5 grade groups from MRI images, it could serve as a base method for further investigations and improvements. (C) 2018 Elsevier Ltd. All rights reserved.	187.88281907022082
1820.	A downside of next-generation sequencing technology is the high technical error rate. We built a tool, which uses array-based genotype information to classify next-generation sequencing-based SNPs into the correct and the incorrect calls. The deep learning algorithms were implemented via Keras. Several algorithms were tested: (i) the basic, naive algorithm, (ii) the naive algorithm modified by pre-imposing different weights on incorrect and correct SNP class in calculating the loss metric and (iii)-(v) the naive algorithm modified by random re-sampling (with replacement) of the incorrect SNPs to match 30%/60%/100% of the number of correct SNPs. The training data set was composed of data from three bulls and consisted of 2,227,995 correct (97.94%) and 46,920 incorrect SNPs, while the validation data set consisted of data from one bull with 749,506 correct (98.05%) and 14,908 incorrect SNPs. The results showed that for a rare event classification problem, like incorrect SNP detection in NGS data, the most parsimonious naive model and a model with the weighting of SNP classes provided the best results for the classification of the validation data set. Both classified 19% of truly incorrect SNPs as incorrect and 99% of truly correct SNPs as correct and resulted in the F1 score of 0.21 - the highest among the compared algorithms. We conclude the basic models were less adapted to the specificity of a training data set and thus resulted in better classification of the independent, validation data set, than the other tested models.	187.88278025236878
1821.	Ischemic stroke volume is a strong predictor of functional outcome and may play a role in decision making of reperfusion therapy in the late time window (> 6hr of stroke onset to MRI time) when it is obtained along with penumbra volume. Automatic diffusion lesion segmentation can be performed using a commercial software package and is typically based on a fixed apparent diffusion coefficient (ADC) threshold. ADC values alone may not be guaranteed to be highly accurate in the identification of diffusion lesions. Deep learning has the potential to improve the accuracy of diffusion lesion segmentation, provided that a large set of correctly labeled lesion mask data is used for training. The purpose of this study is to evaluate deep learning-based segmentation methods and compare them with three fixed ADC threshold-based methods. U-net was adopted to train a segmentation model. Two U-net models were developed: a model "U-net (DWI+ADC)" trained from DWI and ADC data, and a model "U-net (DWI)" trained from DWI data only. 296 subjects were used for training, and 134 subjects were used for testing. An expert neurologist manually delineated infarct masks on DWI, which served as ground-truth reference. Lesion volume measurements from the two U-net methods and three fixed ADC threshold-based methods were compared against lesion volume measurements from manual segmentation. In testing, the "U-net (DWI+ADC)" method outperformed other methods in lesion volume measurement, with the smallest root-mean-square error of 2.96 ml and the highest Pearson correlation coefficient of 0.997. The proposed method has the potential to automatically measure diffusion lesion volume in a fast and accurate manner, in patients with acute ischemic stroke.	187.8827696513278
1822.	We provide a novel solution to the inverse problem in medical imaging that takes as input the undersampled k-space data from Magnetic Resonance Imaging (MRI) scans and outputs both the reconstructed images and the segmented myocardium. Previously, the undersampled k-space data is first transformed into a reconstructed MRI image. From this image, the myocardium is contours are subsequently extracted using a segmentation method. However, this sequential approach is not optimal and requires manual intervention. In order to automate and improve the results of these approaches, we propose a new method to solve the reconstruction and segmentation problems simultaneously. Our method is based on a novel deep learning approach we term "Joint-FR-Net", which consists of a reconstruction module derived from the fast iterative shrinkage-thresholding algorithm (FISTA) and a segmentation module. We test our approach on an undersampled short-axis (SAX) cardiac dataset and show the effectiveness of the Joint FR-Net in both image reconstruction and myocardium joint segmentation.	187.88252996090733
1823.	We developed a novel SRR system, called Multi-Angle Gotcha image restoration with Generative Adversarial Network (MAGiGAN), to produce resolution enhancement of 3-5 times from multi-pass EO images. The MAGiGAN SRR system uses a combination of photogrammetric and machine vision approaches including image segmentation and shadow labelling, feature matching and densification, estimation of an image degradation model, and deep learning approaches, to retrieve image information from distorted features and training networks. We have tested the MAGiGAN SRR using the NVIDIA (R) Jetson TX-2 GPU card for onboard processing within a smart-satellite capturing high definition satellite videos, which will enable many innovative remote-sensing applications to be implemented in the future. In this paper, we show SRR processing results from a Planet (R) SkySat HD 70cm spaceborne video using a GPU version of the MAGiGAN system. Image quality and effective resolution enhancement are measured and discussed.	187.88249090663618
1824.	Treatment for patients with acute ischemic stroke is most commonly determined based on findings on noncontrast computerized tomography (CT). Identifying hypoattenuation of the early ischemic changes on CT images is crucial for diagnosis. However, it is difficult to identify hypoattenuation with certainty. We present an atlas-based computerized method using a convolutional neural network (CNN) to identify hypoattenuation in the lentiform nucleus and the insula, two locations where hypoattenuation appears most frequently. The algorithm for this method consisted of anatomic standardization, setting of regions, creation of input images for classification, training on the CNN and classification of hypoattenuation. The regions of the lentiform nucleus and insula were set according to the Alberta Stroke Programme Early CT score (ASPECTS) method, a visual quantitative CT scoring system. AlexNet was used in the classification of the CNN architecture. We applied this method to the lentiform nucleus and insula using a database of 20 patients with right-sided hypoattenuation, 20 patients with left-sided hypoattenuation, and 20 normal subjects. Our method was evaluated using a leave-one-case-out cross-validation test. This new method had an average accuracy of 88.3%, an average sensitivity of 87.5%, and an average specificity of 90% for identifying hypoattenuation in the two regions. These results indicate that this new method has the potential to accurately identify hypoattenuation in the lentiform nucleus and the insula in patients with acute ischemic stroke.	187.88203713111722
1825.	Segmentation in iris biometrics deals with the localisation of inner and outer boundaries of the iris and isolation of the region of interest (ROI) from the input eye image. The isolated ROI is further used to extract the meaningful features of iris for its effective representation. That is why accuracy of the segmentation module directly affects the overall accuracy in an iris recognition system. In view of this, the present study provides a comprehensive review of state-of-the-art methods on iris segmentation that were reported after 2011. Iris segmentation approaches based on eye images captured in both visible and near infrared illumination have been reviewed in this paper. The state-of-the-art iris segmentation approaches have been categorised into four broad classes, namely: integro-differential operator (IDO)-based approaches, circular Hough transform (CHT)-based approaches, deep learning-based approaches, and miscellaneous approaches. The sole purpose of this survey is to deliver insights on ROI segmentation, which is a prominent step of iris recognition process, and to suggest prospective research directions to the readers.	187.88179084736961
1826.	Performance evaluation of fingerprint recognition systems requires large-scale databases. Unfortunately, collecting fingerprints is expensive and time-consuming, and publishing them is restricted due to the privacy protection legislation. Hence, an algorithm which can generate huge fingerprint datasets would be of great help. With the popularization of fingerprint authentication systems, detecting fake fingerprints, also known as presentation attack detection, is an essential problem. Inspired by the fast development of deep learning, this paper demonstrates novel algorithms to generate artificial fingerprints and detect fake fingerprints using deep neural networks. The experimental results prove that the proposed system can generate fingerprints which have the same characteristics as real fingerprints. Regarding presentation attack detection, the proposed system shows an average detection error rate of 1.57% on three LivDet databases, including LivDet 2011, 2013, and 2015.	187.88174206486147
1827.	Land surface temperature (LST) data is essential for urban engineering as well as modeling the atmospheric phenomena. Such modeling efforts require accurate temperature prediction which is then used for predicting other meteorological phenomena such as urban heat island and fine dust air pollution. The automatic weather system (AWS) provides accurate temperature with high frequency but it cannot grasp spatially continuous distribution in detail because it is collected only at specific points. On the contrary, the LST data obtained from satellite imagery has a high spatial resolution and spatially continuous temperature can be grasped, but it is difficult to get high temporal frequency temperature data because of its revisit time. In this study, to solve this spatio-temporal tradeoff problem, a deep-learning method was used to create a spatially continuous temperature image using AWS data with a spatial resolution of 30 m. The seasonal temperature was predicted with accuracy of 3.6 degrees C for spring, 1.9 degrees C for summer, 3 degrees C for fall, and 1.4 degrees C for winter. The predicted temperature accuracy for spatial resolution of 30 m is better than other reported interpolation methods. In order to improve the prediction accuracy of the model, fine tuning procedures were applied to the deep learning model hyper parameters as well as the input feature data.	187.88171079678716
1828.	Machine learning (ML) models are increasingly used to study complex environmental phenomena with high variability in time and space. In this study, the potential of exploiting three categories of ML regression models, including classical regression, shallow learning and deep learning for predicting soil greenhouse gas (GHG) emissions from an agricultural field was explored. Carbon dioxide (CO2) and nitrous oxide (N2O) fluxes, as well as various environmental, agronomic and soil data were measured at the site over a five-year period in Quebec, Canada. The rigorous analysis, which included statistical comparison and cross-validation for the prediction of CO2 and N2O fluxes, confirmed that the LSTM model performed the best among the considered ML models with the highest R coefficient and the lowest root mean squared error (RMSE) values (R = 0.87 and RMSE = 30.3 mg.m(-2).hr(-1) for CO2 flux prediction and R = 0.86 and RMSE = 0.19 mg.m(-2).hr(-1) for N2O flux prediction). The predictive performances of LSTM were more accurate than those simulated in a previous study conducted by a biophysical-based Root Zone Water Quality Model (RZWQM2). The classical regression models (namely RF, SVM and LASSO) satisfactorily simulated cyclical and seasonal variations of CO2 fluxes (R = 0.75, 0.71 and 0.68, respectively); however, they failed to reasonably predict the peak values of N2O fluxes (R < 0.25). Shallow ML was found to be less effective in predicting GHG fluxes than other considered ML models (R < 0.7 for CO2 flux and R < 0.3 for estimating N2O fluxes) and was the most sensitive to hyperparameter tuning. Based on this comprehensive comparison study, it was elicited that the LSTM model can be employed successfully in simulating GHG emissions from agricultural soils, providing a new perspective on the application of machine learning modeling for predicting GHG emissions to the environment. (c) 2020 Elsevier B.V. All rights reserved.	187.8815802232792
1829.	The Nootka fault zone is a ridge-trench-trench transform fault that was initiated 4Ma when the Explorer ridge became independent of the Juan de Fuca ridge. Multibeam data around the fault zone and a compilation of several seismic reflection surveys provide insight into initiation of strike-slip faults. Previous interpretations assumed that the two faults seen cutting the seafloor are subparallel to shear between the Explorer and Juan de Fuca plates and formed instantaneously at 4Ma. Increased data density shows that these faults are subparallel to seafloor magnetic anomalies and appear to have utilized extensional faults formed at the ridge. They are surrounded by numerous buried steeply dipping, small-offset growth faults; at least some of which are likely still active. Our observations corroborate analogue models of strike-slip fault initiation that predict formation of Riedel-like shears within a zone of faulting and that displacement localizes over time. The existence of several long subparallel faults and a very wide zone of faulting has been predicted by models of distributed shear at depth. Along the Nootka fault zone basement has risen by several hundred meters and bright reversed-polarity reflectors some of which are interpreted to be methane hydrate reflectors are common. Hydration, likely as serpentinization, of the upper mantle could explain both sets of observations: Serpentinization can result in a 30-50% volume expansion and methane is observed in vents driven by this process. Biogenic sources of methane are likely to be present and concentrated by currently active fluid flow in the faulted sediments. Plain Language Summary Four million years ago the Juan de Fuca oceanic plate offshore British Columbia was sheared and began to split off its northern section. This occurred along a shear zone we now call the Nootka fault zone. It generates many small earthquakes in the oceanic rocks, and its extension under Vancouver Island has generated sizable earthquakes felt by residents of the island. Understanding the composition and form of the fault zone allows a greater understanding of the seismic hazards associated with this fault. By studying detailed acoustic profiles of the seafloor morphology, sediments' structure, and the underlying hard rocks, we learned that the split of the Juan de Fuca plate was not a clean break but began in a zone at least 80km wide and is now just 8 to 18km wide. The faults have likely changed the density and composition of rocks at depth by allowing water to percolate through the fractures. We also observe high-amplitude reflections from gas trapped in shallow sediments. Methane can be generated by bacteria in the sediments and is also often observed when deep rocks are being hydrated.	187.88148238862703
1830.	Purpose: In breast cancer medical follow-up, due to the lack of specialized aided diagnosis tools, many breast cancer patients may continue to receive chemotherapy even if they do not respond to the treatment. In this work, we propose a new approach for early prediction of breast cancer response to chemotherapy from two follow-up DCE-MRI exams. We present a method that takes advantage of a deep convolutional neural network (CNN) model to classify patients who are responsive or non-responsive to chemotherapy. Methods and material: To provide an early prediction of breast cancer response to chemotherapy, we used a two branch Convolution Neural Network (CNN) architecture, taking as inputs two breast tumor MRI slices acquired before and after the first round of chemotherapy. We trained our model on a 693 x 2 ROIs belonging to 42 patients with local breast cancer. Image pretreatment, volumetric image registration and tumor segmentation were applied to MRI exams as a pre-processing step. As a ground truth, we used the anapathological standard reference provided of each patient. Results: Within 80 training epochs, an accuracy of 92.72% was obtained using 20% as validation data. The Area Under the Curve (AUC) was 0.96. Conclusion: In this paper, it was demonstrated that deep CNNs models can be used to solve breast cancer follow-up related problems. Therefore, the model obtained in this work can be exploited in future clinical applications after improving its efficiency with the used data.	187.88137881791107
1831.	In powder metallurgy engineering, the master sintering curve (MSC) is crucial for estimating the mechanical properties of sintered products and optimizing sintering process parameters. A rapid evaluation method, that is, a domain-adversarial neural network, is established in the field of sintering to transfer learning from Al2O3 to SiC, concerning the effect of the heating rate on the sintering densification, in which one material (e.g. SiC) lacks an MSC and the material (e.g. Al2O3) has an overabundance of MSCs. In the unsupervised mode, we can roughly predict the densification evolution of SiC based on the MSC data of Al2O3. In the semi-supervised mode, prediction accuracy gradually increases with the increase of Al2O3 data and approaches a certain upper limit. Compared with the traditional sintering density prediction models, the proposed approach can provide an effective and rapid solution to the problem of data scarcity in the sintering field.	187.881074322828
1832.	Detection and localization of microcalcification (MC) clusters are very important in mammography diagnosis. Supervised MC detectors require learning from extracted individual MCs and MC clusters. However, they are limited by number of datasets given that MC images are hard to obtain. In this work, we propose a method to detect malignant microcalcification (MC) clusters using unsupervised, one-class, deep convolutional autoencoder. Specifically, we designed a deep autoencoder model where only patches extracted from normal cases' mammograms are used during training. We then applied our trained model on patches extracted from testing images. Our training dataset contains 408 normal subjects, including 1961 full-field digital mammography images. Our testing datasets contains 276 subjects. Specifically, 106 of them were patients diagnosed with Ductal Carcinoma In-Situ (DCIS); 70 of them were diagnosed with Invasive Ductal Carcinoma (IDC); the rest 100 are normal cases containing 484 negative screening mammograms. Patches extracted from DCIS and IDC cases (positive patches) contain MC clusters, whereas patches extracted from normal cases (negative patches) don't. As the model is trained only on negative images that do not contain MCs, it cannot reconstruct MCs well, and thus, the reconstruction error will be larger on positive patches than negative patches. Our detection algorithm's decision is made based on Max-Squared Error between autoencoder's input and output patches. To confirm the results were not simply due to blurring, we then compared our designed detector with unsharp mask with Gaussian blur results. The results using the unsupervised autoencoder on testing patches with size 64x64 achieves an AUC result of 0.93. The best performance on testing patches using Gaussian blur with kernel size equal to 11has an overall AUC of 0.82.	187.88093368208587
1833.	Purpose: To develop a super-resolution technique using convolutional neural networks for generating thin-slice knee MR images from thicker input slices, and compare this method with alternative through-plane interpolation methods. Methods: We implemented a 3D convolutional neural network entitled DeepResolve to learn residual-based transformations between high-resolution thin-slice images and lower-resolution thick-slice images at the same center locations. DeepResolve was trained using 124 double echo in steady-state (DESS) data sets with 0.7-mm slice thickness and tested on 17 patients. Ground-truth images were compared with DeepResolve, clinically used tricubic interpolation, and Fourier interpolation methods, along with state-of-the-art single-image sparse-coding super-resolution. Comparisons were performed using structural similarity, peak SNR, and RMS error image quality metrics for a multitude of thin-slice downsampling factors. Two musculoskeletal radiologists ranked the 3 data sets and reviewed the diagnostic quality of the DeepResolve, tricubic interpolation, and ground-truth images for sharpness, contrast, artifacts, SNR, and overall diagnostic quality. Mann-Whitney U tests evaluated differences among the quantitative image metrics, reader scores, and rankings. Cohen's Kappa (kappa) evaluated interreader reliability. Results: DeepResolve had significantly better structural similarity, peak SNR, and RMS error than tricubic interpolation, Fourier interpolation, and sparse-coding super-resolution for all downsampling factors (p < .05, except 4 x and 8 x sparse-coding super-resolution downsampling factors). In the reader study, DeepResolve significantly outperformed (p < .01) tricubic interpolation in all image quality categories and overall image ranking. Both readers had substantial scoring agreement (kappa = 0.73). Conclusion: DeepResolve was capable of resolving high-resolution thin-slice knee MRI from lower-resolution thicker slices, achieving superior quantitative and qualitative diagnostic performance to both conventionally used and state-of-the-art methods.	187.88062255939337
1834.	Epilepsy diagnosis can be costly, time-consuming, and not uncommonly inaccurate. The reference standard diagnostic monitoring is continuous video-electroencephalography (EEG) monitoring, ideally capturing all events or concordant interictal discharges. Automating EEG data review would save time and resources, thus enabling more people to receive reference standard monitoring and also potentially heralding a more quantitative approach to therapeutic outcomes. There is substantial research into the automated detection of seizures and epileptic activity from EEG. However, automated detection software is not widely used in the clinic, and despite numerous published algorithms, few methods have regulatory approval for detecting epileptic activity from EEG. This study reports on a deep learning algorithm for computer-assisted EEG review. Deep convolutional neural networks were trained to detect epileptic discharges using a preexisting dataset of over 6000 labelled events in a cohort of 103 patients with idiopathic generalized epilepsy (IGE). Patients underwent 24-hour ambulatory outpatient EEG, and all data were curated and confirmed independently by two epilepsy specialists (Seneviratne et al., 2016). The resulting automated detection algorithm was then used to review diagnostic scalp EEG for seven patients (four with IGE and three with events mimicking seizures) to validate performance in a clinical setting. The automated detection algorithm showed state-of-the-art performance for detecting epileptic activity from clinical EEG, with mean sensitivity of >95% and corresponding mean false positive rate of 1 detection per minute. Importantly, diagnostic case studies showed that the automated detection algorithm reduced human review time by 80%-99%, without compromising event detection or diagnostic accuracy. The presented results demonstrate that computer-assisted review can increase the speed and accuracy of EEG assessment and has the potential to greatly improve therapeutic outcomes. This article is part of the Special Issue "NEWroscience 2018".	187.8806116647317
1835.	YouTube is the most popular platform for streaming of user-generated videos. Nowadays, professional YouTubers are organized in so-called multichannel networks (MCNs). These networks offer services such as brand deals, equipment, and strategic advice in exchange for a share of the YouTubers' revenues. A dominant strategy to gain more subscribers and, hence, revenue is collaborating with other YouTubers. Yet, collaborations on YouTube have not been studied in a detailed quantitative manner. To close this gap, first, we collect a YouTube dataset covering video statistics over 3 months for 7,942 channels. Second, we design a framework for collaboration detection given a previously unknown number of persons featured in YouTube videos. We denote this framework, for the detection and analysis of collaborations in YouTube videos using a Deep Neural Network (DNN)-based approach, as CATANA. Third, we analyze about 2.4 years of video content and use CATANA to answer research questions guiding YouTubers and MCNs for efficient collaboration strategies. Thereby, we focus on (1) collaboration frequency and partner selectivity, (2) the influence of MCNs on channel collaborations, (3) collaborating channel types, and (4) the impact of collaborations on video and channel popularity. Our results show that collaborations are in many cases significantly beneficial regarding viewers and newly attracted subscribers for both collaborating channels, often showing more than 100% popularity growth compared with noncollaboration videos.	187.88038827742525
1836.	Background and Purpose:Automatic segmentation model is proven to be efficient in delineation of organs at risk (OARs) in radiotherapy; its performance is usually evaluated with geometric differences between automatic and manual delineations. However, dosimetric differences attract more interests than geometric differences in the clinic. Therefore, this study aimed to evaluate the performance of automatic segmentation with dosimetric metrics for volumetric modulated arc therapy of esophageal cancer patients. Methods:Nineteen esophageal cancer cases were included in this study. Clinicians manually delineated the target volumes and the OARs for each case. Another set of OARs was automatically generated using convolutional neural network models. The radiotherapy plans were optimized with the manually delineated targets and the automatically delineated OARs separately. Segmentation accuracy was evaluated by Dice similarity coefficient (DSC) and mean distance to agreement (MDA). Dosimetric metrics of manually and automatically delineated OARs were obtained and compared. The clinically acceptable dose difference and volume difference of OARs between manual and automatic delineations are supposed to be within 1 Gy and 1%, respectively. Results:Average DSC values were greater than 0.92 except for the spinal cord (0.82), and average MDA values were <0.90 mm except for the heart (1.74 mm). Eleven of the 20 dosimetric metrics of the OARs were not significant (P> 0.05). Although there were significant differences (P< 0.05) for the spinal cord (D2%), left lung (V10, V20, V30, and mean dose), and bilateral lung (V10, V20, V30, and mean dose), their absolute differences were small and acceptable for the clinic. The maximum dosimetric metrics differences of OARs between manual and automatic delineations were Delta D2% = 0.35 Gy for the spinal cord and Delta V30 = 0.4% for the bilateral lung, which were within the clinical criteria in this study. Conclusion:Dosimetric metrics were proposed to evaluate the automatic delineation in radiotherapy planning of esophageal cancer. Consequently, the automatic delineation could substitute the manual delineation for esophageal cancer radiotherapy planning based on the dosimetric evaluation in this study.	187.8802201569206
1837.	Machine learning (ML) is one of two standard approaches (together with SED fitting) for estimating the redshifts of galaxies when only photometric information is available. ML photo-z solutions have traditionally ignored the morphological information available in galaxy images or partly included it in the form of hand-crafted features, with mixed results. We train a morphology-aware photometric redshift machine using modern deep learning tools. It uses a custom architecture that jointly trains on galaxy fluxes, colours, and images. Galaxy-integrated quantities are fed to a Multi-Layer Perceptron (MLP) branch, while images are fed to a convolutional (convnet) branch that can learn relevant morphological features. This split MLP-convnet architecture, which aims to disentangle strong photometric features from comparatively weak morphological ones, proves important for strong performance: a regular convnet-only architecture, while exposed to all available photometric information in images, delivers comparatively poor performance. We present a cross-validated MLP-convnet model trained on 130 000 SDSS-DR12 (Sloan Digital Sky Survey - Data Release 12) galaxies that outperforms a hyperoptimized Gradient Boosting solution (hyperopt+XGBoost), as well as the equivalent MLP-only architecture, on the redshift bias metric. The fourfold cross-validated MLP-convnet model achieves a bias delta z/(1 + z) = -0.70 +/- 1 x 10(-3), approaching the performance of a reference ANNZ2 ensemble of 100 distinct models trained on a comparable data set. The relative performance of the morphology-aware and morphology-blind models indicates that galaxy morphology does improve ML-based photometric redshift estimation.	187.87961691836028
1838.	Automated object detection systems are a key component of modern surveillance applications. These systems rely on computationally expensive computer vision algorithms that perform object detection on visual data recorded by surveillance cameras. Due to the security and safety implications of these systems, this visual data st be processed accurately and in real-time. However, many of the frames that are created by the surveillance cameras may be of low importance, providing little or no useful information to the object detection system. Sub-sampling surveillance data by prioritizing important camera frames can greatly reduce unnecessary computation. Consequently, several works have explored dynamic visual data sub-sampling using various modalities of information (ie. spatial or temporal information) for prioritization. Few works, however, have combined and evaluated different modalities of information together for real-time prioritization of visual surveillance data. This work evaluates several individual and combined prioritization metrics derived from different modalities of information for use with a modern deep learning-based object detection algorithm. Both processing time and object detection rate are measured and used to rank the prioritization metrics. A novel approach that uses the historical detection confidences created by the object detection algorithm was demonstrated to be the best standalone prioritization metric. Additionally, a novel ensemble method that uses a KNN regressor to combine the best of the previously evaluated metrics to create a dynamic prioritization method is presented. This ensemble approach is shown to increase the object detection rate by up to 60% as compared to a static sub-sampling baseline as demonstrated using three publicly available datasets. The increased object detection rate was achieved while meeting the real-time constraints of the automated object detection system. (c) 2020 Elsevier Ltd. All rights reserved.	187.8793094235047
1839.	The Fine Mode Fraction (FMF) of atmospheric aerosol is very important for environment and climate studies. Attempts have been made to retrieve the FMF from satellite data with varying success. In this work, the development of an artificial Neural Network for AEROsol retrieval (NNAero) is presented. NNAero uses data from the NASA MODerate resolution Imaging Spectroradiometer (MODIS) flying on the NASA Terra and Aqua satellites. The MODIS-derived spectral reflectances of solar radiation at the top of the atmosphere (TOA) and at the surface were used together with ground-based Aerosol Robotic Network (AERONET) measurements of Aerosol Optical Depth (AOD) and FMF to train a Convolutional Neural Network (CNN) for the joint retrieval of FMF and AOD. The NNAero results over northern and eastern China were validated against an independent reference AERONET dataset (i.e. not used in training the CNN). The results show that 68% of the NNAero AOD values are within the MODIS expected error (EE) envelope over land of +/-(0.05 + 15%), which is similar to the results from the MODIS Deep Blue (DB) algorithm (63% within EE), and both are better than the Dark Target (DT) algorithm (31% within EE). The validation of the NNAero FMF vs AERONET data shows a significant improvement with respect to the DT FMF, with Root Mean Squared Prediction Errors (RMSE) of 0.1567 (NNAero) and 0.34 (DT). The NNAero method shows the potential of improved retrieval of the FMF.	187.8792398420618
1840.	Toxicological datasets tend to be small and imbalanced. This quickly causes models to overfit and disregard the minority class. To solve this issue we generate conformations of molecules. Thereby, we can balance datasets as well as increase their size. Using this approach on the Tox21 Challenge data we observed conformational oversampling to be a viable approach to train datasets, increasing the balanced accuracy of trained models.	187.87923913749054
1841.	Automated semantic segmentation is applied to the quantification of microstructural features in three-phase composite cathode materials of solid oxide fuel cells (SOFCs), i.e., GDC/LSC/Pore where GDC stands for Gd2O3-doped CeO2 and LSC for La0.6Sr0.4CoO3-delta. Our aim is to eliminate the tedious involvement of human experts and the associated errors. The high volume of image information sets is generated using automatic acquisition systems involving focused-ion beam scanning electron microscopy through a so-called slice-view procedure. Through the integration of semantic segmentation with image processing-assisted stereography tools, the following detailed microstructural features are quantitatively extracted automatically and objectively without any human involvement: size distribution, surface (or equivalently, volume) fraction, lengths of two-phase boundaries, and density of triple-phase boundaries based on two-dimensional images. The extracted two-dimensional information is connected with three-dimensional reconstruction analysis. The implications of semantic segmentation in SOFCs are discussed considering efficient analysis and design of high-performance electrode structures in energy-oriented devices.	187.87922178678207
1842.	Convolutional neural networks (CNNs) are classical models for computer vision and machine learning applications such as video surveillance, pattern recognition, weather forecasting, traffic, and safety. CNNs involve computationally intensive operations and require huge off-chip memory bandwidth, which makes it a challenging task to deploy on real-time embedded systems. Compared to central processing units and graphic processing units, field programmable gate arrays (FPGA)-based CNNs are gaining popularity owing to their flexibility and efficiency. In this work, we present an efficient CNN accelerator based on blocked Winograd-GEMM architecture with high performance. We implement ResNet-18 CNN model on XC7VX690T FPGA using proposed architecture. This implementation operates at a clock frequency of 200 MHz and gives average throughput of 383 GOPS which is comparable to other state-of-art implementations. This manuscript is an extended version of [S. Kala, J. Mathew, B. R. Jose, and S. Nalesh, "UniWiG: Unified Winograd-GEMM Architecture for Accelerating CNN on FPGAs," in2019 32nd International Conference on VLSI Design and 2019 18th International Conference on Embedded Systems (VLSID), Delhi, NCR, India, 2019, pp. 209-214. DOI: 10.1109/VLSID.2019.00055.].	187.87917401155653
1843.	Accurate prediction of the host phenotypes from a microbial sample and identification of the associated microbial markers are important in understanding the impact of the microbiome on the pathogenesis and progression of various diseases within the host. A deep learning tool, PopPhy-CNN, has been developed for the task of predicting host phenotypes using a convolutional neural network (CNN). By representing samples as annotated taxonomic trees and further representing these trees as matrices, PopPhy-CNN utilizes the CNN's innate ability to explore locally similar microbes on the taxonomic tree. Furthermore, PopPhy-CNN can be used to evaluate the importance of each taxon in the prediction of host status. Here, we describe the underlying methodology, architecture, and core utility of PopPhy-CNN. We also demonstrate the use of PopPhy-CNN on a microbial dataset.	187.87910680473567
1844.	In this study, the relationship between expressible fluid (EF) measurements and the woody breast (WB) condition in broiler breast fillets (pectoralis major) was investigated and the deep learning algorithm (DLA) was evaluated to predict degrees of the WB condition based on EF images. Fillet samples were collected from a commercial plant and categorized into normal (no WB), moderate WB, and severe WB groups. EF of fresh and frozen samples were measured using the filter paper press method. The features of the images were analyzed using traditional manual method, gray level co-occurrence matrix (GLCM) method and the DLA method, respectively. The results show that there were significant differences in average EF measurements between three WB categories (P < 0.05) regardless of fillet state (Fresh or Frozen). The DLA feature, instead of EF ratios, showed a close relationship between the WB grade and Water-holding capacity (WHC) in broiler breast fillets directly based on EF images. The correct classification rate of WB grades could be as high as 93.3% for fresh and 92.3% for frozen fillets in independent validation set. Data suggest that the WB condition significantly affects the meat WHC measured by the EF method. The deep learning algorithm provides a useful reference for the assessment of the EF images.	187.8789843744689
1845.	This study investigates whether elementary science teachers participating in a four-week professional development workshop develop new understandings about classroom discourse and whether they are able to implement strategies toward teaching science as student-to-student discourse. Perspectives and the extent of teacher use of discourse strategies were examined. Hundred and twenty teachers in grades 4 through 6 from 29 schools participated in the professional development at four public, research-intensive universities situated in a Mid-Atlantic state. Teacher reflections indicate an understanding of the strategies and a belief that they were important. Analysis of program transcripts exposed that elementary teachers were implementing the strategies learned during the professional development. However, they continued to control the conversation and continued to use more traditional talk moves. They tried to use questions to probe student thinking and to have students build on one another. The teachers wrestled with how to ask open-ended questions and guide the discussion to elicit deeper understanding. The professional development model proved effective for raising awareness and reflection, but the model did not result in a significant change in teacher practice. Analysis of classroom practice after this institute may show change toward a more student-centered discourse.	187.87888098644862
1846.	Optimal use of multiparametric magnetic resonance imaging (mpMRI) can identify key MRI parameters and provide unique tissue signatures defining phenotypes of breast cancer. We have developed and implemented a new machine-learning informatic system, termed Informatics Radiomics Integration System (IRIS) that integrates clinical variables, derived from imaging and electronic medical health records (EHR) with multiparametric radiomics (mpRad) for identifying potential risk of local or systemic recurrence in breast cancer patients. We tested the model in patients (n = 80) who had Estrogen Receptor positive disease and underwent OncotypeDX gene testing, radiomic analysis, and breast mpMRI. The IRIS method was trained using the mpMRI, clinical, pathologic, and radiomic descriptors for prediction of the OncotypeDX risk score. The trained mpRad IRIS model had a 95% and specificity was 83% with an Area Under the Curve (AUC) of 0.89 for classifying low risk patients from the intermediate and high-risk groups. The lesion size was larger for the high-risk group (2.9  1.7 mm) and lower for both low risk (1.9  1.3 mm) and intermediate risk (1.7  1.4 mm) groups. The lesion apparent diffusion coefficient (ADC) map values for high- and intermediate-risk groups were significantly (p < 0.05) lower than the low-risk group (1.14 vs. 1.49 * 10-3 mm2/s). These initial studies provide deeper insight into the clinical, pathological, quantitative imaging, and radiomic features, and provide the foundation to relate these features to the assessment of treatment response for improved personalized medicine.	187.87850644415005
1847.	Accurate segmentation of pancreatic venous vessels (PVV) is of great significance for clinical pancreatic cancer radiotherapy. Magnetic resonance imaging (MRI) can provide qualitative assessment of PVV through visualization. Therefore, there is a strong need for an automated segmentation method that can be directly applied to the segmentation of PVV in MR images. In this paper, we develop a deep learning based method with distance and contour regularized level set evolution (DCRLSE) model refinement for automatic detection and segmentation of PVV. The proposed method consists of two main steps: (1) venous vessel localization and segmentation using a dual convolutional neural network (DualCNN) (2) refinement of the initial segmentation with DLRSE model. As PBV is very challenging to segment due to the high inter-patient anatomical variability in both shape and size, the learned weights from other cases are utilized and finetuned to be applied on new cases to obtain consistent and accurate segmentation results. The proposed method was evaluated on 40 MRI scans from a clinical thoracic-abdomen dynamic MRI dataset. Dice similarity coefficient (DSC), sensitivity, specificity, and modified Hausdorff distance (MHD) were calculated to evaluate the segmentation performance of the proposed method. An average sensitivity: 87.60%, specificity: 99.60%, DSC: 86.3%, and MHD: 0.0991mm were obtained. Comparison with other state-of-the-art segmentation methods demonstrate that the proposed method can provide more accurate and consistent segmentation results of PVV in MR images.	187.87842502930226
1848.	Heat flow and thermal state complement seismic information and provide strong constraints on the thickness, geophysical properties, and tectonic evolution of the lithosphere. The North Jiangsu Basin (NJB) is located in Lower Yangtze Craton as a wedge block of ancient plate boundary-adjacent to the southeast corner of the North China Craton experienced destruction in the Late Mesozoic, and it is of great interest to learn the geothermal characteristics of the basin. We present 71 new heat flow measurements derived from temperature logs and detailed thermal conductivity measurements of 189 dry core samples and 24 outcrop samples. We analyze these new data in combination with published data to plot the temperature gradient and heat flow distribution maps. The results show that: (1) temperature gradient values in the NJB are in the 21.5-59.2 degrees C km(-1) range, with mean value of 30.2 +/- 6.5 degrees C km(-1); (2) heat flow values are in the 45.7-109.7 mW m(-2) range, with a mean value of 67.9 +/- 7.7 mW m(-2); (3) the highest temperature gradient and heat flow value is located in or around the Jianhu Uplift, and thermal refraction is the leading cause; and (4) the destruction of the North China Craton at the end of the Late Mesozoic was likely to affect the NJB, and the unified deep dynamic mechanism makes NJB and the Bohai Bay Basin now in a similar thermal state.	187.87832684146798
1849.	Automatic human emotion recognition is a key technology for human-machine interaction. In this paper, we propose an electroencephalogram (EEG) feature extraction method that leverages empirical mode decomposition and Approximation Entropy. In our proposed method, Empirical Mode Decomposition (EMD) is used to process EEG signals after data processing and obtains several intrinsic eigenmode functions. The Approximation Entropy (ApEn) of the first four Intrinsic Mode Functions (IMFs) is computed, which is used as the features from EEG signals for learning and recognition. An integration of Deep Belief Network and Support Vector Machine is devised for classification, which takes the eigenvectors from the extracted feature to identify four principal human emotions, namely happy, calm, sad, and fear. Experiments are conducted with EEG data acquired with a 16-lead device. Our experimental results demonstrate that the proposed method achieves an improved accuracy that is highly competitive to the state-of-the-art methods. The average accuracy is 83.34%, and the best accuracy reaches 87.32%. (C) 2018 Elsevier Ltd. All rights reserved.	187.87828202860112
1850.	Automated semantic segmentation of multiple knee joint tissues is desirable to allow faster and more reliable analysis of large datasets and to enable further downstream processing e.g. automated diagnosis. In this work, we evaluate the use of conditional Generative Adversarial Networks (cGANs) as a robust and potentially improved method for semantic segmentation compared to other extensively used convolutional neural network, such as the U-Net. As cGANs have not yet been widely explored for semantic medical image segmentation, we analysed the effect of training with different objective functions and discriminator receptive field sizes on the segmentation performance of the cGAN. Additionally, we evaluated the possibility of using transfer learning to improve the segmentation accuracy. The networks were trained on i) the SKI10 dataset which comes from the MICCAI grand challenge "Segmentation of Knee Images 2010, ii) the OAI ZIB dataset containing femoral and tibial bone and cartilage segmentations of the Osteoarthritis Initiative cohort and iii) a small locally acquired dataset (Advanced MRI of Osteoarthritis (AMROA) study) consisting of 3D fat-saturated spoiled gradient recalled-echo knee MRIs with manual segmentations of the femoral, tibial and patellar bone and cartilage, as well as the cruciate ligaments and selected peri-articular muscles. The Sorensen-Dice Similarity Coefficient (DSC), volumetric overlap error (VOE) and average surface distance (ASD) were calculated for segmentation performance evaluation. DSC  0.95 were achieved for all segmented bone structures, DSC  0.83 for cartilage and muscle tissues and DSC of 0.66 were achieved for cruciate ligament segmentations with both cGAN and U-Net on the in-house AMROA dataset. Reducing the receptive field size of the cGAN discriminator network improved the networks segmentation performance and resulted in segmentation accuracies equivalent to those of the U-Net. Pretraining not only increased segmentation accuracy of a few knee joint tissues of the fine-tuned dataset, but also increased the network's capacity to preserve segmentation capabilities for the pretrained dataset. cGAN machine learning can generate automated semantic maps of multiple tissues within the knee joint which could increase the accuracy and efficiency for evaluating joint health.	187.8779277514909
1851.	Data parallelism has become the de facto standard for training Deep Neural Network on multiple processing units. In this work we propose DC-S3GD, a decentralized (without Parameter Server) stale-synchronous version of the Delay-Compensated Asynchronous Stochastic Gradient Descent (DC-ASGD) algorithm. In our approach, we allow for the overlap of computation and communication, and compensate the inherent error with a first-order correction of the gradients. We prove the effectiveness of our approach by training Convolutional Neural Network with large batches and achieving state-of-the-art results.	187.87778957629317
1852.	Aim: Accurate predictions of cetacean distributions are essential to their conservation but are limited by statistical challenges and a paucity of data. This study aimed at comparing the capacity of various statistical algorithms to deal with biases commonly found in nonsystematic cetacean surveys and to evaluate the potential for citizen science data to improve habitat modelling and predictions. An endangered population of humpback whales (Megaptera novaeangliae) in their breeding ground was used as a case study. Location: New Caledonia, Oceania. Methods: Five statistical algorithms were used to model the habitat preferences of humpback whales from 1,360 sightings collected over 14 years of nonsystematic research surveys. Three different background sampling approaches were tested when developing models from 625 crowdsourced sightings to assess methods accounting for citizen science spatial sampling bias. Model evaluation was conducted through cross-validation and prediction to an independent satellite tracking dataset. Results: Algorithms differed in complexity of the environmental relationships modelled, ecological interpretability and transferability. While parameter tuning had a great effect on model performances, GLMs generally had low predictive performance, SVMs were particularly hard to interpret, and BRTs had high descriptive power but showed signs of overfitting. MAXENT and especially GAMs provided a valuable complexity trade-off, accurate predictions and were ecologically intelligible. Models showed that humpback whales favoured cool (22-23 degrees C) and shallow waters (0-100 m deep) in coastal as well as offshore areas. Citizen science models converged with research survey models, specifically when accounting for spatial sampling bias. Main conclusions: Marine megafauna distribution models present specific challenges that may be addressed through integrative evaluation, independent testing and appropriately tuned statistical algorithms. Specifically, controlling overfitting is a priority when predicting cetacean distributions for large-scale conservation perspectives. Citizen science data appear to be a powerful tool to describe cetacean habitat.	187.87768068168216
1853.	Wireless capsule endoscopy (WCE) is a gastrointestinal examination technology, which can help find the polyps in small bowel noninvasively. The computer-aided polyp recognition systems based on deep learning require large amounts of manually annotated data, which is often unavailable for WCE images. Meanwhile, there is a serious imbalance between normal and polypoid samples in WCE image database. We proposed a few-shot learning method of automatic polyp recognition under the circumstance of absolute lack of data, named Robust Prototypical Networks (RPNs), and RPNs made adjustments to polyp position changing. Trained with an imbalanced polypoid WCE image dataset and a polypoid colon endoscopy (CE) image dataset, RPNs can extract their common features by introducing a multi-task learning scheme, separating-diffusing, to overcome imbalance problem. RPNs outperforms the previous work, and the best average AUC-PR score is 0.87.	187.8774707454973
1854.	Aging biomarkers are the qualitative and quantitative indicators of the aging processes of the human body. Estimation of biological age is important for assessing the physiological state of an organism. The advent of machine learning lead to the development of the many age predictors commonly referred to as the "aging clocks" varying in biological relevance, ease of use, cost, actionability, interpretability, and applications. Here we present and investigate a novel non-invasive class of visual photographic biomarkers of aging. We developed a simple and accurate predictor of chronological age using just the anonymized images of eye corners called the PhotoAgeClock. Deep neural networks were trained on 8414 anonymized high-resolution images of eye corners labeled with the correct chronological age. For people within the age range of 20 to 80 in a specific population, the model was able to achieve a mean absolute error of 2.3 years and 95% Pearson and Spearman correlation.	187.8773397411303
1855.	Aiming at the problems of complex outdoor background lighting conditions, unsatisfactory moving target features, and high degree of background fusion of wind turbines with large target background, the proposed wind turbine detection and tracking method based on deep learning convolutional neural network is proposed. This paper uses migration learning technology to use a pre-trained SSD model trained with COCO data sets and makes a dedicated localized wind turbine dataset. Through data enhancement, the neural network model can effectively improve the accuracy of wind turbine identification and the average accuracy remains above 96%. The fast recognition speed enables detection and tracking of the fan target in aerial video quickly and accurately.	187.87709319652527
1856.	Background: Postoperative mortality occurs in 1-2% of patients undergoing major inpatient surgery. The currently available prediction tools using summaries of intraoperative data are limited by their inability to reflect shifting risk associated with intraoperative physiological perturbations. We sought to compare similar benchmarks to a deep-learning algorithm predicting postoperative 30-day mortality. Methods: We constructed a multipath convolutional neural network model using patient characteristics, co-morbid conditions, preoperative laboratory values, and intraoperative numerical data from patients undergoing surgery with tracheal intubation at a single medical centre. Data for 60 min prior to a randomly selected time point were utilised. Model performance was compared with a deep neural network, a random forest, a support vector machine, and a logistic regression using predetermined summary statistics of intraoperative data. Results: Of 95 907 patients, 941 (1%) died within 30 days. The multipath convolutional neural network predicted postoperative 30-day mortality with an area under the receiver operating characteristic curve of 0.867 (95% confidence interval [CI]: 0.835-0.899). This was higher than that for the deep neural network (0.825; 95% CI: 0.790-0.860), random forest (0.848; 95% CI: 0.815-0.882), support vector machine (0.836; 95% CI: 0.802-870), and logistic regression (0.837; 95% CI: 0.803-0.871). Conclusions: A deep-learning time-series model improves prediction compared with models with simple summaries of intraoperative data. We have created a model that can be used in real time to detect dynamic changes in a patient's risk for postoperative mortality.	187.87693017768333
1857.	Neuropathic ulcers form and proliferate because of peripheral neuropathy, usually in diabetic patients. The existing ulcer assessment process which relies on visual examination, potentially be imprecise and inefficient. Therefore this indicates the necessity of a more quantitative and cost-effective solution that enables ulcer diagnosing process much faster. In the current literature, different deep learning approaches are available for diagnosing illnesses through medical imagery. When diagnosing diabetic patients who are suffering from neuropathic ulcers through imagery, the locating and segmenting of ulcer boundaries is of great importance. In this study, we propose an approach to automate the process of locating and segmenting ulcers through Mask-RCNN model. We use a dataset of 400 ulcer imagery and corresponding annotations of ulcers for this task. This approach achieves an overall ulcer detection average precision (AP) at Intersection over union (IoU) threshold 0.5 of 0.8632 and mean average precision (mAP) at Intersection over union (IoU) threshold 0.5 to 0.95 by steps of size 0.05 of 0.5084 for ResNet-101 backbone.	187.87657526592022
1858.	Lung cancer is the leading cause of cancer deaths. Low-dose computed tomography (CT) screening has been shown to significantly reduce lung cancer mortality but suffers from a high false positive rate that leads to unnecessary diagnostic procedures. The development of deep learning techniques has the potential to help improve lung cancer screening technology. Here we present the algorithm, DeepScreener, which can predict a patient's cancer status from a volumetric lung CT scan. DeepScreener is based on our model of Spatial Pyramid Pooling, which ranked 16th of 1972 teams (top 1%) in the Data Science Bowl 2017 (DSB2017) competition, evaluated with the challenge datasets. Here we test the algorithm with an independent set of 1449 low-dose CT scans of the National Lung Screening Trial (NLST) cohort, and we find that DeepScreener has consistent performance of high accuracy. Furthermore, by combining Spatial Pyramid Pooling and 3D Convolution, it achieves an AUC of 0.892, surpassing the previous state-of-the-art algorithms using only 3D convolution. The advancement of deep learning algorithms can potentially help improve lung cancer detection with low-dose CT scans.	187.8764167311585
1859.	Detecting faults in axial piston pumps is of significance to enhance the reliability and security of hydraulic systems. However, it is difficult to detect multiple faults in the hydraulic electromechanical coupling systems because the fault mechanism of some faults is unclear. In this paper, a method using deep belief networks (DBNs) is proposed to detect multiple faults in axial piston pumps. Firstly, for each individual fault, all the data indicators extracted from the raw signals in time domain, frequency domain and time-frequency domain are calculated to construct training and testing samples. Then, the constructed samples are fed into DBNs to classify the multiple faults in axial piston pumps. With restricted Boltzmann machine (RBM) stacked layer by layer, DBNs can automatically learn fault features. Numerical simulations using the benchmark data of five faults in rolling bearings are classified by the present method to select the relative optimal combination of indicators. The classification results are also compared with those commonly used support vector machine (SVM) and artificial neural network (ANN) to manifest the classification accuracy of the present method. Experimental investigations are performed to classify four faults in an axial piston pump. The classification accuracy ratio is 97.40%, which confirms the feasibility and effectiveness of multiple faults detection in axial piston pumps using DBNs. (C) 2018 Elsevier Ltd. All rights reserved.	187.87576343442586
1860.	OBJECTIVE: To investigate the clinical utility of deep convolutional neural network (DCNN) tract classification as a new imaging tool in the preoperative evaluation of children with focal epilepsy (FE). METHODS: A DCNN tract classification deeply learned spatial trajectories of DWI white matter pathways linking electrical stimulation mapping (ESM) findings from 89 children with FE, and then automatically identified white matter pathways associated with eloquent functions (i.e., primary motor, language, and vision). Clinical utility was examined by 1) measuring the nearest distance between DCNN-determined pathways and ESM, 2) evaluating the effectiveness of DCNN-determined pathways to optimize surgical margins via Kalman filter analysis, and 3) evaluating how accurately changes in DCNN-determined language pathway volume can predict changes in language ability via canonical correlation analysis. RESULTS: DCNN tract classification outperformed other existing methods, achieving an excellent accuracy of 98 % while non-invasively detecting eloquent areas within the spatial resolution of ESM (i.e., 1cm). The Kalman filter analysis found that the preservation of brain areas within a surgical margin determined by DCNN tract classification predicted lack of postoperative deficit with a high accuracy of 92 %. Postoperative change of DCNN-determined language pathway volume showed a significant correlation with postoperative changes in language ability (R = 0.7, p 0.001). CONCLUSION: Our findings demonstrate that postoperative functional deficits substantially differ according to the extent of resected white matter, and that DCNN tract classification may offer key translational information by identifying these pathways in pediatric epilepsy surgery. SIGNIFICANCE: DCNN tract classification may be an effective tool to improve surgical outcome of children with FE.	187.87515863705116
1861.	Opioid abuse epidemics is a major public health emergency in the US. Social media platforms have facilitated illicit drug trading, with significant amount of drug advertisement and selling being carried out online. In order to understand dynamics of drug abuse epidemics and design efficient public health interventions, it is essential to extract and analyze data from online drug markets. In this paper, we present a computational framework for automatic detection of illicit drug ads in social media, with Google+ being used for a proof-of-concept. The proposed SVM- and CNN-based methods have been extensively validated on the large dataset containing millions of posts collected using Google+ API. Experimental results demonstrate that our methods can efficiently identify illicit drug ads with high accuracy. Both approaches have been extensively validated using the dataset containing millions of posts collected using Google+ API. Experimental results demonstrate that both methods allow for accurate identification of illicit drug ads.	187.87430342643069
1862.	Recycled aggregate concrete (RAC) contributes to mitigating the depletion of natural aggregates, alleviating the carbon footprint of concrete construction, and averting the landfilling of colossal amounts of construction and demolition waste. However, complexities in the mixture optimization of RAC due to the variability of recycled aggregates and lack of accuracy in estimating its compressive strength require novel and sophisticated techniques. This paper aims at developing state-of-the-art machine learning models to predict the RAC compressive strength and optimize its mixture design. Results show that the developed models including Gaussian processes, deep learning, and gradient boosting regression achieved robust predictive performance, with the gradient boosting regression trees yielding highest prediction accuracy. Furthermore, a particle swarm optimization coupled with gradient boosting regression trees model was developed to optimize the mixture design of RAC for various compressive strength classes. The hybrid model achieved cost-saving RAC mixture designs with lower environmental footprint for different target compressive strength classes. The model could be further harvested to achieve sustainable concrete with optimal recycled aggregate content, least cost, and least environmental footprint.	187.87404953688207
1863.	This paper introduces a new image-based handwritten historical digit dataset named Arkiv Digital Sweden (ARDIS). The images in ARDIS dataset are extracted from 15,000 Swedish church records which were written by different priests with various handwriting styles in the nineteenth and twentieth centuries. The constructed dataset consists of three single-digit datasets and one-digit string dataset. The digit string dataset includes 10,000 samples in red-green-blue color space, whereas the other datasets contain 7600 single-digit images in different color spaces. An extensive analysis of machine learning methods on several digit datasets is carried out. Additionally, correlation between ARDIS and existing digit datasets Modified National Institute of Standards and Technology (MNIST) and US Postal Service (USPS) is investigated. Experimental results show that machine learning algorithms, including deep learning methods, provide low recognition accuracy as they face difficulties when trained on existing datasets and tested on ARDIS dataset. Accordingly, convolutional neural network trained on MNIST and USPS and tested on ARDIS provide the highest accuracies58.80% respectively. Consequently, the results reveal that machine learning methods trained on existing datasets can have difficulties to recognize digits effectively on our dataset which proves that ARDIS dataset has unique characteristics. This dataset is publicly available for the research community to further advance handwritten digit recognition algorithms.	187.87381952407958
1864.	Predicting lesion malignancy accurately and reliably in digital breast tomosynthesis is critically important for breast cancer screening. Tumor shape and interactive effect between the tumor and surrounding normal tissue are two of the most important indicators in radiologists' reading. On the other hand, the density and texture of region within the tumor also play an important role in malignancy classification. Inspired by the above observations, shell and kernel descriptors were proposed in this work for breast lesion malignancy prediction, in which the shell descriptor is used for describing the tumor shape and surrounding normal tissue while the kernel descriptor is used to describe the internal tumor region. A joint deep learning model based on the AlexNet was designed to learn and fuse features from shell and kernel. Additionally, to obtain more reliable predictive results, a multi-objective optimization algorithm and a reliable classifier fusion strategy were used to train the predictive model and optimally combine outputs from both shell and kernel descriptors. In this study, 278 malignant and 685 benign cases were used through 2-fold cross validation. Compared with the single descriptor based models using either shell or kernel, the experimental results demonstrated that the combined shell and kernel descriptors can capture the most important features and the corresponding predictive model achieved the best performance as well.	187.87380962297726
1865.	Visual evaluation of electroencephalogram (EEG) for Interictal Epileptiform Discharges (IEDs) as distinctive biomarkers of epilepsy has various limitations, including time-consuming reviews, steep learning curves, interobserver variability, and the need for specialized experts. The development of an automated IED detector is necessary to provide a faster and reliable diagnosis of epilepsy. In this paper, we propose an automated IED detector based on Convolutional Neural Networks (CNNs). We have evaluated the proposed IED detector on a sizable database of 554 scalp EEG recordings (84 epileptic patients and 461 nonepileptic subjects) recorded at Massachusetts General Hospital (MGH), Boston. The proposed CNN IED detector has achieved superior performance in comparison with conventional methods with a mean cross-validation area under the precision-recall curve (AUPRC) of 0.838[Formula: see text][Formula: see text]0.040 and false detection rate of 0.2[Formula: see text][Formula: see text]0.11 per minute for a sensitivity of 80%. We demonstrated the proposed system to be noninferior to 30 neurologists on a dataset from the Medical University of South Carolina (MUSC). Further, we clinically validated the system at National University Hospital (NUH), Singapore, with an agreement accuracy of 81.41% with a clinical expert. Moreover, the proposed system can be applied to EEG recordings with any arbitrary number of channels.	187.87378585101402
1866.	Inverse sensing is an important research direction to provide new perspectives for optical sensing. For inverse sensing, the primary challenge is that scattered photon has a complicated profile, which is hard to derive a general solution. Instead of a general solution, it is more feasible and practical to derive a solution based on a specific environment. With deep learning, we develop a multifunctional inverse sensing approach for a specific environment. This inverse sensing approach can reconstruct the information of scattered photons and characterize multiple optical parameters simultaneously. Its functionality can be upgraded dynamically after learning more data. It has wide measurement range and can characterize the optical signals behind obstructions. The high anti-noise performance, flexible implementation, and extremely high threshold to optical damage or saturation make it useful for a wide range of applications, including self-driving car, space technology, data security, biological characterization, and integrated photonics.	187.8731450690364
1867.	Semantic segmentation of remote sensing data such as multispectral imagery has been boosted recently using deep convolutional neural networks (CNN). However, segmentation of multispectral images using supervised machine learning algorithms such as CNN requires a significant number of pixel-level annotated data, often unavailable, making the task extremely challenging. To address this, this paper puts forward a semi-supervised framework, based on generative adversarial networks (GAN). The proposed solution consists of a generator network to provide photo-realistic images as extra training data to a multi-class classifier acting as a discriminator and trained on a small annotated dataset. Performance of the proposed semi-supervised GAN is evaluated on two benchmarks multispectral semantic segmentation datasets collected from urban scenes of Vaihingen and Potsdam. Results indicate that the proposed framework achieves competitive performance compared to state-of-the-art semantic segmentation methods and show the potential of GAN-based methods for the challenging task of multispectral image segmentation.	187.873055115736
1868.	Coral reef research and management efforts can be improved when supported by reef maps providing local-scale details across global extents. However, such maps are difficult to generate due to the broad geographic range of coral reefs, the complexities of relating satellite imagery to geomorphic or ecological realities, and other challenges. However, reef extent maps are one of the most commonly used and most valuable data products from the perspective of reef scientists and managers. Here, we used convolutional neural networks to generate a globally consistent coral reef probability map-a probabilistic estimate of the geospatial extent of reef ecosystems-to facilitate scientific, conservation, and management efforts. We combined a global mosaic of high spatial resolution Planet Dove satellite imagery with regional Millennium Coral Reef Mapping Project reef extents to build training, validation, and application datasets. These datasets trained our reef extent prediction model, a neural network with a dense-unet architecture followed by a random forest classifier, which was used to produce a global coral reef probability map. Based on this probability map, we generated a global coral reef extent map from a 60% threshold of reef probability (reef: probability >= 60%, non-reef: probability < 60%). Our findings provide a proof-of-concept method for global reef extent estimates using a consistent and readily updateable methodology that leverages modern deep learning approaches to support downstream users. These maps are openly-available through the Allen Coral Atlas.	187.87302912577513
1869.	Financial time series analysis is an important research area that can predict various economic indicators such as the foreign currency exchange rate. In this paper, a deep-learning-based model is proposed to forecast the foreign exchange rate. Since the currency market is volatile and susceptible to ongoing social and political events, the proposed model incorporates event sentiments to accurately predict the exchange rate. Moreover, as the currency market is heavily dependent upon highly volatile factors such as gold and crude oil prices, we considered these sensitive factors for exchange rate forecasting. The validity of the model is tested over three currency exchange rates, which are Pak Rupee to US dollar (PKR/USD), British pound sterling to US dollar (GBP/USD), and Hong Kong Dollar to US dollar (HKD/USD). The study also shows the importance of incorporating investor sentiment of local and foreign macro-level events for accurate forecasting of the exchange rate. We processed approximately 5.9 million tweets to extract major events' sentiment. The results show that this deep-learning-based model is a better predictor of foreign currency exchange rate in comparison with statistical techniques normally employed for prediction. The results present evidence that the exchange rate of all the three countries is more exposed to events happening in the US.	187.87285193569085
1870.	In order to solve the problem that, in complex and wide traffic scenes, the accuracy and speed of multi-object detection can hardly be balanced by the existing object detection algorithms that are based on deep learning and big data, we improve the object detection framework SSD (Single Shot Multi-box Detector) and propose a new detection framework AP-SSD (Adaptive Perceive). We design a feature extraction convolution kernel library composed of multi-shape Gabor and color Gabor and then we train and screen the optimal feature extraction convolution kernel to replace the low-level convolution kernel of the original network to improve the detection accuracy. After that, we combine the single image detection framework with convolution long-term and short-term memory networks and by using the Bottle Neck-LSTM memory layer to refine and propagate the feature mapping between frames, we realize the temporal association of network frame-level information, reduce the calculation cost, succeed in tracking and identifying the targets affected by strong interference in video and reduce the missed alarm rate and false alarm rate by adding an adaptive threshold strategy. Moreover, we design a dynamic region amplification network framework to improve the detection and recognition accuracy of low-resolution small objects. Therefore, experiments on the improved AP-SSD show that this new algorithm can achieve better detection results when small objects, multiple objects, cluttered background and large-area occlusion are involved, thus ensuring this algorithm a good engineering application prospect.	187.87277787696635
1871.	Thrombosis has become a global disease threatening human health. The left atrial appendage (LAA) is a major source of thrombosis in patients with atrial fibrillation (AF). Positive correlation exists between LAA volume and AF risk. LAA morphology has been suggested to influence thromboembolic risk in AF patients and to help predict thromboembolic events in low-risk patient groups. Automatic segmentation of LAA can greatly help physicians diagnose AF. In consideration of the large anatomical variations of the LAA, we proposed a robust method for automatic LAA segmentation on computed tomographic angiography (CTA) data using fully convolutional neural networks with three-dimensional (3-D) conditional random fields (CRFs). After manual localization of ROI of LAA, we adopted the FCN in natural image segmentation and transferred their learned models by fine-tuning the networks to segment each 2-D LAA slice. Subsequently, we used a modified dense 3-D CRF that accounts for the 3-D spatial information and larger contextual information to refine the segmentations of all slices. Our method was evaluated on 150 sets of CTA data using five-fold cross validation. Compared with manual annotation, we obtained a mean dice overlap of 94.76% and a mean volume overlap of 91.10% with a computation time of less than 40 s per volume. Experimental results demonstrated the robustness of our method in dealing with large anatomical variations and computational efficiency for adoption in a daily clinical routine.)	187.8724548503457
1872.	In order to accurately detect the location of pulmonary nodules in hundreds of chest CT images in routine reading environment, this paper proposes an improved algorithm based on Faster R-CNN. Firstly, we concatenate multi-level feature maps in VGG16 model to fuse the shallow and deep features of the shared convolution layer, which recovers the more fine-grained features. Then, we design a new "Pyramid RPN" structure with three parallel convolution kernels of different sizes to generate more accurate candidate regions. Finally, the region of interest (ROI) pooling layer is optimized by removing quantization operations and using bilinear interpolation to compute the exact value to reduce regression deviation. The experimental results show that the sensitivity and the false positive rate of each scan have a better performance improvement. The proposed method can more accurately detect small pulmonary nodules and has certain clinical significance for early screening of lung cancer.	187.87237499274576
1873.	Diagnosis of benign-malignant nodules in the lung on Computed Tomography (CT) images is critical for determining tumor level and reducing patient mortality. Deep learning-based diagnosis of nodules in lung CT images, however, is time-consuming and less accurate due to redundant structure and the lack of adequate training data. In this paper, a novel diagnosis method based on Deep Transfer Convolutional Neural Network (DTCNN) and Extreme Learning Machine (ELM) is explored, which merges the synergy of two algorithms to deal with benign-malignant nodules classification. An optimal DTCNN is first adopted to extract high-level features of lung nodules, which has been trained with the ImageNet dataset beforehand. After that, an ELM classifier is further developed to classify benign and malignant lung nodules. Two datasets, including the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) public dataset and a private dataset from the First Affiliated Hospital of Guangzhou Medical University in China (FAH-GMU), have been conducted to verify the efficiency and effectiveness of the proposed approach. For LIDC-IDRI dataset, the experimental results show that our novel DTCNN-ELM model achieved the performance with an accuracy of 94.57%, a sensitivity of 93.69%, a specificity of 95.15%, an area under the receiver operator curve (AUC) of 94.94%, and testing time per nodule of 0.5 ms, which has the most reliable results compared with current state-of-the-art methods. Codes are available(1). (C) 2020 Elsevier B.V. All rights reserved.	187.87198166934445
1874.	A deep learning MR parameter mapping framework which combines accelerated radial data acquisition with a multi-scale residual network (MS-ResNet) for image reconstruction is proposed. The proposed supervised learning strategy uses input image patches from multi-contrast images with radial undersampling artifacts and target image patches from artifact-free multi-contrast images. Subspace filtering is used during pre-processing to denoise input patches. For each anatomy and relaxation parameter, an individual network is trained. in vivo T-1 mapping results are obtained on brain and abdomen datasets and in vivo T-2 mapping results are obtained on brain and knee datasets. Quantitative results for the T-2 mapping of the knee show that MS-ResNet trained using either fully sampled or undersampled data outperforms conventional model-based compressed sensing methods. This is significant because obtaining fully sampled training data is not possible in many applications. in vivo brain and abdomen results for T-1 mapping and in vivo brain results for T-2 mapping demonstrate that MS-ResNet yields contrast-weighted images and parameter maps that are comparable to those achieved by model-based iterative methods while offering two orders of magnitude reduction in reconstruction times. The proposed approach enables recovery of high-quality contrast-weighted images and parameter maps from highly accelerated radial data acquisitions. The rapid image reconstructions enabled by the proposed approach makes it a good candidate for routine clinical use.	187.8716140064157
1875.	Prostate segmentation of MR volumes is a very important task for treatment planning and image-guided brachytherapy and radiotherapy. Manual delineation of prostate in MR image is very time-consuming and depends on the subjective experience of the physicians. On the other hand, automatic prostate segmentation becomes a reasonable and attractive choice for its speed, even though the task is very challenging because of inhomogeneous intensity and variability of prostate appearance and shape. In this paper, we propose a method to automatically segment MR prostate image based on 3D deeply supervised FCN with concatenated atrous convolution (3D DSA-FCN). More discriminative features provide explicit convergence acceleration in training stage using straightforward dense predictions as deep supervision and the concatenated atrous convolution extract more global contextual information for accurate predictions. The presented method was evaluated on the internal dataset comprising 15 T2-weighted prostate MR volumes from Winship Cancer Institute and obtained a mean Dice similarity coefficient (DSC) of 0.852 +/- 0.031, 95% Hausdorff distance (95%HD) 7.189 +/- 1.953 mm and mean surface distance (MSD) of 1.597 +/- 0.360 mm. The experimental results show that our 3D DSA-FCN could yield satisfied MR prostate segmentation, which can be used for image-guided radiotherapy.	187.87159224235592
1876.	BACKGROUND AND PURPOSE: To enable accurate magnetic resonance imaging (MRI)-based dose calculations, synthetic computed tomography (sCT) images need to be generated. We aim at assessing the feasibility of dose calculations from MRI acquired with a heterogeneous set of imaging protocol for paediatric patients affected by brain tumours. MATERIALS AND METHODS: Sixty paediatric patients undergoing brain radiotherapy were included. MR imaging protocols varied among patients, and data heterogeneity was maintained in train/validation/test sets. Three 2D conditional generative adversarial networks (cGANs) were trained to generate sCT from T1-weighted MRI, considering the three orthogonal planes and its combination (multi-plane sCT). For each patient, median and standard deviation (sigma) of the three views were calculated, obtaining a combined sCT and a proxy for uncertainty map, respectively. The sCTs were evaluated against the planning CT in terms of image similarity and accuracy for photon and proton dose calculations. RESULTS: A mean absolute error of 6114 HU (mean1sigma) was obtained in the intersection of the body contours between CT and sCT. The combined multi-plane sCTs performed better than sCTs from any single plane. Uncertainty maps highlighted that multi-plane sCTs differed at the body contours and air cavities. A dose difference of -0.10.3% and 0.10.4% was obtained on the D>90% of the prescribed dose and mean gamma2%,2mm pass-rate of 99.50.8% and 99.21.1% for photon and proton planning, respectively. CONCLUSION: Accurate MR-based dose calculation using a combination of three orthogonal planes for sCT generation is feasible for paediatric brain cancer patients, even when training on a heterogeneous dataset.	187.87086432365936
1877.	In this study, we present deep learning-based approaches to automatic segmentation and applicator reconstruction with high accuracy and efficiency in the planning computed tomography (CT) for cervical cancer brachytherapy (BT). A novel three-dimensional (3D) convolutional neural network (CNN) architecture was proposed and referred to as DSD-UNET. The dataset of 91 patients received CT-based BT of cervical cancer was used to train and test DSD-UNET model for auto-segmentation of high-risk clinical target volume (HR-CTV) and organs at risk (OARs). Automatic applicator reconstruction was achieved with DSD-UNET-based segmentation of applicator components followed by 3D skeletonization and polynomial curve fitting. Digitization of the channel paths for tandem and ovoid applicator in the planning CT was evaluated utilizing the data from 32 patients. Dice similarity coefficient (DSC), Jaccard Index (JI), and Hausdorff distance (HD) were used to quantitatively evaluate the accuracy. The segmentation performance of DSD-UNET was compared with that of 3D U-Net. Results showed that DSD-UNET method outperformed 3D U-Net on segmentations of all the structures. The mean DSC values of DSD-UNET method were 86.9%, 82.9%, and 82.1% for bladder, HR-CTV, and rectum, respectively. For the performance of automatic applicator reconstruction, outstanding segmentation accuracy was first achieved for the intrauterine and ovoid tubes (average DSC value of 92.1%, average HD value of 2.3 mm). Finally, HDs between the channel paths determined automatically and manually were 0.88 +/- 0.12 mm, 0.95 +/- 0.16 mm, and 0.96 +/- 0.15 mm for the intrauterine, left ovoid, and right ovoid tubes, respectively. The proposed DSD-UNET method outperformed the 3D U-Net and could segment HR-CTV, bladder, and rectum with relatively good accuracy. Accurate digitization of the channel paths could be achieved with the DSD-UNET-based method. The proposed approaches could be useful to improve the efficiency and consistency of treatment planning for cervical cancer BT.	187.87072094187005
1878.	Research of starlight-level wide-spectrum full-color imaging technology is aimed at the current demand of obtaining the real color image in the low ambient light. because traditional visible light imaging, laser imaging, thermal imaging and other technical methods can only obtain the target grayscale imaging information, but not obtain the target true color information. According to statistics, color images contain 30 times more information than grayscale images, and spectral information is extremely critical in target recognition. This paper intends to adopt an imaging method that integrates super large pixels, ultra-thin process microlens collection, and large-diameter light transmission to increase the sensitivity of the device by 50 similar to 100 times. The technical difficulty at this stage is based on large pixel, large area array, high pass light rate, low noise imaging device preparation technology. The key to achieving full-color imaging is the fabrication of large-pixel, large-area imaging devices and high-transmission, low-noise process technology. On this basis, we also designed deep learning image processing algorithms, conducted color brightening and enhancement of devices' physical true color, and increased the signal-to-background ratio of images, which laid a technological foundation for the follow-up target detection and identification, and industrialized application. lastly, the minimum illumination of color night vision is 0.0001Lux@25Hz, F1.0, thereby achieving wide-spectrum full-color imaging.	187.87072080083243
1879.	In Korea, weather forecasts for fundamental weather factors, such as temperature, precipitation, wind direction and speed, humidity, and cloudiness, are provided for a three-day period in each region. This can facilitate predicting photovoltaic power generation based on weather forecasting. For this purpose, in the present paper, we aim to propose corresponding model. However, the Korea Meteorological Administration does not forecast the amount of solar radiation and sunshine that mostly influence the results of photovoltaic power generation prediction. In this study, we predict these parameters considering various input/output (I/O) variables and learning algorithms applied to weather forecasts on hourly weather data. Finally, we predict photovoltaic power generation based on the best sunshine and solar radiation prediction results. The data structure underlying all predictions relies on four models applied to fundamental weather factors on sunshine and solar radiation data two hours ago. Then, the photovoltaic power generation prediction is implemented using four models depending on whether to add the predicted sunshine and solar radiation data obtained at the previous step. The prediction algorithm relies on an adaptive neuro-fuzzy inference system and artificial neural network (ANN) techniques, including dynamic neural network (DNN), recurrent neural network (RNN), and long short-term memory (LSTM). The results of the conducted experiment indicate that ANN perform better than the neuro-fuzzy approach. Moreover, we demonstrate that RNN and LSTM are more suitable for the time series data structures compared with DNN. Furthermore, we report that the weather forecast structure and the model 4 structure, which includes sunshine and solar radiation data two hours ago, achieve the best prediction results.	187.87062461694273
1880.	Recent years have seen growing interest in utilizing sensors to detect learner affect. Modeling frustration has particular significance because of its central role in learning. However, sensor-based affect detection poses important challenges. Motion-tracking cameras produce vast streams of spatial and temporal data, but relatively few systems have harnessed this data successfully to produce accurate run-time detectors of learner frustration outside of the laboratory. In this paper, we introduce a data-driven framework that leverages spatial and temporal posture data to detect learner frustration using deep neural network-based data fusion techniques. To train and validate the detectors, we utilize posture data collected with Microsoft Kinect sensors from students interacting with a game-based learning environment for emergency medical training. Ground-truth labels of learner frustration were obtained using the BROMP quantitative observation protocol. Results show that deep neural network-based late fusion techniques that combine spatial and temporal data yield significant improvements to frustration detection relative to baseline models.	187.87053797533827
1881.	Recently, as a variety of position sensors are developed, a large amount of urban position data is collected in the urban traffic networks. Based on the data collected through such location sensors, high-resolution urban mobility data of individual users using urban road networks is generated and collected in the transportation systems. Urban mobility data generated by these sensors provide a novel spatio-temporal insights into the mobility patterns of traffic network users and can be used to develop models and strategies to predict traffic flows in urban areas and improve traffic efficiency. This study proposes an algorithm for predicting urban mobility patterns. Deep learning based algorithm is used to train mobility patterns in urban areas and predict mobility. The proposed algorithm is trained and tested using Bluetooth data collected in Brisbane for one year. As a result of evaluating the performance of the algorithm with the test dataset, the proposed algorithm shows an average prediction accuracy of 70% or more.	187.87025853461316
1882.	Dual-energy X-ray absorptiometry (DXA) is widely used for clinical assessment of bone mineral density (BMD). Recent evidence shows that DXA images may also contain microstructural information of trabecular bones. However, no current image processing techniques could aptly extract the information. Inspired by the success of deep learning techniques in medical image analyses, we hypothesized in this study that DXA image-based deep learning models could predict the major microstructural features of trabecular bone with a reasonable accuracy. To test the hypothesis, 1249 trabecular cubes (6mm*6mm*6mm) were digitally dissected out from the reconstruction of seven human cadaveric proximal femurs using microCT scans. From each cube, simulated DXA images in designated projections were generated, and the histomorphometric parameters (i.e., BV/TV, BS, Tb.Th, DA, Conn. D, and SMI) of the cube were determined using Image J. Convolutional neural network (CNN) models were trained using the simulated DXA images to predict the histomorphometric parameters of trabecular bone cubes. The results exhibited that the CNN models achieved high fidelity in predicting these histomorphometric parameters (from R=0.80 to R=0.985), showing that the DL models exhibited the capability of predicting the microstructural features using DXA images. This study also showed that the number and resolution of input simulated DXA images had considerable impacts on the prediction accuracy of the DL models. These findings support the hypothesis of this study and indicate a high potential of using DXA images in prediction of osteoporotic bone fracture risk.	187.87018015347854
1883.	Synchronous chip seal is an advanced road constructing technology, and the gravel coverage rate is an important indicator of the construction quality. In this paper, a novel approach for gravel coverage rate measurement is proposed based on deep learning. Convolutional neural network (CNN) is used to segment the image of ground covered with gravels, and the gravel coverage rate is computed by the percentage of gravel pixels in the segmented image. The gravel coverage rate dataset for model training and testing is built. The performance of fully convolutional neural network (FCN) and U-Net model in the dataset is tested. A better model named GravelNet is constructed based on U-Net. The scaled exponential linear unit (SELU) is employed in the GravelNet to replace the popular combination of rectified linear unit (ReLU) and batch normalization (BN). Data augmentation and alpha dropout are performed to reduce overfitting. The experimental results demonstrate the effectiveness and accuracy of our proposed method. Our trained GravelNet achieves the mean gravel coverage rate error of 0.35% on test dataset.	187.87000173474883
1884.	Segmentation of optic disk (OD) from retinal images is a crucial task for early detection of many eye diseases, including glaucoma and diabetic retinopathy. The main goal of this research is to facilitate early diagnosis of certain pathologies via fully automated segmentation of the OD from retinal images. We propose a deep learning-based technique to delineate the boundary of OD from retinal images of patients with diabetic retinopathy and diabetic macular edema. In our method, we first localized OD within a region of interest (ROI) using random forest (RF). The RF is an ensemble algorithm, which trains and combines multiple decision trees to produce a highly accurate classifier. We then used a convolutional neural network (CNN) based model to segment OD from chosen ROIs in the retinal images. The developed algorithm has been validated on 480,249 image patches extracted from 49 images of public Indian diabetic retinopathy image dataset (IDRiD). This dataset includes images with large variability in terms of the spatial location of OD and presence of other eye lesions that resemble the contrast of OD. Validation metrics including average of Dice and Jaccard indexes (DI and JI), Hausdorff distance (HD), and absolute surface difference (ASD) were reported as 82.62 +/- 11.07%, 71.78 +/- 14.87%, 13.19 +/- 10.90 mm, and 22.74 +/- 19.78%, respectively. As compared to other alternative methods, such as K-nearest neighbors (KNN), deformable models, graph-cuts, and image thresholding, our method yielded higher accuracy for OD segmentation in comparison to manual expert delineation. The algorithm-generated results demonstrate the usefulness of our proposed method for automated segmentation of OD from retinal images.	187.86990716023362
1885.	Automatic diagnosing lung cancer from computed tomography scans involves two steps: detect all suspicious lesions (pulmonary nodules) and evaluate the whole-lung/pulmonary malignancy. Currently, there are many studies about the first step, but few about the second step. Since the existence of nodule does not definitely indicate cancer, and the morphology of nodule has a complicated relationship with cancer, the diagnosis of lung cancer demands careful investigations on every suspicious nodule and integration of information of all nodules. We propose a 3-D deep neural network to solve this problem. The model consists of two modules. The first one is a 3-D region proposal network for nodule detection, which outputs all suspicious nodules for a subject. The second one selects the top five nodules based on the detection confidence, evaluates their cancer probabilities, and combines them with a leaky noisy-OR gate to obtain the probability of lung cancer for the subject. The two modules share the same backbone network, a modified U-net. The overfitting caused by the shortage of the training data is alleviated by training the two modules alternately. The proposed model won the first place in the Data Science Bowl 2017 competition.	187.86932811608307
1886.	Object recognition distinguish objects which are different from each other. But Face recognition distinguishes Identity of Faces with Similar Patterns. Feature extraction algorithm such as LBP, HOG, Gabor is being replaced with Deep Learning. As the technology that identify individual face with machine learning using Deep Learning Technology is developing, The Face Recognition Technology is being used in various field. In particular, the technology can provide individual and detailed service by being used in various offline environments requiring user identification, such as Smart Mirror. Face Recognition Technology can be developed as the technology that authenticate user easily by device like Smart Mirror and provide service authenticated user. In this paper, we present investigation about Face Recognition among various techniques for user authentication and analysis of Python source case of Face recognition and possibility of various service using Face Recognition Technolog	187.86924428902617
1887.	The thickness normal to deposition (isopachs) and vertical thickness (isochores) of geological units is important for assessing various geologic processes. We present the first marine global sediment isochore estimates for five geological periods dating from middle Miocene (15.97 Ma) to present. We use sparsely distributed sediment depth vs. age observations from the Deep Sea Drilling Project and global maps of biological, oceanographic, geographic, and geological variables as training features in a k-nearest neighbor regressor to estimate isochores. Results are compared to isochore estimates generated by applying a constant depositional rate from recent estimates of global total sediment thicknesses. Both models of isochore thickness exhibit consistent error. Results from a machine learning approach show major advantages, including results that are quantitative, easily updatable, and accompanied with uncertainty estimation. Final predictions can provide first-order constraints on sediment deposition with geologic time, which is of timely importance for assessing past climate variability.	187.868799282076
1888.	PURPOSE OF REVIEW: Pathomics, the fusion of digitalized pathology and artificial intelligence, is currently changing the landscape of medical pathology and biologic disease classification. In this review, we give an overview of Pathomics and summarize its most relevant applications in urology. RECENT FINDINGS: There is a steady rise in the number of studies employing Pathomics, and especially deep learning, in urology. In prostate cancer, several algorithms have been developed for the automatic differentiation between benign and malignant lesions and to differentiate Gleason scores. Furthermore, several applications have been developed for the automatic cancer cell detection in urine and for tumor assessment in renal cancer. Despite the explosion in research, Pathomics is not fully ready yet for widespread clinical application. SUMMARY: In prostate cancer and other urologic pathologies, Pathomics is avidly being researched with commercial applications on the close horizon. Pathomics is set to improve the accuracy, speed, reliability, cost-effectiveness and generalizability of pathology, especially in uro-oncology.	187.8687640353642
1889.	Neurodevelopmental spectrum disorders like autism (ASD) are diagnosed, on average, beyond age 4 y, after multiple critical periods of brain development close and behavioral intervention becomes less effective. This raises the urgent need for quantitative, noninvasive, and translational biomarkers for their early detection and tracking. We found that both idiopathic (BTBR) and genetic (CDKL5- and MeCP2-deficient) mouse models of ASD display an early, impaired cholinergic neuromodulation as reflected in altered spontaneous pupil fluctuations. Abnormalities were already present before the onset of symptoms and were rescued by the selective expression of MeCP2 in cholinergic circuits. Hence, we trained a neural network (ConvNetACh) to recognize, with 97% accuracy, patterns of these arousal fluctuations in mice with enhanced cholinergic sensitivity (LYNX1-deficient). ConvNetACh then successfully detected impairments in all ASD mouse models tested except in MeCP2-rescued mice. By retraining only the last layers of ConvNetACh with heart rate variation data (a similar proxy of arousal) directly from Rett syndrome patients, we generated ConvNetPatients, a neural network capable of distinguishing them from typically developing subjects. Even with small cohorts of rare patients, our approach exhibited significant accuracy before (80% in the first and second year of life) and into regression (88% in stage III patients). Thus, transfer learning across species and modalities establishes spontaneous arousal fluctuations combined with deep learning as a robust noninvasive, quantitative, and sensitive translational biomarker for the rapid and early detection of neurodevelopmental disorders before major symptom onset.	187.86869996273418
1890.	The gold standard of histopathology for the diagnosis of Barrett's esophagus (BE) is hindered by inter-observer variability among gastrointestinal pathologists. Deep learning-based approaches have shown promising results in the analysis of whole-slide tissue histopathology images (WSIs). We performed a comparative study to elucidate the characteristics and behaviors of different deep learning-based feature representation approaches for the WSI-based diagnosis of diseased esophageal architectures, namely, dysplastic and non-dysplastic BE. The results showed that if appropriate settings are chosen, the unsupervised feature representation approach is capable of extracting more relevant image features from WSIs to classify and locate the precursors of esophageal cancer compared to weakly supervised and fully supervised approaches.	187.868636789045
1891.	BACKGROUND: Magnetic resonance imaging (MRI) images are crucial unstructured data for prognostic evaluation in nasopharyngeal carcinoma (NPC). We developed and validated a prognostic system based on the MRI features and clinical data of locoregionally advanced NPC (LA-NPC) patients to distinguish low-risk patients with LA-NPC, for whom concurrent chemoradiotherapy (CCRT) is sufficient. METHODS: This multicenter, retrospective study included 3444 patients with LA-NPC from January 1, 2010, to January 31, 2017. A three-dimensional convolutional neural network was used to learn the image features from pretreatment MRI images. An eXtreme Gradient Boosting model was trained with the MRI features and clinical data to assign an overall score to each patient. Comprehensive evaluations were implemented to assess the performance of the predictive system. We applied the overall score to distinguish high-risk patients from low-risk patients. The clinical benefit of induction chemotherapy (IC) was analyzed in each risk group by survival curves. RESULTS: We constructed a prognostic system displaying a concordance index of 0.776 (95% CI=0.746-0.806) for the internal validation cohort and 0.757 (95% CI=0.695-0.819), 0.719 (95% CI=0.650-0.789) and 0.746 (95% CI=0.699-0.793) for the three external validation cohorts, which presented a statistically significant improvement compared to the conventional tumor-node-metastasis (TNM) staging system. In the high-risk group, patients who received IC plus CCRT had better outcomes than patients who received CCRT alone, while there was no statistically significant difference in the low-risk group. CONCLUSIONS: The proposed framework can capture more complex and heterogeneous information to predict the prognosis of patients with LA-NPC and potentially contribute to clinical decision making.	187.8684122753753
1892.	Hemorrhagic stroke is a medical emergency. Artificial intelligence techniques and algorithms may be used to automatically detect and quantitate intracranial hemorrhage in a semiautomated fashion. This article reviews the use of deep learning convolutional neural networks for managing hemorrhagic stroke. Such a capability may be used to alert appropriate care teams, make decisions about patient transport from a primary care center to a comprehensive stroke center, and assist in treatment selection. This article reviews artificial intelligence algorithms for intracranial hemorrhage detection, quantification, and prognostication. Multiple algorithms currently being explored are described and illustrated with the help of examples.	187.86814458000742
1893.	Background: The current gold-standard formalin-fixed and paraffin-embedded (FFPE) histology typically requires several days for tissue fixing, embedding, sectioning, and staining to provide depth-resolved tissue feature visualization. During these timeand laborintense processes, the in vivo tissue dynamics and threedimensional structures undergo inevitable loss and distortion. Methods: A simultaneous label-free autofluorescence multiharmonic (SLAM) microscope is used to conduct ex vivo and in vivo imaging of fresh human and rat tissues. Four nonlinear optical imaging modalities are integrated into this SLAM microscope, including second harmonic generation (SHG), two-photon fluorescence (2PF), third harmonic generation (THG), and three-photon fluorescence (3PF). By imaging fresh human and rat tissues without any tissue processing or staining, various biological tissue features are effectively visualized by one or multiple imaging modalities of the SLAM microscope. In particular, some of the most essential features in hematoxylin and eosin (H&E)-stained histology, such as collagen fibers and nuclei, are also present in the SLAM microscopy images with good contrast. Because nuclei are evident from negative contrast, the nuclei are segmented from the SLAM images using deep learning. Finally, a color transforming algorithm is developed to convert the grey-scale images acquired by the SLAM microscope to the virtually H&E-stained histology-like images. The converted histology-like images are later compared with the FFPE histology at the same tissue site. In addition, the nuclear-to-cytoplasmic ratios (N/C ratios) of the cells in the SLAM image are quantified, which has diagnostic relevance for cancer. Results: Various histological correlations are identified with high similarities for the color-converted histology-like SLAM microscopy images. By applying the color transforming algorithm on real-time SLAM image sequences and 3D SLAM image stacks, we report, for the first time and to the best our knowledge, real-time 3D histology-like imaging. Furthermore, the quantified N/C ratio of the cells in the SLAM image are overlaid on the converted histology-like image as a new image contrast. Conclusions: We demonstrated real-time 3D histology-like imaging and its future potential using SLAM microscopy aided by color remapping and deep-learning-based feature segmentation.	187.86812622635705
1894.	OBJECTIVES: Moyamoya disease is a unique cerebrovascular disorder that is characterized by chronic bilateral stenosis of the internal carotid arteries and by the formation of an abnormal vascular network called moyamoya vessels. In this stury, the authors inspected whether differentiation between patients with moyamoya disease and those with atherosclerotic disease or normal controls might be possible by using deep machine learning technology. MATERIALS AND METHODS: This study included 84 consecutive patients diagnosed with moyamoya disease at our hospital between April 2009 and July 2016. In each patient, two axial continuous slices of T2-weighed imaging at the level of the basal cistern, basal ganglia, and centrum semiovale were acquired. The image sets were processed by using code written in the programming language Python 3.7. Deep learning with fine tuning developed using VGG16 comprised several layers. RESULTS: The accuracies of distinguishing between patients with moyamoya disease and those with atherosclerotic disease or controls in the basal cistern, basal ganglia, and centrum semiovale levels were 92.8, 84.8, and 87.8%, respectively. CONCLUSION: The authors showed excellent results in terms of accuracy of differential diagnosis of moyamoya disease using AI with the conventional T2 weighted images. The authors suggest the possibility of diagnosing moyamoya disease using AI technique and demonstrate the area of interest on which AI focuses while processing magnetic resonance images.	187.86811444301657
1895.	In the past few years, a convolutional neural network (CNN) based deep learning model has been broadly applied in image processing and computer vision. And different from other multiscale decomposition methods in infrared and visible image fusion field, a hybrid l(0)-l(1) layer decomposition model, which combines the superiority of l(0) sparsity term and l(1) sparsity term, is carried out to decompose the image into the base layer and the detail layer. Thus, a CNN model and visual saliency-based methods are utilized to fuse the detail layer and the base layer, respectively. Finally, the experiments show that this combination of CNN and saliency detection fusion rule has outperform some of the existing methods in infrared and visible image fusion both subjective and objective evaluations. (C) 2018 SPIE and IS&T	187.86806562447777
1896.	Background: Coronary computed tomography angiography (CTA) allows quantification of stenosis. However, such quantitative analysis is not part of clinical routine. We evaluated the feasibility of utilizing deep learning for quantifying coronary artery disease from CTA. Methods: A total of 716 diseased segments in 156 patients (66 +/- 10 years) who underwent CTA were analyzed. Minimal lumina! area (MLA), percent diameter stenosis (DS), and percent contrast density difference (CDD) were measured using semi-automated software (Autoplaque) by an expert reader. Using the expert annotations, deep learning was performed with convolutional neural networks using 10-fold cross-validation to segment CTA lumen and calcified plaque. MLA, DS and CDD computed using deep-learning-based approach was compared to expert reader measurements. Results: There was excellent correlation between the expert reader and deep learning for all quantitative measures (r=0.984 for MLA; r=0.957 for DS; and r=0.975 for CDD, p<0.001 for all). The expert reader and deep learning method was not significantly different for MLA (median 4.3 mm(2) for both, p=0.68) and CDD (11.6 vs 11.1%, p=0.30), and was significantly different for DS (26.0 vs 26.6%, p<0.05); however, the ranges of all the quantitative measures were within inter-observer variability between 2 expert readers. Conclusions: Our deep learning-based method allows quantitative measurement of coronary artery disease segments accurately from CTA and may enhance clinical reporting.	187.86786068773148
1897.	PURPOSE: To develop an objective and automated method for measuring intraocular pressure using deep learning and fixed-force Goldmann applanation tonometry (GAT) techniques. DESIGN: Prospective cross-sectional study. PARTICIPANTS: Patients from an academic glaucoma practice. METHODS: Intraocular pressure was estimated by analyzing videos recorded using a standard slit-lamp microscope and fixed-force GAT. Video frames were labeled to identify the outline of the reference tonometer and the applanation mires. A deep learning model was trained to localize and segment the tonometer and mires. Intraocular pressure values were calculated from the deep learning-predicted tonometer and mire diameters using the Imbert-Fick formula. A separate test set was collected prospectively in which standard and automated GAT measurements were collected in random order by 2 independent masked observers to assess the deep learning model as well as interobserver variability. MAIN OUTCOME MEASURES: Intraocular pressure measurements between standard and automated methods were compared. RESULTS: Two hundred sixty-three eyes of 135 patients were included in the training and validation videos. For the test set, 50 eyes from 25 participants were included. Each eye was measured by 2 observers, resulting in 100 videos. Within the test set, the mean difference between automated and standard GAT results was -0.9 mmHg (95% limits of agreement [LoA], -5.4 to 3.6 mmHg). Mean difference between the 2 observers using standard GAT was 0.09 mmHg (LoA,-3.8 to 4.0 mmHg). Mean difference between the 2 observers using automated GAT videos was -0.3 mmHg (LoA, -4.1 to 3.5 mmHg). The coefficients of repeatability for automated and standard GAT were 3.8 and 3.9 mmHg, respectively. The bias for even-numbered measurements was reduced when using automated GAT. CONCLUSIONS: Preliminary measurements using deep learning to automate GAT demonstrate results comparable with those of standard GAT. Automated GAT has the potential to improve on our current GAT measurement standards significantly by reducing bias and improving repeatability. In addition, ocular pulse amplitudes could be observed using this technique.	187.86768877173637
1898.	BACKGROUND: Deep brain stimulation (DBS) is an important treatment modality for movement disorders. Its role in tasks and processes of higher cortical function continues to increase in importance and relevance. This review investigates the impact of DBS on measures of impulsivity. METHODS: A total of 45 studies were collated from PubMed (30 prospective, 8 animal, 4 questionnairebased, and 3 computational models), excluding case reports and review articles. Two areas extensively studied are the subthalamic nucleus (STN) and nucleus accumbens (NAc). RESULTS: While both are part of the basal ganglia, the STN and NAc have extensive connections to the prefrontal cortex, cingulate cortex, and limbic system. Therefore understanding cause and treatment of impulsivity requires understanding motor pathways, learning, memory, and emotional processing. DBS of the STN and NAc shell can increase objective measures of impulsivity, as measured by reaction times or reward-based learning, independent from patient insight. The ability for DBS to treat impulse control disorders, and also cause and/or worsen impulsivity in Parkinson's disease, may be explained by the affected closely-related neuroanatomical areas with discrete and sometimes opposing functions. CONCLUSIONS: As newer, more refined DBS technology emerges, large-scale prospective studies specifically aimed at treatment of impulsivity disorders are needed.	187.8675680459634
1899.	Background:Diagnosis of skin diseases is often challenging and computer-aided diagnostic tools are urgently needed to underpin decision making. Objective:To develop a convolutional neural network model to classify clinically relevant selected multiple-lesion skin diseases, this in accordance to the STARD guidelines. Methods:This was an image-based retrospective study using multi-task learning for binary classification. A VGG-16 model was trained on 16,543 non-standardized images. Image data was distributed in training set (80%), validation set (10%), and test set (10%). All images were collected from a clinical database of a Danish population attending one dermatological department. Included was patients categorized with ICD-10 codes related to acne, rosacea, psoriasis, eczema, and cutaneous t-cell lymphoma. Results:Acne was distinguished from rosacea with a sensitivity of 85.42% CI 72.24-93.93% and a specificity of 89.53% CI 83.97-93.68%, cutaneous t-cell lymphoma was distinguished from eczema with a sensitivity of 74.29% CI 67.82-80.05% and a specificity of 84.09% CI 80.83-86.99%, and psoriasis from eczema with a sensitivity of 81.79% CI 78.51-84.76% and a specificity of 73.57% CI 69.76-77.13%. All results were based on the test set. Conclusion:The performance rates reported were equal or superior to those reported for general practitioners with dermatological training, indicating that computer-aided diagnostic models based on convolutional neural network may potentially be employed for diagnosing multiple-lesion skin diseases.	187.86665653544952
1900.	The article presents a proposal of using engineering data acquisition techniques and deep learning methods for an objective analysis of images created during the history-taking in patients with neurodegenerative disorders.	187.86663165884465
1901.	Acceleration of training and inference of convolutional neural networks (CNNs) plays a significant role in deep learning efforts for large-scale datasets. However, it is difficult to accelerate the training and inference of CNNs based on traditional Fourier domain acceleration frameworks because Fourier domain training and inference are related to many complicated factors, such as the architecture of Fourier domain propagation passes, the representation of the activation function and the design of downsampling operations. A conceptually intuitive, useful and general Fourier domain acceleration framework for CNNs is proposed in this paper. Taking the proposed Fourier domain rectified linear unit (FReLU) as an activation function and the proposed Fourier domain pooling function (FPool) as a downsampling function, a Fourier domain acceleration framework is established for CNNs, and the inverse activation function (FReLU-1) and inverse downsampling function (FPool(-1)) are further obtained for the backward propagation pass. Furthermore, a block decomposition pipeline is integrated into the Fourier domain forward/backward propagation passes of CNNs to accelerate the training and inference of CNNs. The results show that the proposed acceleration framework can accelerate the training and inference of CNNs by a significant factor without reducing the recognition precision. (C) 2019 Elsevier B.V. All rights reserved.	187.86638264925762
1902.	Screening and assessing diabetic retinopathy (DR) are essential for reducing morbidity associated with diabetes. Macular ischemia is known to correlate with the severity of retinopathy. Recent studies have shown that optical coherence tomography angiography (OCTA), with intrinsic contrast from blood flow motion, is well suited for quantified analysis of the avascular area, which is potentially a useful biomarker in DR. In this study, we propose the first deep learning solution to segment the avascular area in OCTA of DR. The network design consists of a multi-scaled encoder-decoder neural network (MEDnet) to detect the non-perfusion area in 6 x 6 mm(2) and in ultra-wide field retinal angiograms. Avascular areas were effectively detected in DR subjects of various disease stages as well as in the foveal avascular zone of healthy subjects. (C) 2018 Optical Society of America under the terms of the OSA Open Access Publishing Agreement	187.86625609581392
1903.	Mobile edge caching is a promising technique to reduce network traffic and improve the quality of experience of mobile users. However, mobile edge caching is a challenging decision making problem with unknown future content popularity and complex network characteristics. In this article, we advocate the use of DRL to solve mobile edge caching problems by presenting an overview of recent works on mobile edge caching and DRL. We first examine the key issues in mobile edge caching and review the existing learning-based solutions proposed in the literature. We also discuss the unique features in the application of DRL in mobile edge caching, and illustrate an example of DRL-based mobile edge caching with trace-data-driven simulation results. This article concludes with a discussion of several open issues that call for substantial future research efforts.	187.8660716990058
1904.	Supervised deep learning methods have the ability to extract useful features from raw data when a sufficient volume of labeled data is available for training. However, in emerging application areas such as mobile health, the high cost of data collection often precludes collecting large-scale labeled data sets. As a result, machine learning pipelines based on hand-engineered features remain common. In this paper, we investigate architectures for combining hand-engineered features with deep learning-based feature extraction from raw data to enhance prediction performance on small labeled data sets. We use smoking puff detection from wearable sensor data as an example application domain.	187.86601838133063
1905.	Objectives Deep learning reconstruction (DLR) is a new reconstruction method; it introduces deep convolutional neural networks into the reconstruction flow. This study was conducted in order to examine the clinical applicability of abdominal ultra-high-resolution CT (U-HRCT) exams reconstructed with a new DLR in comparison to hybrid and model-based iterative reconstruction (hybrid-IR, MBIR). Methods Our retrospective study included 46 patients seen between December 2017 and April 2018. A radiologist recorded the standard deviation of attenuation in the paraspinal muscle as the image noise and calculated the contrast-to-noise ratio (CNR) for the aorta, portal vein, and liver. The overall image quality was assessed by two other radiologists and graded on a 5-point confidence scale ranging from 1 (unacceptable) to 5 (excellent). The difference between CT images subjected to hybrid-IR, MBIR, and DLR was compared. Results The image noise was significantly lower and the CNR was significantly higher on DLR than hybrid-IR and MBIR images (p < 0.01). DLR images received the highest and MBIR images the lowest scores for overall image quality. Conclusions DLR improved the quality of abdominal U-HRCT images.	187.86582063405828
1906.	Brain imaging analysis on clinically acquired computed tomography (CT) is essential for the diagnosis, risk prediction of progression, and treatment of the structural phenotypes of traumatic brain injury (TBI). However, in real clinical imaging scenarios, entire body CT images (e.g., neck, abdomen, chest, pelvis) are typically captured along with whole brain CT scans. For instance, in a typical sample of clinical 1131 imaging cohort, only similar to 15% of CT scans actually contain whole brain CT images suitable for volumetric brain analyses; the remaining are partial brain or non-brain images. Therefore, a manual image retrieval process is typically required to isolate the whole brain CT scans from the entire cohort. However, the manual image retrieval is time and resource consuming and even more difficult for the larger cohorts. To alleviate the manual efforts, in this paper we propose an automated 3D medical image retrieval pipeline, called deep montage-based image retrieval (dMIR), which performs classification on 2D montage images via a deep convolutional neural network. The novelty of the proposed method for image processing is to characterize the medical image retrieval task based on the montage images. In a cohort of 2000 clinically acquired TBI scans, 794 scans were used as training data, 206 scans were used as validation data, and the remaining 1000 scans were used as testing data. The proposed achieved accuracy=1.0, recall=1.0, precision=1.0, f1=1.0 for validation data, while achieved accuracy=0.988, recall=0.962, precision=0.962, f1=0.962 for testing data. Thus, the proposed dMIR is able to perform accurate CT whole brain image retrieval from large-scale clinical cohorts.	187.8657015925187
1907.	Retinal fundus photographs have been used in the diagnosis of many ocular diseases such as glaucoma, pathological myopia, age-related macular degeneration, and diabetic retinopathy. With the development of computer science, computer aided diagnosis has been developed to process and analyze the retinal images automatically. One of the challenges in the analysis is that the quality of the retinal image is often degraded. For example, a cataract in human lens will attenuate the retinal image, just as a cloudy camera lens which reduces the quality of a photograph. It often obscures the details in the retinal images and posts challenges in retinal image processing and analyzing tasks. In this paper, we approximate the degradation of the retinal images as a combination of human-lens attenuation and scattering. A novel structure-preserving guided retinal image filtering (SGRIF) is then proposed to restore images based on the attenuation and scattering model. The proposed SGRIF consists of a step of global structure transferring and a step of global edge-preserving smoothing. Our results show that the proposed SGRIF method is able to improve the contrast of retinal images, measured by histogram flatness measure, histogram spread, and variability of local luminosity. In addition, we further explored the benefits of SGRIF for subsequent retinal image processing and analyzing tasks. In the two applications of deep learning-based optic cup segmentation and sparse learning-based cup-to-disk ratio (CDR) computation, our results show that we are able to achieve more accurate optic cup segmentation and CDR measurements from images processed by SGRIF.	187.8656047685226
1908.	Atmospheric ducts are typical occurrences in marine environments. They can trap electromagnetic waves in ducts layer and extend propagation ranges significantly. Thus, affecting systems such as radar communications. Because the direct measurement of the atmospheric ducts refractivity has a certain degree of difficulty, the radar sea clutter power, which is easily measured, is used to solve the inversion problem of atmospheric refractivity estimation. In this study, based on the refractivity profile of the evaporation duct and the surface based duct, combined with the deep learning, we established a network mapping model between the sea clutter and the refractivity profile parameters. The model is applied to the inversion problem of atmospheric refractivity estimation, and the inversion results are analyzed to verify the feasibility of deep learning in the inversion problem. We herein report the high-precision inversion results of the atmospheric refractivity estimation.	187.86504660091936
1909.	The computer-aided diagnosis of prostate ultrasound images can aid in the detection and treatment of prostate cancer. However, the ultrasound images of the prostate sometimes come with serious speckle noise, low signal-to-noise ratio, and poor detection accuracy. To overcome this shortcoming, we proposed a deep learning model that integrates S-Mask R-CNN and Inception-v3 in the ultrasound image-aided diagnosis of prostate cancer in this paper. The improved S-Mask R-CNN was used to realize the accurate segmentation of prostate ultrasound images and generate candidate regions. The region of interest align algorithm was used to realize the pixel-level feature point positioning. The corresponding binary mask of prostate images was generated by the convolution network to segment the prostate region and the background. Then, the background information was shielded, and a data set of segmented ultrasound images of the prostate was constructed for the Inception-v3 network for lesion detection. A new network model was added to replace the original classification module, which is composed of forward and back propagation. Forward propagation mainly transfers the characteristics extracted from the convolution layer pooling layer below the pool_3 layer through the transfer learning strategy to the input layer and then calculates the loss value between the classified and label values to identify the ultrasound lesion of the prostate. The experimental results showed that the proposed method can accurately detect the ultrasound image of the prostate and segment prostate information at the pixel-level simultaneously. The proposed method has higher accuracy than that of the doctor's manual diagnosis and other detection methods. Our simple and effective approach will serve as a solid baseline and help ease future research in the computer-aided diagnosis of prostate ultrasound images. Furthermore, this work will promote the development of prostate cancer ultrasound diagnostic technology. (C) 2020 Elsevier B.V. All rights reserved.	187.86484614064744
1910.	Background & Aims: Personalised risk prediction of the development of hepatocellular carcinoma (HCC) among patients with liver cirrhosis on potent antiviral therapy is important for targeted screening and individualised intervention. This study aimed to develop and validate a new model for risk prediction of HCC development based on deep learning, and to compare it with previously reported risk models. Methods: A novel deep-learning-based model was developed from a cohort of 424 patients with HBV-related cirrhosis on entecavir therapy with 2 residual blocks, including 7 layers of a neural network, and it was validated using an independent external cohort (n= 316). The deep-learning-based model was compared to 6 previously reported models (platelet, age, and gender-hepatitis B score [PAGE-B], Chinese University HCC score [CU-HCC], HCC-Risk Estimating Score in CHB patients Under Entecavir [HCC-RESCUE], age, diabetes, race, etiology of cirrhosis, sex, and severity HCC score [ADRESS-HCC], modified PAGE-B score [mPAGE], and Toronto HCC risk index [THRI]) using Harrell's concordance (c)-index. Results: During a median 5.2 yr of follow-up (inter-quartile range 2.8-6.9 yr), 86 patients (20.3%) developed HCC. The deep-learning-based model had a Harrell's c-index of 0.719 in the derivation cohort and 0.782 in the validation cohort. Goodness of fit was confirmed by the Hosmer-Lemeshow test (p >0.05). Moreover, this model in the validation cohort had the highest c-index among the 6 previously reported models: PAGE-B (0.570), CU-HCC (0.548), HCC-RESCUE (0.577), ADRESS-HCC (0.551), mPAGE (0.598), and THRI (0.587) (all p <0.001). The misclassification rate of this model was 23.7% (model accuracy: 76.3%) in the validation group. Conclusions: The deep-learning-based model had better performance than the previous models for predicting the HCC risk in patients with HBV-related cirrhosis on potent antivirals. Lay summary: For early detection of hepatocellular carcinoma, it is important to maintain regular surveillance. However, there is currently no standard prediction model for risk stratification that can be used to establish a personalised surveillance strategy. We develop and validate a deep-learning-based model that showed better performance than previous models.	187.86473886402976
1911.	In this paper, the mining method of shallow-hole and deep-hole shrinkage with ductule grouting in advance for roof reinforcement is studied, which is used to recover steeply inclined thick orebody with broken roof. The main innovations in mining technology are as follows: the orebody is artificially divided into two layers, the upper layer is mined by shallow hole blasting, the lower layer is mined by parallel deep holes, both layers advance simultaneously from bottom to top, the mining face of the upper layer is 3.6 meters higher than that of the lower layer, thus forming an inverted step working face in which the mining operation and roof protection are carried out, using ductule to reinforce the broken roof by grouting in advance, and arranging bolts systematically to anchor the grouting reinforced layer into deep rock mass. By using the method of orthogonal test design and in-situ experiment, the reasonable construction parameters of ductule grouting are obtained, which have been applied to No. 7 stope of of stage 3840 in Qaza Lead-Zinc Mine in Yunnan Province and achieved good results. By monitoring the displacement of reinforced layer during and after mining, no obvious displacement and collapse are found, which proves the feasibility of this technology. The mining scheme has a good reference value for similar ore deposits with mining technical conditions.	187.86470996121724
1912.	The incorporation of diffusion-weighted imaging (DWI) in breast magnetic resonance imaging (MRI) has shown potential in improving the accuracy of breast cancer diagnosis. Since DWI measures possibly complementary biological properties to dynamic contrast-enhanced (DCE) MRI parameters, DWI computer-aided diagnosis (CADx) can potentially improve the performance of current CADx systems in distinguishing between benign and malignant breast lesions. This study was performed on a database of 397 diffusion-weighted breast MR images (69 benign and 328 malignant). Lesions were automatically segmented using a fuzzy C-means method. The apparent diffusion coefficient (ADC)-based radiomic features were extracted and used to train a classifier. Another classifier was trained on convolutional neural network (CNN)-based features extracted by a pre-trained VGG19 network. The outputs from these two classifiers were fused by averaging the posterior probability of malignancy for each case to construct a fusion classifier. The performance evaluation for the three proposed classifiers was performed with five-fold cross-validation. The area under the receiver operating characteristic curve (AUC) was 0.68 (se = 0.04) for the ADC-based classifier, 0.74 (se = 0.03) for the CNN-based classifier, and 0.76 (se = 0.03) for the fusion classifier. The fusion classifier performed significantly better than the ADC-based classifier (p = 0.013). The CNN-based classifier failed to show statistically significant performance difference from the ADC-based classifier or the fusion classifier. The findings demonstrate promising performance of the proposed classifiers and the potential for DWI CADx as well as for the development of multiparametric CADx that incorporates information from both DWI and DCE-MRI in breast lesion classification.	187.86451997234178
1913.	The volumetric assessment and accurate grading of meningiomas before surgery are highly relevant for therapy planning and prognosis prediction. This study was to design a deep learning algorithm and evaluate the performance in detecting meningioma lesions and grade classification. In total, 5088 patients with histopathologically confirmed meningioma were retrospectively included. The pyramid scene parsing network (PSPNet) was trained to automatically detect and delineate the meningiomas. The results were compared to manual segmentations by evaluating the mean intersection over union (mIoU). The performance of grade classification was evaluated by accuracy. For the automated detection and segmentation of meningiomas, the mean pixel accuracy, tumor accuracy, background accuracy and mIoU were 99.68%, 81.36%, 99.88% and 81.36% for all patients; 99.52%, 84.86%, 99.93% and 84.86% for grade I meningiomas; 99.57%, 80.11%, 99.92% and 80.12% for grade II meningiomas; and 99.75%, 78.40%, 99.99% and 78.40% for grade III meningiomas, respectively. For grade classification, the accuracy values of the training and test datasets were 99.93% and 81.52% for all patients; 99.98% and 98.51% for grade I meningiomas; 99.91% and 66.67% for grade II meningiomas; and 99.88% and 73.91% for grade III meningiomas, respectively. The automated detection, segmentation and grade classification of meningiomas based on deep learning were accurate and reliable and may improve the monitoring and treatment of this frequently occurring tumor entity. Furthermore, the method could function as a useful tool for preassessment and preselection for radiologists, offering auxiliary information for clinical decision making in presurgical evaluation.	187.86350445289432
1914.	Background Clinical Decision Support Systems (CDSSs) have recently attracted attention as a method for minimizing medical errors. Existing CDSSs are limited in that they do not reflect actual data. To overcome this limitation, we propose a CDSS based on deep learning. Methods We propose the Colorectal Cancer Chemotherapy Recommender (C3R), which is a deep learning-based chemotherapy recommendation model. Our model improves on existing CDSSs in which data-based decision making is not well supported. C3R is configured to study the clinical data collected at the Gachon Gil Medical Center and to recommend appropriate chemotherapy based on the data. To validate the model, we compared the treatment concordance rate with the National Comprehensive Cancer Network (NCCN) Guidelines, a representative set of cancer treatment guidelines, and with the results of the Gachon Gil Medical Center's Colorectal Cancer Treatment Protocol (GCCTP). Results For the C3R model, the treatment concordance rates with the NCCN guidelines were 70.5% for Top-1 Accuracy and 84% for Top-2 Accuracy. The treatment concordance rates with the GCCTP were 57.9% for Top-1 Accuracy and 77.8% for Top-2 Accuracy. Conclusions This model is significant, i.e., it is the first colon cancer treatment clinical decision support system in Korea that reflects actual data. In the future, if sufficient data can be secured through cooperation among multiple organizations, more reliable results can be obtained.	187.86343099288246
1915.	Introduction Permanent His bundle pacing is feasible and effective in patients with atrioventricular block or left bundle branch block. However, pacing thresholds to capture the distal His bundle is often higher. Recently left bundle branch area pacing (LBBP) has been shown to be feasible by advancing the lead transvenously, deep into the interventricular septum to reach the left ventricular endocardial surface. In this article we describe the utility of three dimensional (3D) mapping to achieve LBBP. Methods Ensite Precision (Abbott) mapping system was used to perform LBBP. A decapolar catheter was used to create 3D map of right atrium and right ventricle (RV). Regions of interest (His bundle, potential LBBP sites of interest in RV) were tagged in the 3D map. The LBBP lead was implanted utilizing the 3D map. The lead depth in the septum was assessed in the 3D map. Results LBBP was performed in three patients: chronic LBBB and intermittent 2:1 atrioventricular block; atrioventricular (AV) node ablation and conduction system pacing; and bifascicular block and intermittent AV block in a patient with severe left ventricular hypertrophy. LBBP was successful in all three patients. The lead depth in the interventricular septum was 12, 11, and 21 mm, respectively as assessed by 3D mapping. Conclusions Three-dimensional mapping was helpful in achieving LBBP in patients with LBBB, severe left ventricular hypertrophy or during AV node ablation. 3D mapping also facilitated easy assessment of lead depth during and after lead fixation. 3D mapping techniques may be a valuable tool to reduce the learning curve of implanters with minimal experience in LBBP.	187.86291511483324
1916.	Neurons in parasubiculum (PaS), presubiculum (PrS), and medial entorhinal cortex (MEC) code for place (grid cells) and head direction. Directional input has been shown to be important for stable grid cell properties in MEC, and PaS and PrS have been postulated to provide this information to MEC. In line with this, head direction cells in those brain areas are present at postnatal day 11 (P11), having directional tuning that stabilizes shortly after eye opening, which is before premature grid cells emerge in MEC at P16. Whether functional connectivity between these structures exists at those early postnatal stages is unclear. Using anatomical tracing, voltage-sensitive dye imaging and single-cell patch recordings in female and male rat brain slices between P2 and P61, we determined when the pathways from PaS and PrS to MEC emerge, become functional, and how they develop. Anatomical connections from PaS and PrS to superficial MEC emerge between P4 and P6. Monosynaptic connectivity from PaS and PrS to superficial MEC was measurable from P9 to PIO onward, whereas connectivity with deep MEC was measurable from P11 to P12. From P14/P15 on, reactivity of MEC neurons to parasubicular and presubicular inputs becomes adult-like and continues to develop until P28-P30. The maturation of the efficacy of both inputs between P9 and P21 is paralleled by maturation of morphological properties, changes in intrinsic properties of MEC principal neurons, and changes in the GABAergic network of MEC. In conclusion, synaptic projections from PaS and PrS to MEC become functional and adult-like before the emergence of grid cells in MEC.	187.86218432711448
1917.	Complex and changing driving environments not only affect the operating requirements of automatic wheel loader but also threaten its driving safety. Therefore, the automatic wheel loader must adopt appropriate braking strategies to realize accurate control of the brake pedal aperture under certain operating conditions. For the V-shaped operation mode of wheel loader, the operator's operation specification is evaluated using three characteristics: operation time, driving distance and friction work. By combining the driving data of experienced drivers in different driving environments with deep learning, a deep long short-term memory network was constructed to predict the brake pedal aperture for different braking types. The proposed anthropomorphic control method that combines driving data and deep learning can be used to predict the aperture value of the wheel loader brake pedal in complex driving environments. This would enable the braking process to conform to the braking decisions of experienced drivers and thereby meet the operational requirements while ensuring driving safety.	187.86162504637826
1918.	This paper introduces a novel content-based video copy detection method using the deep CNN features. An efficient deep CNN feature is employed to encode the image content while retaining the discrimination capability. Taking advantage of the extremely fast Euclidean distance similarity of deep CNN features, a keyframe-based copy retrieval method that exhaustively searches the copy candidates from the large keyframe database without indexing is proposed. Moreover, a graph-based sequence matching algorithm is employed to obtain the copy clips and accurately locate the video segments. The experimental evaluation has been performed to show the efficacy of the proposed deep CNN features. The promising results demonstrate the effectiveness of our proposed approach.	187.86157697523078
1919.	Adipocyte size, i.e., the cell area of adipose tissue, is correlated directly with metabolic disease risk in obese humans. This study proposes an approach of processing the photoacoustic (PA) signal power spectrum using a deep learning method to evaluate adipocyte size in human adipose tissue. This approach has the potential to provide noninvasive assessment of adipose tissue dysfunction, replacing traditional invasive methods of evaluating adipose tissue via biopsy and histopathology. A deep neural network with fully connected layers was used to fit the relationship between PA spectrum and average adipocyte size. Experiments on human adipose tissue specimens were performed, and the optimal parameters of the deep learning method were applied to establish the relationship between the PA spectrum and average adipocyte size. By studying different spectral bands in the entire spectral range using the deep network, a spectral band mostly sensitive to the adipocyte size was identified. A method of combining all frequency components of PA spectrum was tested to achieve a more accurate evaluation.	187.86142330257155
1920.	Acute ischemic stroke constitutes approximately 85% of strokes. Most strokes occur in community settings; thus, automatic algorithms techniques are attractive for managing these cases. This article reviews the use of deep learning convolutional neural networks in the management of ischemic stroke. Artificial intelligence-based algorithms may be used in patient triage to detect and sound the alarm based on early imaging, alert care teams, and assist in treatment selection. This article reviews algorithms for artificial intelligence techniques that may be used to detect and localize acute ischemic stroke. We describe artificial intelligence algorithms for these tasks and illustrate them with examples.	187.86136399436486
1921.	In this paper, a deep learning-based detection scheme is proposed for the visible light communication (VLC) systems using generalized spatial modulation (GenSM). In the proposed detection scheme, a deep neural network consisting of several neural layers is applied to detect the received signals. By integrating the signal processing modules of the conventional detection schemes into one deep neural network, the proposed scheme is able to extract the information bits from the received signals efficiently. After offline training, the proposed detection scheme can serve as a promising detection method for the VLC system with GenSM. Simulation results validate that the proposed detection scheme is capable of achieving superior detection error performance than conventional detection schemes at acceptable complexity.	187.86123958652385
1922.	Interactions between RNAs and proteins play essential roles in many important biological processes. Benefitting from the advances of next generation sequencing technologies, hundreds of RNA-binding proteins (RBP) and their associated RNAs have been revealed, which enables the large-scale prediction of RNA-protein interactions using machine learning methods. Till now, a wide range of computational tools and pipelines have been developed, including deep learning models, which have achieved remarkable performance on the identification of RNA-protein binding affinities and sites. In this review, we provide an overview of the successful implementation of various deep learning approaches for predicting RNA-protein interactions, mainly focusing on the prediction of RNA-protein interaction pairs and RBP-binding sites on RNAs. Furthermore, we discuss the advantages and disadvantages of these approaches, and highlight future perspectives on how to design better deep learning models. Finally, we suggest some promising future directions of computational tasks in the study of RNA-protein interactions, especially the interactions between noncoding RNAs and proteins. This article is categorized under: RNA Interactions with Proteins and Other Molecules > Protein-RNA Interactions: Functional Implications RNA Evolution and Genomics > Computational Analyses of RNA RNA Interactions with Proteins and Other Molecules > Protein-RNA Recognition	187.8611451802138
1923.	The isotope effects in x-ray absorption spectra of liquid water are studied by a many-body approach within electron-hole excitation theory. The molecular structures of both light and heavy water are modeled by path-integral molecular dynamics based on the advanced deep-learning technique. The neural network is trained on ab initio data obtained with SCAN density functional theory. The experimentally observed isotope effect in x-ray absorption spectra is reproduced semiquantitatively in theory. Compared to the spectrum in normal water, the blueshifted and less pronounced pre- and main-edge in heavy water reflect that the heavy water is more structured at short- and intermediate-range of the hydrogen-bond network. In contrast, the isotope effect on the spectrum is negligible at post-edge, which is consistent with the identical long-range ordering in both liquids as observed in the diffraction experiment.	187.86100921671198
1924.	Atrophic age-related macular degeneration (AMD) or geographic atrophy (GA), and atrophic juvenile macular degeneration (JMD) or Stargardt atrophy, have been proven to be the leading cause of blindness respectively in older adults, and in children and young adults. Automated techniques of timely screening and detection of such atrophic diseases would appear to be of critical importance in prevention and early treatment of vision loss. We first developed a deep learning-based automated screening system using the residual networks (ResNet), which can differentiate the eyes with atrophic AMD and JMD from normal eyes on fundus autofluorescene (FAF) images. We further developed another deep learning-based automated system to segment the atrophic AMD and JMD lesions using a fully convolutional neural network - U-Net. Transfer learning based on a pre-trained model was applied for ResNet to facilitate the algorithm training, and excessive data augmentation techniques for both ResNet and U-Net were applied to enhance the algorithm generalization ability. In total, 320 FAF images from normal subjects, 320 with atrophic AMD, and 100 with atrophic JMD were included. The performance of the algorithms were evaluated by comparing with manual gradings by reading center graders. For the screening system, there was no reported algorithm and our algorithm demonstrated a high screening accuracy with 0.98 for atrophic AMD and 0.95 for atrophic JMD. For the segmentation system, our algorithm presented a high overlapping ratio with 0.89 +/- 0.06 for atrophic AMD and 0.78 +/- 0.17 for atrophic JMD.	187.86035031783285
1925.	Intrinsic and acquired drug resistance is a major challenge in cancer therapy. Synergistic drug combinations could help to overcome drug resistance. However, the number of possible drug combinations is enormous, and it is infeasible to experimentally screen all drug combinations with limited resources. Therefore, computational models to predict and prioritize effective drug combinations are important for combination therapy discovery. Compared with existing models, we propose a novel deep learning model, AuDNNsynergy, to predict the synergy of pairwise drug combinations by integrating multiomics data. Specifically, three autoencoders are trained using the gene expression, copy number, and genetic mutation data of tumor samples from The Cancer Genome Atlas (TCGA). Then the gene expression, copy number, and mutation of individual cancer cell lines are coded using the three trained autoencoders. The physicochemical features of individual drugs and the encoded omics data of individual cancer cell lines are used as the input features of a deep neural network that predicts the synergy score of given pairwise drug combinations against the specific cancer cell lines. The comparison results showed the proposed AuDNNsynergy model outperforms, specifically in terms of rank correlation metric, four state-of-the-art approaches, namely, DeepSynergy, Gradient Boosting Machines, Random Forests, and Elastic Nets.	187.86014782459358
1926.	A computer-aided detection (CAD) tool for locating and detecting polyps can help reduce the chance of missing polyps during colonoscopy. Nevertheless, state-of-the-art algorithms were either computationally complex or suffered from low sensitivity and therefore unsuitable to be used in real clinical setting. In this paper, a novel regression-based Convolutional Neural Network (CNN) pipeline is presented for polyp detection during colonoscopy. The proposed pipeline was constructed in two parts: 1) to learn the spatial features of colorectal polyps, a fast object detection algorithm named ResYOLO was pre-trained with a large non-medical image database and further fine-tuned with colonoscopic images extracted from videos; and 2) temporal information was incorporated via a tracker named Efficient Convolution Operators (ECO) for refining the detection results given by ResYOLO. Evaluated on 17,574 frames extracted from 18 endoscopic videos of the AsuMayoDB, the proposed method was able to detect frames with polyps with a precision of 88.6%, recall of 71.6% and processing speed of 6.5 frames per second, i.e. the method can accurately locate polyps in more frames and at a faster speed compared to existing methods. In conclusion, the proposed method has great potential to be used to assist endoscopists in tracking polyps during colonoscopy. (C) 2018 Elsevier Ltd. All rights reserved.	187.86014736798708
1927.	With the recent developments in deep learning technologies, artificial intelligence (Al) has gradually been transformed from cutting-edge technology into practical applications. Al plays an important role in disease diagnosis and treatment, health management, drug research and development, and precision medicine. Interdisciplinary collaborations will be crucial to develop new Al algorithms for medical applications. In this paper, we review the basic workflow for building an Al model, identify publicly available databases of ocular fundus images, and summarize over 60 papers contributing to the field of Al development.	187.8596445837921
1928.	Background Non-small-cell lung cancer (NSCLC) patients often demonstrate varying clinical courses and outcomes, even within the same tumor stage. This study explores deep learning applications in medical imaging allowing for the automated quantification of radiographic characteristics and potentially improving patient stratification. Methods and findings We performed an integrative analysis on 7 independent datasets across 5 institutions totaling 1,194 NSCLC patients (age median = 68.3 years [range 32.5-93.3], survival median = 1.7 years [range 0.0-11.7]). Using external validation in computed tomography (CT) data, we identified prognostic signatures using a 3D convolutional neural network (CNN) for patients treated with radiotherapy (n = 771, age median = 68.0 years [range 32.5-93.3], survival median = 1.3 years [range 0.0-11.7]). We then employed a transfer learning approach to achieve the same for surgery patients (n = 391, age median = 69.1 years [range 37.2-88.0], survival median = 3.1 years [range 0.0-8.8]). We found that the CNN predictions were significantly associated with 2-year overall survival from the start of respective treatment for radiotherapy (area under the receiver operating characteristic curve [AUC] = 0.70 [95% CI 0.63-0.78], p < 0.001) and surgery (AUC = 0.71 [95% CI 0.60-0.82], p < 0.001) patients. The CNN was also able to significantly stratify patients into low and high mortality risk groups in both the radiotherapy (p < 0.001) and surgery (p = 0.03) datasets. Additionally, the CNN was found to significantly outperform random forest models built on clinical parameters-including age, sex, and tumor node metastasis stage-as well as demonstrate high robustness against test-retest (intraclass correlation coefficient = 0.91) and inter-reader (Spearman's rank-order correlation = 0.88) variations. To gain a better understanding of the characteristics captured by the CNN, we identified regions with the most contribution towards predictions and highlighted the importance of tumor-surrounding tissue in patient stratification. We also present preliminary findings on the biological basis of the captured phenotypes as being linked to cell cycle and transcriptional processes. Limitations include the retrospective nature of this study as well as the opaque black box nature of deep learning networks. Conclusions Our results provide evidence that deep learning networks may be used for mortality risk stratification based on standard-of-care CT images from NSCLC patients. This evidence motivates future research into better deciphering the clinical and biological basis of deep learning networks as well as validation in prospective data.	187.85959803575392
1929.	In recent decades, automatic retinal blood vessel segmentation and classification (RBVSC) helps to determine many diseases such as glaucoma, hypertension, macular-degeneration, diabetes-mellitus, etc. The early recognition of these disorders is essential for preventing patients from blindness. In this work, a new supervised system was developed to enhance the performance of RBVSC. At first, the input retinal images were collected from two datasets such as: Digital Retinal Image for Vessel Extraction (DRIVE) and STARE (STructured Analysis of the Retina). Then, the retinal vessels were segmented utilizing mean orientation based super-pixel segmentation. Besides, Convolutional Neural Network (CNN) was applied to extract the feature vectors from segmented regions. Finally, a binary classifier [Support Vector Machine (SVM)] performs classification on the extracted features for classifying the "vessel" and "non-vessel" regions. The combination of CNN and SVM automatically learns the feature values from raw images and classifies the patterns easily. From the experimental study, the proposed system improved RBVSC up to 2-4% compared to other existing systems and classification methodologies: Deep Neural Network (DNN), Random Forest (RF) and Naive Bayes (NB) by means of specificity, accuracy, sensitivity and kappa index.	187.85950115173387
1930.	Background Access to quantitative information is crucial to obtain a deeper understanding of biological systems. In addition to being low-throughput, traditional image-based analysis is mostly limited to error-prone qualitative or semi-quantitative assessment of phenotypes, particularly for complex subcellular morphologies. The PVD neuron inCaenorhabditis elegans, which is responsible for harsh touch and thermosensation, undergoes structural degeneration as nematodes age characterized by the appearance of dendritic protrusions. Analysis of these neurodegenerative patterns is labor-intensive and limited to qualitative assessment. Results In this work, we apply deep learning to perform quantitative image-based analysis of complex neurodegeneration patterns exhibited by the PVD neuron inC. elegans. We apply a convolutional neural network algorithm (Mask R-CNN) to identify neurodegenerative subcellular protrusions that appear after cold-shock or as a result of aging. A multiparametric phenotypic profile captures the unique morphological changes induced by each perturbation. We identify that acute cold-shock-induced neurodegeneration is reversible and depends on rearing temperature and, importantly, that aging and cold-shock induce distinct neuronal beading patterns. Conclusion The results of this work indicate that implementing deep learning for challenging image segmentation of PVD neurodegeneration enables quantitatively tracking subtle morphological changes in an unbiased manner. This analysis revealed that distinct patterns of morphological alteration are induced by aging and cold-shock, suggesting different mechanisms at play. This approach can be used to identify the molecular components involved in orchestrating neurodegeneration and to characterize the effect of other stressors on PVD degeneration.	187.85878023987283
1931.	The lateral vertebral foramen (LVF) is an osseous feature found in thoracic and lumbar vertebrae of some artiodactyls and perissodactyls. To learn more about the distribution and characteristics of the LVF, we examined museum specimens from the Smithsonian mammal collection and teaching specimens from the Cornell University College of Veterinary Medicine. We identified five anatomically different types of LVF and noted their occurrence in 60 species. The LVF varies from a deep lateral groove at the cranial intervertebral notch, to as many as three distinct foramina located bilaterally in the caudal half of each vertebra. A nomenclature was developed to describe these five distinctly different LVF forms. The interspecific distribution of the LVF varies from examples such as the gazelle Gazella spekei, where the LVF occurs only in the thoracic region, to others such as the Siberian musk deer Moschus berezovski, where the LVF is predominant only in the lumbar region. Others, such as the Bos (cows), have large LVF along most of both the thoracic and lumbar regions of the vertebral column. Some did not have any form of LVF, such as the Giraffidae (giraffes) and Cetacea (whales). No LVF were found in 15 species representing nine families of the outgroup Carnivora, thus the LVF appears to be a characteristic specific to the artiodactyls and perissodactyls.	187.85833586197305
1932.	Immunotherapy has revolutionized the treatment of cancer. Nevertheless, the majority of patients do not respond to therapy, meaning a deeper understanding of tumor immune evasion strategies is required to boost treatment efficacy. The vast majority of immunotherapy studies have focused on how treatment reinvigorates exhausted CD8(+)T cells within the tumor. In contrast, how therapies influence regulatory processes within the draining lymph node is less well studied. In particular, relatively little has been done to examine how tumors may exploit peripheral CD8(+)T cell tolerance, an under-studied immune checkpoint that under normal circumstances prevents detrimental autoimmune disease by blocking the initiation of T cell responses. Here we review the therapeutic potential of blocking peripheral CD8(+)T cell tolerance for the treatment of cancer. We first comprehensively review what has been learnt about the regulation of CD8(+)T cell peripheral tolerance from the non-tumor models in which peripheral tolerance was first defined. We next consider how the tolerant state differs from other states of negative regulation, such as T cell exhaustion and senescence. Finally, we describe how tumors hijack the peripheral tolerance immune checkpoint to prevent anti-tumor immune responses, and argue that disruption of peripheral tolerance may contribute to both the anti-cancer efficacy and autoimmune side-effects of immunotherapy. Overall, we propose that a deeper understanding of peripheral tolerance will ultimately enable the development of more targeted and refined cancer immunotherapy approaches.	187.85792195822984
1933.	DNA accessibility is a key dynamic feature of chromatin regulation that can potentiate transcriptional events and tumor progression. To gain insight into chromatin state across existing tumor data, we improved neural network models for predicting accessibility from DNA sequence and extended them to incorporate a global set of RNA sequencing gene expression inputs. Our expression-informed model expanded the application domain beyond specific tissue types to tissues not present in training and achieved consistently high accuracy in predicting DNA accessibility at promoter and promoter flank regions. We then leveraged our new tool by analyzing the DNA accessibility landscape of promoters across The Cancer Genome Atlas. We show that in lung adenocarcinoma the accessibility perspective uniquely highlights immune pathways inversely correlated with a more open chromatin state and that accessibility patterns learned from even a single tumor type can discriminate immune inflammation across many cancers, often with direct relation to patient prognosis.	187.85778657982252
1934.	Breast cancer risk prediction refers to the task of predicting whether a healthy patient is likely to develop breast cancer in the future. Breast density and parenchymal texture features are well-known imaging-based breast cancer risk markers that can be qualitatively/visually assessed by radiologists or even quantitatively measured by computerized software. Recently, deep learning has emerged as a promising strategy to solve tasks in a variety of classification and prediction scenarios, including breast imaging. Building on this premise, we propose a deep learning-based modeling method for breast cancer risk prediction in a case-control setting purely using prior normal screening mammogram images. In addition, considering the fact that clinical statistics shows that the upper outer quadrant is the most common site of origin for breast cancer, we designed a simple experiment on 226 patients ( a total of 1,632 images) to explore the concept of localized breast cancer risk prediction. We built two deep learning models with the same settings but fed one with the top halves of the mammogram images (corresponding to the outer portion of a breast) and the other with the bottom halves (corresponding to the inner portion of a breast). Our preliminary results showed that the top halves have a higher prediction performance (AUC=0.89) than the bottom halves (AUC=0.69) in predicting the case/control outcome. This indicates a relation between localized imaging features extracted from a sub-region of the full mammogram images and the underlying risk of developing breast cancer in this specific sub-region.	187.85775138975345
1935.	PURPOSE: To apply a deep learning algorithm for automated, objective, and comprehensive quantification of optical coherence tomography (OCT) scans to a large real-world dataset of eyes with neovascular age-related macular degeneration (AMD), and make the raw segmentation output data openly available for further research. DESIGN: Retrospective analysis of OCT images from the Moorfields Eye Hospital AMD Database. PARTICIPANTS: 2473 first-treated eyes and another 493 second-treated eyes that commenced therapy for neovascular AMD between June 2012 and June 2017. METHODS: A deep learning algorithm was used to segment all baseline OCT scans. Volumes were calculated for segmented features such as neurosensory retina (NSR), drusen, intraretinal fluid (IRF), subretinal fluid (SRF), subretinal hyperreflective material (SHRM), retinal pigment epithelium (RPE), hyperreflective foci (HRF), fibrovascular pigment epithelium detachment (fvPED), and serous PED (sPED). Analyses included comparisons between first and second eyes, by visual acuity (VA) and by race/ethnicity, and correlations between volumes. MAIN OUTCOME MEASURES: Volumes of segmented features (mm3), central subfield thickness (CST) (mum). RESULTS: In first-treated eyes, the majority had both IRF and SRF (54.7%). First-treated eyes had greater volumes for all segmented tissues, with the exception of drusen, which was greater in second-treated eyes. In first-treated eyes, older age was associated with lower volumes for RPE, SRF, NSR and sPED; in second-treated eyes, older age was associated with lower volumes of NSR, RPE, sPED, fvPED and SRF. Eyes from black individuals had higher SRF, RPE and serous PED volumes, compared with other ethnic groups. Greater volumes of the vast majority of features were associated with worse VA. CONCLUSION: We report the results of large scale automated quantification of a novel range of baseline features in neovascular AMD. Major differences between first and second-treated eyes, with increasing age, and between ethnicities are highlighted. In the coming years, enhanced, automated OCT segmentation may assist personalization of real-world care, and the detection of novel structure-function correlations. These data will be made publicly available for replication and future investigation by the AMD research community.	187.85709242066727
1936.	This paper presents, DeepTrain, an embedded platform for high-performance and energy-efficient training of deep neural network (DNN). The key architectural concept of DeepTrain is to develop a spatially homogeneous computing (and memory) fabric with temporally heterogeneous programmable data flows to optimize memory mapping and data reuse during different phases of training operation. The DeepTrain is demonstrated as an in-memory accelerator integrated in the logic layer of a 3-D memory module. A programming model and supporting architecture utilizes the flexible data flow to efficiently accelerate training of various types of DNNs. The cycle level simulation and synthesized design in 15 nm FinFET shows power efficiency of 500 GFLOPS/W, and almost similar throughput for a wide range of DNNs, including convolutional, recurrent, and mixed (CNN+RNN) networks.	187.85691239844414
1937.	Background Pneumothorax can precipitate a life-threatening emergency due to lung collapse and respiratory or circulatory distress. Pneumothorax is typically detected on chest X-ray; however, treatment is reliant on timely review of radiographs. Since current imaging volumes may result in long worklists of radiographs awaiting review, an automated method of prioritizing X-rays with pneumothorax may reduce time to treatment. Our objective was to create a large human-annotated dataset of chest X-rays containing pneumothorax and to train deep convolutional networks to screen for potentially emergent moderate or large pneumothorax at the time of image acquisition. Methods and findings In all, 13,292 frontal chest X-rays (3,107 with pneumothorax) were visually annotated by radiologists. This dataset was used to train and evaluate multiple network architectures. Images showing large- or moderate-sized pneumothorax were considered positive, and those with trace or no pneumothorax were considered negative. Images showing small pneumothorax were excluded from training. Using an internal validation set (n = 1,993), we selected the 2 top-performing models; these models were then evaluated on a held-out internal test set based on area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and positive predictive value (PPV). The final internal test was performed initially on a subset with small pneumothorax excluded (as in training; n = 1,701), then on the full test set (n = 1,990), with small pneumothorax included as positive. External evaluation was performed using the National Institutes of Health (NIH) ChestX-ray14 set, a public dataset labeled for chest pathology based on text reports. All images labeled with pneumothorax were considered positive, because the NIH set does not classify pneumothorax by size. In internal testing, our "high sensitivity model" produced a sensitivity of 0.84 (95% CI 0.78-0.90), specificity of 0.90 (95% CI 0.89-0.92), and AUC of 0.94 for the test subset with small pneumothorax excluded. Our "high specificity model" showed sensitivity of 0.80 (95% CI 0.72-0.86), specificity of 0.97 (95% CI 0.96-0.98), and AUC of 0.96 for this set. PPVs were 0.45 (95% CI 0.39-0.51) and 0.71 (95% CI 0.63-0.77), respectively. Internal testing on the full set showed expected decreased performance (sensitivity 0.55, specificity 0.90, and AUC 0.82 for high sensitivity model and sensitivity 0.45, specificity 0.97, and AUC 0.86 for high specificity model). External testing using the NI H dataset showed some further performance decline (sensitivity 0.28-0.49, specificity 0.85-0.97, and AUC 0.75 for both). Due to labeling differences between internal and external datasets, these findings represent a preliminary step towards external validation. Conclusions We trained automated classifiers to detect moderate and large pneumothorax in frontal chest X-rays at high levels of performance on held-out test data. These models may provide a high specificity screening solution to detect moderate or large pneumothorax on images collected when human review might be delayed, such as overnight. They are not intended for unsupervised diagnosis of all pneumothoraces, as many small pneumothoraces (and some larger ones) are not detected by the algorithm. Implementation studies are warranted to develop appropriate, effective clinician alerts for the potentially critical finding of pneumothorax, and to assess their impact on reducing time to treatment.	187.856370542451
1938.	This paper proposes a new signal detection method based on a recurrence plot (RP) algorithm for detecting a burst signal. For detecting the burst signal, the conventional energy detection method performance is degraded because of the characteristic of the very short length of the burst signal. We use a three RP algorithm to visualize the burst signal and to utilize the CNN model for training and validating. performance improvement. The proposed methods based on three RP algorithm and CNN model show better performance than the conventional energy detection method through the simulation results.	187.85494462296464
1939.	BACKGROUND AND OBJECTIVE: Recently, deep convolutional neural network has significantly improved image classification and image segmentation. If coronary artery disease (CAD) can be diagnosed through machine learning and deep learning, it will significantly reduce the burdens of the doctors and accelerate the critical patient diagnoses. The purpose of the study is to assess the practicability of utilizing deep learning approaches to process coronary computed tomographic angiography (CCTA) imaging (termed CCTA-artificial intelligence, CCTA-AI) in coronary artery stenosis. MATERIALS AND METHODS: A CCTA reconstruction pipeline was built by utilizing deep learning and transfer learning approaches to generate auto-reconstructed CCTA images based on a series of two-dimensional (2D) CT images. 150 patients who underwent successively CCTA and digital subtraction angiography (DSA) from June 2017 to December 2017 were retrospectively analyzed. The dataset was divided into two parts comprising training dataset and testing dataset. The training dataset included the CCTA images of 100 patients which are trained using convolutional neural networks (CNN) in order to further identify various plaque classifications and coronary stenosis. The other 50 CAD patients acted as testing dataset that is evaluated by comparing the auto-reconstructed CCTA images with traditional CCTA images on the condition that DSA images are regarded as the reference method. Receiver operating characteristic (ROC) analysis was used for statistical analysis to compare CCTA-AI with DSA and traditional CCTA in the aspect of detecting coronary stenosis and plaque features. RESULTS: AI significantly reduces time for post-processing and diagnosis comparing to the traditional methods. In identifying various degrees of coronary stenosis, the diagnostic accuracy of CCTA-AI is better than traditional CCTA (AUCAI=0.870, AUCCCTA = 0.781, P < 0.001). In identifying  50% stenotic vessels, the accuracy, sensitivity, specificity, positive predictive value and negative predictive value of CCTA-AI and traditional method are 86% and 83%, 88% and 59%, 85% and 94%, 73% and 84%, 94% and 83%, respectively. In the aspect of identifying plaque classification, accuracy of CCTA-AI is moderate compared to traditional CCTA (AUC=0.750, P < 0.001). CONCLUSION: The proposed CCTA-AI allows the generation of auto-reconstructed CCTA images from a series of 2D CT images. This approach is relatively accurate for detecting 50% stenosis and analyzing plaque features compared to traditional CCTA.	187.85470019289068
1940.	The accurate detection of P-wave arrival time is imperative for determining the hypocenter location of an earthquake. However, precise detection of onset time becomes more difficult when the signal-to-noise ratio (SNR) of the seismic data is low, such as during microearthquakes. In this letter, a stacked denoising autoencoder (SDAE) is proposed to smooth the background noise. The SDAE acts as a denoising filter for the seismic data. In the proposed algorithm, the SDAE is utilized to reduce background noise such that the onset time becomes more clear and sharp. Afterward, a hard decision with one threshold is used to detect the onset time of the event. The proposed algorithm is evaluated on both synthetic and field seismic data. As a result, the proposed algorithm outperforms the short-time average/long-time average and the Akaike information criterion algorithms. The proposed algorithm accurately picks the onset time of 94.1% for 407 field seismic waveforms with a standard deviation error of 0.10 s. In addition, the results indicate that the proposed algorithm can pick arrival times accurately for weak SNR seismic data with SNR higher than -14 dB.	187.85441955869788
1941.	In the present era, secure data storage for any Internet of Things (IoT) platform is plagued by poor performance of secure read and write operations, which limits the use of data storage security on any IoT platform. Therefore, in this paper, a data storage security method based on double secret key encryption and Hadoop suitable for any IoT platform is proposed. First, the Hadoop deep learning architecture and implementation process are analyzed, and the process of client Kerberos identity authentication in the Hadoop framework is discussed. From this, the current shortcomings of data storage security based on the Hadoop framework are analyzed. The elements of data storage security are also determined. Furthermore, a novel double secret key encryption method for data storage security and to improve the security of stored data itself is introduced. Simultaneously, hash computing is used to improve the read and write performance of data after secure storage. Experimental results clearly show that our proposed method can effectively improve read and write performance of data, and that the performance of data security operations is improved from current standard implementations.	187.85361171505554
1942.	Purpose: Detailed and accurate absorbed dose calculations from radiation interactions with the human body can be obtained with the Monte Carlo (MC) method. However, the MC method can be slow for use in the time-sensitive clinical workflow. The aim of this study was to provide a solution to the accuracy-time trade-off for Ir-192-based high-dose-rate brachytherapy by using deep learning. Methods and Materials: RapidBrachyDL, a 3-dimensional deep convolutional neural network (CNN) model, is proposed to predict dose distributions calculated with the MC method given a patient's computed tomography images, contours of clinical target volume (CTV) and organs at risk, and treatment plan. Sixty-one patients with prostate cancer and 10 patients with cervical cancer were included in this study, with data from 47 patients with prostate cancer being used to train the model. Results: Compared with ground truth MC simulations, the predicted dose distributions by RapidBrachyDL showed a consistent shape in the dose-volume histograms (DVHs); comparable DVH dosimetric indices including 0.73% difference for prostate CTV D-90, 1.1% for rectum D-2cc, 1.45% for urethra D-0.1cc, and 1.05% for bladder D-2cc; and substantially smaller prediction time, acceleration by a factor of 300. RapidBrachyDL also demonstrated good generalization to cervical data with 1.73%, 2.46%, 1.68%, and 1.74% difference for CTV D-90, rectum D-2cc sigmoid D-2cc and bladder D-2cc respectively, which was unseen during the training. Conclusion: Deep CNN-based dose estimation is a promising method for patient-specific brachytherapy dosimetry. Desired radiation quantities can be obtained with accuracies arbitrarily close to those of the source MC algorithm, but with much faster computation times. The idea behind deep CNN-based dose estimation can be safely extended to other radiation sources and tumor sites by following a similar training process. (C) 2020 Elsevier Inc. All rights reserved.	187.85322940258953
1943.	In this work, we conducted a literature review about deep learning (DNN, RNN, CNN, and so on) for analyzing EEG data for decoding the activity of human's brain and diagnosing disease and explained details about various architectures for understanding the details of CNN and RNN. It has analyzed a word, which presented a model based on CNN and LSTM methods, and how these methods can be used to both optimize and set up the hyper parameters of deep learning architecture. Later, it is studied how semi-supervised learning on EEG data analytics can be applied. We review some studies about different methods of semi-supervised learning on EEG data analytics and discussing the importance of semi-supervised learning for analyzing EEG data. In this paper, we also discuss the most common applications for human EEG research and review some papers about the application of EEG data analytics such as Neuromarketing, human factors, social interaction, and BCI. Finally, some future trends of development and research in this area, according to the theoretical background on deep learning, are given.	187.85283754086683
1944.	Charting cortical growth trajectories is of paramount importance for understanding brain development. However, such analysis necessitates the collection of longitudinal data, which can be challenging due to subject dropouts and failed scans. In this paper, we will introduce a method for longitudinal prediction of cortical surfaces using a spatial graph convolutional neural network (GCNN), which extends conventional CNNs from Euclidean to curved manifolds. The proposed method is designed to model the cortical growth trajectories and jointly predict inner and outer cortical surfaces at multiple time points. Adopting a binary flag in loss calculation to deal with missing data, we fully utilize all available cortical surfaces for training our deep learning model, without requiring a complete collection of longitudinal data. Predicting the surfaces directly allows cortical attributes such as cortical thickness, curvature, and convexity to be computed for subsequent analysis. We will demonstrate with experimental results that our method is capable of capturing the nonlinearity of spatiotemporal cortical growth patterns and can predict cortical surfaces with improved accuracy.	187.8528029212842
1945.	Background: The wide adoption of electronic health record systems (EHRs) in hospitals in China has made large amounts of data available for clinical research including breast cancer. Unfortunately, much of detailed clinical information is embedded in clinical narratives e.g., breast radiology reports. The American College of Radiology (ACR) has developed a Breast Imaging Reporting and Data System (BI-RADS) to standardize the clinical findings from breast radiology reports. Objectives: This study aims to develop natural language processing (NLP) methods to extract BI-RADS findings from breast ultrasound reports in Chinese, thus to support clinical operation and breast cancer research in China. Methods: We developed and compared three different types of NLP approaches, including a rule-based method, a traditional machine learning-based method using the Conditional Random Fields (CRF) algorithm, and deep learning-based approaches, to extract all BI-RADS finding categories from breast ultrasound reports in Chinese. Results: Using a manually annotated dataset containing 540 reports, our evaluation shows that the deep learning-based method achieved the best F1-score of 0.904, when compared with rule-based and CRF-based approaches (0.848 and 0.881 respectively). Conclusions: This is the first study that applies deep learning technologies to BI-RADS findings extraction in Chinese breast ultrasound reports, demonstrating its potential on enabling international collaborations on breast cancer research.	187.85240830302814
1946.	Background: Cancer subtype classification attains the great importance for accurate diagnosis and personalized treatment of cancer. Latest developments in high-throughput sequencing technologies have rapidly produced multi-omics data of the same cancer sample. Many computational methods have been proposed to classify cancer subtypes, however most of them generate the model by only employing gene expression data. It has been shown that integration of multi-omics data contributes to cancer subtype classification. Results: A new hierarchical integration deep flexible neural forest framework is proposed to integrate multi-omics data for cancer subtype classification named as HI-DFNForest. Stacked autoencoder (SAE) is used to learn high-level representations in each omics data, then the complex representations are learned by integrating all learned representations into a layer of autoencoder. Final learned data representations (from the stacked autoencoder) are used to classify patients into different cancer subtypes using deep flexible neural forest (DFNForest) model.Cancer subtype classification is verified on BRCA, GBM and OV data sets from TCGA by integrating gene expression, miRNA expression and DNA methylation data. These results demonstrated that integrating multiple omics data improves the accuracy of cancer subtype classification than only using gene expression data and the proposed framework has achieved better performance compared with other conventional methods. Conclusion: The new hierarchical integration deep flexible neural forest framework(HI-DFNForest) is an effective method to integrate multi-omics data to classify cancer subtypes.	187.85181287536915
1947.	Images of the endothelial cell layer of the cornea can be used to evaluate corneal health. Quantitative biomarkers extracted from these images such as cell density, coefficient of variation of cell area, and cell hexagonality are commonly used to evaluate the status of the endothelium. Currently, fully-automated endothelial image analysis systems in use often give inaccurate results, while semi-automated methods, requiring trained image analysis readers to identify cells manually, are both challenging and time-consuming. We are investigating two deep learning methods to automatically segment cells in such images. We compare the performance of two deep neural networks, namely U-Net and SegNet. To train and test the classifiers, a dataset of 130 images was collected, with expert reader annotated cell borders in each image. We applied standard training and testing techniques to evaluate pixel-wise segmentation performance, and report corresponding metrics such as the Dice and Jaccard coefficients. Visual evaluation of results showed that most pixel-wise errors in the U-Net were rather non-consequential. Results from the U-Net approach are being applied to create endothelial cell segmentations and quantify important morphological measurements for evaluating cornea health.	187.85110966497265
1948.	Coronary artery calcium (CAC) is biomarker of advanced subclinical coronary artery disease and predicts myocardial infarction and death prior to age 60 years. The slice-wise manual delineation has been regarded as the gold standard of coronary calcium detection. However, manual efforts are time and resource consuming and even impracticable to be applied on large-scale cohorts. In this paper, we propose the attention identical dual network (AID-Net) to perform CAC detection using scan-rescan longitudinal non-contrast CT scans with weakly supervised attention by only using per scan level labels. To leverage the performance, 3D attention mechanisms were integrated into the AID-Net to provide complementary information for classification tasks. Moreover, the 3D Gradient-weighted Class Activation Mapping (Grad-CAM) was also proposed at the testing stage to interpret the behaviors of the deep neural network. 5075 non-contrast chest CT scans were used as training, validation and testing datasets. Baseline performance was assessed on the same cohort. From the results, the proposed AID-Net achieved the superior performance on classification accuracy (0.9272) and AUC (0.9627).	187.85045651286094
1949.	We evaluated whether using synthetic mammograms for training data augmentation may reduce the effects of overfitting and increase the performance of a deep learning algorithm for breast mass detection. Synthetic mammograms were generated using a combination of an in-silico random breast generation algorithm and x-ray transport simulation. In-silico breast phantoms containing masses were modeled across the four BI-RADS breast density categories, and the masses were modeled with different sizes, shapes and margins. A Monte Carlo-based x-ray transport simulation code, MC-GPU, was used to project the 3D phantoms into realistic synthetic mammograms. A training data set of 2,000 mammograms with 2,522 masses were generated and used for augmenting a data set of real mammograms for training. The data set of real mammograms included all the masses in the Curated Breast Imaging Subset of Digital Database for Screening Mammography (CBIS-DDSM) and consisted of 1,112 mammograms (1,198 masses) for training, 120 mammograms (120 masses) for validation, and 361 mammograms (378 masses) for testing. We used Faster R-CNN for our deep learning network with pre-training from ImageNet using Resnet-101 architecture. We compared the detection performance when the network was trained using only the CBIS-DDSM training images, and when subsets of the training set were augmented with 250, 500, 1,000 and 2,000 synthetic mammograms. FROC analysis was performed to compare performances with and without the synthetic mammograms. Our study showed that enlarging the training data with synthetic mammograms shows promise in reducing the overfitting, and that the inclusion of the synthetic images for training increased the performance of the deep learning algorithm for mass detection on mammograms.	187.85010005247534
1950.	Arrhythmia is a cardiac conduction disorder characterized by irregular heartbeats. Abnormalities in the conduction system can manifest in the electrocardiographic (ECG) signal. However, it can be challenging and time-consuming to visually assess the ECG signals due to the very low amplitudes. Implementing an automated system in the clinical setting can potentially help expedite diagnosis of arrhythmia, and improve the accuracies. In this paper, we propose an automated system using a combination of convolutional neural network (CNN) and long short-term memory (LSTM) for diagnosis of normal sinus rhythm, left bundle branch block (LBBB), right bundle branch block (RBBB), atrial premature beats (APB) and premature ventricular contraction (PVC) on ECG signals. The novelty of this work is that we used ECG segments of variable length from the MIT-BIT arrhythmia physio bank database. The proposed system demonstrated high classification performance in the handling of variable-length data, achieving an accuracy of 98.10%, sensitivity of 97.50% and specificity of 98.70% using ten-fold cross validation strategy. Our proposed model can aid clinicians to detect common arrhythmias accurately on routine screening ECG.	187.84988746348313
1951.	BACKGROUND AND OBJECTIVE: Deep learning techniques are instrumental in developing network models that aid in the early diagnosis of life-threatening diseases. To screen and diagnose the retinal fundus and coronary blood vessel disorders, the most important step is the proper segmentation of the blood vessels. METHODS: This paper aims to segment the blood vessels from both the coronary angiogram and the retinal fundus images using a single VSSC Net after performing the image-specific preprocessing. The VSSC Net uses two-vessel extraction layers with added supervision on top of the base VGG-16 network. The vessel extraction layers comprise of the vessel-specific convolutional blocks to localize the blood vessels, skip chain convolutional layers to enable rich feature propagation, and a unique feature map summation. Supervision is associated with the two-vessel extraction layers using separate loss/sigmoid function. Finally, the weighted fusion of the individual loss/sigmoid function produces the desired blood vessel probability map. It is then binary segmented and validated for performance. RESULTS: The VSSC Net shows improved accuracy values on the standard retinal and coronary angiogram datasets respectively. The computational time required to segment the blood vessels is 0.2 seconds using GPU. Moreover, the vessel extraction layer uses a lesser parameter count of 0.4 million parameters to accurately segment the blood vessels. CONCLUSION: The proposed VSSC Net that segments blood vessels from both the retinal fundus images and coronary angiogram can be used for the early diagnosis of vessel disorders. Moreover, it could aid the physician to analyze the blood vessel structure of images obtained from multiple imaging sources.	187.8494421503263
1952.	Emerging complex deep neural networks require vast amounts of data to achieve high precision. However, the information is often collected from user logs and personal data. In this article, we summarize recent cryptographic methodologies for provably privacy-preserving deep learning and inference.	187.8493880211431
1953.	Chemical plant leak accidents are classified as one of the major industrial accidents that can spread secondary and tertiary major disasters. It is very important to keep track and diagnose the source location(s) and notify the plant manager and emergency responders promptly to alleviate secondary and tertiary damages, improving the effectiveness of emergency responses. In this study, we propose an emergency response system that can cope with leak accidents of a chemical plant by monitoring sensor data and track down the suspected leak source using machine learning: Deep-learning and Random Forest classifiers. It is also difficult to get enough chemical leak accident scenario data or perform actual leak experiments on real plants due to high risk and cost factors. Consequently, Computational Fluid Dynamics (CFD) simulations are used to derive fence monitoring data for chemical leak accident scenarios. These data are to train the machine learning models to predict leak source locations. Six time-series Deep Neural Network (DNN) structures and three Random Forest (RF) structures are trained using CFD dispersion simulation results for 640 leak accident scenarios of a real chemical plant, divided as training and test datasets. As a result, on DNN model using 25 hidden layers and on RF model using 100 decision trees, 75.43% and 86.33% prediction accuracy are achieved, respectively, classifying the most probable leak source out of 40 potential leak source locations. Analyzing the predicted leak source locations that are wrongly classified, those predicted leak sources are also quite adjacent to the actual leak location and hardly called as misclassifications. Considering the superb performance of DNN and RF classifiers for chemical leak tracking, the proposed method would be very useful for chemical emergency management and is highly recommended for real-time diagnosis of the chemical leak sources.	187.84926427361634
1954.	In this study, a novel analytical approach is proposed for the identification of pesticide residues in tea by combining surface-enhanced Raman scattering (SERS) with a deep learning method one-dimensional convolutional neural network (1D CNN). First, a handheld Raman spectrometer was used for rapid on-site collection of SERS spectra. Second, the collected SERS spectra were augmented by a data augmentation strategy. Third, based on the augmented SERS spectra, the 1D CNN models were established on the cloud server, and then the trained 1D CNN models were used for subsequent pesticide residue identification analysis. In addition, to investigate the identification performance of the 1D CNN method, four conventional identification methods, including partial least square-discriminant analysis (PLS-DA), k-nearest neighbour (k-NN), support vector machine (SVM) and random forest (RF), were also developed on the basis of the augmented SERS spectra and applied for pesticide residue identification analysis. The comparative studies show that the 1D CNN method possesses better identification accuracy, stability and sensitivity than the other four conventional identification methods. In conclusion, the proposed novel analytical approach that exploits the advantages of SERS and a deep learning method (1D CNN) is a promising method for rapid on-site identification of pesticide residues in tea.	187.8478190147092
1955.	Expression recognition is the development direction for improving human-computer interaction. At the same time, Electroencephalo-gram(EEG) signals provide us with a way to quantify changes in human emotions. The identification of human emotions through the use of multimodal data sets based on EEG signals is a convenient and safe solution. Using deep learning for expression recognition is a new direction for the development of current emotion recognition. Since EEG signals are biomass signals with temporal characteristics, the use of recurrent neural networks to identify and classify EEG signals has certain advantages. Long-term and Short-term Memory Networks (LSTM) is an important representative of recurrent neural networks, and has achieved good recognition results in the classification and recognition of EEG signals. Gated Recurrent Unit (GRU) is a simpler algorithm than the structure of long-term and short-term memory. We use a gated loop unit with batch normalization for the classification of EEG signals. On the public dataset DEAP, GRU with batch normalization added a better recognition rate for arousal and valence than LSTM.	187.84676767333048
1956.	Aim:To assess the ablative margin (AM) after microwave ablation (MWA) for hepatocellular carcinoma (HCC) with a deep learning-based deformable image registration (DIR) technique and analyze the relation between the AM and local tumor progression (LTP). Patients and Methods:From November 2012 to April 2019, 141 consecutive patients with single HCC (diameter <= 5 cm) who underwent MWA were reviewed. Baseline characteristics were collected to identify the risk factors for the determination of LTP after MWA. Contrast-enhanced magnetic resonance imaging scans were performed within 1 month before and 3 months after treatment. Complete ablation was confirmed for all lesions. The AM was measured based on the margin size between the tumor region and the deformed ablative region. To correct the misalignment, DIR between images before and after ablation was achieved by an unsupervised landmark-constrained convolutional neural network. The patients were classified into two groups according to their AMs: group A (AM <= 5 mm) and group B (AM > 5 mm). The cumulative LTP rates were compared between the two groups using Kaplan-Meier curves and the log-rank test. Multivariate analyses were performed on clinicopathological variables to identify factors affecting LTP. Results:After a median follow-up period of 28.9 months, LTP was found in 19 patients. The mean tumor and ablation zone sizes were 2.3 +/- 0.9 cm and 3.8 +/- 1.2 cm, respectively. The mean minimum ablation margin was 3.4 +/- 0.7 mm (range, 0-16 mm). The DIR technique had higher AUC for 2-year LTP without a significant difference compared with the registration assessment without DL (P= 0.325). The 6-, 12-, and 24-month LTP rates were 9.9, 20.6, and 24.8%, respectively, in group A, and 4.0, 8.4, and 8.4%, respectively, in group B. There were significant differences between the two groups (P= 0.011). Multivariate analysis showed that being >65 years of age (P= 0.032, hazard ratio (HR): 2.463, 95% confidence interval (CI), 1.028-6.152) and AM <= 5 mm (P= 0.010, HR: 3.195, 95% CI, 1.324-7.752) were independent risk factors for LTP after MWA. Conclusion:The novel technology of unsupervised landmark-constrained convolutional neural network-based DIR is feasible and useful in evaluating the ablative effect of MWA for HCC.	187.84596272548745
1957.	We present an interactive visual analytics system that enables traffic congestion exploration, surveillance, and forecasting based on vehicle detector data. Through domain expert collaboration, we have extracted task requirements, incorporated the Long Short-Term Memory (LSTM) model for congestion forecasting, and designed a weighting method for detecting the causes of congestion and congestion propagation directions. Our visual analytics system is designed to enable users to explore congestion causes, directions, and severity. Congestion conditions of a city are visualized using a Volume-Speed Rivers (VSRivers) visualization that simultaneously presents traffic volumes and speeds. To evaluate our system, we report performance comparison results, wherein our model is more accurate than other forecasting algorithms. We demonstrate the usefulness of our system in the traffic management and congestion broadcasting domains through three case studies and domain expert feedback.	187.84591419228025
1958.	Early detection of lung cancer has shown to significantly improve patient survival. Apart from lesion detection, tumour segmentation is critical for developing radiomics signatures. In this work, we propose a novel hybrid approach for lung lesion detection and segmentation on CT scans, where the segmentation task is assisted by prior detection of regions containing lesions. For the detection task, we introduce a 2.5D residual deep CNN working in a sliding-window fashion, whereas segmentation is tackled by a modified residual U-Net with a weighted-dice plus cross-entropy loss. Experimental results on the LIDC-IDRI dataset and on the lung tumour task dataset within the Medical Segmentation Decathlon show competitive detection performance of the proposed approach (0.902 recall) and superior segmentation capabilities (0.709 dice score). These results confirm the high potential of simpler models, with lower hardware requirements, thus of more general applicability.	187.84579951263837
1959.	We compile baselines, along with dataset split, for multimodal sentiment analysis. In this paper, we explore three different deep-learning-based architectures for multimodal sentiment classification, each improving upon the previous. Further, we evaluate these architectures with multiple datasets with fixed train/test partition. We also discuss some major issues, frequently ignored in multimodal sentiment analysis research, e.g., the role of speaker-exclusive models, the importance of different modalities, and generalizability. This framework illustrates the different facets of analysis to be considered while performing multimodal sentiment analysis and, hence, serves as a new benchmark for future research in this emerging field.	187.84546283340717
1960.	The use of knowledge discovery on the Internet of Things (IoT) and its allied domains is undeniably one of the most indispensable ones, which results in optimized placement architectures, efficient routing protocols, device energy savings, and enhanced security measures for the implementation. The absence of knowledge discovery in IoT results in just an implementation of large-scale sensor networks, which generates a huge amount of data, and which needs, an often under-optimized, processing for actionable outputs. In this survey, we explore various domains of IoT for which knowledge discovery is inseparable from the application, and show how it benefits the overall implementation of the IoT architecture. This article is categorized under: Fundamental Concepts of Data and Knowledge > Knowledge Representation Technologies > Machine Learning Application Areas > Internet and Web-Based Applications Algorithmic Development > Spatial and Temporal Data Mining	187.84507834936647
1961.	Stroke is a significant cause of morbidity and long-term disability globally. Detection of injured neuron is a prerequisite for defining the degree of focal ischemic brain injury, which can be used to guide further therapy. Here, we demonstrate the capability of two-photon microscopy (TPM) to label-freely identify injured neurons on unstained thin section and fresh tissue of rat cerebral ischemia-reperfusion model, revealing definite diagnostic features compared with conventional staining images. Moreover, a deep learning model based on convolutional neural network is developed to automatically detect the location of injured neurons on TPM images. We then apply deep learning-assisted TPM to evaluate the ischemic regions based on tissue edema, two-photon excited fluorescence signal intensity, as well as neuronal injury, presenting a novel manner for identifying the infarct core, peri-infarct area, and remote area. These results propose an automated and label-free method that could provide supplementary information to augment the diagnostic accuracy, as well as hold the potential to be used as an intravital diagnostic tool for evaluating the effectiveness of drug interventions and predicting potential therapeutics.	187.84372710180946
1962.	Racism serves as a major barrier in access to health and social services, leading to absent, delayed, and/or avoidance of treatment. Metis Peoples experience barriers to accessing both Indigenous-specific and mainstream services yet are often left out of discourses surrounding racism and service access. Racism and discrimination experienced by Metis people is rooted within a deep history of assimilative and racist colonial policies. The objective of this research was to create space for the all too often unacknowledged voices of Metis Peoples by engaging with the traditional community health experts, Metis women. This research aimed to learn from Metis women's experiences to build an understanding on steps toward filling the health service gap. Nested within a longitudinal cohort study, this research employed a conversational method with urban Metis women in Toronto, Canada. In this paper, we share the experiences of racism and discrimination faced by urban Metis women when accessing and working within health and social services. Metis women (n = 11) experience racial discrimination such as witnessing, absorbing, and facing racism in mainstream service settings, while experiencing lateral violence and discrimination in Indigenous-specific services. This research highlights the need for reframing conversations around race, identity, health services, and the urban Metis community.	187.84329813802472
1963.	Breast density is one of the strongest risk factors for breast cancer. Our purpose of this study is to develop a deep learning model for BI-RADS density classification on digital mammograms (DM). With IRB approval, 2581 DMs were retrospectively collected from 672 women in our institution. We designed a multi-path DCNN (MP-DCNN) to classify each DM into one of four BI-RADS density categories. The MP-DCNN has four inputs: (1) subsampled DM (800 mu m pixel spacing), (2) a mask of dense area (MDA) obtained with a U-net (800 mu m pixel spacing), (3) the largest square region of interest (ROI) within mammographic breast (100 mu m pixel spacing), and ( 4) automated percentage of breast density (PD). As the baseline statistic, a single path DCNN with subsampled DM (800 um pixel spacing) as input was used. An experienced Mammography Quality Standards Act (MQSA) radiologist provided BI-RADS density category and PD by interactive thresholding as the reference standards. With ten-fold cross-validation, the BI-RADS categories by MP-DCNN for 2068 of the 2581 cases agreed with radiologist's assessment (accuracy = 80.7%, weighted kappa = 0.83) and the accuracy reached 89.0% if the breasts were categorized as non-dense (BI-RADS A & B) and dense (BI-RADS C & D). For comparison, a single path DCNN as the baseline model obtained agreement in 1906 of the 2581 cases (accuracy = 73.8%, weighted kappa = 0.75). The improvement in BI-RADS classification from the baseline to the MP-DCNN was statistically significant (p<0.001).	187.8431930127358
1964.	Fluorescent in situ hybridization (FISH) is a molecular cytogenetic technique that provides reliable imaging biomarkers to diagnose cancer and genetic disorders in the cellular level. One prerequisite step to identify carcinoma cells in FISH images is to accurately segment cells, so as to quantify DNA/RNA signals within each cell. Manual cell segmentation is a tedious and time-consuming task, which demands automatic methods. However, automatic cell segmentation is hindered by low image contrast, weak cell boundaries, and cell touching in FISH images. In this paper, we develop a fast mini-U-Net method to address these challenges. Some special characteristics are tailored in the mini-U-Net, including connections between input images and their feature maps to accurately localize cells, mlpcon (multilayer perceptron + convolution) to segment cell regions, and morphology operators and the watershed algorithm to separate each individual cell. In comparison with the U-Net, the mini-U-Net has fewer training parameters and less computational cost. The validation on 510 cells indicated that the Dice coefficients of the mini-U-Net and U-Net were 80.20% and 77.27%, and area overlap ratios were 69.17% and 68.04%, respectively. These promising results suggest that the mini-U-Net could generate accurate cell segmentation for fully automatic FISH image analysis.	187.84293789816408
1965.	Objectives Computed tomography (CT) and magnetic resonance imaging (MRI) are the most commonly selected methods for imaging gliomas. Clinically, radiotherapists always delineate the CT glioma region with reference to multi-modal MR image information. On this basis, we develop a deep feature fusion model (DFFM) guided by multi-sequence MRIs for postoperative glioma segmentation in CT images. Methods DFFM is a multi-sequence MRI-guided convolutional neural network (CNN) that iteratively learns the deep features from CT images and multi-sequence MR images simultaneously by utilizing a multi-channel CNN architecture, and then combines these two deep features together to produce the segmentation result. The whole network is optimized together via a standard back-propagation. A total of 59 CT and MRI datasets (T1/T2-weighted FLAIR, T1-weighted contrast-enhanced, T2-weighted) of postoperative gliomas as tumor grade II (n = 24), grade III (n = 18), or grade IV (n = 17) were included. Dice coefficient (DSC), precision, and recall were used to measure the overlap between automated segmentation results and manual segmentation. The Wilcoxon signed-rank test was used for statistical analysis. Results DFFM showed a significantly (p < 0.01) higher DSC of 0.836 than U-Net trained by single CT images and U-Net trained by stacking the CT and multi-sequence MR images, which yielded 0.713 DSC and 0.818 DSC, respectively. The precision values showed similar behavior as DSC. Moreover, DSC and precision values have no significant statistical difference (p > 0.01) with difference grades. Conclusions DFFM enables the accurate automated segmentation of CT postoperative gliomas of profit guided by multi-sequence MR images and may thus improve and facilitate radiotherapy planning.	187.8419748720509
1966.	The surface quality of tungsten heavy alloy parts has an important influence on its service performance. The accurate on-line prediction of surface roughness in ultra-precision cutting of tungsten heavy alloy has always been the difficulty of research. In this paper, the ultrasonic elliptical vibration cutting technology is used for ultra-precision machining of tungsten heavy alloy. Based on the idea of deep learning, the surface roughness is discretized, and the fitting problem in surface roughness is transformed into a classification problem. The generalization ability of the prediction model is improved by introducing batch standardization and Dropout. The relationship between the vibration signal and the surface roughness is established. Experimental results show that the model can achieve on-line prediction of cutting surface roughness. The prediction accuracy rate can be improved by more than 10% compared with the direct fitting method.	187.84183190052892
1967.	In recent years, the web phishing attack has become one of the most serious web security problems, in which the phishers can steal significant financial information about the internet users to carry out financial thefts. Several blacklist-based conventional phishing website detection methods are used to predict the phishing websites. However, numerous phishing websites are not predicted precisely by these blacklist-based conventional methods since many new phishing websites are constantly developed and launched on the Web over time. In this study, hybrid intelligent phishing website prediction using deep neural networks (DNNs) with evolutionary algorithm-based feature selection and weighting methods are suggested to enhance the phishing website prediction. In the proposed hybrid intelligent phishing website prediction approaches, the most influential features and the optimal weights of website features are heuristically identified with the genetic algorithm (GA) to help in increasing the accuracy of phishing website prediction. Accordingly, the website features selected and weighted by the GA are utilised to train DNNs to accurately predict the phishing websites. The experimental results demonstrated that the proposed hybrid intelligent phishing website prediction approaches achieved significantly higher classification accuracy, sensitivity, specificity, and geometric mean in phishing website prediction compared to those proposed in other studies.	187.8416894503483
1968.	This paper proposes the detection and removal of crosstalk noise using a convolutional neural network in the images of forward scan sonar. Because crosstalk noise occurs near an underwater object and distorts the shape of the object, underwater object detection is limited. The proposed method can detect crosstalk noise using the neural network and remove crosstalk noise based on the detection result. Thus, the proposed method can be applied to other sonar-image-based algorithms and enhance the reliability of those algorithms. We applied the proposed method to a three-dimensional point cloud generation and generated a more accurate point cloud. We verified the performance of the proposed method by performing multiple indoor and field experiments.	187.84152996072373
1969.	Several models have been developed using conventional regression approaches to extend the criteria for liver transplantation (LT) in hepatocellular carcinoma (HCC) beyond the Milan criteria. We aimed to develop a novel model to predict tumor recurrence after LT by adopting artificial intelligence (MoRAL-AI). This study included 563 patients who underwent LT for HCC at three large LT centers in Korea. Derivation (n = 349) and validation (n = 214) cohorts were independently established. The primary outcome was time-to-recurrence after LT. A MoRAL-AI was derived from the derivation cohort with a residual block-based deep neural network. The median follow-up duration was 74.7 months (interquartile-range, 18.5-107.4); 204 patients (36.2%) had HCC beyond the Milan criteria. The optimal model consisted of seven layers including two residual blocks. In the validation cohort, the MoRAL-AI showed significantly better discrimination function (c-index = 0.75) than the Milan (c-index = 0.64), MoRAL (c-index = 0.69), University of California San Francisco (c-index = 0.62), up-to-seven (c-index = 0.50), and Kyoto (c-index = 0.50) criteria (all p < 0.001). The largest weighted parameter in the MoRAL-AI was tumor diameter, followed by alpha-fetoprotein, age, and protein induced by vitamin K absence-II. The MoRAL-AI had better predictability of tumor recurrence after LT than conventional models. The MoRAL-AI can also evolve with further data.	187.8413886491972
1970.	Background FLAIR (fluid attenuated inversion recovery) imaging via synthetic MRI methods leads to artifacts in the brain, which can cause diagnostic limitations. The main sources of the artifacts are attributed to the partial volume effect and flow, which are difficult to correct by analytical modeling. In this study, a deep learning (DL)-based synthetic FLAIR method was developed, which does not require analytical modeling of the signal. Purpose To correct artifacts in synthetic FLAIR using a DL method. Study Type Retrospective. Subjects A total of 80 subjects with clinical indications (60.6 +/- 16.7 years, 38 males, 42 females) were divided into three groups: a training set (56 subjects, 62.1 +/- 14.8 years, 25 males, 31 females), a validation set (1 subject, 62 years, male), and the testing set (23 subjects, 57.3 +/- 20.4 years, 13 males, 10 females). Field Strength/Sequence 3 T MRI using a multiple-dynamic multiple-echo acquisition (MDME) sequence for synthetic MRI and a conventional FLAIR sequence. Assessment Normalized root mean square (NRMSE) and structural similarity (SSIM) were computed for uncorrected synthetic FLAIR and DL-corrected FLAIR. In addition, three neuroradiologists scored the three FLAIR datasets blindly, evaluating image quality and artifacts for sulci/periventricular and intraventricular/cistern space regions. Statistical Tests Pairwise Student's t-tests and a Wilcoxon test were performed. Results For quantitative assessment, NRMSE improved from 4.2% to 2.9% (P < 0.0001) and SSIM improved from 0.85 to 0.93 (P < 0.0001). Additionally, NRMSE values significantly improved from 1.58% to 1.26% (P < 0.001), 3.1% to 1.5% (P < 0.0001), and 2.7% to 1.4% (P < 0.0001) in white matter, gray matter, and cerebral spinal fluid (CSF) regions, respectively, when using DL-corrected FLAIR. For qualitative assessment, DL correction achieved improved overall quality, fewer artifacts in sulci and periventricular regions, and in intraventricular and cistern space regions. Data Conclusion The DL approach provides a promising method to correct artifacts in synthetic FLAIR. Technical Efficacy: Stage 1 J. Magn. Reson. Imaging 2019;50:1413-1423.	187.84127492389797
1971.	A broadband beam-forming antenna is designed for intelligent emergency detection and rescue systems. Recognizing emergencies hinges on identifying and analyzing the motion of humans. Combined with deep learning, the radio frequency signal of an antenna can capture the motion of humans behind a wall and in closed rooms using frequency-modulated carrier wave (FMCW) signals operating in broadband from 5.56 GHz to 7.25 GHz (26%). The beam-forming antenna is composed of four slot-coupled patch antennas. The proposed array antenna satisfies a broad FMCW bandwidth and sufficient gain over 15.8 dBi in the overall bandwidth. To extend the focusing capability, we specifically design a 4 x 1 array structure and optimize the distance of antenna to 32.9 mm (0.7 lambda(0)). The antenna is compact enough to realize a handheld motion-tracking device. The array antenna forms a fan beam with a wide beam coverage and low side lobe level. The motion of a human body is tracked as a beam scanning by the antenna array. To accomplish this goal with adaptive array architectures, we implement beam-forming techniques with a phase shifter, an amplifier, and a power divider.	187.84059314089023
1972.	We propose a rootkit installation method inside a GPU kernel execution process which works through GPU context manipulation. In GPU-based applications such as deep learning computations and cryptographic operations, the proposed method uses the feature by which the execution flow of the GPU kernel obeys the GPU context information in GPU memory. The proposed method consists of two key ideas. The first is GPU code manipulation, which is able to hijack the execution flow of the original GPU kernel to execute an injected payload without affecting the original GPU computation result. The second is a self-page-table update execution during which the GPU kernel updates its page table to access any location in system memory. After the installation, the malicious payload is executed only in the GPU kernel, and any no evidence remains in system memory. Thus, it cannot be detected by conventional rootkit detection methods.	187.8403733892896
1973.	It is very important to diagnose patients with rectal cancer, which can provide reference for the follow-up treatment. The gold standard for rectal cancer diagnosis is biopsy, but biopsy is invasive and risky. With the development of contrast-enhanced ultrasound (CEUS) technology, CEUS has become a reliable modality to diagnose rectal cancer. The degree of contrast enhancement can reflect the distribution of micro vessels inside the tumor. CEUS images are classified into three grades according to the inhomogeneity of enhancement inside rectal cancer. In this paper, we use deep learning and transfer learning to classify CEUS images. Features of rectal CEUS images were extracted by AlexNet, VGG16 and Resnet50. The extracted features were combined and normalized. A three-layer fully connected neural network was trained to classify the features of rectal CEUS images. The combination of features extracted by VGG16 and ResNet50 achieve 87.91% accuracy and AUC is 0.978.	187.8402977148425
1974.	Objectives To investigate whether liver fibrosis can be staged by deep learning techniques based on CT images. Methods This clinical retrospective study, approved by our institutional review board, included 496 CT examinations of 286 patients who underwent dynamic contrast-enhanced CT for evaluations of the liver and for whom histopathological information regarding liver fibrosis stage was available. The 396 portal phase images with age and sex data of patients (F0/F1/F2/F3/F4 = 113/36/56/66/125) were used for training a deep convolutional neural network (DCNN); the data for the other 100 (F0/F1/F2/F3/F4 = 29/9/14/16/32) were utilised for testing the trained network, with the histopathological fibrosis stage used as reference. To improve robustness, additional images for training data were generated by rotating or parallel shifting the images, or adding Gaussian noise. Supervised training was used to minimise the difference between the liver fibrosis stage and the fibrosis score obtained from deep learning based on CT images (F-DLCT score) output by the model. Testing data were input into the trained DCNNs to evaluate their performance. Results The F-DLCT scores showed a significant correlation with liver fibrosis stage (Spearman's correlation coefficient = 0.48, p < 0.001). The areas under the receiver operating characteristic curves (with 95% confidence intervals) for diagnosing significant fibrosis (>= F2), advanced fibrosis (>= F3) and cirrhosis (F4) by using F-DLCT scores were 0.74 (0.64-0.85), 0.76 (0.66-0.85) and 0.73 (0.62-0.84), respectively. Conclusions Liver fibrosis can be staged by using a deep learning model based on CT images, with moderate performance. Key Points Liver fibrosis can be staged by a deep learning model based on magnified CT images including the liver surface, with moderate performance. Scores from a trained deep learning model showed moderate correlation with histopathological liver fibrosis staging. Further improvement are necessary before utilisation in clinical settings.	187.8396883984979
1975.	Surface solar radiation is an indispensable parameter for numerical models, and the diffuse component contributes to the carbon uptake in ecosystems. We generated a 12-year (2007-2018) hourly dataset from Multi-functional Transport Satellite (MTSAT) satellite observations, including surface total solar radiation (R-s) and diffuse radiation (R-dif), with 5-km spatial resolution through deep learning techniques. The used deep network tacks the integration of spatial pattern and the simulation of complex radiation transfer by combining convolutional neural network and multi-layer perceptron. Validation against ground measurements shows the correlation coefficient, mean bias error and root mean square error are 0.94, 2.48 W/m(2)and 89.75 W/m(2) for hourly R-s and 0.85, 8.63 W/m(2) and 66.14 W/m(2) for hourly R-dif, respectively. The correlation coefficient of R-s and R-dif increases to 0.94 (0.96) and 0.89 (0.92) at daily (monthly) scales, respectively. The spatially continuous hourly maps accurately reflect regional differences and restore the diurnal cycles of solar radiation at fine resolution. This dataset can be valuable for studies on regional climate changes, terrestrial ecosystem simulations and photovoltaic applications.	187.83961820740146
1976.	Purpose: Angiographic Parametric Imaging (API) based on Digital Subtraction Angiography (DSA) of Intracranial Aneurysms (IA) can provide parameters related to contrast flow. In this study we propose to investigate the use of a Deep Neural Network (DNN) to analyze API parameters to classify IAs as un-treated or treated, quantify the prediction accuracy, and compare its performance with the Naive Bayes (NB) and K-Nearest Neighbor (KNN) algorithms. Materials and Methods: DSA scans were obtained from patients with un-treated and treated IAs. Three datasets were created based on treatment method: coiled, flow-diverted and combined. These scans were analyzed to provide API parameters for the IA and corresponding main artery. IA parameters were normalized to the main artery parameters. Data was augmented by adding Gaussian noise. The DNN, NB and KNN models were trained on API parameters and tested to classify aneurysms as un-treated or treated. This was performed on each dataset for both normalized and un-normalized data. Results: The DNN had an accuracy and ROC AUC of 72.4% and 0.80 respectively on un-normalized coiled data, 87.9% and 0.95 respectively on normalized coiled data, 73.9% and 0.79 respectively on un-normalized flow-diverted data, 85.3% and 0.80 respectively on normalized flow-diverted data, 62.9% and 0.64 respectively on un-normalized combined data, 64.8% and 0.73 respectively on normalized combined data. Conclusions: This study proves feasibility of using DNNs to classify IAs and make other clinical predictions using normalized API data with treatment methods separated, in addition to being more effective than other classifiers.	187.83911921050185
1977.	Short text categorization is a crucial issue to many applications, e.g., Information Retrieval, Question-Answering System, MRI Database Construction and so forth. Many researches focus on data sparsity and ambiguity issues in short text categorization. To tackle these issues, we propose a novel short text categorization strategy based on abundant representation, which utilizes Bi-directional Recurrent Neural Network(Bi-RNN) with Long Short-Term Memory(LSTM) and topic model to catch more contextual and semantic information. Bi-RNN enriches contextual information, and topic model discovers more latent semantic information for abundant text representation of short text. Experimental results demonstrate that the proposed model is comparable to state-of-the-art neural network models and method proposed is effective.	187.83902899534942
1978.	Radiation therapy presents a need for dynamic tracking of a target tumor volume. Fiducial markers such as implanted gold seeds have been used to gate radiation delivery but the markers are invasive and gating significantly increases treatment time. Pretreatment acquisition of a respiratory correlated 4DCT allows for determination of accurate motion tracking which is useful in treatment planning. We design a patient-specific motion subspace and a deep convolutional neural network to recover anatomical positions from a single fluoroscopic projection in real-time. We use this deep network to approximate the nonlinear inverse of a diffeomorphic deformation composed with radiographic projection. This network recovers subspace coordinates to define the patient-specific deformation of the lungs from a baseline anatomic position. The geometric accuracy of the subspace deformations on real patient data is similar to accuracy attained by original image registration between individual respiratory-phase image volumes.	187.83894766250936
1979.	Response of breast cancer to neoadjuvant chemotherapy (NAC) can be monitored using the change in visible tumor on magnetic resonance imaging (MRI). In our current workflow, seed points are manually placed in areas of enhancement likely to contain cancer. A constrained volume growing method uses these manually placed seed points as input and generates a tumor segmentation. This method is rigorously validated using complete pathological embedding. In this study, we propose to exploit deep learning for fast and automatic seed point detection, replacing manual seed point placement in our existing and well-validated workflow. The seed point generator was developed in early breast cancer patients with pathology-proven segmentations (N=100), operated shortly after MRI. It consisted of an ensemble of three independently trained fully convolutional dilated neural networks that classified breast voxels as tumor or non-tumor. Subsequently, local maxima were used as seed points for volume growing in patients receiving NAC (N=10). The percentage of tumor volume change was evaluated against semi-automatic segmentations. The primary cancer was localized in 95% of the tumors at the cost of 0.9 false positive per patient. False positives included focally enhancing regions of unknown origin and parts of the intramammary blood vessels. Volume growing from the seed points showed a median tumor volume decrease of 70% (interquartile range: 50%-77%), comparable to the semi-automatic segmentations (median: 70%, interquartile range 23%-76%). To conclude, a fast and automatic seed point generator was developed, fully automating a well-validated semi-automatic workflow for response monitoring of breast cancer to neoadjuvant chemotherapy.	187.83890123598638
1980.	Background Lymph node metastasis (LNM) in gastric cancer is a prognostic factor and has implications for the extent of lymph node dissection. The lymphatic drainage of the stomach involves multiple nodal stations with different risks of metastases. The aim of this study was to develop a deep learning system for predicting LNMs in multiple nodal stations based on preoperative CT images in patients with gastric cancer. Methods Preoperative CT images from patients who underwent gastrectomy with lymph node dissection at two medical centres were analysed retrospectively. Using a discovery patient cohort, a system of deep convolutional neural networks was developed to predict pathologically confirmed LNMs at 11 regional nodal stations. To gain understanding about the networks' prediction ability, gradient-weighted class activation mapping for visualization was assessed. The performance was tested in an external cohort of patients by analysis of area under the receiver operating characteristic (ROC) curves (AUC), sensitivity and specificity. Results The discovery and external cohorts included 1172 and 527 patients respectively. The deep learning system demonstrated excellent prediction accuracy in the external validation cohort, with a median AUC of 0 center dot 876 (range 0 center dot 856-0 center dot 893), sensitivity of 0 center dot 743 (0 center dot 551-0 center dot 859) and specificity of 0 center dot 936 (0 center dot 672-0 center dot 966) for 11 nodal stations. The imaging models substantially outperformed clinicopathological variables for predicting LNMs (median AUC 0 center dot 652, range 0 center dot 571-0 center dot 763). By visualizing nearly 19 000 subnetworks, imaging features related to intratumoral heterogeneity and the invasive front were found to be most useful for predicting LNMs. Conclusion A deep learning system for the prediction of LNMs was developed based on preoperative CT images of gastric cancer. The models require further validation but may be used to inform prognosis and guide individualized surgical treatment.	187.83867964970625
1981.	Recent advances in artificial intelligence (AI) and deep learning (DL) hold promise to augment neuroimaging diagnosis for patients with brain tumors and stroke. Here, the authors review the diverse landscape of emerging neuroimaging applications of AI, including workflow optimization, lesion segmentation, and precision education. Given the many modalities used in diagnosing neurologic diseases, AI may be deployed to integrate across modalities (MR imaging, computed tomography, PET, electroencephalography, clinical and laboratory findings), facilitate crosstalk among specialists, and potentially improve diagnosis in patients with trauma, multiple sclerosis, epilepsy, and neurodegeneration. Together, there are myriad applications of AI for neuroradiology."	187.8384664670396
1982.	Though three-dimensional (3D) fluorescence microscopy has been an essential tool for modern life science research, the light scattering by biological specimens fundamentally prevents its more widespread applications in live imaging. We hereby report a deep-learning approach, termed ScatNet, that enables reversion of 3D fluorescence microscopy from high-resolution targets to low-quality, light-scattered measurements, thereby allowing restoration for a blurred and light-scattered 3D image of deep tissue. Our approach can computationally extend the imaging depth for current 3D fluorescence microscopes, without the addition of complicated optics. Combining ScatNet approach with cutting-edge light-sheet fluorescence microscopy (LSFM), we demonstrate the image restoration of cell nuclei in the deep layer of live Drosophilamelanogaster embryos at single-cell resolution. Applying our approach to two-photon excitation microscopy, we could improve the signal-to-noise ratio (SNR) and resolution of neurons in mouse brain beyond the photon ballistic region.	187.83710354278026
1983.	Parkinson's disease (PD) is a neurodegenerative disease of the central nervous system caused due to the loss of dopaminergic neurons. It is classified under movement disorder as patients with PD present with tremor, rigidity, postural changes, and a decrease in spontaneous movements. Comorbidities including anxiety, depression, fatigue, and sleep disorders are observed prior to the diagnosis of PD. Gene mutations, exposure to toxic substances, and aging are considered as the causative factors of PD even though its genesis is unknown. This paper reviews PD etiologies, progression, and in particular measurable indicators of PD such as neuroimaging and electrophysiology modalities. In addition to gene therapy, neuroprotective, pharmacological, and neural transplantation treatments, researchers are actively aiming at identifying biological markers of PD with the goal of early diagnosis. Neuroimaging modalities used together with advanced machine learning techniques offer a promising path for the early detection and intervention in PD patients.	187.83691166877804
1984.	Mitotic count is an important indicator for assessing the invasiveness of breast cancers. Currently, the number of mitoses is manually counted by pathologists, which is both tedious and time-consuming. To address this situation, we propose a fast and accurate method to automatically detect mitosis from the histopathological images. The proposed method can automatically identify mitotic candidates from histological sections for mitosis screening. Specifically, our method exploits deep convolutional neural networks to extract high-level features of mitosis to detect mitotic candidates. Then, we use spatial attention modules to re-encode mitotic features, which allows the model to learn more efficient features. Finally, we use multi-branch classification subnets to screen the mitosis. Compared to existing related methods in literature, our method attains the best detection results on the dataset of the International Pattern Recognition Conference (ICPR) 2012 Mitosis Detection Competition. Code has been made available at: https://github.com/ liushaomin/MitosisDetection.	187.83652135851077
1985.	Intravascular photoacoustic tomography (IVPAT) is a newly developed imaging modality in the interventional diagnosis and treatment of coronary artery diseases. Incomplete acoustic measurement caused by limitedview scanning of the detector in the vascular lumen results in under-sampling artifacts and distortion in the images reconstructed by using the standard reconstruction methods. A method for limited-view IVPAT image reconstruction based on deep learning is presented in this paper. A convolutional neural network (CNN) is constructed and trained with computer-simulated image data set. Then, the trained CNN is used to optimize the cross-sectional images of the vessel which are recovered from the incomplete photoacoustic measurements by using the standard time-reversal (TR) algorithm to obtain the images with the improved quality. Results of numerical demonstration indicate that the method can effectively reduce the image distortion and artifacts caused by the limited-view detection. Furthermore, it is superior to the compressed sensing (CS) method in recovering the unmeasured information of the imaging target with the structural similarity around 10% higher than CS reconstruction.	187.8364841319701
1986.	Integrated science, technology, engineering, and mathematics (STEM) curricula have taken center stage in the recent education reforms. However, the challenge in teaching STEM curricula lies in finding ways to develop students' content knowledge and plan suitable learning activities and instructional strategies. This paper is focused on the implementation of STEM curricula by secondary technology and engineering teachers and presents a framework for implementing a STEM curriculum centered on engineering design while illuminating its components, such as curriculum theme, content knowledge, learning activities, and teaching strategies. As an effective STEM teaching strategy relies on content integration, the focal point of this framework is the use of learning activities, such as "inquiry and experiment" and "design and making," to integrate STEM content into lessons and help students develop core competencies through engineering design processes. This paper is meant to serve as a reference for technology and engineering educators to use when designing and implementing engineering-oriented STEM curricula, thereby providing a deeper learning experience of engineering design and STEM integration in secondary-school classrooms.	187.83568367548355
1987.	In this paper, we propose a new Intelligent Traffic Sign Recognition (ITSR) system with illumination preprocessing capability. Our proposed Dark Area Sensitive Tone Mapping (DASTM) technique can enhance the illumination of only dark regions of an image with little impact on bright regions. We used this technique as a pre-processing module for our new traffic sign recognition system. We combined DASTM with a TS detector, an optimized version of YOLOv3 for the detection of three classes of traffic signs. We trained ITSR on a dataset of Korean traffic signs with prohibitory, mandatory, and danger classes. We achieved Mean Average Precision (MAP) value of 90.07% (previous best result was 86.61%) on challenging Korean Traffic Sign Detection (KTSD) dataset and 100% on German Traffic Sign Detection Benchmark (GTSDB). Result comparisons of ITSR with latest D-Patches, TS detector, and YOLOv3 show that our new ITSR significantly outperforms in recognition performance.	187.83553982280478
1988.	Experimental protocols at synchrotron light sources typically process and validate data only after an experiment has completed, which can lead to undetected errors and cannot enable online steering. Real-time data analysis can enable both detection of, and recovery from, errors, and optimization of data acquisition. However, modern scientific instruments, such as detectors at synchrotron light sources, can generate data at GBs/sec rates. Data processing methods such as the widely used computational tomography usually require considerable computational resources, and yield poor quality reconstructions in the early stages of data acquisition when available views are sparse. We describe here how a deep convolutional neural network can be integrated into the real-time streaming tomography pipeline to enable better-quality images in the early stages of data acquisition. Compared with conventional streaming tomography processing, our method can significantly improve tomography image quality, deliver comparable images using only 32% of the data needed for conventional streaming processing, and save 68% experiment time for data acquisition.	187.83486897902097
1989.	In patients with suspected lymphoma, the tissue biopsy provides lymphoma confirmation, classification, and prognostic factors, including genetic changes. We developed a deep learning algorithm to detect MYC rearrangement in scanned histological slides of diffuse large B-cell lymphoma. The H&E-stained slides of 287 cases from 11 hospitals were used for training and evaluation. The overall sensitivity to detect MYC rearrangement was 0.93 and the specificity 0.52, showing that prediction of MYC translocation based on morphology alone was possible in 93% of MYC-rearranged cases. This would allow a simple and fast prescreening, saving approximately 34% of genetic tests with the current algorithm.	187.83432482385706
1990.	Autonomous cars employed as mobile base stations could provide communication networks in network-congested areas. In this paper, the authors leverage emerging deep reinforcement learning (DRL) techniques for enabling autonomous cars control and present a novel and highly effective DRL-based control framework called DRL-C3.	187.83418314021918
1991.	Identifying channel states as line-of-sight or non-line-of-sight helps to optimize location-based services in wireless communications. The received signal strength identification and channel state information are used to estimate channel conditions for orthogonal frequency division multiplexing systems in indoor wireless local area networks. This paper proposes a joint convolutional neural network and recurrent neural network architecture to classify channel conditions. Convolutional neural networks extract the feature from frequency-domain characteristics of channel state information data and recurrent neural networks extract the feature from time-varying characteristics of received signal strength identification and channel state information between packet transmissions. The performance of the proposed methods is verified under indoor propagation environments. Experimental results show that the proposed method has a 2% improvement in classification performance over the conventional recurrent neural network model.	187.83316952234546
1992.	Pathology diagnosis is usually done by a human pathologist observing tissue stained glass slide under a microscope. In the case of multi-specimen study to locate cancer region, such as in thyroidectomy, significant labor-intensive processing is required at high cost. Multispectral photoacoustic (MPA) specimen imaging, has proven successful in differentiating photoacoustic (PA) signal characteristics between a histopathology defined cancer region and normal tissue. A more pragmatic research question to ask is, can MPA imaging data predict, whether a sectioned tissue slice has cancer region(s)? We propose to use inception-resnet-v2 convolutional neural networks (CNNs) on the thyroid MPA data to evaluate this potential by transfer learning. The proposed algorithm first extracts features from the thyroid MPA image data using CNN and then detects cancer using the softmax function, the last layer of the network. The model achieved an area under curve (AUC) of cancer, benign nodule and normal are 0:73, 0:81, and 0:88 respectively.	187.8331632430644
1993.	Understanding humoral responses to SARS-CoV-2 is critical for improving diagnostics, therapeutics, and vaccines. Deep serological profiling of 232 COVID-19 patients and 190 pre-COVID-19 era controls using VirScan revealed over 800 epitopes in the SARS-CoV-2 proteome, including 10 epitopes likely recognized by neutralizing antibodies. Pre-existing antibodies in controls recognized SARS-CoV-2 ORF1, while only COVID-19 patients primarily recognized spike and nucleoprotein. A machine learning model trained on VirScan data predicted SARS-CoV-2 exposure history with 99% sensitivity and 98% specificity; a rapid Luminex-based diagnostic was developed from the most discriminatory SARS-CoV-2 peptides. Individuals with more severe COVID-19 exhibited stronger and broader SARS-CoV-2 responses, weaker antibody responses to prior infections, and higher incidence of CMV and HSV-1, possibly influenced by demographic covariates. Among hospitalized patients, males make greater SARS-CoV-2 antibody responses than females.	187.83307799327687
1994.	Background and Purpose- The availability of and expertise to interpret advanced neuroimaging recommended in the guideline-based endovascular stroke therapy (EST) evaluation are limited. Here, we develop and validate an automated machine learning-based method that evaluates for large vessel occlusion (LVO) and ischemic core volume in patients using a widely available modality, computed tomography angiogram (CTA). Methods- From our prospectively maintained stroke registry and electronic medical record, we identified patients with acute ischemic stroke and stroke mimics with contemporaneous CTA and computed tomography perfusion (CTP) with RAPID (IschemaView) post-processing as a part of the emergent stroke workup. A novel convolutional neural network named DeepSymNet was created and trained to identify LVO as well as infarct core from CTA source images, against CTP-RAPID definitions. Model performance was measured using 10-fold cross validation and receiver-operative curve area under the curve (AUC) statistics. Results- Among the 297 included patients, 224 (75%) had acute ischemic stroke of which 179 (60%) had LVO. Mean CTP-RAPID ischemic core volume was 23 +/- 42 mL. LVO locations included internal carotid artery (13%), M1 (44%), and M2 (21%). The DeepSymNet algorithm autonomously learned to identify the intracerebral vasculature on CTA and detected LVO with AUC 0.88. The method was also able to determine infarct core as defined by CTP-RAPID from the CTA source images with AUC 0.88 and 0.90 (ischemic core <= 30 mL and <= 50 mL). These findings were maintained in patients presenting in early (0-6 hours) and late (6-24 hours) time windows (AUCs 0.90 and 0.91, ischemic core <= 50 mL). DeepSymNet probabilities from CTA images corresponded with CTP-RAPID ischemic core volumes as a continuous variable with r=0.7 (Pearson correlation, P<0.001). Conclusions- These results demonstrate that the information needed to perform the neuroimaging evaluation for endovascular therapy with comparable accuracy to advanced imaging modalities may be present in CTA, and the ability of machine learning to automate the analysis.	187.83170023952323
1995.	Joined the 1 GW installed capacity club in 2017, Turkey has undeniable production and potential for geothermal energy, ranking top 5 worldwide. Harnessing geothermal energy has many challenges, from planning to commercial phases. This study features the challenges, experiences and latest advances in drilling fluids utilized in geothermal well construction process in Turkey; focusing to provide a comprehensive information about drilling fluids systems and their design principles in geothermal wells in Turkey. GEOS act as a major player in Turkish geothermal drilling industry; providing drilling and completion fluids, solids control equipment and waste management services; having drilled more than 250 deep geothermal wells in utmost challenging downhole environments of Turkish geothermal fields with major operators. Drilling geothermal wells comes along with several challenges. Most important of which could be high temperatures, relatively high pressures and some of the wells having tough lithologies to drill through. Providing wellbore stability across dispersive shales or pressurized ophiolitic formation requires special attention in planning and execution phases. Another special attention has been given to minimize formation damage in reservoir intervals of geothermal wells. Therefore, different options of reservoir drilling fluids are presented and discussed in detail. Drilling fluids systems used in geothermal wells have evolved over the last decade and tailored to suit the challenges to be faced, not only in top hole and intermediate intervals, but also in reservoir intervals. Main objective of this paper is to share the knowledge and experience gained during the learning curve over the years; extensive laboratory studies and field case studies for geothermal well drilling fluids in Turkey are presented.	187.8303065938622
1996.	Infrared spectroscopy of cells and tissues is prone to Mie scattering distortions, which grossly obscure the relevant chemical signals. The state-of-the-art Mie extinction extended multiplicative signal correction (ME-EMSC) algorithm is a powerful tool for the recovery of pure absorbance spectra from highly scatter-distorted spectra. However, the algorithm is computationally expensive and the correction of large infrared imaging datasets requires weeks of computations. In this paper, we present a deep convolutional descattering autoencoder (DSAE) which was trained on a set of ME-EMSC corrected infrared spectra and which can massively reduce the computation time for scatter correction. Since the raw spectra showed large variability in chemical features, different reference spectra matching the chemical signals of the spectra were used to initialize the ME-EMSC algorithm, which is beneficial for the quality of the correction and the speed of the algorithm. One DSAE was trained on the spectra, which were corrected with different reference spectra and validated on independent test data. The DSAE outperformed the ME-EMSC correction in terms of speed, robustness, and noise levels. We confirm that the same chemical information is contained in the DSAE corrected spectra as in the spectra corrected with ME-EMSC.	187.82993922839657
1997.	Retinopathy of Prematurity (ROP) is a fibrovascular proliferative disorder, which affects the developing peripheral retinal vasculature of premature infants. Early detection of ROP is possible in stage 1 and stage 2 characterized by demarcation line and ridge with width which separates vascularised retina and the peripheral retina. To detect demarcation line/ ridge from neonatal retinal images is a complex task because of low contrast images. In this paper we focus on detection of ridge, the important landmark in ROP diagnosis, using Convolutional Neural Network(CNN). Our contribution is to use a CNN-based model Mask R-CNN for demarcation line/ridge detection allowing clinicians to detect ROP stage 2 better. The proposed system applies a pre-processing step of image enhancement to overcome poor image quality. In this study we use labelled neonatal images and we explore the use of CNN to localize ridge in these images. We used a dataset of 220 images of 45 babies from the KIDROP project. The system was trained on 175 retinal images with ground truth segmentation of ridge region. The system was tested on 45 images and reached detection accuracy of 0.88, showing that deep learning detection with pre-processing by image normalization allows robust detection of ROP in early stages.	187.82986317842258
1998.	Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of morbidity and mortality worldwide. Identifying those at highest risk of deterioration would allow more effective distribution of preventative and surveillance resources. Secondary pulmonary hypertension is a manifestation of advanced COPD, which can be reliably diagnosed by the main Pulmonary Artery (PA) to Ascending Aorta (Ao) ratio. In effect, a PA diameter to Ao diameter ratio of greater than 1 has been demonstrated to be a reliable marker of increased pulmonary arterial pressure. Although clinically valuable and readily visualized, the manual assessment of the PA and the Ao diameters is time consuming and under-reported. The present study describes a non invasive method to measure the diameters of both the Ao and the PA from contrast-enhanced chest Computed Tomography (CT). The solution applies deep learning techniques in order to select the correct axial slice to measure, and to segment both arteries. The system achieves test Pearson correlation coefficient scores of 93% for the Ao and 92% for the PA. To the best of our knowledge, it is the first such fully automated solution.	187.8296119018363
1999.	In this work, terahertz time-domain (THz) spectroscopy and deep learning were used to analyze the spectral characteristics of a sample in the terahertz region. Nonlinear dimensionality reduction of the THz spectral data and a detection model for the freshness of stored wheat were investigated by deep learning and THz-TDS. The aim of this work was to enrich and develop the theory and method for testing stored grain quality, and improving the storage of rice through the use of THz technology. Furthermore, the work will provide theoretical basis for reducing the loss of grain storage.	187.82787089960698
2000.	Exact solution to the Schrodinger equation for multiple electron systems typically comes at high computational cost. PauliNet uses deep learning quantum Monte Carlo to find multidimensional wavefunctions that describe molecules with up to 30 electrons.	187.8269879337945
2001.	Aggregating layers can be designed from binary classifiers on the principle of preserving data sets separability. Formal neurons or logical elements are treated here as basic examples of binary classifiers. Learning data sets are composed of such feature vectors which are linked to particular categories (classes). Separability of the learning sets is preserved during transformation of feature vectors from these sets by a dipolar layer of binary classifiers. The dipolar layer separates all such pairs of feature vectors that have been linked to different classes and belong to different learning sets.	187.8262949583838
2002.	Millimetre wave radar is an emerging technology that can monitor vital signs without contact. This unique feature is very suitable for some particular situations, such as burn patient monitoring. Currently, electrocardiogram (ECG) is still the most common approach for monitoring heart disease. Deep learning algorithms have already been applied to classifying ECG recordings and have achieved good diagnostic results. However, it is very rare to see deep learning-based heartbeat classification using radar signals. The reason is a lack of radar-based heart disease datasets, which are the most important part of training a Convolutional Neural Network (CNN). Specifically, the ECG recordings and radar signals are heterogeneous; thus, the ECG dataset cannot train the CNN for directly classifying the radar signals. In this paper, we propose a novel signal processing algorithm called the Common Features Extraction Method (CFEM) to extract the common features of ECG recordings and radar signals to train a CNN for radar heartbeat signal classification. By using CFEM, the ECG dataset is transferred to the radar field, which means that the core issue for training the CNN using radar signals has been solved. Practical experiments show that the CFEM-based CNN can classify heartbeat radar signals accurately.	187.82567603484816
2003.	Deep Brain Stimulation (DBS) is commonly used to treat, inter alia, movement disorder symptoms in patients with Parkinson's disease, dystonia or essential tremor. The procedure stimulates a targeted region of the brain through implanted leads that are powered by a device called an implantable pulse generator (IPG). The mentioned targeted region is mainly chosen to be subthalamic nucleus (STN) during most of the operations. STN is a nucleus in the midbrain with a size of 3 mm x 5 mm x 9 mm that consist of parts with different physiological functions. The purpose of the study was to predict Parkinson's patient's symptoms defined by Unified Parkinson's Disease Rating Scale (UPDRS) that may occur after the DBS treatment. Parameters had been obtained from 3DSlicer (Harvard Medical School, Boston, MA), which allowed us to track connections between the stimulated part of STN and the cortex based on the DTI (diffusion tensor imaging).	187.8232564466376
2004.	Background and aims Improving the rate of polyp detection is an important measure to prevent colorectal cancer (CRC). Real-time automatic polyp detection systems, through deep learning methods, can learn and perform specific endoscopic tasks previously performed by endoscopists. The purpose of this study was to explore whether a high-performance, real-time automatic polyp detection system could improve the polyp detection rate (PDR) in the actual clinical environment. Methods The selected patients underwent same-day, back-to-back colonoscopies in a random order, with either traditional colonoscopy or artificial intelligence (AI)-assisted colonoscopy performed first by different experienced endoscopists (> 3000 colonoscopies). The primary outcome was the PDR. It was registered with. (NCT047126265). Results In this study, we randomized 150 patients. The AI system significantly increased the PDR (34.0% vs 38.7%,p< 0.001). In addition, AI-assisted colonoscopy increased the detection of polyps smaller than 6 mm (69 vs 91,p< 0.001), but no difference was found with regard to larger lesions. Conclusions A real-time automatic polyp detection system can increase the PDR, primarily for diminutive polyps. However, a larger sample size is still needed in the follow-up study to further verify this conclusion.	187.82295170651835
2005.	Osteoporosis is a prevalent but underdiagnosed condition. As compared to dual-energy X-ray absorptiometry (DXA) measures, we aimed to develop a deep convolutional neural network (DCNN) model to classify osteopenia and osteoporosis with the use of lumbar spine X-ray images. Herein, we developed the DCNN models based on the training dataset, which comprising 1616 lumbar spine X-ray images from 808 postmenopausal women (aged 50 to 92 years). DXA-derived bone mineral density (BMD) measures were used as the reference standard. We categorized patients into three groups according to DXA BMD T-score: normal (T >= -1.0), osteopenia (- 2.5 < T < - 1.0), and osteoporosis (T <= - 2.5). T-scores were calculated by using the BMD dataset of young Chinese female aged 20-40 years as a reference. A 3-class DCNN model was trained to classify normal BMD, osteoporosis, and osteopenia. Model performance was tested in a validation dataset (204 images from 102 patients) and two test datasets (396 images from 198 patients and 348 images from 147 patients respectively). Model performance was assessed by the receiver operating characteristic (ROC) curve analysis. The results showed that in the test dataset 1, the model diagnosing osteoporosis achieved an AUC of 0.767 (95% confidence interval [CI]: 0.701-0.824) with sensitivity of 73.7% (95% CI: 62.3-83.1), the model diagnosing osteopenia achieved an AUC of 0.787 (95% CI: 0.723-0.842) with sensitivity of 81.8% (95% CI: 67.3-91.8); In the test dataset 2, the model diagnosing osteoporosis yielded an AUC of 0.726 (95% CI: 0.646-0.796) with sensitivity of 68.4% (95% CI: 54.8-80.1), the model diagnosing osteopenia yielded an AUC of 0.810 (95% CI, 0.737-0.870) with sensitivity of 85.3% (95% CI, 68.9-95.0). Accordingly, a deep learning diagnostic network may have the potential in screening osteoporosis and osteopenia based on lumbar spine radiographs. However, further studies are necessary to verify and improve the diagnostic performance of DCNN models.	187.8227259315465
2006.	Rationale and Objectives:To compare cerebral pulsed arterial spin labeling (PASL) perfusion among controls, hypoxic ischemic encephalopathy (HIE) neonates with normal conventional MRI(HIE/MRI circle plus), and HIE neonates with abnormal conventional MRI(HIE/MRI circle minus). To create a predictive machine learning model of neurodevelopmental outcomes using cerebral PASL perfusion. Materials and Methods:A total of 73 full-term neonates were evaluated. The cerebral perfusion values were compared by permutation test to identify brain regions with significant perfusion changes among 18 controls, 40 HIE/MRI circle minus patients, and 15 HIE/MRI circle plus patients. A machine learning model was developed to predict neurodevelopmental outcomes using the averaged perfusion in those identified brain regions. Results:Significantly decreased PASL perfusion in HIE/MRI circle minus group, when compared with controls, were found in the anterior corona radiata, caudate, superior frontal gyrus, precentral gyrus. Both significantly increased and decreased cerebral perfusion changes were detected in HIE/MRI circle plus group, when compared with HIE/MRI circle minus group. There were no significant perfusion differences in the cerebellum, brainstem and deep structures of thalamus, putamen, and globus pallidus among the three groups. The machine learning model demonstrated significant correlation (p< 0.05) in predicting language(r= 0.48) and motor(r= 0.57) outcomes in HIE/MRI circle minus patients, and predicting language(r= 0.76), and motor(r= 0.53) outcomes in an additional group combining HIE/MRI circle minus and HIE/MRI circle plus. Conclusion:Perfusion MRI can play an essential role in detecting HIE regardless of findings on conventional MRI and predicting language and motor outcomes in HIE survivors. The perfusion changes may also reveal important insights into the reperfusion response and intrinsic autoregulatory mechanisms. Our results suggest that perfusion imaging may be a useful adjunct to conventional MRI in the evaluation of HIE in clinical practice.	187.82218924504522
2007.	Traditional analysis of smoke extent from satellite imagery relies largely on spectral analysis using multispectral data thereby requiring large data volumes or subjective and time-consuming evaluation. These methods are not scalable to observing capabilities of the new generation of remote sensing platforms. We propose an automated, deep learning based detection model capable of identifying smoke plumes from shortwave reflectance for the Geostationary Operational Environmental Satellite R series of satellites. Hand-labelled, past instances of smoke plumes from the NOAA Hazard Mapping System, quality controlled for spatiotemporal accuracy by a subject matter expert, comprises the reference truth dataset. The detection pipeline comprises of pre-process, detection, and post-process stages. A Convolutional Neural Network (CNN), trained on smoke events with varying optical thicknesses and sun-satellite viewing geometry is used to predict the probability score for a given pixel containing smoke. The model is able to detect smoke over both low and high reflectance surfaces and discriminate smoke from clouds though challenges remain in identifying optically thin smoke. Finally, we discuss a web-based interface to visualize daily smoke prediction and analyze the predictions over time.	187.82194525528334
2008.	The quality of sesame oil (SO) has been paid more and more attention. In this study, total synchronous fluorescence (TSyF) spectroscopy and deep neural networks were utilized to identify counterfeit and adulterated sesame oils. Firstly, typical samples including pure SO, counterfeit sesame oil (CSO) and adulterated sesame oil (ASO) were characterized by TSyF spectra. Secondly, three data augmentation methods were selected to increase the number of spectral data and enhance the robustness of the identification model. Then, five deep network architectures, including Simple Recurrent Neural Network (Simple RNN), Long Short-Term Memory (LSTM) network, Gated Recurrent Unit (GRU) network, Bidirectional LSTM (BLSTM) network and LSTM fortified with Convolutional Neural Network (LSTMC), were designed to identify the CSO and trace the source with 100% accuracy. Finally, ASO samples were also 100% correctly identified by training these network architectures. These results supported the feasibility of the novel method.	187.8209973973542
2009.	Optical coherence tomography (OCT) is a fiber-based intravascular imaging modality that produces high-resolution tomographic images of artery lumen and vessel wall morphology. Manual analysis of the diseased arterial wall is time consuming and sensitive to inter-observer variability; therefore, machine-learning methods have been developed to automatically detect and classify mural composition of atherosclerotic vessels. However, none of the tissue classification methods include in their analysis the outer border of the OCT vessel, they consider the whole arterial wall as pathological, and they do not consider in their analysis the OCT imaging limitations, e.g. shadowed areas. The aim of this study is to present a deep learning method that subdivides the whole arterial wall into six different classes: calcium, lipid tissue, fibrous tissue, mixed tissue, non-pathological tissue or media, and no visible tissue. The method steps include defining wall area (WAR) using previously developed lumen and outer border detection methods, and automatic characterization of the WAR using a convolutional neural network (CNN) algorithm. To validate this approach, 700 images of diseased coronary arteries from 28 patients were manually annotated by two medical experts, while the non-pathological wall and media was automatically detected based on the Euclidian distance of the lumen to the outer border of the WAR. Using the proposed method, an overall classification accuracy 96% is reported, indicating great promise for clinical translation.	187.82011710832447
2010.	Worldwide, glaucoma and age-related macular degeneration (AMD) cause 12.3% and 8.7% of the cases of blindness and/or vision loss, respectively. According to a 5-year study of Medicare beneficiaries, patients who undergo a regular eye screening, experience less decline of vision than those who had less-frequent examinations. A computer-based screening of retinopathies can be highly cost-effective and efficient; however, most auto-screening software address only one eye disease, limiting their clinical utility and cost-effectiveness. Therefore, we propose a computer-based retinopathy screening system for detection of AMD and glaucoma by integrating information from retinal fundus images and clinical data. First, the retinal image analysis algorithms were developed using Transfer Learning approach to determine presence or absence of the eye disease. The clinical data was then utilized to improve disease detection performance where the image-analysis based algorithms provided sub-optimal classification. The results for binary detection (present/absent) of AMD and Glaucoma were compared with the ground truth provided by a certified retinal reader. We applied the proposed method to a dataset of 304 retinal images with AMD, 299 retinal images with Glaucoma, and 2,341 control retinal images. The algorithms demonstrated sensitivity/specificity of 100%/99.5% for detection of any AMD, 82%/70% for detection of referable AMD, and 75%/81% for detection of referable Glaucoma. The automated detection results agree well with the ground truth suggesting its potential in screening for AMD and Glaucoma.	187.81832229296947
2011.	Protein lysine acetylation regulation is an important molecular mechanism for regulating cellular processes and plays critical physiological and pathological roles in cancers and diseases. Although massive acetylation sites have been identified through experimental identification and high-throughput proteomics techniques, their enzyme-specific regulation remains largely unknown. Here, we developed the deep learning-based protein lysine acetylation modification prediction (Deep-PLA) software for histone acetyltransferase (HAT)/histone deacetylase (HDAC)-specific acetylation prediction based on deep learning. Experimentally identified substrates and sites of several HATs and HDACs were curated from the literature to generate enzyme-specific data sets. We integrated various protein sequence features with deep neural network and optimized the hyperparameters with particle swarm optimization, which achieved satisfactory performance. Through comparisons based on cross-validations and testing data sets, the model outperformed previous studies. Meanwhile, we found that protein-protein interactions could enrich enzyme-specific acetylation regulatory relations and visualized this information in the Deep-PLA web server. Furthermore, a cross-cancer analysis of acetylation-associated mutations revealed that acetylation regulation was intensively disrupted by mutations in cancers and heavily implicated in the regulation of cancer signaling. These prediction and analysis results might provide helpful information to reveal the regulatory mechanism of protein acetylation in various biological processes to promote the research on prognosis and treatment of cancers. Therefore, the Deep-PLA predictor and protein acetylation interaction networks could provide helpful information for studying the regulation of protein acetylation. The web server of Deep-PLA could be accessed at http://deeppla.cancerbio.info.	187.81804238949172
2012.	Accurate classification and precise quantification of interstitial lung disease (ILD) types on CT images remain important challenges in clinical diagnosis. Multi-modality image information is required to assist diagnosing diseases. To build scalable deep-learning solutions for this problem, how to take full advantage of existing large-scale datasets in modern hospitals has become a critical task. In this paper, we present DeepILD, as a novel computer-aided diagnostic framework to address the ILD classification task only from single modality (CT image) using a deep neural network. More specifically, we propose integrating spherical semi-supervised K-means clustering and convolutional neural networks for ILD classification and disease quantification. We firstly use semi-supervised spherical K-means to divide the CT lung area into normal and abnormal sub-regions. A convolutional neural network (CNN) is subsequently invoked to perform training using image patches extracted from the abnormal regions. Here, we focus on the classification of three chronic fibrosing ILD types: idiopathic pulmonary fibrosis (IPF), idiopathic non-specific interstitial pneumonia (iNSIP), and chronic hypersensitivity pneumonia (CHP). Excellent classification accuracy has been achieved using a dataset of 188 CT scans; in particular, our IPF classification reached about 88% accuracy.	187.8176689624409
2013.	This research work explores the possibility of using deep learning to produce an autonomous system for detecting potholes on video to assist in road monitoring and maintenance. Video data of roads was collected using a GoPro camera mounted on a car. Region-based Fully Convolutional Networks (R-FCN) was employed to produce the model to detect potholes from images, and validated on the collected videos. The R-FCN model is able to achieve a Mean Average Precision (MAP) of 89% and a True Positive Rate (TPR) of 89% with no false positive.	187.81541414427699
2014.	BACKGROUND: The myelin sheath produced by glial cells insulates the axons, and supports the function of the nervous system. Myelin sheath degeneration causes neurodegenerative disorders, such as multiple sclerosis (MS). There are no therapies for MS that promote remyelination. Drug discovery frequently involves screening thousands of compounds. However, this is not feasible for remyelination drugs, since myelin quantification is a manual labor-intensive endeavor. Therefore, the development of assistive software for expedited myelin detection is instrumental for MS drug discovery by enabling high-content image-based drug screens. NEW METHOD: In this study, we developed a machine learning based expedited myelin detection approach in fluorescence microscopy images. Multi-channel three-dimensional microscopy images of a mouse stem cell-based myelination assay were labeled by experts. A spectro-spatial feature extraction method was introduced to represent local dependencies of voxels both in spatial and spectral domains. Feature extraction yielded two data set of over forty-seven thousand annotated images in total. RESULTS: Myelin detection performances of 23 different supervised machine learning techniques including a customized-convolutional neural network (CNN), were assessed using various train/test split ratios of the data sets. The highest accuracy values of 98.840.09% and 98.460.11% were achieved by Boosted Trees and customized-CNN, respectively. COMPARISON WITH EXISTING METHODS: Our approach can detect myelin in a common experimental setup. Myelin extending in any orientation in 3 dimensions is segmented from 3 channel z-stack fluorescence images. CONCLUSIONS: Our results suggest that the proposed expedited myelin detection approach is a feasible and robust method for remyelination drug screening.	187.8148602999085
2015.	Detection of suspicious breast cancer lesion in screening mammography images is an important step for the downstream diagnosis the of breast cancer. A trained radiologist can usually take advantage of multi-view correlation of suspicious lesions to locate abnormalities. In this work, we investigate the feasibility of using a random image pair of the same breast from the same exam for the detection of suspicious lesions. We present a novel approach to utilize a single shot detection system inspired by You only look once (YOLO) v1 to simultaneously process a primary detection view and a secondary view for the localization of lesion in the primary detection view. We used a combination of screening exams from Duke University Hospital and OPTIMAM to conduct our experiments. The Duke dataset includes 850 positive cases and around 10,000 negative cases. The OPTIMAM dataset includes around 350 cases. We observed a consistent left shift of the Free-Response Receiver Operating Characteristic (FROC) curve in the multi-view detection model compared to the single-view detection model. This result is promising for future development of automated lesion detection systems focusing on modern full-field digital mammography (FFDM).	187.814785655614
2016.	In this study, deep neural network is utilized as another approach for improving accuracy of the precipitation based on microwave-sensor. And The ensemble Bayesian model averaging(EBMA), which employs a weighting scheme for each member using posterior probability, in order to produce a more improved blending of precipitation from multi-satellite and to evaluate the effect of accuracy improvement. Experiments to improve rain rate were carried out based on data obtained from Global Precipitation Measurement (GPM) Microwave Imager (GMI). Input data for the DNN model include 7 brightness temperatures (Tb), ice water path (IWP), convective rain rate, scattering index (SI) and land sea mask is used. The experiment for blending of precipitation product was performed using rain rate product of three satellites and sensors, namely GMI of GPM core observatory, special sensor microwave imager/sounder (SSMI/S) of the Defense Meteorological Satellite Program (DMSP) F16 and microwave humidity sounder (MHS) of NOAA-18. In both experiments, precipitation product of the Dual-frequency Precipitation Radar (DPR) of CO was used as reference data. The probability density function(PDF) of gamma distribution combined with logistic regression is used to estimate the probability and quantity of precipitation for considering the characteristics of precipitation. And then, the exponent for these two functions and the percentile threshold of the cumulative density function were set by optimizing simulations. After that, the validation statistics of the blending precipitation through comparison with precipitation obtained from DPR is carried out.	187.81394220191157
2017.	As a subclass of interstitial lung diseases, fibrosing idiopathic interstitial pneumonia (IIP), whose cause is mostly unknown, is a continuous and irreversible process, manifesting as progressive worsening of lung function. Quantifying the evolution of the patient status imposes the development of automated CAD tools to depict the pathology occurrence in the lung but also an associated severity degree. In this paper we propose several biomarkers for IIP quantification, associating spatial localization of the disease using lung texture classification, and severity measures in relation with vascular and bronchial remodeling which correlate with clinical parameters. We follow-up our work on lung texture analysis based on convolutional neural networks (reporting an increased performance in sensitivity, specificity and accuracy) on an enlarged training/testing database (110/20 patients respectively). The area under the curve (AUC:2-6) for vessel calibers distribution between 2-6 mm radii ( evaluated in 70 patients) showed up as a promising biomarker of the severity of the disease, independently of the extent of lesions, correlating with the composite physiologic index. In the same way, normalized airway lobe length, normalized airway lobe volume and the score of distal airway caliber deviation from the physiologically power decrease law correlated with radiologic severity score, manifesting as potential biomarkers of traction bronchiectasis (assessment in 18 patients).	187.81360642271028
2018.	Raman optical spectroscopy promises label-free bacterial detection, identification, and antibiotic susceptibility testing in a single step. However, achieving clinically relevant speeds and accuracies remains challenging due to weak Raman signal from bacterial cells and numerous bacterial species and phenotypes. Here we generate an extensive dataset of bacterial Raman spectra and apply deep learning approaches to accurately identify 30 common bacterial pathogens. Even on low signal-to-noise spectra, we achieve average isolate-level accuracies exceeding 82% and antibiotic treatment identification accuracies of 97.0 +/- 0.3%. We also show that this approach distinguishes between methicillin-resistant and -susceptible isolates of Staphylococcus aureus (MRSA and MSSA) with 89 +/- 0.1% accuracy. We validate our results on clinical isolates from 50 patients. Using just 10 bacterial spectra from each patient isolate, we achieve treatment identification accuracies of 99.7%. Our approach has potential for culture-free pathogen identification and antibiotic susceptibility testing, and could be readily extended for diagnostics on blood, urine, and sputum.	187.81329893731186
2019.	OBJECTIVE Pituitary adenomas occur in a heterogeneous patient population with diverse perioperative risk factors, endocrinopathies, and other tumor-related comorbidities. This heterogeneity makes predicting postoperative outcomes challenging when using traditional scoring systems. Modern machine learning algorithms can automatically identify the most predictive risk factors and learn complex risk-factor interactions using training data to build a robust predictive model that can generalize to new patient cohorts. The authors sought to build a predictive model using supervised machine learning to accurately predict early outcomes of pituitary adenoma surgery. METHODS A retrospective cohort of 400 consecutive pituitary adenoma patients was used. Patient variables/predictive features were limited to common patient characteristics to improve model implementation. Univariate and multivariate odds ratio analysis was performed to identify individual risk factors for common postoperative complications and to compare risk factors with model predictors. The study population was split into 300 training/validation patients and 100 testing patients to train and evaluate four machine learning models using binary classification accuracy for predicting early outcomes. RESULTS The study included a total of 400 patients. The mean +/- SD patient age was 53.9 +/- 16.3 years, 59.8% of patients had nonfunctioning adenomas and 84.7% had macroadenomas, and the mean body mass index (BMI) was 32.6 +/- 7.8 (58.0% obesity rate). Multivariate odds ratio analysis demonstrated that age < 40 years was associated with a 2.86 greater odds of postoperative diabetes insipidus and that nonobese patients (BMI < 30) were 2.2 times more likely to develop postoperative hyponatremia. Using broad criteria for a poor early postoperative outcome-major medical and early surgical complications, extended length of stay, emergency department admission, inpatient readmission, and death-31.0% of patients met criteria for a poor early outcome. After model training, a logistic regression model with elastic net (LR-EN) regularization best predicted early postoperative outcomes of pituitary adenoma surgery on the 100-patient testing set-sensitivity 68.0%, specificity 93.3%, overall accuracy 87.0%. The receiver operating characteristic and precision-recall curves for the LR-EN model had areas under the curve of 82.7 and 69.5, respectively. The most important predictive variables were lowest perioperative sodium, age, BMI, highest perioperative sodium, and Cushing's disease. CONCLUSIONS Early postoperative outcomes of pituitary adenoma surgery can be predicted with 87% accuracy using a machine learning approach. These results provide insight into how predictive modeling using machine learning can be used to improve the perioperative management of pituitary adenoma patients.	187.81109952766036
2020.	Addison's disease (AD) is the most common endocrine manifestation of antiphospholipid syndrome (APS), but it remains a very rare complication of the syndrome. It is caused by adrenal venous thrombosis and consequent hemorrhagic infarction or by spontaneous (without thrombosis) adrenal hemorrhage, usually occurring after surgery or anticoagulant therapy. We present a clinical case of a 36-year-old female patient with a previous diagnosis of APS. She presented with multiple thrombotic events, including spontaneous abortions. During evaluation by the third episode of abortion, a CT imaging revealed an adrenal hematoma, but the patient was discharged without further investigation. A few weeks later, she presented in the emergency department with manifestations suggestive of adrenal insufficiency. Based on that assumption, she started therapy with glucocorticoids, with significant clinical improvement. After stabilization, additional investigation confirmed AD and excluded other etiologies; she also started mineralocorticoid replacement. This case illustrates a rare complication of APS that, if misdiagnosed, may be life threatening. A high index of suspicion is necessary for its diagnosis, and prompt treatment is crucial to reduce the morbidity and mortality potentially associated.	187.81041749330814
2021.	An image analysis method was developed based on deep-learning algorithms to extract phase fractions quantitatively in a rectangular trickle bed, and the average identification error was lower than 5%. Furthermore, the flow regime transition in the trickle bed was studied. In trickle-to-pulse flow transition, the trickle flow could be further classified into the stable trickle flow and accelerated one. The SD of liquid fractions and the peak width at half-height of the probability density curve of liquid fractions were close to zero in stable trickle flow, increased rapidly in accelerated trickle flow, and remained approximately constant in pulse flow. In bubble-to-pulse flow transition, dispersed bubbles in bubble flow induced the outliers outside the upper boundary of the boxplot of gas fraction, while alternative appearance of gas-rich zone and liquid-rich zone in pulse flow induced outliers outside both the upper and lower boundaries of the boxplot of gas fraction.	187.8097223863534
2022.	Methylation of the O-6-methylguanine methyltransferase (MGMT) gene promoter is correlated with the effectiveness of the current standard of care in glioblastoma patients. In this study, a deep learning pipeline is designed for automatic prediction of MGMT status in 87 glioblastoma patients with contrast-enhanced T1W images and 66 with fluid-attenuated inversion recovery(FLAIR) images. The end-to-end pipeline completes both tumor segmentation and status classification. The better tumor segmentation performance comes from FLAIR images (Dice score, 0.897 +/- 0.007) compared to contrast-enhanced T1WI (Dice score, 0.828 +/- 0.108), and the better status prediction is also from the FLAIR images (accuracy, 0.827 +/- 0.056; recall, 0.852 +/- 0.080; precision, 0.821 +/- 0.022; and F1score, 0.836 +/- 0.072). This proposed pipeline not only saves the time in tumor annotation and avoids interrater variability in glioma segmentation but also achieves good prediction of MGMT methylation status. It would help find molecular biomarkers from routine medical images and further facilitate treatment planning.	187.80969902419284
2023.	Mitochondria are the main source of cellular energy and thus essential for cell survival. Pathological conditions like cancer, can cause functional alterations and lead to mitochondrial dysfunction. Indeed, electron micrographs of mitochondria that are isolated from cancer cells show a different morphology as compared to mitochondria from healthy cells. However, the description of mitochondrial morphology and the classification of the respective samples are so far qualitative. Furthermore, large intra-class variability and impurities such as mitochondrial fragments and other organelles in the micrographs make a clear separation between healthy and cancerous samples challenging. In this study, we propose a deep-learning based model to quantitatively assess the status of each intact mitochondrion with a continuous score, which measures its closeness to the healthy/tumor classes based on its morphology. This allows us to describe the structural transition from healthy to cancerous mitochondria. Methodologically, we train two USK networks, one to segment individual mitochondria from an electron micrograph, and the other to softly classify each image pixel as belonging to (i) healthy mitochondrial, (ii) cancerous mitochondrial and (iii) non-mitochondrial (image background & impurities) tissue. Our combined model outperforms each network alone in both pixel classification and object segmentation. Moreover, our model can quantitatively assess the mitochondrial heterogeneity within and between healthy samples and different tumor types, hence providing insightful information of mitochondrial alterations in cancer development.	187.8096686590136
2024.	OBJECTIVE: Prediction of post-hemorrhagic hydrocephalus (PHH) outcome-i.e., whether it requires intervention or not-in premature neonates using cranial ultrasound (CUS) images is challenging. In this paper, we present a novel fully-automatic method to perform phenotyping of the brain lateral ventricles and predict PHH outcome from CUS. METHODS: Our method consists of two parts: ventricle quantification followed by prediction of PHH outcome. First, cranial bounding box and brain interhemispheric fissure are detected to determine the anatomical position of ventricles and correct the cranium rotation. Then, lateral ventricles are extracted using a new deep learning-based method by incorporating the convolutional neural network into a probabilistic atlas-based weighted loss function and an image-specific adaption. PHH outcome is predicted using a support vector machine classifier trained using ventricular morphological phenotypes and clinical information. RESULTS: Experiments demonstrated that our method achieves accurate ventricle segmentation results with an average Dice similarity coefficient of 0.86, as well as very good PHH outcome prediction with accuracy of 0.91. CONCLUSION: Automatic CUS-based ventricular phenotyping in premature newborns could objectively and accurately predict the progression to severe PHH. SIGNIFICANCE: Early prediction of severe PHH development in premature newborns could potentially advance criteria for diagnosis and offer an opportunity for early interventions to improve outcome.	187.8071886550883
2025.	OBJECTIVE: Tumour pathology contains rich information, including tissue structure and cell morphology, that reflects disease progression and patient survival. However, phenotypic information is subtle and complex, making the discovery of prognostic indicators from pathological images challenging. DESIGN: An interpretable, weakly supervised deep learning framework incorporating prior knowledge was proposed to analyse hepatocellular carcinoma (HCC) and explore new prognostic phenotypes on pathological whole-slide images (WSIs) from the Zhongshan cohort of 1125 HCC patients (2451 WSIs) and TCGA cohort of 320 HCC patients (320 WSIs). A 'tumour risk score (TRS)' was established to evaluate patient outcomes, and then risk activation mapping (RAM) was applied to visualise the pathological phenotypes of TRS. The multi-omics data of The Cancer Genome Atlas(TCGA) HCC were used to assess the potential pathogenesis underlying TRS. RESULTS: Survival analysis revealed that TRS was an independent prognosticator in both the Zhongshan cohort (p<0.0001) and TCGA cohort (p=0.0003). The predictive ability of TRS was superior to and independent of clinical staging systems, and TRS could evenly stratify patients into up to five groups with significantly different prognoses. Notably, sinusoidal capillarisation, prominent nucleoli and karyotheca, the nucleus/cytoplasm ratio and infiltrating inflammatory cells were identified as the main underlying features of TRS. The multi-omics data of TCGA HCC hint at the relevance of TRS to tumour immune infiltration and genetic alterations such as the FAT3 and RYR2 mutations. CONCLUSION: Our deep learning framework is an effective and labour-saving method for decoding pathological images, providing a valuable means for HCC risk stratification and precise patient treatment.	187.8066974737487
2026.	Background Based on international diagnostic guidelines, high-resolution CT plays a central part in the diagnosis of fibrotic lung disease. In the correct clinical context, when high-resolution CT appearances are those of usual interstitial pneumonia, a diagnosis of idiopathic pulmonary fibrosis can be made without surgical lung biopsy. We investigated the use of a deep learning algorithm for provision of automated classification of fibrotic lung disease on high-resolution CT according to criteria specified in two international diagnostic guideline statements: the 2011 American Thoracic Society (ATS)/European Respiratory Society (ERS)/Japanese Respiratory Society (JRS)/Latin American Thoracic Association (ALAT) guidelines for diagnosis and management of idiopathic pulmonary fibrosis and the Fleischner Society diagnostic criteria for idiopathic pulmonary fibrosis. Methods In this case-cohort study, for algorithm development and testing, a database of 1157 anonymised high-resolution CT scans showing evidence of diffuse fibrotic lung disease was generated from two institutions. We separated the scans into three non-overlapping cohorts (training set, n=929; validation set, n=89; and test set A, n=139) and classified them using 2011 ATS/ERS/JRS/ALAT idiopathic pulmonary fibrosis diagnostic guidelines. For each scan, the lungs were segmented and resampled to create a maximum of 500 unique four slice combinations, which we converted into image montages. The final training dataset consisted of 420096 unique montages for algorithm training. We evaluated algorithm performance, reported as accuracy, prognostic accuracy, and weighted kappa coefficient (kappa w) of interobserver agreement, on test set A and a cohort of 150 high-resolution CT scans (test set B) with fibrotic lung disease compared with the majority vote of 91 specialist thoracic radiologists drawn from multiple international thoracic imaging societies. We then reclassified high-resolution CT scans according to Fleischner Society diagnostic criteria for idiopathic pulmonary fibrosis. We retrained the algorithm using these criteria and evaluated its performance on 75 fibrotic lung disease specific high-resolution CT scans compared with four specialist thoracic radiologists using weighted kappa coefficient of interobserver agreement. Findings The accuracy of the algorithm on test set A was 76.4%, with 92.7% of diagnoses within one category. The algorithm took 2.31 s to evaluate 150 four slice montages (each montage representing a single case from test set B). The median accuracy of the thoracic radiologists on test set B was 70.7% (IQR 65.3-74.7), and the accuracy of the algorithm was 73.3% (93.3% were within one category), outperforming 60 (66%) of 91 thoracic radiologists. Median interobserver agreement between each of the thoracic radiologists and the radiologist's majority opinion was good (kappa w=0.67 [IQR 0.58-0.72]). Interobserver agreement between the algorithm and the radiologist's majority opinion was good (kappa w=0.69), outperforming 56 (62%) of 91 thoracic radiologists. The algorithm provided equally prognostic discrimination between usual interstitial pneumonia and non-usual interstitial pneumonia diagnoses (hazard ratio 2-88, 95% CI 1.79-4-61, p<0.0001) compared with the majority opinion of the thoracic radiologists (2.74, 1-67-4.48, p<0-0001). For Fleischner Society high-resolution CT criteria for usual interstitial pneumonia, median interobserver agreement between the radiologists was moderate (kappa w=0.56 [IQR 0.55-0-58]), but was good between the algorithm and the radiologists (kappa w=0.64 [0-55-0.72]). Interpretation High-resolution CT evaluation by a deep learning algorithm might provide low-cost, reproducible, near-instantaneous classification of fibrotic lung disease with human-level accuracy. These methods could be of benefit to centres at which thoracic imaging expertise is scarce, as well as for stratification of patients in clinical trials. Copyright (C) 2018 Elsevier Ltd. All rights reserved.	187.80384541166848
2027.	Objectives In case of surgical removal of oral squamous cell carcinomas, a resection of mandibular bone is frequently part of the treatment. Nowadays, such resections frequently include the application of 3D virtual surgical planning (VSP) and guided surgery techniques. In this paper, current methods for 3D VSP leads for optimisation of the workflow, and patient-specific application of guides and implants are reviewed. Recent findings Current methods for 3D VSP enable multi-modality fusion of images. This fusion of images is not restricted to a specific software package or workflow. New strategies for 3D VSP in Oral and Maxillofacial Surgery include finite element analysis, deep learning and advanced augmented reality techniques. These strategies aim to improve the treatment in terms of accuracy, predictability and safety. Conclusions Application of the discussed novel technologies and strategies will improve the accuracy and safety of mandibular resection and reconstruction planning. Accurate, easy-to-use, safe and efficient three-dimensional VSP can be applied for every patient with malignancies needing resection of the mandible.	187.80337636839744
2028.	Background Higher-resolution MRI of the patellofemoral cartilage under loading is hampered by subject motion since knee flexion is required during the scan. Purpose To demonstrate robust quantification of cartilage compression and contact area changes in response to in situ loading by means of MRI with prospective motion correction and regularized image postprocessing. Study Type Cohort study. Subjects Fifteen healthy male subjects. Field Strength 3 T. Sequence Spoiled 3D gradient-echo sequence augmented with prospective motion correction based on optical tracking. Measurements were performed with three different loads (0/200/400 N). Assessment Bone and cartilage segmentation was performed manually and regularized with a deep-learning approach. Average patellar and femoral cartilage thickness and contact area were calculated for the three loading situations. Reproducibility was assessed via repeated measurements in one subject. Statistical Tests Comparison of the three loading situations was performed by Wilcoxon signed-rank tests. Results Regularization using a deep convolutional neural network reduced the variance of the quantified relative load-induced changes of cartilage thickness and contact area compared to purely manual segmentation (average reduction of standard deviation by similar to 50%) and repeated measurements performed on the same subject demonstrated high reproducibility of the method. For the three loading situations (0/200/400 N), the patellofemoral cartilage contact area as well as the mean patellar and femoral cartilage thickness were significantly different from each other (P < 0.05). While the patellofemoral cartilage contact area increased under loading (by 14.5/19.0% for loads of 200/400 N), patellar and femoral cartilage thickness exhibited a load-dependent thickness decrease (patella: -4.4/-7.4%, femur: -3.4/-7.1% for loads of 200/400 N). Data Conclusion MRI with prospective motion correction enables quantitative evaluation of patellofemoral cartilage deformation and contact area changes in response to in situ loading. Regularizing the manual segmentations using a neural network enables robust quantification of the load-induced changes. Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019;50:1561-1570.	187.80334740532032
2029.	BACKGROUND AND PURPOSE: Clinical methods have incomplete diagnostic value for early diagnosis of acute stroke and large vessel occlusion (LVO). Electroencephalography is rapidly sensitive to brain ischemia. This study examined the diagnostic utility of electroencephalography for acute stroke/transient ischemic attack (TIA) and for LVO. METHODS: Patients (n=100) with suspected acute stroke in an emergency department underwent clinical exam then electroencephalography using a dry-electrode system. Four models classified patients, first as acute stroke/TIA or not, then as acute stroke with LVO or not: (1) clinical data, (2) electroencephalography data, (3) clinical+electroencephalography data using logistic regression, and (4) clinical+electroencephalography data using a deep learning neural network. Each model used a training set of 60 randomly selected patients, then was validated in an independent cohort of 40 new patients. RESULTS: Of 100 patients, 63 had a stroke (43 ischemic/7 hemorrhagic) or TIA (13). For classifying patients as stroke/TIA or not, the clinical data model had area under the curve=62.3, whereas clinical+electroencephalography using deep learning neural network model had area under the curve=87.8. Results were comparable for classifying patients as stroke with LVO or not. CONCLUSIONS: Adding electroencephalography data to clinical measures improves diagnosis of acute stroke/TIA and of acute stroke with LVO. Rapid acquisition of dry-lead electroencephalography is feasible in the emergency department and merits prehospital evaluation.	187.80130405589034
2030.	Background: Nonalcoholic fatty liver disease and its consequences are a growing public health concern requiring cross-sectional imaging for noninvasive diagnosis and quantification of liver fat. Purpose: To investigate a deep learning-based automated liver fat quantification tool at nonenhanced CT for establishing the prevalence of steatosis in a large screening cohort. Materials and Methods: In this retrospective study, a fully automated liver segmentation algorithm was applied to noncontrast abdominal CT examinations from consecutive asymptomatic adults by using three-dimensional convolutional neural networks, including a subcohort with follow-up scans. Automated volume-based liver attenuation was analyzed, including conversion to CT fat fraction, and compared with manual measurement in a large subset of scans. Results: A total of 11 669 CT scans in 9552 adults (mean age +/- standard deviation, 57.2 years +/- 7.9; 5314 women and 4238 men; median body mass index [BMI], 27.8 kg/m(2)) were evaluated, including 2117 follow-up scans in 1862 adults (mean age, 59.2 years; 971 women and 891 men; mean interval, 5.5 years). Algorithm failure occurred in seven scans. Mean CT liver attenuation was 55 HU +/- 10, corresponding to CT fat fraction of 6.4% (slightly fattier in men than in women [7.4% +/- 6.0 vs 5.8% +/- 5.7%; P < .001]). Mean liver Hounsfield unit varied little by age (<4 HU difference among all age groups) and only weak correlation was seen with BMI (r(2) = 0.14). By category, 47.9% (5584 of 11 669) had negligible or no liver fat (CT fat fraction <5%), 42.4% (4948 of 11 669) had mild steatosis (CT fat fraction of 5%-14%), 8.8% (1025 of 11 669) had moderate steatosis (CT fat fraction of 14%-28%), and 1% (112 of 11 669) had severe steatosis (CT fat fraction >28%). Excellent agreement was seen between automated and manual measurements, with a mean difference of 2.7 HU (median, 3 HU) and r(2) of 0.92. Among the subcohort with longitudinal follow-up, mean change was only 23 HU +/- 9, but 43.3% (806 of 1861) of patients changed steatosis category between first and last scans. Conclusion: This fully automated CT-based liver fat quantification tool allows for population-based assessment of hepatic steatosis and nonalcoholic fatty liver disease, with objective data that match well with manual measurement. The prevalence of at least mild steatosis was greater than 50% in this asymptomatic screening cohort. (C) RSNA, 2019	187.79955079620805
2031.	Purpose: Urothelial carcinoma of the bladder (UCB) is the most common urinary cancer. White-light cystoscopy (WLC) forms the corner stone for the diagnosis of UCB. However, histopathological assessment is required for adjuvant treatment selection. Probe-based confocal laser endomicroscopy (pCLE) enables visualization of the microarchitecture of bladder lesions during WLC, which allows for real-time tissue differentiation and grading of UCB. To improve the diagnostic process of UCB, computer-aided classification of pCLE videos of in vivo bladder lesions were evaluated in this study. Materials and Methods: We implemented preprocessing methods to optimize contrast and to reduce striping artifacts in each individual pCLE frame. Subsequently, a semiautomatic frame selection was performed. The selected frames were used to train a feature extractor based on pretrained ImageNet networks. A recurrent neural network, in specific long short-term memory (LSTM), was used to predict the grade of bladder lesions. Differentiation of lesions was performed at two levels, namely (i) healthy and benign vs malignant tissue and (ii) low-grade vs high-grade papillary UCB. A total of 53 patients with 72 lesions were included in this study, resulting in similar to 140,000 pCLE frames. Results: The semiautomated frame selection reduced the number of frames to similar to 66,500 informative frames. The accuracy for differentiation of (i) healthy and benign vs malignant urothelium was 79% and (ii) high-grade and low-grade papillary UCB was 82%. Conclusions: A feature extractor in combination with LSTM results in proper stratification of pCLE videos of in vivo bladder lesions.	187.79601258046603
2032.	Background Large vessel occlusion (LVO) stroke is one of the most time-sensitive diagnoses in medicine and requires emergent endovascular therapy to reduce morbidity and mortality. Leveraging recent advances in deep learning may facilitate rapid detection and reduce time to treatment. Purpose To develop a convolutional neural network to detect LVOs at multiphase CT angiography. Materials and Methods This multicenter retrospective study evaluated 540 adults with CT angiography examinations for suspected acute ischemic stroke from February 2017 to June 2018. Examinations positive for LVO (n = 270) were confirmed by catheter angiography and LVO-negative examinations (n = 270) were confirmed through review of clinical and radiology reports. Preprocessing of the CT angiography examinations included vasculature segmentation and the creation of maximum intensity projection images to emphasize the contrast agent-enhanced vasculature. Seven experiments were performed by using combinations of the three phases (arterial, phase 1; peak venous, phase 2; and late venous, phase 3) of the CT angiography. Model performance was evaluated on the held-out test set. Metrics included area under the receiver operating characteristic curve (AUC), sensitivity, and specificity. Results The test set included 62 patients (mean age, 69.5 years; 48% women). Single-phase CT angiography achieved an AUC of 0.74 (95% confidence interval [CI]: 0.63, 0.85) with sensitivity of 77% (24 of 31; 95% CI: 59%, 89%) and specificity of 71% (22 of 31; 95% CI: 53%, 84%). Phases 1, 2, and 3 together achieved an AUC of 0.89 (95% CI: 0.81, 0.96), sensitivity of 100% (31 of 31; 95% CI: 99%, 100%), and specificity of 77% (24 of 31; 95% CI: 59%, 89%), a statistically significant improvement relative to single-phase CT angiography (P = .01). Likewise, phases 1 and 3 and phases 2 and 3 also demonstrated improved fit relative to single phase (P = .03). Conclusion This deep learning model was able to detect the presence of large vessel occlusion and its diagnostic performance was enhanced by using delayed phases at multiphase CT angiography examinations.  RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Ospel and Goyal in this issue.	187.79330333102945
2033.	We report here the long-term effects of deep hypobaric hypoxia or dexamethasone administration (0.8 mg/kg) endured at the early prenatal period of gestation (days 14-16 or 17-19) on contextual and cued fear conditioning in postnatal ontogenesis of male rats. Fear responses conditioned to a context or a cue (tone) were comparatively evaluated in the male offspring of rats exposed to hypoxia or injected with dexamethasone at different gestational ages. Hypoxic exposures at any period of early prenatal ontogenesis were found to entail no statistically significant differences in the offspring relative to control. During contextual fear conditioning or extinction, the freezing time increased relative to control in animals born to females that were injected with dexamethasone on gestational days 17-19. In an analogous test on fear conditioning to a tone, the freezing time decreased relative to control in rats born to females injected with dexamethasone on gestational days 14-16 and increased in those whose mothers were injected with dexamethasone on days 17-19. We suggest that effects induced by dexamethasone administration at both gestation periods were mainly due to the involvement of the amygdala nuclei. The effect of dexamethasone on contextual fear conditioning, which seems to be due to functional changes in the hippocampus, was only detected upon its injection on gestational days 17-19.	187.78946099503452
2034.	A new study of deep learning based on electronic health records promises to forecast acute kidney injury up to 48 hours before it can be diagnosed clinically. However, employing data science to predict acute kidney injury might be more challenging than it seems.	187.78877442032908
2035.	In medical imaging, segmenting brain tumor becomes a vital task, and it provides a way for early diagnosis and treatment. Manual segmentation of brain tumor in magnetic resonance (MR) images is a time-consuming and challenging task. Hence, there is a need for a computer-aided brain tumor segmentation approach. Using deep learning algorithms, a robust brain tumor segmentation approach is implemented by integrating convolution neural network (CNN) and multiple kernel K means clustering (MKKMC). In this proposed CNN-MKKMC approach, classification of MR images into normal and abnormal is performed by CNN algorithm. At next, MKKMC algorithm is employed to segment the brain tumor from the abnormal brain image. The proposed CNN-MKKMC algorithm is evaluated both visually and objectively in terms of accuracy, sensitivity, and specificity with the existing segmentation methods. The experimental results demonstrate that the proposed CNN-MKKMC approach yields better accuracy in segmenting brain tumor with less time cost.	187.7867602167257
2036.	This study aimed to assess the potential of state-of-the-art ultrasound analysis techniques to non-invasively diagnose axillary lymph nodes involvement in breast cancer. After exclusion criteria, 105 patients were selected from two different hospitals. The 118 lymph node ultrasound images taken from these patients were divided into 53 cases and 65 controls, which made up the study series. The clinical outcome of each node was verified by ultrasound-guided fine needle aspiration, core needle biopsy or surgical biopsy. The achieved accuracy of the proposed method was 86.4%, with 84.9% sensitivity and 87.7% specificity. When tested on breast cancer patients only, the proposed method improved the accuracy of the sonographic assessment of axillary lymph nodes performed by expert radiologists by 9% (87.0% vs 77.9%). In conclusion, the results demonstrate the potential of ultrasound image analysis to detect the microstructural and compositional changes that occur in lymph nodes because of metastatic involvement. (C) 2019 World Federation for Ultrasound in Medicine & Biology. All rights reserved.	187.78235143515457
2037.	Identification of anomalies related to mineralization and integration of multi-source geoscience data are essential for mapping mineral prospectivity. In this study, we applied big data analytics and a deep learning algorithm to process geoscience data to identify and integrate anomalies related to skarn-type Iron mineralization in the southwestern Fujian metallogenic zone of China. Based on the geological setting and environment for the formation of skarn-type Iron mineralization, 42 relevant variables, including two geological, one geophysical, and 39 geochemical variables, were analyzed and integrated for detecting anomalies related to mineralization using a deep autoencoder network. The results indicate that the mapped prospectivity areas have a strong spatial relationship with the locations of known mineralization and demonstrate that big data analytics supported by deep learning methods is a potential technique to be considered for use in mineral prospectivity mapping.	187.78089384084154
2038.	Convolutional Neural Network (CNN) has established as an effective deep learning model for hyperspectral image classification by considering both spectral and spatial information. In this study, the performance of two-dimensional (2D) CNN architecture is evaluated at hyperspectral and multispectral resolution. Two types of multispectral data are analyzed viz., original and transformed multispectral data. Hyperspectral bands are transformed to spectral resolution of multispectral bands by averaging the reflectances of specific hyperspectral narrow bands which are falling within the spectral ranges of multispectral bands. The well-known Pavia University dataset and a new dataset of Pear orchard are investigated in this study. In case of Pear orchard dataset, classification is performed with both types of multispectral data. All the experiments are carried out with the same 2D CNN architecture. In case of Pavia University dataset, hyperspectral and transformed multispectral data achieve OA(%) of 94.29 +/- 1.28 and 94.27 +/- 2.01 respectively considering 20% samples as training. In case of Pear orchard dataset, hyperspectral, multispectral and transformed multispectral data achieve OA(%) of 91.59 +/- 0.89, 88.65 +/- 1.35, and 93.24 +/- 0.16 respectively considering 20% samples as training. It is evident that transformed multispectral data, which comprises of inherent hyperspectral information, provides similar or better performance compared to hyperspectral data. Further, with the use of 3D CNN architecture, classification performance improves in case of Pavia University dataset, whereas it remains statistically similar in case of Pear orchard dataset. The present promising results illustrates the performance of CNN even in small dataset which is comparable to several published state-of-the art results on the same dataset.	187.77681074078458
2039.	This article presents a voice and acoustic activity detector that uses a mixer-based architecture and ultra-low-power neural network (NN)-based classifier. By sequentially scanning 4 kHz of frequency bands and down-converting to below 500 Hz, feature extraction power consumption is reduced by 4 x. The NN processor employs computational sprinting, enabling 12 x power reduction. The system also features inaudible acoustic signature detection for intentional remote silent wakeup of the system while re-using a subset of the same system components. The measurement results achieve 91.5%/90% speech/non-speech hit rates at 10-dB SNR with babble noise and 142-nW power consumption. Acoustic signature detection consumes 66 nW, successfully detecting a signature 10 dB below the noise level.	187.7759667851877
2040.	We propose a designing of multi-layer neural networks using 2D NAND flash memory cell as a high-density and reliable synaptic device. Our operation scheme eliminates the waste of NAND flash cells and allows analogue input values. A 3-layer perceptron network with 40,545 synapses is trained on a MNIST database set using an adaptive weight update method for hardware-based multi-layer neural networks. The conductance response of NAND flash cells is measured and it is shown that the unidirectional conductance response is suitable for implementing multi-layer neural networks using NAND flash memory cells as synaptic devices. Using an online-learning, we obtained higher learning accuracy with NAND synaptic devices compared to that with a memristor-based synapse regardless of weight update methods. Using an adaptive weight update method based on a unidirectional conductance response, we obtained a 94.19% learning accuracy with NAND synaptic devices. This accuracy is comparable to 94.69% obtained by synapses based on the ideal perfect linear device. Therefore, NAND flash memory which is mature technology and has great advantage in cell density can be a promising synaptic device for implementing high-density multi-layer neural networks.	187.7758578668332
2041.	Ocular Toxoplasmosis (OT) is a widespread infectious chorioretinal disease whose timely diagnosis and treatment are crucial to prevent potential vision loss. Diagnosing OT is a challenging task ranging from tedious analyses of fundus images of the eye to serological clinical tests. An automated approach using convolutional neural networks (CNNs) towards diagnosing OT by analyzing fundus images is described. Fundus images are segmented to patches using a sliding window and are classified into healthy and unhealthy fundus image patches using a CNN model. An OT lesion heat map of a fundus image is generated from these patches. The heat map and patch features are then combined to develop a dual input hybrid CNN model detecting OT fundus images with high accuracy. The approach was applied to a dataset of fundus images involving OT and normal subjects and was highly effective in identifying fundus images having OT lesions.	187.77526012793513
2042.	A reliable classification of meteorites is of great importance in order to study the meteorite history. Secondary ion mass spectrometry is applied to collect a database of spectra for four meteorite classes, H chondrite, IAB iron, L chondrite, and achondrite and based on convolutional neural network to determine the meteorite class of un unknown sample. The focus of the presented analysis is on the Kosice meteorite which is identified with following elements Li, B, Na, Mg, Al, Si, P, K, Ca, Ti, Cr, Mn, Fe, and Ni. Due to the high mass resolution of 7000, several isotopes of these elements are clearly identified. The Secondary ion mass spectrometry images provide also mineralogical analysis by revealing distributions of chemical composition. The minerals of albite, troilite, augite, and diopside are recognized. Using 88 reference spectra, the unknown sample is identified as the H chondrite based on calculated probability. Secondary ion mass spectrometry technique coupled with convolutional neural network proves to be the advanced tool to analyze meteorites, to classify them, and to determine a meteorite of unknown origin.	187.77525178513991
2043.	The daily pollen forecast provides crucial information for allergic patients to avoid exposure to specific pollen. Pollen counts are typically measured with air samplers and analyzed with microscopy by trained experts. In contrast, this study evaluated the effectiveness of identifying the component pollens using the metabolites extracted from an air-sampled pollen mixture. Ambient air-sampled pollen from Munich in 2016 and 2017 was visually identified from reference pollens and extracts were prepared. The extracts were lyophilized, rehydrated in optimal NMR buffers, and filtered to remove large proteins. NMR spectra were analyzed for pollen associated metabolites. Regression and decision-tree based algorithms using the concentration of metabolites, calculated from the NMR spectra outperformed algorithms using the NMR spectra themselves as input data for pollen identification. Categorical prediction algorithms trained for low, medium, high, and very high pollen count groups had accuracies of 74% for the tree, 82% for the grass, and 93% for the weed pollen count. Deep learning models using convolutional neural networks performed better than regression models using NMR spectral input, and were the overall best method in terms of relative error and classification accuracy (86% for tree, 89% for grass, and 93% for weed pollen count). This study demonstrates that NMR spectra of air-sampled pollen extracts can be used in an automated fashion to provide taxa and type-specific measures of the daily pollen count.	187.7718132496891
2044.	The proliferation of image- and video-sharing websites has increased revenge porn images. In this paper, we propose a photo forensic-based prototype to aid revenge porn victims to automatically retrieve offending images. Our prototype combines a deep learning-based nude detection filter with a face recognition filter to find if a nude image containing the victim's face is posted on targeted social media accounts. After finding revenge porn images from the targeted accounts, our prototype iteratively finds other accounts containing potential revenge porn images. Revenge porn images from these newly identified accounts are then filtered out. Experiment with 1254 images shows that our method can filter revenge porn images in 91% cases.	187.7713459367924
2045.	PURPOSE: Cyclin-dependent kinase 12 (CDK12) aberrations have been reported as a biomarker of response to immunotherapy for metastatic castration-resistant prostate cancer (mCRPC). Herein, we characterize CDK12-mutated mCRPC, presenting clinical, genomic, and tumor-infiltrating lymphocyte (TIL) data. EXPERIMENTAL DESIGN: Patients with mCRPC consented to the molecular analyses of diagnostic and mCRPC biopsies. Genomic analyses involved targeted next-generation (MiSeq; Illumina) and exome sequencing (NovaSeq; Illumina). TILs were assessed by validated immunocytochemistry coupled with deep learning-based artificial intelligence analyses including multiplex immunofluorescence assays for CD4, CD8, and FOXP3 evaluating TIL subsets. The control group comprised a randomly selected mCRPC cohort with sequencing and clinical data available. RESULTS: Biopsies from 913 patients underwent targeted sequencing between February 2015 and October 2019. Forty-three patients (4.7%) had tumors with CDK12 alterations. CDK12-altered cancers had distinctive features, with some revealing high chromosomal break numbers in exome sequencing. Biallelic CDK12-aberrant mCRPCs had shorter overall survival from diagnosis than controls [5.1 years (95% confidence interval (CI), 4.0-7.9) vs. 6.4 years (95% CI, 5.7-7.8); hazard ratio (HR), 1.65 (95% CI, 1.07-2.53); P = 0.02]. Median intratumoral CD3+ cell density was higher in CDK12 cancers, although this was not statistically significant (203.7 vs. 86.7 cells/mm2; P = 0.07). This infiltrate primarily comprised of CD4+FOXP3- cells (50.5 vs. 6.2 cells/mm2; P < 0.0001), where high counts tended to be associated with worse survival from diagnosis (HR, 1.64; 95% CI, 0.95-2.84; P = 0.077) in the overall population. CONCLUSIONS: CDK12-altered mCRPCs have worse prognosis, with these tumors surprisingly being primarily enriched for CD4+FOXP3- cells that seem to associate with worse outcome and may be immunosuppressive.	187.7703449371157
2046.	Follicle size is closely related to ovarian function and is an important biomarker in transvaginal ultrasound examinations for assessing follicular maturity during an assisted reproduction cycle. However, manual measurement is time consuming and subject to high inter- and intra- observer variability. Based on the deep learning model CR-Unet described in our previous study, the aim of our present study was to investigate further the feasibility of using this model in clinical practice by validating its performance in reducing the inter- and intra-observer variability of follicle diameter measurement. This study also investigated whether follicular area is a better biomarker than diameter in assessing follicular maturity. Data on 106 ovaries and 230 follicles collected from 80 cases of single follicular cycles and 26 cases of multiple follicular cycles constituted the validation set. Intra-observer variability was 0.973 and 0.982 for the senior sonographer and junior sonographer in single follicular cycles and 0.979 (0.971, 0.985) and 0.920 (0.892, 0.943) in multiple follicular cycles, respectively, while CR-Unet had no intra-group variation. Bland-Altman plot analysis indicated that the 95% limits of agreement between senior sonographer and CR-Unet (-2.1 to 1.1 mm, -2.02 to 0.75 mm) were smaller than those between senior sonographer and junior sonographer (-1.51 to 1.15 mm, -2.1 to 1.56 mm) in single and multiple follicular cycles. The average operating times of diameter measurement taken by the junior sonographer, senior sonographer and CR-Unet were 7.54  1.8, 4.87  0.84 and 1.66  0.76 s, respectively (p < 0.001). Correlation analysis indicated that both manual and automated follicular area correlated better with follicular volume than diameter. The deep learning algorithm and the new biomarker of follicular area hold potential for clinical application of ultrasonic follicular monitoring.	187.76843371834426
2047.	Purpose of review Diabetic retinopathy is the most common specific complication of diabetes mellitus. Traditional care for patients with diabetes and diabetic retinopathy is fragmented, uncoordinated and delivered in a piecemeal nature, often in the most expensive and high-resource tertiary settings. Transformative new models incorporating digital technology are needed to address these gaps in clinical care. Recent findings Artificial intelligence and telehealth may improve access, financial sustainability and coverage of diabetic retinopathy screening programs. They enable risk stratifying patients based on individual risk of vision-threatening diabetic retinopathy including diabetic macular edema (DME), and predicting which patients with DME best respond to antivascular endothelial growth factor therapy. Progress in artificial intelligence and tele-ophthalmology for diabetic retinopathy screening, including artificial intelligence applications in 'real-world settings' and cost-effectiveness studies are summarized. Furthermore, the initial research on the use of artificial intelligence models for diabetic retinopathy risk stratification and management of DME are outlined along with potential future directions. Finally, the need for artificial intelligence adoption within ophthalmology in response to coronavirus disease 2019 is discussed. Digital health solutions such as artificial intelligence and telehealth can facilitate the integration of community, primary and specialist eye care services, optimize the flow of patients within healthcare networks, and improve the efficiency of diabetic retinopathy management.	187.763839346212
2048.	Objective Conventional risk stratification models for mortality of acute myocardial infarction (AMI) have potential limitations. This study aimed to develop and validate deep-learning-based risk stratification for the mortality of patients with AMI (DAMI). Methods The data of 22,875 AMI patients from the Korean working group of the myocardial infarction (KorMI) registry were exclusively divided into 12,152 derivation data of 36 hospitals and 10,723 validation data of 23 hospitals. The predictor variables were the initial demographic and laboratory data. The endpoints were in-hospital mortality and 12-months mortality. We compared the DAMI performance with the global registry of acute coronary event (GRACE) score, acute coronary treatment and intervention outcomes network (ACTION) score, and the thrombolysis in myocardial infarction (TIMI) score using the validation data. Results In-hospital mortality for the study subjects was 4.4% and 6-month mortality after survival upon discharge was 2.2%. The areas under the receiver operating characteristic curves (AUCs) of the DAMI were 0.905 [95% confidence interval 0.902-0.909] and 0.870 [0.8650.876] for the ST elevation myocardial infarction (STEMI) and non ST elevation myocardial infarction (NSTEMI) patients, respectively; these results significantly outperformed those of the GRACE (0.851 [0.846-0.856], 0.810 [0.803-0.819]), ACTION (0.852 [0.847-0.857], 0.806 [0.799-0.814] and TIMI score (0.781 [0.775-0.787], 0.593[0.585-0.603]). DAMI predicted 30.9% of patients more accurately than the GRACE score. As secondary outcome, during the 6-month follow-up, the high risk group, defined by the DAMI, has a significantly higher mortality rate than the low risk group (17.1% vs. 0.5%, p < 0.001). Conclusions The DAMI predicted in-hospital mortality and 12-month mortality of AMI patients more accurately than the existing risk scores and other machine-learning methods.	187.7603097008066
2049.	PURPOSE: To develop and evaluate a three-dimensional (3D) generative model of computed tomography (CT) images of lung nodules using a generative adversarial network (GAN). To guide the GAN, lung nodule size was used. MATERIALS AND METHODS: A public CT dataset of lung nodules was used, from where 1182 lung nodules were obtained. Our proposed GAN model used masked 3D CT images and nodule size information to generate images. To evaluate the generated CT images, two radiologists visually evaluated whether the CT images with lung nodule were true or generated, and the diagnostic ability was evaluated using receiver-operating characteristic analysis and area under the curves (AUC). Then, two models for classifying nodule size into five categories were trained, one using the true and the other using the generated CT images of lung nodules. Using true CT images, the classification accuracy of the sizes of the true lung nodules was calculated for the two classification models. RESULTS: The sensitivity, specificity, and AUC of the two radiologists were respectively as follows: radiologist 1: 81.3%, 37.7%, and 0.592; radiologist 2: 77.1%, 30.2%, and 0.597. For categorization of nodule size, the mean accuracy of the classification model constructed with true CT images was 85% (range 83.2-86.1%), and that with generated CT images was 85% (range 82.2-88.1%). CONCLUSIONS: Our results show that it was possible to generate 3D CT images of lung nodules that could be used to construct a classification model of lung nodule size without true CT images.	187.751570988837
2050.	Cells are faced with various stresses during their growth and development, and autophagy is a degradative process in which cells can break down their own components to recycle macromolecules and provide energy under these stresses. For pathogenic fungi that utilize cell wall as the first barrier against external stress, the cell wall integrity (CWI) pathway also provides an essential role in responding to these stresses. However, the specific connection between autophagy and CWI remains elusive in either the model fungi including budding yeast Saccharomyces cerevisiae or the rice blast fungus Magnaporthe oryzae. Here, we provided evidence that the endoplasmic reticulum (ER) stress is highly induced during M. oryzae infection and that CWI MAP kinase kinase MoMkk1 (S. cerevisiae Mkk1/2 homolog) was subject to phosphorylation regulation by MoAtg1, the only identified kinase in the core autophagy machinery. We also identified MoMkk1 serine 115 as the MoAtg1-dependent phosphorylation site and this phosphorylation could activate CWI, similar to that by the conserved MAP kinase kinase kinase MoMck1 (S. cerevisiae Bck1 homolog). Together with the first report of MoMkk1 subjects to phosphorylation regulation by MoAtg1, we revealed a new mechanism by which autophagy coordinates with CWI signaling under ER stress, and this MoAtg1-dependent MoMkk1 phosphorylation is essential for the pathogenicity of M. oryzae.	187.75034022975308
2051.	BACKGROUND: The Lombardy region suffered severely during the acute phase of the coronavirus diease 2019 outbreak in Italy (Mar-Apr 2020) with 16,000 diagnosed coronavirus disease 2019-related deaths (49% of the total coronavirus disease 2019-related deaths in Italy). In the area surrounding Pavia during the critical stage of the outbreak (Mar-Apr 2020), 1,225 of the documented 4,200 deaths were related to coronavirus disease 2019 infection, with a mortality rate of 181/100,000 inhabitants and an increase in deaths of 138% compared with the same period during previous years. Our aim was to report the experience of the Department of Vascular Surgery of Pavia (Lombardy, Italy), including the lessons learned and future perspectives regarding the management of coronavirus disease 2019 patients who developed severe acute ischemia with impending lower limb loss or deep vein thrombosis. MATERIALS AND METHODS: We carried out a retrospective data collection of coronavirus disease 2019 patients with severe acute ischemia of the lower limbs or deep vein thrombosis, which we observed in our department during the period March 1, 2020, to April 30, 2020. Primary outcomes of the analysis were postoperative mortality for all patients and amputation rates only in those coronavirus disease 2019 patients suffering from acute lower limb ischemia. Secondary outcomes were the prevalence of the disease among admitted coronavirus disease 2019 patients, and any possible correlation among inflammatory parameters, thrombolytic status, and the presence of acute ischemia or deep vein thrombosis. RESULTS: We observed 38 patients (28 male) with severe coronavirus disease 2019 infection (6 with lower limb arterial thrombosis and 32 with deep vein thrombosis). The median patient age was 64 years (range 30-94 y). In the arterial group, 3 had thrombosis on plaque and 3 on healthy arteries ("simple" arterial thrombosis). All underwent operative or hybrid (open/endo) revascularization; 1 patient died from major organ failure and 1 patient underwent major amputation. In the deep vein thrombosis group, 9 (28%) patients died from major organ failure, despite aggressive medical therapy. In patients with simple arterial thrombosis and those with deep vein thrombosis, we observed a decrease in inflammatory parameters (C-reactive protein) and in D-dimer and fibrinogen after aggressive therapy (P <.001). CONCLUSION: Our study confirms that critically ill, coronavirus disease 2019 patients who develop arterial and deep vein thrombosis have a high risk of mortality, but, if treated properly, there is an improvement in overall survival, especially in patients of 60 years of age or younger.	187.74120242763422
2052.	Question Does an artificial intelligence algorithm trained to detect pulmonary nodules improve lung cancer detection on chest radiographs? Findings In this diagnostic study of data from 5485 participants in the National Lung Screening Trial, the sensitivity and specificity of an artificial intelligence algorithm for nodule detection were 86% and 85%, respectively. When the same artificial intelligence algorithm was applied for cancer detection, the sensitivity was 94%, specificity 83%, positive predictive value 3%, and negative predictive value was 100% for the detection of malignant pulmonary nodules. Meaning The study findings suggest that an artificial intelligence algorithm trained to detect pulmonary nodules can help to improve lung cancer detection on chest radiographs. This diagnostic study uses data from participants in the National Lung Screening Trial to assess the performance of a deep learning-based nodule detection algorithm for the detection of lung cancer on chest radiographs. Importance The improvement of pulmonary nodule detection, which is a challenging task when using chest radiographs, may help to elevate the role of chest radiographs for the diagnosis of lung cancer. Objective To assess the performance of a deep learning-based nodule detection algorithm for the detection of lung cancer on chest radiographs from participants in the National Lung Screening Trial (NLST). Design, Setting, and Participants This diagnostic study used data from participants in the NLST ro assess the performance of a deep learning-based artificial intelligence (AI) algorithm for the detection of pulmonary nodules and lung cancer on chest radiographs using separate training (in-house) and validation (NLST) data sets. Baseline (T0) posteroanterior chest radiographs from 5485 participants (full T0 data set) were used to assess lung cancer detection performance, and a subset of 577 of these images (nodule data set) were used to assess nodule detection performance. Participants aged 55 to 74 years who currently or formerly (ie, quit within the past 15 years) smoked cigarettes for 30 pack-years or more were enrolled in the NLST at 23 US centers between August 2002 and April 2004. Information on lung cancer diagnoses was collected through December 31, 2009. Analyses were performed between August 20, 2019, and February 14, 2020. Exposures Abnormality scores produced by the AI algorithm. Main Outcomes and Measures The performance of an AI algorithm for the detection of lung nodules and lung cancer on radiographs, with lung cancer incidence and mortality as primary end points. Results A total of 5485 participants (mean [SD] age, 61.7 [5.0] years; 3030 men [55.2%]) were included, with a median follow-up duration of 6.5 years (interquartile range, 6.1-6.9 years). For the nodule data set, the sensitivity and specificity of the AI algorithm for the detection of pulmonary nodules were 86.2% (95% CI, 77.8%-94.6%) and 85.0% (95% CI, 81.9%-88.1%), respectively. For the detection of all cancers, the sensitivity was 75.0% (95% CI, 62.8%-87.2%), the specificity was 83.3% (95% CI, 82.3%-84.3%), the positive predictive value was 3.8% (95% CI, 2.6%-5.0%), and the negative predictive value was 99.8% (95% CI, 99.6%-99.9%). For the detection of malignant pulmonary nodules in all images of the full T0 data set, the sensitivity was 94.1% (95% CI, 86.2%-100.0%), the specificity was 83.3% (95% CI, 82.3%-84.3%), the positive predictive value was 3.4% (95% CI, 2.2%-4.5%), and the negative predictive value was 100.0% (95% CI, 99.9%-100.0%). In digital radiographs of the nodule data set, the AI algorithm had higher sensitivity (96.0% [95% CI, 88.3%-100.0%] vs 88.0% [95% CI, 75.3%-100.0%]; P = .32) and higher specificity (93.2% [95% CI, 89.9%-96.5%] vs 82.8% [95% CI, 77.8%-87.8%]; P = .001) for nodule detection compared with the NLST radiologists. For malignant pulmonary nodule detection on digital radiographs of the full T0 data set, the sensitivity of the AI algorithm was higher (100.0% [95% CI, 100.0%-100.0%] vs 94.1% [95% CI, 82.9%-100.0%]; P = .32) compared with the NLST radiologists, and the specificity (90.9% [95% CI, 89.6%-92.1%] vs 91.0% [95% CI, 89.7%-92.2%]; P = .91), positive predictive value (8.2% [95% CI, 4.4%-11.9%] vs 7.8% [95% CI, 4.1%-11.5%]; P = .65), and negative predictive value (100.0% [95% CI, 100.0%-100.0%] vs 99.9% [95% CI, 99.8%-100.0%]; P = .32) were similar to those of NLST radiologists. Conclusions and Relevance In this study, the AI algorithm performed better than NLST radiologists for the detection of pulmonary nodules on digital radiographs. When used as a second reader, the AI algorithm may help to detect lung cancer.	187.7356906045611
2053.	Excess exposure to fluoride causes substantive health burden in humans and livestock globally. However, few studies have assessed the distribution and controls of variability of ambient background concentrations of fluoride in soil. Ambient background concentrations of fluoride in soil were collated for Greater Melbourne, Greater Geelong, Ballarat and Mitchell in Victoria, Australia (n = 1005). Correlation analysis and machine learning techniques were used to identify environmental and anthropogenic influences of fluoride variability in soil. Sub-soils (>0.3 m deep), in some areas overlying siltstone and sandstone, and to a lesser extent, overlying basalt, were naturally enriched with fluoride at concentrations above ecological thresholds for grazing animals. Soil fluoride enrichment was predominantly influenced by parent material (mineralogy), precipitation (illuviation), leaching during palaeoclimates and marine inputs. Industrial air pollution did not significantly influence ambient background concentrations of fluoride at a regional scale. However, agricultural practices (potentially the use of phosphate fertilisers) were indicated to have resulted in added fluoride to surface soils overlying sediments. Geospatial variables alone were not sufficient to accurately model ambient background soil fluoride concentrations. A multiple regression model based on soil chemistry and parent material was shown to accurately predict ambient background fluoride concentrations in soils and support assessment of fluoride enrichment in the environment. (C) 2018 Elsevier Ltd. All rights reserved.	187.73398986057845
2054.	GPRC5B is a membrane glycoprotein robustly expressed in mouse cerebellar Purkinje cells (PCs). Its function is unknown. In Gprc5b(-/-) mice that lack GPRC5B, PCs develop distal axonal swellings in deep cerebellar nuclei (DCN). Numerous misshapen mitochondria, which generated excessive amounts of reactive oxygen species (ROS), accumulated in these distal axonal swellings. In primary cell cultures of Gprc5b-/- PCs, pharmacological reduction of ROS prevented the appearance of such swellings. To examine the physiological role of GPRC5B in PCs, we analyzed cerebellar synaptic transmission and cerebellum-dependent motor learning in Gprc5b-/- mice. Patch-clamp recordings in cerebellum slicesin vitro revealed that the induction of long-term depression (LTD) at parallel fiber-PC synapses was normal in adult Gprc5b-/- mice, whereas the induction of long-term potentiation (LTP) at mossy fiber-DCNneuron synapses was attenuated in juvenile Gprc5b-/- mice. In Gprc5b-/- mice, long-term motor learning was impaired in both the rotarod test and the horizontal optokinetic response eye movement (HOKR) test. These observations suggest that GPRC5B plays not only an important role in the development of distal axons of PCs and formation of synapses with DCN neurons, but also in the synaptic plasticity that underlies long-term motor learning. (c) 2018 Elsevier B.V. and Japan Neuroscience Society. All rights reserved.	187.7332145032675
2055.	OBJECTIVE: To evaluate the effect of resident involvement in thoracic endovascular aortic repair (TEVAR). SUMMARY OF BACKGROUND DATA: Although the influence of resident intraoperative involvement in several types of surgical procedures has been reported, the effect of resident participation in TEVAR is unknown. We evaluated patient outcomes in resident-involved TEVAR procedures. METHODS: The American College of Surgeons National Surgical Quality Improvement Program (ACS-NSQIP) database was analyzed for TEVAR performed from 2010 to 2012. Current procedural terminology codes were used to identify adult patients (>= 18 y) who underwent TEVAR. Patients were grouped into those with and without resident involvement. Descriptive and binomial logistic statistics were used to determine the effect of resident involvement on post-TEVAR outcomes. p values < 0.05 were considered statistically significant. RESULTS: A total of 676 patients met inclusion criteria for this study. Of these, 517 (76.5%) had residents involved. Overall mortality was 9.8%, with no significant difference between the 2 groups (p = 0.88). Resident involvement was not a significant predictor of any post-TEVAR complication. Postoperative pneumonia (3.5% vs 6.9%, p = 0.06), prolonged mechanical ventilation (11.8% vs 11.9%, p = 0.96), stroke (2.7% vs 5.7%, p = 0.07), urinary tract infection (3.3% vs 4.4%, p = 0.50), progressive renal insufficiency (1.2% vs 2.5%, p = 0.22), acute renal failure (4.1% vs 5.0%, p = 0.60), cardiac arrest (2.9% vs 5.0%, p = 0.20), myocardial infarction (1.7% vs 1.9%, p = 0.91), deep venous thrombosis (1.7% vs 1.3%, p = 0.67), red blood cells transfusions (29.2% vs 36.5%, p = 0.08), sepsis (2.9% vs 4.4%, p = 0.35), septic shock (1.9% vs 3.8%, p = 0.18), and unplanned reintubation (8.7% vs 9.4%, p = 0.78) were not significantly affected. Additionally, resident involvement did not significantly affect operative time (176.1 +/- 122.8 min vs 180.3 +/- 119.1 min, p = 0.71) and anesthesia time (282.1 +/- 146.6 min vs 278.3 +/- 140.5 min, p = 0.78). CONCLUSIONS: The participation of residents in TEVAR did not significantly affect all 30-day patient outcomes. Resident involvement in TEVAR is safe and should be encouraged. MINI ABSTRACT: This study evaluated the effect of resident participation on postoperative outcomes of thoracic endovascular aortic repair (TEVAR) using the American College of Surgeons National Surgical Quality Improvement (ACS-NSQIP) database. Results showed that resident involvement in TEVAR does not negatively affect patient outcomes. ((C) 2018 Published by Elsevier Inc. on behalf of Association of Program Directors in Surgery.)	187.6979970712535
2056.	Objective: To explore the application value of cardiovascular extraction technique in the complex and/or complex malformation of congenital heart disease (CHD) and the application of deep learning to the diagnosis of medical imaging. Methods: Quantitative description of cardiovascular lesions and reconstruction of three-dimensional cardiovascular using angiographic images, the cardiovascular representation of the contrast image as a single pixel wide cardiovascular skeleton, using a rotating Gaussian function to enhance the image, using adaptive tracking circular template pair Enhanced cardiovascular images for cardiovascular extraction. The 360 cases of complex and/or complex malformation were analyzed and their association with clinical examinations such as echocardiography. Results: This group of 360 patients (including 75 cases of pulmonary atresia with ventricular septal defect, 62 cases of right ventricular double exit, 60 cases of tetralogy of Fallot, 52 cases of single ventricle, 42 cases of aortic dislocation, 15 cases of tricuspid atresia, 6 cases of coronary artery Abnormalities, 5 cases of complete pulmonary venous malformation, 5 cases of complete endocardial pad defect, 4 cases of common arterial trunk, 3 cases of interventricular complete pulmonary atresia, 7 cases of other cases and 24 cases of postoperative examination) angiography. Compared with ultrasound, the latter was corrected in 34 cases, missed diagnosis in 30 cases, and misdiagnosis in 16 cases of combined malformation. The detection and diagnosis of collateral vessels, coronary artery malformations and branches of pulmonary arteries and their abnormalities in complex and/or complex malformations are superior to echocardiography, and can measure pulmonary arterial and venous pressures and collateral vessel pressure It is superior to other imaging methods. Conclusions: Cardiac angiography (DSA) is still important for the diagnosis and differential diagnosis of difficult cases of congenital heart disease complex and/or complex malformation, especially showing the whole appearance and related lesions of the body, lung and coronary branches, as well as measuring pulmonary artery and ventricular pressure.	187.6972514932133
2057.	Purpose: To evaluate functional and anatomical outcome in patients undergoing deep anterior lamellar keratoplasty (DALK) with intraoperative Descemet's membrane (DM) perforation (macro and micro). Methods: A retrospective cross sectional study (January 2009 to December 2015) of sixteen eyes of sixteen patients which included nine patients of advanced keratoconus (KC), two patients with paracentral DM scarring post hydrops, KC with Bowman's membrane scarring, macular corneal dystrophy and one patient of advanced Pellucid Marginal Degeneration (PMD). All underwent DALK with intraoperative DM perforation. Big bubble technique was attempted in all except in the two patients with post hydrops DM scar. Preoperative and postoperative best corrected visual acuity (BCVA), astigmatism and endothelial count (EC) were compared. Results: Postoperative BCVA and astigmatism were found to be better and statistically significant (` p value' 0.00 and 0.003 respectively). BCVA preoperative and postoperative was 1.07 +/- 0.3 and 0.28 +/- 0.09 in LogMAR respectively and astigmatism pre and postoperative 4.14 +/- 1.5 D and 2.7 +/- 0.97 D respectively. Percentage decrease in EC at sixth postoperative week was 7.48% and at sixth month and 1 year postoperative was 15.1%. Two patients developed postoperative double anterior chamber and two patients developed pupillary block glaucoma and all were successfully managed. Conclusion: Not all patients of intraoperative DM perforation (including macro perforation) needs to be converted to penetrating keratoplasty. DALK can be successfully done if the perforation is identified early and managed adequately. This is the only known study which has shown a large series of successful DALK even with macro perforations.	187.6680561135126
2058.	ADAD AD MCI AD HCMCI  MCI  AD MCI  AD MRI AD CNN AD  CNN  MRI .	187.34430431295283
2059.	  .	-99999
2060.	   .	-99999
